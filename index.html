<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title> anzhen.tech</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css"
      />
      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
       
 
<script>
var _hmt = _hmt || [];
(function() {
	var hm = document.createElement("script");
	hm.src = "https://hm.baidu.com/hm.js?20878462c8c8a6915b11b2d93a956d26";
	var s = document.getElementsByTagName("script")[0]; 
	s.parentNode.insertBefore(hm, s);
})();
</script>


      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
      <meta name="baidu-site-verification" content="code-mBRwXRLQqk" />
      <meta name="google-site-verification" content="bqavzWFaou2XjWPiLJI2ZoQwSGDVv_wZFPMkWKjEAz0" />
      
    <link rel="alternate" href="/atom.xml" title="anzhen.tech" type="application/atom+xml">
</head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      
<section class="cover">
    
      
      <a class="forkMe" href="https://gitee.com/anzhen-tech"
        target="_blank"><img width="149" height="149" src="/images/forkme.png"
          class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="/images/cover1.jpg" alt="image frame" />
    </div>
    <div class="cover-inner text-center text-white">
      <h1><a href="/">anzhen.tech</a></h1>
      <div id="subtitle-box">
        
        <span id="subtitle"></span>
        
      </div>
      <div>
        
        <img
          src="/images/ayer.svg"
          class="cover-logo"
          alt="anzhen.tech"
        />
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>



<script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js"></script>


<!-- Subtitle -->

  <script>
    try {
      var typed = new Typed("#subtitle", {
        strings: ['越努力，越美好', '愿你一生努力，一生被爱', '想要的都拥有，得不到的都释怀'],
        startDelay: 0,
        typeSpeed: 200,
        loop: true,
        backSpeed: 100,
        showCursor: true
      });
    } catch (err) {
      console.log(err)
    }
  </script>
  
<div id="main">
  <section class="outer">
  
  <ul class="ads">
    
        <li>
            <a target="_blank" rel="noopener" href="https://www.aliyun.com/minisite/goods?userCode=e6rdw2zn&amp;share_source=copy_link">
                <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/WX20211107-102324@2x.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10" width="300" alt="阿里云服务器">
            </a>
        </li>
    
</ul>
  
  
  

<div class="notice" style="margin-top:50px">
    <i class="ri-heart-fill"></i>
    <div class="notice-content" id="broad"></div>
</div>
<script type="text/javascript">
    fetch('https://v1.hitokoto.cn')
        .then(response => response.json())
        .then(data => {
            document.getElementById("broad").innerHTML = data.hitokoto;
        })
        .catch(console.error)
</script>

<style>
    .notice {
        padding: 20px;
        border: 1px dashed #e6e6e6;
        color: #969696;
        position: relative;
        display: inline-block;
        width: 100%;
        background: #fbfbfb50;
        border-radius: 10px;
    }

    .notice i {
        float: left;
        color: #999;
        font-size: 16px;
        padding-right: 10px;
        vertical-align: middle;
        margin-top: -2px;
    }

    .notice-content {
        display: initial;
        vertical-align: middle;
    }
</style>
  
  <article class="articles">
    
    
    
    
    <article
  id="post-Docker"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/04/24/Docker/"
    >Docker</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/04/24/Docker/" class="article-date">
  <time datetime="2022-04-24T12:13:22.000Z" itemprop="datePublished">2022-04-24</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%AE%B9%E5%99%A8/">容器</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h1><!-- GFM-TOC -->
<ul>
<li><a href="#docker">Docker</a><ul>
<li><a href="#%E4%B8%80%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98">一、解决的问题</a></li>
<li><a href="#%E4%BA%8C%E4%B8%8E%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E6%AF%94%E8%BE%83">二、与虚拟机的比较</a><ul>
<li><a href="#%E5%90%AF%E5%8A%A8%E9%80%9F%E5%BA%A6">启动速度</a></li>
<li><a href="#%E5%8D%A0%E7%94%A8%E8%B5%84%E6%BA%90">占用资源</a></li>
</ul>
</li>
<li><a href="#%E4%B8%89%E4%BC%98%E5%8A%BF">三、优势</a><ul>
<li><a href="#%E6%9B%B4%E5%AE%B9%E6%98%93%E8%BF%81%E7%A7%BB">更容易迁移</a></li>
<li><a href="#%E6%9B%B4%E5%AE%B9%E6%98%93%E7%BB%B4%E6%8A%A4">更容易维护</a></li>
<li><a href="#%E6%9B%B4%E5%AE%B9%E6%98%93%E6%89%A9%E5%B1%95">更容易扩展</a></li>
</ul>
</li>
<li><a href="#%E5%9B%9B%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF">四、使用场景</a><ul>
<li><a href="#%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90">持续集成</a></li>
<li><a href="#%E6%8F%90%E4%BE%9B%E5%8F%AF%E4%BC%B8%E7%BC%A9%E7%9A%84%E4%BA%91%E6%9C%8D%E5%8A%A1">提供可伸缩的云服务</a></li>
<li><a href="#%E6%90%AD%E5%BB%BA%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84">搭建微服务架构</a></li>
</ul>
</li>
<li><a href="#%E4%BA%94%E9%95%9C%E5%83%8F%E4%B8%8E%E5%AE%B9%E5%99%A8">五、镜像与容器</a></li>
<li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a><!-- GFM-TOC --></li>
</ul>
</li>
</ul>
<h2 id="一、解决的问题"><a href="#一、解决的问题" class="headerlink" title="一、解决的问题"></a>一、解决的问题</h2><p>由于不同的机器有不同的操作系统，以及不同的库和组件，在将一个应用部署到多台机器上需要进行大量的环境配置操作。</p>
<p>Docker 主要解决环境配置问题，它是一种虚拟化技术，对进程进行隔离，被隔离的进程独立于宿主操作系统和其它隔离的进程。使用 Docker 可以不修改应用程序代码，不需要开发人员学习特定环境下的技术，就能够将现有的应用程序部署在其它机器上。</p>
<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/011f3ef6-d824-4d43-8b2c-36dab8eaaa72-1.png" width="400px"/> </div><br>

<h2 id="二、与虚拟机的比较"><a href="#二、与虚拟机的比较" class="headerlink" title="二、与虚拟机的比较"></a>二、与虚拟机的比较</h2><p>虚拟机也是一种虚拟化技术，它与 Docker 最大的区别在于它是通过模拟硬件，并在硬件上安装操作系统来实现。</p>
<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/be608a77-7b7f-4f8e-87cc-f2237270bf69.png" width="500"/> </div><br>

<h3 id="启动速度"><a href="#启动速度" class="headerlink" title="启动速度"></a>启动速度</h3><p>启动虚拟机需要先启动虚拟机的操作系统，再启动应用，这个过程非常慢；</p>
<p>而启动 Docker 相当于启动宿主操作系统上的一个进程。</p>
<h3 id="占用资源"><a href="#占用资源" class="headerlink" title="占用资源"></a>占用资源</h3><p>虚拟机是一个完整的操作系统，需要占用大量的磁盘、内存和 CPU 资源，一台机器只能开启几十个的虚拟机。</p>
<p>而 Docker 只是一个进程，只需要将应用以及相关的组件打包，在运行时占用很少的资源，一台机器可以开启成千上万个 Docker。</p>
<h2 id="三、优势"><a href="#三、优势" class="headerlink" title="三、优势"></a>三、优势</h2><p>除了启动速度快以及占用资源少之外，Docker 具有以下优势：</p>
<h3 id="更容易迁移"><a href="#更容易迁移" class="headerlink" title="更容易迁移"></a>更容易迁移</h3><p>提供一致性的运行环境。已经打包好的应用可以在不同的机器上进行迁移，而不用担心环境变化导致无法运行。</p>
<h3 id="更容易维护"><a href="#更容易维护" class="headerlink" title="更容易维护"></a>更容易维护</h3><p>使用分层技术和镜像，使得应用可以更容易复用重复的部分。复用程度越高，维护工作也越容易。</p>
<h3 id="更容易扩展"><a href="#更容易扩展" class="headerlink" title="更容易扩展"></a>更容易扩展</h3><p>可以使用基础镜像进一步扩展得到新的镜像，并且官方和开源社区提供了大量的镜像，通过扩展这些镜像可以非常容易得到我们想要的镜像。</p>
<h2 id="四、使用场景"><a href="#四、使用场景" class="headerlink" title="四、使用场景"></a>四、使用场景</h2><h3 id="持续集成"><a href="#持续集成" class="headerlink" title="持续集成"></a>持续集成</h3><p>持续集成指的是频繁地将代码集成到主干上，这样能够更快地发现错误。</p>
<p>Docker 具有轻量级以及隔离性的特点，在将代码集成到一个 Docker 中不会对其它 Docker 产生影响。</p>
<h3 id="提供可伸缩的云服务"><a href="#提供可伸缩的云服务" class="headerlink" title="提供可伸缩的云服务"></a>提供可伸缩的云服务</h3><p>根据应用的负载情况，可以很容易地增加或者减少 Docker。</p>
<h3 id="搭建微服务架构"><a href="#搭建微服务架构" class="headerlink" title="搭建微服务架构"></a>搭建微服务架构</h3><p>Docker 轻量级的特点使得它很适合用于部署、维护、组合微服务。</p>
<h2 id="五、镜像与容器"><a href="#五、镜像与容器" class="headerlink" title="五、镜像与容器"></a>五、镜像与容器</h2><p>镜像是一种静态的结构，可以看成面向对象里面的类，而容器是镜像的一个实例。</p>
<p>镜像包含着容器运行时所需要的代码以及其它组件，它是一种分层结构，每一层都是只读的（read-only layers）。构建镜像时，会一层一层构建，前一层是后一层的基础。镜像的这种分层存储结构很适合镜像的复用以及定制。</p>
<p>构建容器时，通过在镜像的基础上添加一个可写层（writable layer），用来保存着容器运行过程中的修改。</p>
<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/docker-filesystems-busyboxrw.png"/> </div><br>

<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://blog.docker.com/2017/08/docker-101-introduction-docker-webinar-recap/">DOCKER 101: INTRODUCTION TO DOCKER WEBINAR RECAP</a></li>
<li><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html">Docker 入门教程</a></li>
<li><a target="_blank" rel="noopener" href="http://www.bogotobogo.com/DevOps/Docker/Docker_Container_vs_Virtual_Machine.php">Docker container vs Virtual machine</a></li>
<li><a target="_blank" rel="noopener" href="https://linoxide.com/linux-how-to/dockerfile-create-docker-container/">How to Create Docker Container using Dockerfile</a></li>
<li><a target="_blank" rel="noopener" href="http://www.cnblogs.com/sammyliu/p/5877964.html">理解 Docker（2）：Docker 镜像</a></li>
<li><a target="_blank" rel="noopener" href="https://yeasy.gitbooks.io/docker_practice/introduction/why.html">为什么要使用 Docker？</a></li>
<li><a target="_blank" rel="noopener" href="https://www.docker.com/what-docker">What is Docker</a></li>
<li><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blog/2015/09/continuous-integration.html">持续集成是什么？</a></li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/" rel="tag">微服务</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8/" rel="tag">面试宝典</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-什么是微服务"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/04/24/%E4%BB%80%E4%B9%88%E6%98%AF%E5%BE%AE%E6%9C%8D%E5%8A%A1/"
    >什么是微服务</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/04/24/%E4%BB%80%E4%B9%88%E6%98%AF%E5%BE%AE%E6%9C%8D%E5%8A%A1/" class="article-date">
  <time datetime="2022-04-24T11:55:17.000Z" itemprop="datePublished">2022-04-24</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/">微服务</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <blockquote>
<p>摘要: 原创出处 <a target="_blank" rel="noopener" href="https://blog.csdn.net/wuxiaobingandbob/article/details/78642020">https://blog.csdn.net/wuxiaobingandbob/article/details/78642020</a> 「武晓兵」欢迎转载，保留摘要，谢谢！</p>
</blockquote>
<p>[TOC]</p>
<h1 id="一、微服务介绍"><a href="#一、微服务介绍" class="headerlink" title="一、微服务介绍"></a>一、微服务介绍</h1><h2 id="1-什么是微服务"><a href="#1-什么是微服务" class="headerlink" title="1. 什么是微服务"></a>1. 什么是微服务</h2><ul>
<li>在介绍微服务时，首先得先理解什么是微服务，顾名思义，微服务得从两个方面去理解，什么是”微”、什么是”服务”， 微 狭义来讲就是体积小、著名的”2 pizza 团队”很好的诠释了这一解释（2 pizza 团队最早是亚马逊 CEO Bezos提出来的，意思是说单个服务的设计，所有参与人从设计、开发、测试、运维所有人加起来 只需要2个披萨就够了 ）。 而所谓服务，一定要区别于系统，服务一个或者一组相对较小且独立的功能单元，是用户可以感知最小功能集。</li>
</ul>
<h2 id="2-微服务由来"><a href="#2-微服务由来" class="headerlink" title="2. 微服务由来"></a>2. 微服务由来</h2><ul>
<li>微服务最早由Martin Fowler与James Lewis于2014年共同提出，微服务架构风格是一种使用一套小服务来开发单个应用的方式途径，每个服务运行在自己的进程中，并使用轻量级机制通信，通常是HTTP API，这些服务基于业务能力构建，并能够通过自动化部署机制来独立部署，这些服务使用不同的编程语言实现，以及不同数据存储技术，并保持最低限度的集中式管理。</li>
</ul>
<h2 id="3-为什么需要微服务？"><a href="#3-为什么需要微服务？" class="headerlink" title="3. 为什么需要微服务？"></a>3. 为什么需要微服务？</h2><ul>
<li>在传统的IT行业软件大多都是各种独立系统的堆砌，这些系统的问题总结来说就是扩展性差，可靠性不高，维护成本高。到后面引入了SOA服务化，但是，由于 SOA 早期均使用了总线模式，这种总线模式是与某种技术栈强绑定的，比如：J2EE。这导致很多企业的遗留系统很难对接，切换时间太长，成本太高，新系统稳定性的收敛也需要一些时间。最终 SOA 看起来很美，但却成为了企业级奢侈品，中小公司都望而生畏。</li>
</ul>
<h3 id="3-1-最期的单体架构带来的问题"><a href="#3-1-最期的单体架构带来的问题" class="headerlink" title="3.1 最期的单体架构带来的问题"></a>3.1 最期的单体架构带来的问题</h3><p>单体架构在规模比较小的情况下工作情况良好，但是随着系统规模的扩大，它暴露出来的问题也越来越多，主要有以下几点：</p>
<ol>
<li>复杂性逐渐变高<br> 比如有的项目有几十万行代码，各个模块之间区别比较模糊，逻辑比较混乱，代码越多复杂性越高，越难解决遇到的问题。</li>
<li>技术债务逐渐上升<br> 公司的人员流动是再正常不过的事情，有的员工在离职之前，疏于代码质量的自我管束，导致留下来很多坑，由于单体项目代码量庞大的惊人，留下的坑很难被发觉，这就给新来的员工带来很大的烦恼，人员流动越大所留下的坑越多，也就是所谓的技术债务越来越多。</li>
<li>部署速度逐渐变慢<br> 这个就很好理解了，单体架构模块非常多，代码量非常庞大，导致部署项目所花费的时间越来越多，曾经有的项目启动就要一二十分钟，这是多么恐怖的事情啊，启动几次项目一天的时间就过去了，留给开发者开发的时间就非常少了。</li>
<li>阻碍技术创新<br> 比如以前的某个项目使用struts2写的，由于各个模块之间有着千丝万缕的联系，代码量大，逻辑不够清楚，如果现在想用spring mvc来重构这个项目将是非常困难的，付出的成本将非常大，所以更多的时候公司不得不硬着头皮继续使用老的struts架构，这就阻碍了技术的创新。</li>
<li>无法按需伸缩<br> 比如说电影模块是CPU密集型的模块，而订单模块是IO密集型的模块，假如我们要提升订单模块的性能，比如加大内存、增加硬盘，但是由于所有的模块都在一个架构下，因此我们在扩展订单模块的性能时不得不考虑其它模块的因素，因为我们不能因为扩展某个模块的性能而损害其它模块的性能，从而无法按需进行伸缩。<h3 id="3-2-微服务与单体架构区别"><a href="#3-2-微服务与单体架构区别" class="headerlink" title="3.2 微服务与单体架构区别"></a>3.2 微服务与单体架构区别</h3></li>
<li>单体架构所有的模块全都耦合在一块，代码量大，维护困难，微服务每个模块就相当于一个单独的项目，代码量明显减少，遇到问题也相对来说比较好解决。</li>
<li>单体架构所有的模块都共用一个数据库，存储方式比较单一，微服务每个模块都可以使用不同的存储方式（比如有的用redis，有的用mysql等），数据库也是单个模块对应自己的数据库。</li>
<li>单体架构所有的模块开发所使用的技术一样，微服务每个模块都可以使用不同的开发技术，开发模式更灵活。<br><img src="https://s2.loli.net/2022/04/24/Bia5f6csAu3DVPk.jpg"></li>
</ol>
<h3 id="3-3-微服务与SOA区别"><a href="#3-3-微服务与SOA区别" class="headerlink" title="3.3 微服务与SOA区别"></a>3.3 微服务与SOA区别</h3><p>微服务，从本质意义上看，还是 SOA 架构。但内涵有所不同，微服务并不绑定某种特殊的技术，在一个微服务的系统中，可以有 Java 编写的服务，也可以有 Python编写的服务，他们是靠Restful架构风格统一成一个系统的。所以微服务本身与具体技术实现无关，扩展性强。</p>
<h2 id="4-微服务本质"><a href="#4-微服务本质" class="headerlink" title="4. 微服务本质"></a>4. 微服务本质</h2><ol>
<li>微服务，关键其实不仅仅是微服务本身，而是系统要提供一套基础的架构，这种架构使得微服务可以独立的部署、运行、升级，不仅如此，这个系统架构还让微服务与微服务之间在结构上“松耦合”，而在功能上则表现为一个统一的整体。这种所谓的“统一的整体”表现出来的是统一风格的界面，统一的权限管理，统一的安全策略，统一的上线过程，统一的日志和审计方法，统一的调度方式，统一的访问入口等等。</li>
<li>微服务的目的是有效的拆分应用，实现敏捷开发和部署 。</li>
<li>微服务提倡的理念团队间应该是 inter-operate, not integrate 。inter-operate是定义好系统的边界和接口，在一个团队内全栈，让团队自治，原因就是因为如果团队按照这样的方式组建，将沟通的成本维持在系统内部，每个子系统就会更加内聚，彼此的依赖耦合能变弱，跨系统的沟通成本也就能降低。</li>
</ol>
<h2 id="5-什么样的项目适合微服务"><a href="#5-什么样的项目适合微服务" class="headerlink" title="5. 什么样的项目适合微服务"></a>5. 什么样的项目适合微服务</h2><p>微服务可以按照业务功能本身的独立性来划分，如果系统提供的业务是非常底层的，如：操作系统内核、存储系统、网络系统、数据库系统等等，这类系统都偏底层，功能和功能之间有着紧密的配合关系，如果强制拆分为较小的服务单元，会让集成工作量急剧上升，并且这种人为的切割无法带来业务上的真正的隔离，所以无法做到独立部署和运行，也就不适合做成微服务了。<br>能不能做成微服务，取决于四个要素：</p>
<ul>
<li>小：微服务体积小，2 pizza 团队。</li>
<li>独：能够独立的部署和运行。</li>
<li>轻：使用轻量级的通信机制和架构。</li>
<li>松：为服务之间是松耦合的。</li>
</ul>
<h2 id="6-微服务折分与设计"><a href="#6-微服务折分与设计" class="headerlink" title="6. 微服务折分与设计"></a>6. 微服务折分与设计</h2><ol>
<li>从单体式结构转向微服务架构中会持续碰到服务边界划分的问题：比如，我们有user 服务来提供用户的基础信息，那么用户的头像和图片等是应该单独划分为一个新的service更好还是应该合并到user服务里呢？如果服务的粒度划分的过粗，那就回到了单体式的老路；如果过细，那服务间调用的开销就变得不可忽视了，管理难度也会指数级增加。目前为止还没有一个可以称之为服务边界划分的标准，只能根据不同的业务系统加以调节</li>
<li>拆分的大原则是当一块业务不依赖或极少依赖其它服务，有独立的业务语义，为超过2个的其他服务或客户端提供数据，那么它就应该被拆分成一个独立的服务模块。</li>
</ol>
<h3 id="6-1-微服务设计原则"><a href="#6-1-微服务设计原则" class="headerlink" title="6.1 微服务设计原则"></a>6.1 微服务设计原则</h3><ul>
<li>单一职责原则<ul>
<li>意思是每个微服务只需要实现自己的业务逻辑就可以了，比如订单管理模块，它只需要处理订单的业务逻辑就可以了，其它的不必考虑。</li>
</ul>
</li>
<li>服务自治原则<ul>
<li>意思是每个微服务从开发、测试、运维等都是独立的，包括存储的数据库也都是独立的，自己就有一套完整的流程，我们完全可以把它当成一个项目来对待。不必依赖于其它模块。</li>
</ul>
</li>
<li>轻量级通信原则<ul>
<li>首先是通信的语言非常的轻量，第二，该通信方式需要是跨语言、跨平台的，之所以要跨平台、跨语言就是为了让每个微服务都有足够的独立性，可以不受技术的钳制。</li>
</ul>
</li>
<li>接口明确原则<ul>
<li>由于微服务之间可能存在着调用关系，为了尽量避免以后由于某个微服务的接口变化而导致其它微服务都做调整，在设计之初就要考虑到所有情况，让接口尽量做的更通用，更灵活，从而尽量避免其它模块也做调整。</li>
</ul>
</li>
</ul>
<h2 id="7-微服务优势与缺点"><a href="#7-微服务优势与缺点" class="headerlink" title="7. 微服务优势与缺点"></a>7. 微服务优势与缺点</h2><h2 id="7-1-特性"><a href="#7-1-特性" class="headerlink" title="7.1 特性"></a>7.1 特性</h2><ol>
<li>每个微服务可独立运行在自己的进程里；</li>
<li>一系列独立运行的微服务共同构建起了整个系统；</li>
<li>每个服务为独立的业务开发，一个微服务一般完成某个特定的功能，比如：订单管理，用户管理等；</li>
<li>微服务之间通过一些轻量级的通信机制进行通信，例如通过REST API或者RPC的方式进行调用。</li>
</ol>
<h2 id="7-2-特点"><a href="#7-2-特点" class="headerlink" title="7.2 特点"></a>7.2 特点</h2><ul>
<li>易于开发和维护<br>  由于微服务单个模块就相当于一个项目，开发这个模块我们就只需关心这个模块的逻辑即可，代码量和逻辑复杂度都会降低，从而易于开发和维护。</li>
<li>启动较快<br>  这是相对单个微服务来讲的，相比于启动单体架构的整个项目，启动某个模块的服务速度明显是要快很多的。</li>
<li>局部修改容易部署<br>  在开发中发现了一个问题，如果是单体架构的话，我们就需要重新发布并启动整个项目，非常耗时间，但是微服务则不同，哪个模块出现了bug我们只需要解决那个模块的bug就可以了，解决完bug之后，我们只需要重启这个模块的服务即可，部署相对简单，不必重启整个项目从而大大节约时间。</li>
<li>技术栈不受限<br>  比如订单微服务和电影微服务原来都是用java写的，现在我们想把电影微服务改成nodeJs技术，这是完全可以的，而且由于所关注的只是电影的逻辑而已，因此技术更换的成本也就会少很多。</li>
<li>按需伸缩<br>  我们上面说了单体架构在想扩展某个模块的性能时不得不考虑到其它模块的性能会不会受影响，对于我们微服务来讲，完全不是问题，电影模块通过什么方式来提升性能不必考虑其它模块的情况。</li>
</ul>
<h2 id="7-3-缺点"><a href="#7-3-缺点" class="headerlink" title="7.3 缺点"></a>7.3 缺点</h2><ul>
<li>运维要求较高<br>  对于单体架构来讲，我们只需要维护好这一个项目就可以了，但是对于微服务架构来讲，由于项目是由多个微服务构成的，每个模块出现问题都会造成整个项目运行出现异常，想要知道是哪个模块造成的问题往往是不容易的，因为我们无法一步一步通过debug的方式来跟踪，这就对运维人员提出了很高的要求。</li>
<li>分布式的复杂性<br>  对于单体架构来讲，我们可以不使用分布式，但是对于微服务架构来说，分布式几乎是必会用的技术，由于分布式本身的复杂性，导致微服务架构也变得复杂起来。</li>
<li>接口调整成本高<br>  比如，用户微服务是要被订单微服务和电影微服务所调用的，一旦用户微服务的接口发生大的变动，那么所有依赖它的微服务都要做相应的调整，由于微服务可能非常多，那么调整接口所造成的成本将会明显提高。</li>
<li>重复劳动<br>  对于单体架构来讲，如果某段业务被多个模块所共同使用，我们便可以抽象成一个工具类，被所有模块直接调用，但是微服务却无法这样做，因为这个微服务的工具类是不能被其它微服务所直接调用的，从而我们便不得不在每个微服务上都建这么一个工具类，从而导致代码的重复。</li>
</ul>
<h2 id="8-微服务开发框架"><a href="#8-微服务开发框架" class="headerlink" title="8. 微服务开发框架"></a>8. 微服务开发框架</h2><p>目前微服务的开发框架，最常用的有以下四个：</p>
<ol>
<li>Spring Cloud：<a target="_blank" rel="noopener" href="http://projects.spring.io/spring-cloud%EF%BC%88%E7%8E%B0%E5%9C%A8%E9%9D%9E%E5%B8%B8%E6%B5%81%E8%A1%8C%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%EF%BC%89">http://projects.spring.io/spring-cloud（现在非常流行的微服务架构）</a></li>
<li>Dubbo：http：//dubbo.io</li>
<li>Dropwizard：<a target="_blank" rel="noopener" href="http://www.dropwizard.io/">http://www.dropwizard.io</a> （关注单个微服务的开发）</li>
<li>Consul、etcd&amp;etc.（微服务的模块）</li>
</ol>
<h2 id="9-Sprint-cloud-和-Sprint-boot区别"><a href="#9-Sprint-cloud-和-Sprint-boot区别" class="headerlink" title="9. Sprint cloud 和 Sprint boot区别"></a>9. Sprint cloud 和 Sprint boot区别</h2><ul>
<li>Spring Boot:<br>  旨在简化创建产品级的Spring应用和服务，简化了配置文件，使用嵌入式web服务器，含有诸多开箱即用微服务功能，可以和spring cloud联合部署。</li>
<li>Spring Cloud：<br>  微服务工具包，为开发者提供了在分布式系统的配置管理、服务发现、断路器、智能路由、微代理、控制总线等开发工具包。</li>
</ul>
<h1 id="二、微服务实践先知"><a href="#二、微服务实践先知" class="headerlink" title="二、微服务实践先知"></a>二、微服务实践先知</h1><ol>
<li>客户端如何访问这些服务？（API Gateway）<br> 传统的开发方式，所有的服务都是本地的，UI可以直接调用，现在按功能拆分成独立的服务，跑在独立的一般都在独立的虚拟机上的 Java进程了。客户端UI如何访问他的？后台有N个服务，前台就需要记住管理N个服务，一个服务下线/更新/升级，前台就要重新部署，这明显不服务我们 拆分的理念，特别当前台是移动应用的时候，通常业务变化的节奏更快。另外，N个小服务的调用也是一个不小的网络开销。还有一般微服务在系统内部，通常是无状态的，用户登录信息和权限管理最好有一个统一的地方维护管理（OAuth）。<br> 所以，一般在后台N个服务和UI之间一般会一个代理或者叫API Gateway，他的作用包括<ul>
<li>提供统一服务入口，让微服务对前台透明</li>
<li>聚合后台的服务，节省流量，提升性能</li>
<li>提供安全，过滤，流控等API管理功能</li>
<li>我的理解其实这个API Gateway可以有很多广义的实现办法，可以是一个软硬一体的盒子，也可以是一个简单的MVC框架，甚至是一个Node.js的服务端。他们最重要的作用是为前台（通常是移动应用）提供后台服务的聚合，提供一个统一的服务出口，解除他们之间的耦合，不过API Gateway也有可能成为单点故障点或者性能的瓶颈。<br><img src="https://s2.loli.net/2022/04/24/G9xJ5zelBuQ4pba.jpg"></li>
</ul>
</li>
</ol>
<ol start="2">
<li><p>服务之间如何通信？（服务调用）</p>
<ul>
<li><p>因为所有的微服务都是独立的Java进程跑在独立的虚拟机上，所以服务间的通行就是IPC（inter process communication），已经有很多成熟的方案。现在基本最通用的有两种方式。这几种方式，展开来讲都可以写本书，而且大家一般都比较熟悉细节了， 就不展开讲了。</p>
<ul>
<li>REST（JAX-RS，Spring Boot）</li>
<li>RPC（Thrift, Dubbo）</li>
<li>异步消息调用(Kafka, Notify)<br><img src="https://s2.loli.net/2022/04/24/B6C7fkb1KFGhdwj.jpg"></li>
</ul>
</li>
<li><p>一般同步调用比较简单，一致性强，但是容易出调用问题，性能体验上也会差些，特别是调用层次多的时候。RESTful和RPC的比较也是一个很有意 思的话题。一般REST基于HTTP，更容易实现，更容易被接受，服务端实现技术也更灵活些，各个语言都能支持，同时能跨客户端，对客户端没有特殊的要 求，只要封装了HTTP的SDK就能调用，所以相对使用的广一些。RPC也有自己的优点，传输协议更高效，安全更可控，特别在一个公司内部，如果有统一个的开发规范和统一的服务框架时，他的开发效率优势更明显些。就看各自的技术积累实际条件，自己的选择了。</p>
</li>
<li><p>而异步消息的方式在分布式系统中有特别广泛的应用，他既能减低调用服务之间的耦合，又能成为调用之间的缓冲，确保消息积压不会冲垮被调用方，同时能 保证调用方的服务体验，继续干自己该干的活，不至于被后台性能拖慢。不过需要付出的代价是一致性的减弱，需要接受数据最终一致性；还有就是后台服务一般要 实现幂等性，因为消息发送出于性能的考虑一般会有重复（保证消息的被收到且仅收到一次对性能是很大的考验）；最后就是必须引入一个独立的broker，如 果公司内部没有技术积累，对broker分布式管理也是一个很大的挑战。</p>
</li>
</ul>
</li>
</ol>
<h2 id="3-这么多服务怎么查找？（服务发现）"><a href="#3-这么多服务怎么查找？（服务发现）" class="headerlink" title="3. 这么多服务怎么查找？（服务发现）"></a>3. 这么多服务怎么查找？（服务发现）</h2><p>​在微服务架构中，一般每一个服务都是有多个拷贝，来做负载均衡。一个服务随时可能下线，也可能应对临时访问压力增加新的服务节点。服务之间如何相互 感知？服务如何管理？这就是服务发现的问题了。一般有两类做法，也各有优缺点。基本都是通过zookeeper等类似技术做服务注册信息的分布式管理。当 服务上线时，服务提供者将自己的服务信息注册到ZK（或类似框架），并通过心跳维持长链接，实时更新链接信息。服务调用者通过ZK寻址，根据可定制算法，找到一个服务，还可以将服务信息缓存在本地以提高性能。当服务下线时，ZK会发通知给服务客户端。</p>
<ul>
<li>客户端做：**优点是架构简单，扩展灵活，只对服务注册器依赖。缺点是客户端要维护所有调用服务的地址，有技术难度，一般大公司都有成熟的内部框架支持，比如Dubbo。</li>
<li>服务端做：**优点是简单，所有服务对于前台调用方透明，一般在小公司在云服务上部署的应用采用的比较多。<br><img src="https://s2.loli.net/2022/04/24/VQy3MpGcgh95W6b.jpg"></li>
</ul>
<h2 id="4-服务挂了怎么办？"><a href="#4-服务挂了怎么办？" class="headerlink" title="4. 服务挂了怎么办？"></a>4. 服务挂了怎么办？</h2><p>​分布式最大的特性就是网络是不可靠 的。通过微服务拆分能降低这个风险，不过如果没有特别的保障，结局肯定是噩梦。我们刚遇到一个线上故障就是一个很不起眼的SQL计数功能，在访问量上升 时，导致数据库load彪高，影响了所在应用的性能，从而影响所有调用这个应用服务的前台应用。所以当我们的系统是由一系列的服务调用链组成的时候，我们必须确保任一环节出问题都不至于影响整体链路。相应的手段有很多：</p>
<ul>
<li>重试机制</li>
<li>限流</li>
<li>熔断机制</li>
<li>负载均衡</li>
<li>降级（本地缓存） 这些方法基本上都很明确通用，就不详细说明了。比如Netflix的Hystrix：<a target="_blank" rel="noopener" href="https://github.com/Netflix/Hystrix">https://github.com/Netflix/Hystrix</a><br><img src="https://s2.loli.net/2022/04/24/z4Xmd7uniY2faxp.jpg"></li>
</ul>
<h2 id="5-微服务需要考虑的问题"><a href="#5-微服务需要考虑的问题" class="headerlink" title="5. 微服务需要考虑的问题"></a>5. 微服务需要考虑的问题</h2><p>这里有一个图非常好的总结微服务架构需要考虑的问题，包括</p>
<ul>
<li>API Gateway</li>
<li>服务间调用</li>
<li>服务发现</li>
<li>服务容错</li>
<li>服务部署</li>
<li>数据调用<br><img src="https://s2.loli.net/2022/04/24/SQoiTBtRH41eMWs.jpg"></li>
</ul>
<h1 id="三、微服务重要部件"><a href="#三、微服务重要部件" class="headerlink" title="三、微服务重要部件"></a>三、微服务重要部件</h1><h2 id="1-微服务基本能力"><a href="#1-微服务基本能力" class="headerlink" title="1. 微服务基本能力"></a>1. 微服务基本能力</h2><p><img src="https://s2.loli.net/2022/04/24/fzsK3VWQErGm9IC.jpg"></p>
<h2 id="2-服务注册中心"><a href="#2-服务注册中心" class="headerlink" title="2. 服务注册中心"></a>2. 服务注册中心</h2><p>服务之间需要创建一种服务发现机制，用于帮助服务之间互相感知彼此的存在。服务启动时会将自身的服务信息注册到注册中心，并订阅自己需要消费的服务。<br>服务注册中心是服务发现的核心。它保存了各个可用服务实例的网络地址（IPAddress和Port）。服务注册中心必须要有高可用性和实时更新功能。上面提到的 Netflix Eureka 就是一个服务注册中心。它提供了服务注册和查询服务信息的REST API。服务通过使用POST请求注册自己的IPAddress和Port。每30秒发送一个PUT请求刷新注册信息。通过DELETE请求注销服务。客户端通过GET请求获取可用的服务实例信息。 Netflix的高可用（Netflix achieves high availability ）是通过在Amazon EC2运行多个实例来实现的,每一个Eureka服务都有一个弹性IP Address。当Eureka服务启动时，有DNS服务器动态的分配。Eureka客户端通过查询 DNS来获取Eureka的网络地址（IP Address和Port）。一般情况下，都是返回和客户端在同一个可用区Eureka服务器地址。 其他能够作为服务注册中心的有：</p>
<ul>
<li>etcd —– 高可用，分布式，强一致性的，key-value，Kubernetes和Cloud Foundry都是使用了etcd。</li>
<li>consul —–一个用于discovering和configuring的工具。它提供了允许客户端注册和发现服务的API。Consul可以进行服务健康检查，以确定服务的可用性。</li>
<li>zookeeper —— 在分布式应用中被广泛使用，高性能的协调服务。 Apache Zookeeper 最初为Hadoop的一个子项目，但现在是一个顶级项目。</li>
</ul>
<h3 id="2-1-zookeeper服务注册和发现"><a href="#2-1-zookeeper服务注册和发现" class="headerlink" title="2.1 zookeeper服务注册和发现"></a>2.1 zookeeper服务注册和发现</h3><ul>
<li><p>简单来讲，zookeeper可以充当一个服务注册表（Service Registry），让多个服务提供者形成一个集群，让服务消费者通过服务注册表获取具体的服务访问地址（ip+端口）去访问具体的服务提供者。如下图所示：<br><img src="https://s2.loli.net/2022/04/24/l3oW46QESiPCVdY.jpg"></p>
</li>
<li><p>具体来说，zookeeper就是个分布式文件系统，每当一个服务提供者部署后都要将自己的服务注册到zookeeper的某一路径上: /{service}/{version}/{ip:port}, 比如我们的HelloWorldService部署到两台机器，那么zookeeper上就会创建两条目录：分别为/HelloWorldService/1.0.0/100.19.20.01:16888 /HelloWorldService/1.0.0/100.19.20.02:16888。</p>
</li>
<li><p>zookeeper提供了“心跳检测”功能，它会定时向各个服务提供者发送一个请求（实际上建立的是一个 socket 长连接），如果长期没有响应，服务中心就认为该服务提供者已经“挂了”，并将其剔除，比如100.19.20.02这台机器如果宕机了，那么zookeeper上的路径就会只剩/HelloWorldService/1.0.0/100.19.20.01:16888。</p>
</li>
<li><p>服务消费者会去监听相应路径（/HelloWorldService/1.0.0），一旦路径上的数据有任务变化（增加或减少），zookeeper都会通知服务消费方服务提供者地址列表已经发生改变，从而进行更新。</p>
</li>
<li><p>更为重要的是zookeeper 与生俱来的容错容灾能力（比如leader选举），可以确保服务注册表的高可用性。</p>
</li>
</ul>
<h2 id="3-负载均衡"><a href="#3-负载均衡" class="headerlink" title="3. 负载均衡"></a>3. 负载均衡</h2><p>服务高可用的保证手段，为了保证高可用，每一个微服务都需要部署多个服务实例来提供服务。此时客户端进行服务的负载均衡。</p>
<h3 id="3-1-负载均衡的常见策略"><a href="#3-1-负载均衡的常见策略" class="headerlink" title="3.1 负载均衡的常见策略"></a>3.1 负载均衡的常见策略</h3><h4 id="3-1-1-随机"><a href="#3-1-1-随机" class="headerlink" title="3.1.1 随机"></a>3.1.1 随机</h4><p>把来自网络的请求随机分配给内部中的多个服务器。</p>
<h4 id="3-1-2-轮询"><a href="#3-1-2-轮询" class="headerlink" title="3.1.2 轮询"></a>3.1.2 轮询</h4><p>每一个来自网络中的请求，轮流分配给内部的服务器，从1到N然后重新开始。此种负载均衡算法适合服务器组内部的服务器都具有相同的配置并且平均服务请求相对均衡的情况。</p>
<h4 id="3-1-3-加权轮询"><a href="#3-1-3-加权轮询" class="headerlink" title="3.1.3 加权轮询"></a>3.1.3 加权轮询</h4><p>根据服务器的不同处理能力，给每个服务器分配不同的权值，使其能够接受相应权值数的服务请求。例如：服务器A的权值被设计成1，B的权值是3，C的权值是6，则服务器A、B、C将分别接受到10%、30％、60％的服务请求。此种均衡算法能确保高性能的服务器得到更多的使用率，避免低性能的服务器负载过重。</p>
<h4 id="3-1-4-IP-Hash"><a href="#3-1-4-IP-Hash" class="headerlink" title="3.1.4 IP Hash"></a>3.1.4 IP Hash</h4><p>这种方式通过生成请求源IP的哈希值，并通过这个哈希值来找到正确的真实服务器。这意味着对于同一主机来说他对应的服务器总是相同。使用这种方式，你不需要保存任何源IP。但是需要注意，这种方式可能导致服务器负载不平衡。</p>
<h4 id="3-1-5-最少连接数"><a href="#3-1-5-最少连接数" class="headerlink" title="3.1.5 最少连接数"></a>3.1.5 最少连接数</h4><p>客户端的每一次请求服务在服务器停留的时间可能会有较大的差异，随着工作时间加长，如果采用简单的轮循或随机均衡算法，每一台服务器上的连接进程可能会产生极大的不同，并没有达到真正的负载均衡。最少连接数均衡算法对内部中需负载的每一台服务器都有一个数据记录，记录当前该服务器正在处理的连接数量，当有新的服务连接请求时，将把当前请求分配给连接数最少的服务器，使均衡更加符合实际情况，负载更加均衡。此种均衡算法适合长时处理的请求服务，如FTP。</p>
<h2 id="4-容错"><a href="#4-容错" class="headerlink" title="4. 容错"></a>4. 容错</h2><p>容错，这个词的理解，直面意思就是可以容下错误，不让错误再次扩张，让这个错误产生的影响在一个固定的边界之内，“千里之堤毁于蚁穴”我们用容错的方式就是让这种蚁穴不要变大。那么我们常见的降级，限流，熔断器，超时重试等等都是容错的方法。</p>
<p>在调用服务集群时，如果一个微服务调用异常，如超时，连接异常，网络异常等，则根据容错策略进行服务容错。目前支持的服务容错策略有快速失败，失效切换。如果连续失败多次则直接熔断，不再发起调用。这样可以避免一个服务异常拖垮所有依赖于他的服务。</p>
<h2 id="4-1-容错策略"><a href="#4-1-容错策略" class="headerlink" title="4.1 容错策略"></a>4.1 容错策略</h2><h4 id="4-1-1-快速失败"><a href="#4-1-1-快速失败" class="headerlink" title="4.1.1 快速失败"></a>4.1.1 快速失败</h4><p>服务只发起一次待用，失败立即报错。通常用于非幂等下性的写操作</p>
<h4 id="4-1-2-失效切换"><a href="#4-1-2-失效切换" class="headerlink" title="4.1.2 失效切换"></a>4.1.2 失效切换</h4><p>服务发起调用，当出现失败后，重试其他服务器。通常用于读操作，但重试会带来更长时间的延迟。重试的次数通常是可以设置的</p>
<h4 id="4-1-3-失败安全"><a href="#4-1-3-失败安全" class="headerlink" title="4.1.3 失败安全"></a>4.1.3 失败安全</h4><p>失败安全， 当服务调用出现异常时，直接忽略。通常用于写入日志等操作。</p>
<h4 id="4-1-4-失败自动恢复"><a href="#4-1-4-失败自动恢复" class="headerlink" title="4.1.4 失败自动恢复"></a>4.1.4 失败自动恢复</h4><p>当服务调用出现异常时，记录失败请求，定时重发。通常用于消息通知。</p>
<h4 id="4-1-5-forking-Cluster"><a href="#4-1-5-forking-Cluster" class="headerlink" title="4.1.5 forking Cluster"></a>4.1.5 forking Cluster</h4><p>并行调用多个服务器，只要有一个成功，即返回。通常用于实时性较高的读操作。可以通过forks=n来设置最大并行数。</p>
<h4 id="4-1-6-广播调用"><a href="#4-1-6-广播调用" class="headerlink" title="4.1.6 广播调用"></a>4.1.6 广播调用</h4><p>广播调用所有提供者，逐个调用，任何一台失败则失败。通常用于通知所有提供者更新缓存或日志等本地资源信息。</p>
<h2 id="5-熔断"><a href="#5-熔断" class="headerlink" title="5. 熔断"></a>5. 熔断</h2><p>熔断技术可以说是一种“智能化的容错”，当调用满足失败次数，失败比例就会触发熔断器打开，有程序自动切断当前的RPC调用,来防止错误进一步扩大。实现一个熔断器主要是考虑三种模式，关闭，打开，半开。各个状态的转换如下图。<br><img src="https://s2.loli.net/2022/04/24/1ZeirbPv8AFEfxu.jpg"></p>
<p>我们在处理异常的时候，要根据具体的业务情况来决定处理方式，比如我们调用商品接口，对方只是临时做了降级处理，那么作为网关调用就要切到可替换的服务上来执行或者获取托底数据，给用户友好提示。还有要区分异常的类型，比如依赖的服务崩溃了，这个可能需要花费比较久的时间来解决。也可能是由于服务器负载临时过高导致超时。作为熔断器应该能够甄别这种异常类型，从而根据具体的错误类型调整熔断策略。增加手动设置，在失败的服务恢复时间不确定的情况下，管理员可以手动强制切换熔断状态。最后，熔断器的使用场景是调用可能失败的远程服务程序或者共享资源。如果是本地缓存本地私有资源，使用熔断器则会增加系统的额外开销。还要注意，熔断器不能作为应用程序中业务逻辑的异常处理替代品。</p>
<p>有一些异常比较顽固，突然发生，无法预测，而且很难恢复，并且还会导致级联失败（举个例子，假设一个服务集群的负载非常高，如果这时候集群的一部分挂掉了，还占了很大一部分资源，整个集群都有可能遭殃）。如果我们这时还是不断进行重试的话，结果大多都是失败的。因此，此时我们的应用需要立即进入失败状态(fast-fail)，并采取合适的方法进行恢复。</p>
<p>我们可以用状态机来实现CircuitBreaker，它有以下三种状态：</p>
<ul>
<li>关闭( Closed )：默认情况下Circuit Breaker是关闭的，此时允许操作执行。CircuitBreaker内部记录着最近失败的次数，如果对应的操作执行失败，次数就会续一次。如果在某个时间段内，失败次数（或者失败比率）达到阈值，CircuitBreaker会转换到开启( Open )状态。在开启状态中，Circuit Breaker会启用一个超时计时器，设这个计时器的目的是给集群相应的时间来恢复故障。当计时器时间到的时候，CircuitBreaker会转换到半开启( Half-Open )状态。</li>
<li>开启( Open )：在此状态下，执行对应的操作将会立即失败并且立即抛出异常。</li>
<li>半开启( Half-Open )：在此状态下，Circuit Breaker会允许执行一定数量的操作。如果所有操作全部成功，CircuitBreaker就会假定故障已经恢复，它就会转换到关闭状态，并且重置失败次数。如果其中 任意一次 操作失败了，Circuit Breaker就会认为故障仍然存在，所以它会转换到开启状态并再次开启计时器（再给系统一些时间使其从失败中恢复）</li>
</ul>
<ol start="6">
<li>限流和降级<br>​ 保证核心服务的稳定性。为了保证核心服务的稳定性，随着访问量的不断增加，需要为系统能够处理的服务数量设置一个极限阀值，超过这个阀值的请求则直接拒绝。同时，为了保证核心服务的可用，可以对否些非核心服务进行降级，通过限制服务的最大访问量进行限流，通过管理控制台对单个微服务进行人工降级</li>
</ol>
<h2 id="7-SLA"><a href="#7-SLA" class="headerlink" title="7. SLA"></a>7. SLA</h2><p>SLA：Service-LevelAgreement的缩写，意思是服务等级协议。 是关于网络服务供应商和客户间的一份合同，其中定义了服务类型、服务质量和客户付款等术语。 典型的SLA包括以下项目：</p>
<ul>
<li>分配给客户的最小带宽；</li>
<li>客户带宽极限；</li>
<li>能同时服务的客户数目；</li>
<li>在可能影响用户行为的网络变化之前的通知安排；</li>
<li>拨入访问可用性；</li>
<li>运用统计学；</li>
<li>服务供应商支持的最小网络利用性能，如99.9%有效工作时间或每天最多为1分钟的停机时间；</li>
<li>各类客户的流量优先权；</li>
<li>客户技术支持和服务；</li>
<li>惩罚规定，为服务供应商不能满足 SLA需求所指定。</li>
</ul>
<h2 id="8-API网关"><a href="#8-API网关" class="headerlink" title="8. API网关"></a>8. API网关</h2><p>这里说的网关是指API网关，直面意思是将所有API调用统一接入到API网关层，有网关层统一接入和输出。一个网关的基本功能有：统一接入、安全防护、协议适配、流量管控、长短链接支持、容错能力。有了网关之后，各个API服务提供团队可以专注于自己的的业务逻辑处理，而API网关更专注于安全、流量、路由等问题。</p>
<h2 id="9-多级缓存"><a href="#9-多级缓存" class="headerlink" title="9. 多级缓存"></a>9. 多级缓存</h2><p>​最简单的缓存就是查一次数据库然后将数据写入缓存比如redis中并设置过期时间。因为有过期失效因此我们要关注下缓存的穿透率，这个穿透率的计算公式，比如查询方法queryOrder(调用次数1000/1s)里面嵌套查询DB方法queryProductFromDb(调用次数300/s)，那么redis的穿透率就是300/1000,在这种使用缓存的方式下，是要重视穿透率的，穿透率大了说明缓存的效果不好。还有一种使用缓存的方式就是将缓存持久化，也就是不设置过期时间，这个就会面临一个数据更新的问题。一般有两种办法，一个是利用时间戳，查询默认以redis为主，每次设置数据的时候放入一个时间戳，每次读取数据的时候用系统当前时间和上次设置的这个时间戳做对比，比如超过5分钟，那么就再查一次数据库。这样可以保证redis里面永远有数据，一般是对DB的一种容错方法。还有一个就是真正的让redis做为DB使用。就是图里面画的通过订阅数据库的binlog通过数据异构系统将数据推送给缓存，同时将将缓存设置为多级。可以通过使用jvmcache作为应用内的一级缓存，一般是体积小，访问频率大的更适合这种jvmcache方式，将一套redis作为二级remote缓存，另外最外层三级redis作为持久化缓存。</p>
<h2 id="10-超时和重试"><a href="#10-超时和重试" class="headerlink" title="10. 超时和重试"></a>10. 超时和重试</h2><p>​超时与重试机制也是容错的一种方法，凡是发生RPC调用的地方，比如读取redis，db，mq等，因为网络故障或者是所依赖的服务故障，长时间不能返回结果，就会导致线程增加，加大cpu负载，甚至导致雪崩。所以对每一个RPC调用都要设置超时时间。对于强依赖RPC调用资源的情况，还要有重试机制，但是重试的次数建议1-2次，另外如果有重试，那么超时时间就要相应的调小，比如重试1次，那么一共是发生2次调用。如果超时时间配置的是2s，那么客户端就要等待4s才能返回。因此重试+超时的方式，超时时间要调小。这里也再谈一下一次PRC调用的时间都消耗在哪些环节，一次正常的调用统计的耗时主要包括： ①调用端RPC框架执行时间 + ②网络发送时间 + ③服务端RPC框架执行时间 + ④服务端业务代码时间。调用方和服务方都有各自的性能监控，比如调用方tp99是500ms，服务方tp99是100ms，找了网络组的同事确认网络没有问题。那么时间都花在什么地方了呢，两种原因，客户端调用方，还有一个原因是网络发生TCP重传。所以要注意这两点。</p>
<h2 id="11-线程池隔离"><a href="#11-线程池隔离" class="headerlink" title="11. 线程池隔离"></a>11. 线程池隔离</h2><p>​在抗量这个环节，Servlet3异步的时候，有提到过线程隔离。线程隔离的之间优势就是防止级联故障，甚至是雪崩。当网关调用N多个接口服务的时候，我们要对每个接口进行线程隔离。比如，我们有调用订单、商品、用户。那么订单的业务不能够影响到商品和用户的请求处理。如果不做线程隔离，当访问订单服务出现网络故障导致延时，线程积压最终导致整个服务CPU负载满。就是我们说的服务全部不可用了，有多少机器都会被此刻的请求塞满。那么有了线程隔离就会使得我们的网关能保证局部问题不会影响全局。</p>
<h2 id="12-降级和限流"><a href="#12-降级和限流" class="headerlink" title="12. 降级和限流"></a>12. 降级和限流</h2><p>​关于降级限流的方法业界都已经有很成熟的方法了，比如FAILBACK机制，限流的方法令牌桶，漏桶，信号量等。这里谈一下我们的一些经验，降级一般都是由统一配置中心的降级开关来实现的，那么当有很多个接口来自同一个提供方，这个提供方的系统或这机器所在机房网络出现了问题，我们就要有一个统一的降级开关，不然就要一个接口一个接口的来降级。也就是要对业务类型有一个大闸刀。还有就是 降级切记暴力降级，什么是暴力降级的，比如把论坛功能降调，结果用户显示一个大白板，我们要实现缓存住一些数据，也就是有托底数据。限流一般分为分布式限流和单机限流，如果实现分布式限流的话就要一个公共的后端存储服务比如redis，在大nginx节点上利用lua读取redis配置信息。我们现在的限流都是单机限流，并没有实施分布式限流。</p>
<h2 id="13-网关监控和统计"><a href="#13-网关监控和统计" class="headerlink" title="13. 网关监控和统计"></a>13. 网关监控和统计</h2><p><img src="https://s2.loli.net/2022/04/24/gmoW8ENrLZB7VyO.jpg"></p>
<p>​ API网关是一个串行的调用，那么每一步发生的异常要记录下来，统一存储到一个地方比如elasticserach中，便于后续对调用异常的分析。鉴于公司docker申请都是统一分配，而且分配之前docker上已经存在3个agent了，不再允许增加。我们自己实现了一个agent程序，来负责采集服务器上面的日志输出，然后发送到kafka集群，再消费到elasticserach中，通过web查询。现在做的追踪功能还比较简单，这块还需要继续丰富。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/" rel="tag">微服务</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8/" rel="tag">面试宝典</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-SparkSQL"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/12/13/SparkSQL/"
    >SparkSQL</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/12/13/SparkSQL/" class="article-date">
  <time datetime="2021-12-13T14:33:38.000Z" itemprop="datePublished">2021-12-13</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Spark-SQL"><a href="#Spark-SQL" class="headerlink" title="Spark SQL"></a>Spark SQL</h1><h1 id="第1章-SparkSQL概述"><a href="#第1章-SparkSQL概述" class="headerlink" title="第1章 SparkSQL概述"></a>第1章 SparkSQL概述</h1><h2 id="1-1-SparkSQL是什么"><a href="#1-1-SparkSQL是什么" class="headerlink" title="1.1 SparkSQL是什么"></a>1.1 SparkSQL是什么</h2><p>Spark SQL是Spark用于结构化数据(structured data)处理的Spark模块。</p>
<h2 id="1-2-Hive-and-SparkSQL"><a href="#1-2-Hive-and-SparkSQL" class="headerlink" title="1.2 Hive and SparkSQL"></a>1.2 Hive and SparkSQL</h2><ul>
<li><p>SparkSQL的前身是Shark，给熟悉RDBMS但又不理解MapReduce的技术人员提供快速上手的工具。</p>
</li>
<li><p>Hive是早期唯一运行在Hadoop上的SQL-on-Hadoop工具。但是MapReduce计算过程中大量的中间磁盘落地过程消耗了大量的I/O，降低的运行效率，为了提高SQL-on-Hadoop的效率，大量的SQL-on-Hadoop工具开始产生，其中表现较为突出的是：</p>
<ul>
<li>Drill</li>
<li>Impala</li>
<li>Shark</li>
</ul>
</li>
<li><p>其中Shark是伯克利实验室Spark生态环境的组件之一，是基于Hive所开发的工具，它修改了下图所示的右下角的内存管理、物理计划、执行三个模块，并使之能运行在Spark引擎上。<br>  <img src="https://s2.loli.net/2021/12/13/7jzrtMVpEQx9Lcn.jpg"></p>
</li>
<li><p>Shark的出现，使得SQL-on-Hadoop的性能比Hive有了10-100倍的提高。<br>  <img src="https://s2.loli.net/2021/12/13/W7HwSAcQyZvsVGX.jpg"></p>
</li>
<li><p>但是，随着Spark的发展，对于野心勃勃的Spark团队来说，Shark对于Hive的太多依赖（如采用Hive的语法解析器、查询优化器等等），制约了Spark的One Stack Rule Them All的既定方针，制约了Spark各个组件的相互集成，所以提出了SparkSQL项目。SparkSQL抛弃原有Shark的代码，汲取了Shark的一些优点，如内存列存储（In-Memory Columnar Storage）、Hive兼容性等，重新开发了SparkSQL代码；由于摆脱了对Hive的依赖性，SparkSQL无论在数据兼容、性能优化、组件扩展方面都得到了极大的方便，真可谓“退一步，海阔天空”。</p>
<ul>
<li>数据兼容方面 SparkSQL不但兼容Hive，还可以从RDD、parquet文件、JSON文件中获取数据，未来版本甚至支持获取RDBMS数据以及cassandra等NOSQL数据；</li>
<li>性能优化方面 除了采取In-Memory Columnar Storage、byte-code generation等优化技术外、将会引进Cost Model对查询进行动态评估、获取最佳物理计划等等；</li>
<li>组件扩展方面 无论是SQL的语法解析器、分析器还是优化器都可以重新定义，进行扩展。</li>
</ul>
</li>
<li><p>2014年6月1日Shark项目和SparkSQL项目的主持人Reynold Xin宣布：停止对Shark的开发，团队将所有资源放SparkSQL项目上，至此，Shark的发展画上了句话，但也因此发展出两个支线：SparkSQL和Hive on Spark。</p>
</li>
<li><p>其中SparkSQL作为Spark生态的一员继续发展，而不再受限于Hive，只是兼容Hive；而Hive on Spark是一个Hive的发展计划，该计划将Spark作为Hive的底层引擎之一，也就是说，Hive将不再受限于一个引擎，可以采用Map-Reduce、Tez、Spark等引擎。</p>
</li>
<li><p><font color ='blue' >对于开发人员来讲，SparkSQL可以简化RDD的开发，提高开发效率</font>，且执行效率非常快，所以实际工作中，基本上采用的就是SparkSQL。Spark SQL为了简化RDD的开发，提高开发效率，提供了2个编程抽象，类似Spark Core中的RDD</p>
<ul>
<li>DataFrame</li>
<li>DataSet</li>
</ul>
</li>
</ul>
<h2 id="1-3-SparkSQL特点"><a href="#1-3-SparkSQL特点" class="headerlink" title="1.3 SparkSQL特点"></a>1.3 SparkSQL特点</h2><h3 id="1-3-1-易整合"><a href="#1-3-1-易整合" class="headerlink" title="1.3.1 易整合"></a>1.3.1 易整合</h3><p>无缝的整合了 SQL 查询和 Spark 编程<br><img src="https://s2.loli.net/2021/12/13/8sTmDI6NikRp1OV.jpg"></p>
<h3 id="1-3-2-统一的数据访问"><a href="#1-3-2-统一的数据访问" class="headerlink" title="1.3.2 统一的数据访问"></a>1.3.2 统一的数据访问</h3><p>使用相同的方式连接不同的数据源<br><img src="https://s2.loli.net/2021/12/13/EBJyWkd2ipO6stN.jpg"></p>
<h3 id="1-3-3-兼容Hive"><a href="#1-3-3-兼容Hive" class="headerlink" title="1.3.3 兼容Hive"></a>1.3.3 兼容Hive</h3><p>在已有的仓库上直接运行 SQL 或者 HiveQL<br><img src="https://s2.loli.net/2021/12/13/AeYlHzuBoViQvbf.jpg"></p>
<h3 id="1-3-4-标准数据连接"><a href="#1-3-4-标准数据连接" class="headerlink" title="1.3.4 标准数据连接"></a>1.3.4 标准数据连接</h3><p>通过 JDBC 或者 ODBC 来连接<br><img src="https://s2.loli.net/2021/12/13/Trg6ZLADS4laVnI.jpg"></p>
<h2 id="1-4-DataFrame是什么"><a href="#1-4-DataFrame是什么" class="headerlink" title="1.4 DataFrame是什么"></a>1.4 DataFrame是什么</h2><ul>
<li><p>在Spark中，DataFrame是一种以RDD为基础的分布式数据集，类似于传统数据库中的二维表格。DataFrame与RDD的主要区别在于，前者带有schema元信息，即DataFrame所表示的二维表数据集的每一列都带有名称和类型。这使得Spark SQL得以洞察更多的结构信息，从而对藏于DataFrame背后的数据源以及作用于DataFrame之上的变换进行了针对性的优化，最终达到大幅提升运行时效率的目标。反观RDD，由于无从得知所存数据元素的具体内部结构，Spark Core只能在stage层面进行简单、通用的流水线优化。</p>
</li>
<li><p>同时，与Hive类似，DataFrame也支持嵌套数据类型（struct、array和map）。从 API 易用性的角度上看，DataFrame API提供的是一套高层的关系操作，比函数式的RDD API 要更加友好，门槛更低。<br><img src="https://s2.loli.net/2021/12/13/aGlVyieYRHDZhrg.jpg"></p>
</li>
<li><p>上图直观地体现了DataFrame和RDD的区别。</p>
<ul>
<li>左侧的RDD[Person]虽然以Person为类型参数，但Spark框架本身不了解Person类的内部结构。而右侧的DataFrame却提供了详细的结构信息，使得 Spark SQL 可以清楚地知道该数据集中包含哪些列，每列的名称和类型各是什么。</li>
<li>DataFrame是为数据提供了Schema的视图。可以把它当做数据库中的一张表来对待</li>
<li>DataFrame也是懒执行的，但性能上比RDD要高，主要原因：优化的执行计划，即查询计划通过Spark catalyst optimiser进行优化。比如下面一个例子:<br>  <img src="https://s2.loli.net/2021/12/13/6ANB9eFt2KlXIaO.jpg"><br><img src="https://s2.loli.net/2021/12/13/gtdbslanASHGu79.jpg"></li>
</ul>
</li>
<li><p>为了说明查询优化，我们来看上图展示的人口数据分析的示例。图中构造了两个DataFrame，将它们join之后又做了一次filter操作。如果原封不动地执行这个执行计划，最终的执行效率是不高的。因为join是一个代价较大的操作，也可能会产生一个较大的数据集。如果我们能将filter下推到 join下方，先对DataFrame进行过滤，再join过滤后的较小的结果集，便可以有效缩短执行时间。而Spark SQL的查询优化器正是这样做的。简而言之，逻辑查询计划优化就是一个利用基于关系代数的等价变换，将高成本的操作替换为低成本操作的过程。<br><img src="https://s2.loli.net/2021/12/13/NrzleGmhZ6S5PvA.jpg"></p>
</li>
</ul>
<h2 id="1-5-DataSet是什么"><a href="#1-5-DataSet是什么" class="headerlink" title="1.5 DataSet是什么"></a>1.5 DataSet是什么</h2><p>DataSet是分布式数据集合。DataSet是Spark 1.6中添加的一个新抽象，是DataFrame的一个扩展。它提供了RDD的优势（强类型，使用强大的lambda函数的能力）以及Spark SQL优化执行引擎的优点。DataSet也可以使用功能性的转换（操作map，flatMap，filter等等）。</p>
<ul>
<li>DataSet是DataFrame API的一个扩展，是SparkSQL最新的数据抽象</li>
<li>用户友好的API风格，既具有类型安全检查也具有DataFrame的查询优化特性；</li>
<li>用样例类来对DataSet中定义数据的结构信息，样例类中每个属性的名称直接映射到DataSet中的字段名称；</li>
<li>DataSet是强类型的。比如可以有DataSet[Car]，DataSet[Person]。</li>
<li>DataFrame是DataSet的特列，DataFrame=DataSet[Row] ，所以可以通过as方法将DataFrame转换为DataSet。Row是一个类型，跟Car、Person这些的类型一样，所有的表结构信息都用Row来表示。获取数据时需要指定顺序</li>
</ul>
<h1 id="第2章-SparkSQL核心编程"><a href="#第2章-SparkSQL核心编程" class="headerlink" title="第2章 SparkSQL核心编程"></a>第2章 SparkSQL核心编程</h1><p>本节重点学习如何使用 Spark SQL所提供的 DataFrame和DataSet模型进行编程。以及了解它们之间的关系和转换，关于具体的SQL语法不是我们的重点。</p>
<h2 id="2-1-新的起点"><a href="#2-1-新的起点" class="headerlink" title="2.1 新的起点"></a>2.1 新的起点</h2><p>Spark Core中，如果想要执行应用程序，需要首先构建上下文环境对象SparkContext，Spark SQL其实可以理解为对Spark Core的一种封装，不仅仅在模型上进行了封装，上下文环境对象也进行了封装。<br>在老的版本中，SparkSQL提供两种SQL查询起始点：一个叫SQLContext，用于Spark自己提供的SQL查询；一个叫HiveContext，用于连接Hive的查询。<br>SparkSession是Spark最新的SQL查询起始点，实质上是SQLContext和HiveContext的组合，所以在SQLContex和HiveContext上可用的API在SparkSession上同样是可以使用的。SparkSession内部封装了SparkContext，所以计算实际上是由sparkContext完成的。当我们使用 spark-shell 的时候, spark框架会自动的创建一个名称叫做spark的SparkSession对象, 就像我们以前可以自动获取到一个sc来表示SparkContext对象一样<br><img src="https://s2.loli.net/2021/12/13/651jx9Y7BymkDhN.jpg"></p>
<h2 id="2-2-DataFrame"><a href="#2-2-DataFrame" class="headerlink" title="2.2 DataFrame"></a>2.2 DataFrame</h2><p>Spark SQL的DataFrame API 允许我们使用 DataFrame 而不用必须去注册临时表或者生成 SQL 表达式。DataFrame API 既有 transformation操作也有action操作。</p>
<h3 id="2-2-1-创建DataFrame"><a href="#2-2-1-创建DataFrame" class="headerlink" title="2.2.1 创建DataFrame"></a>2.2.1 创建DataFrame</h3><p>在Spark SQL中SparkSession是创建DataFrame和执行SQL的入口，创建DataFrame有三种方式：通过Spark的数据源进行创建；从一个存在的RDD进行转换；还可以从Hive Table进行查询返回。</p>
<ol>
<li>从Spark数据源进行创建<ul>
<li>查看Spark支持创建文件的数据源格式  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.read.</span><br><span class="line">csv   format   jdbc   json   load   option   options   orc   parquet   schema   table   text   textFile</span><br><span class="line"></span><br><span class="line">scala&gt; spark.read.</span><br></pre></td></tr></table></figure></li>
<li>在spark的bin/data目录中创建user.json文件  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;id&#x27;:<span class="number">1</span>,&#x27;name&#x27;:&#x27;zhangsan&#x27;,&#x27;age&#x27;:<span class="number">20</span>&#125;</span><br><span class="line">&#123;&#x27;id&#x27;:<span class="number">2</span>,&#x27;name&#x27;:&#x27;lisi&#x27;,&#x27;age&#x27;:<span class="number">30</span>&#125;</span><br><span class="line">&#123;&#x27;id&#x27;:<span class="number">3</span>,&#x27;name&#x27;:&#x27;wangwu&#x27;,&#x27;age&#x27;:<span class="number">40</span>&#125;</span><br><span class="line">&#123;&#x27;id&#x27;:<span class="number">4</span>,&#x27;name&#x27;:&#x27;zhaoliu&#x27;,&#x27;age&#x27;:<span class="number">50</span>&#125;</span><br></pre></td></tr></table></figure></li>
<li>读取json文件创建DataFrame  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> df = spark.read.json(<span class="string">&quot;data/user.json&quot;</span>)</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [age: bigint， username: string]</span><br></pre></td></tr></table></figure>
  注意：如果从内存中获取数据，spark可以知道数据类型具体是什么。如果是数字，默认作为Int处理；但是从文件中读取的数字，不能确定是什么类型，所以用bigint接收，可以和Long类型转换，但是和Int不能进行转换</li>
<li>展示结果:show  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; df.show</span><br><span class="line">+---+---+--------+</span><br><span class="line">|age| id|    name|</span><br><span class="line">+---+---+--------+</span><br><span class="line">| 20|  1|zhangsan|</span><br><span class="line">| 30|  2|    lisi|</span><br><span class="line">| 40|  3|  wangwu|</span><br><span class="line">| 50|  4| zhaoliu|</span><br><span class="line">+---+---+--------+</span><br><span class="line">scala&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>从RDD进行转换<br> 在后续章节中讨论</li>
<li>从Hive Table进行查询返回<br> 在后续章节中讨论</li>
</ol>
<h3 id="2-2-2-SQL语法"><a href="#2-2-2-SQL语法" class="headerlink" title="2.2.2 SQL语法"></a>2.2.2 SQL语法</h3><p>SQL语法风格是指我们查询数据的时候使用SQL语句来查询，这种风格的查询必须要有临时视图或者全局视图来辅助</p>
<ol>
<li>读取JSON文件创建DataFrame <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> df = spark.read.json(<span class="string">&quot;data/user.json&quot;</span>)</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [age: bigint， username: string]</span><br></pre></td></tr></table></figure></li>
<li>对DataFrame创建一个临时表(视图) <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; df.createOrReplaceTempView(<span class="string">&quot;user&quot;</span>)</span><br></pre></td></tr></table></figure></li>
<li>通过SQL语句实现查询全表,结果展示 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.sql(<span class="string">&quot;select * from user&quot;</span>).show</span><br><span class="line">+---+---+--------+</span><br><span class="line">|age| id|    name|</span><br><span class="line">+---+---+--------+</span><br><span class="line">| 20|  1|zhangsan|</span><br><span class="line">| 30|  2|    lisi|</span><br><span class="line">| 40|  3|  wangwu|</span><br><span class="line">| 50|  4| zhaoliu|</span><br><span class="line">+---+---+--------+</span><br><span class="line">scala&gt;</span><br></pre></td></tr></table></figure>
 注意：普通临时表是Session范围内的，如果想应用范围内有效，可以使用全局临时表。使用全局临时表时需要全路径访问，如：global_temp.people</li>
<li>对于DataFrame创建一个全局表 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; df.createGlobalTempView(<span class="string">&quot;user&quot;</span>)</span><br></pre></td></tr></table></figure></li>
<li>通过SQL语句实现查询全表 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.sql(<span class="string">&quot;SELECT * FROM global_temp.user&quot;</span>).show()</span><br><span class="line">+---+---+--------+</span><br><span class="line">|age| id|    name|</span><br><span class="line">+---+---+--------+</span><br><span class="line">| <span class="number">20</span>|  <span class="number">1</span>|zhangsan|</span><br><span class="line">| <span class="number">30</span>|  <span class="number">2</span>|    lisi|</span><br><span class="line">| <span class="number">40</span>|  <span class="number">3</span>|  wangwu|</span><br><span class="line">| <span class="number">50</span>|  <span class="number">4</span>| zhaoliu|</span><br><span class="line">+---+---+--------+</span><br><span class="line">scala&gt; spark.newSession.sql(<span class="string">&quot;SELECT * FROM global_temp.user&quot;</span>).show()</span><br><span class="line">+---+---+--------+</span><br><span class="line">|age| id|    name|</span><br><span class="line">+---+---+--------+</span><br><span class="line">| <span class="number">20</span>|  <span class="number">1</span>|zhangsan|</span><br><span class="line">| <span class="number">30</span>|  <span class="number">2</span>|    lisi|</span><br><span class="line">| <span class="number">40</span>|  <span class="number">3</span>|  wangwu|</span><br><span class="line">| <span class="number">50</span>|  <span class="number">4</span>| zhaoliu|</span><br><span class="line">+---+---+--------+</span><br><span class="line">scala&gt;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-2-3-DSL语法"><a href="#2-2-3-DSL语法" class="headerlink" title="2.2.3 DSL语法"></a>2.2.3 DSL语法</h3><p>DataFrame提供一个特定领域语言(domain-specific language, DSL)去管理结构化的数据。可以在 Scala, Java, Python 和 R 中使用 DSL，使用 DSL 语法风格不必去创建临时视图了</p>
<ol>
<li>创建一个DataFrame <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> df = spark.read.json(<span class="string">&quot;data/user.json&quot;</span>)</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [age: bigint， name: string]</span><br></pre></td></tr></table></figure></li>
<li>查看DataFrame的Schema信息 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; df.printSchema</span><br><span class="line">root</span><br><span class="line"> |-- age: <span class="type">Long</span> (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- username: string (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure></li>
<li>只查看”name”列数据， <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; df.select(<span class="string">&quot;name&quot;</span>).show()</span><br><span class="line">+--------+</span><br><span class="line">|    name|</span><br><span class="line">+--------+</span><br><span class="line">|zhangsan|</span><br><span class="line">|    lisi|</span><br><span class="line">|  wangwu|</span><br><span class="line">| zhaoliu|</span><br><span class="line">+--------+</span><br></pre></td></tr></table></figure></li>
<li>查看”name”列数据以及”age+1”数据<br> 注意:涉及到运算的时候, 每列都必须使用$, 或者采用引号表达式：单引号+字段名 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; df.select($<span class="string">&quot;name&quot;</span>,$<span class="string">&quot;age&quot;</span> + <span class="number">1</span>).show</span><br><span class="line">+--------+---------+</span><br><span class="line">|    name|(age + <span class="number">1</span>)|</span><br><span class="line">+--------+---------+</span><br><span class="line">|zhangsan|       <span class="number">21</span>|</span><br><span class="line">|    lisi|       <span class="number">31</span>|</span><br><span class="line">|  wangwu|       <span class="number">41</span>|</span><br><span class="line">| zhaoliu|       <span class="number">51</span>|</span><br><span class="line">+--------+---------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">scala&gt; df.select(<span class="symbol">&#x27;name</span>, <span class="symbol">&#x27;age</span> + <span class="number">1</span>).show()</span><br><span class="line">+--------+---------+</span><br><span class="line">|    name|(age + <span class="number">1</span>)|</span><br><span class="line">+--------+---------+</span><br><span class="line">|zhangsan|       <span class="number">21</span>|</span><br><span class="line">|    lisi|       <span class="number">31</span>|</span><br><span class="line">|  wangwu|       <span class="number">41</span>|</span><br><span class="line">| zhaoliu|       <span class="number">51</span>|</span><br><span class="line">+--------+---------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">scala&gt; df.select(<span class="symbol">&#x27;name</span>, <span class="symbol">&#x27;age</span> + <span class="number">1</span> as <span class="string">&quot;newage&quot;</span>).show()</span><br><span class="line">+--------+------+</span><br><span class="line">|    name|newage|</span><br><span class="line">+--------+------+</span><br><span class="line">|zhangsan|    <span class="number">21</span>|</span><br><span class="line">|    lisi|    <span class="number">31</span>|</span><br><span class="line">|  wangwu|    <span class="number">41</span>|</span><br><span class="line">| zhaoliu|    <span class="number">51</span>|</span><br><span class="line">+--------+------+</span><br></pre></td></tr></table></figure></li>
<li>查看”age”大于”30”的数据 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; df.filter($<span class="string">&quot;age&quot;</span>&gt;<span class="number">30</span>).show</span><br><span class="line">+---+---+-------+</span><br><span class="line">|age| id|   name|</span><br><span class="line">+---+---+-------+</span><br><span class="line">| <span class="number">40</span>|  <span class="number">3</span>| wangwu|</span><br><span class="line">| <span class="number">50</span>|  <span class="number">4</span>|zhaoliu|</span><br><span class="line">+---+---+-------+</span><br></pre></td></tr></table></figure></li>
<li>按照”age”分组，查看数据条数 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; df.groupBy(<span class="string">&quot;age&quot;</span>).count.show</span><br><span class="line">+---+-----+</span><br><span class="line">|age|count|</span><br><span class="line">+---+-----+</span><br><span class="line">| <span class="number">50</span>|    <span class="number">1</span>|</span><br><span class="line">| <span class="number">30</span>|    <span class="number">1</span>|</span><br><span class="line">| <span class="number">20</span>|    <span class="number">1</span>|</span><br><span class="line">| <span class="number">40</span>|    <span class="number">1</span>|</span><br><span class="line">+---+-----+</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-2-4-RDD转换为DataFrame"><a href="#2-2-4-RDD转换为DataFrame" class="headerlink" title="2.2.4 RDD转换为DataFrame"></a>2.2.4 RDD转换为DataFrame</h3><ul>
<li>在IDEA中开发程序时，如果需要RDD与DF或者DS之间互相操作，那么需要引入 <code>import spark.implicits._</code><ul>
<li>这里的spark不是Scala中的包名，而是创建的sparkSession对象的变量名称，所以必须先创建SparkSession对象再导入。这里的spark对象不能使用var声明，因为Scala只支持val修饰的对象的引入。</li>
</ul>
</li>
<li>spark-shell中无需导入，自动完成此操作。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> idRDD = sc.textFile(<span class="string">&quot;data/id.txt&quot;</span>)</span><br><span class="line">scala&gt; idRDD.toDF(<span class="string">&quot;id&quot;</span>).show</span><br><span class="line">+---+</span><br><span class="line">| id|</span><br><span class="line">+---+</span><br><span class="line">|  <span class="number">1</span>|</span><br><span class="line">|  <span class="number">2</span>|</span><br><span class="line">|  <span class="number">3</span>|</span><br><span class="line">|  <span class="number">4</span>|</span><br><span class="line">+---+</span><br></pre></td></tr></table></figure></li>
<li>实际开发中，一般通过样例类将RDD转换为DataFrame  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">name:<span class="type">String</span>, age:<span class="type">Int</span></span>)</span></span><br><span class="line">defined <span class="class"><span class="keyword">class</span> <span class="title">User</span></span></span><br><span class="line">scala&gt; sc.makeRDD(<span class="type">List</span>((<span class="string">&quot;zhangsan&quot;</span>,<span class="number">30</span>), (<span class="string">&quot;lisi&quot;</span>,<span class="number">40</span>))).map(t=&gt;<span class="type">User</span>(t._1, t._2)).toDF.show</span><br><span class="line">+--------+---+</span><br><span class="line">|     name|age|</span><br><span class="line">+--------+---+</span><br><span class="line">|zhangsan| <span class="number">30</span>|</span><br><span class="line">|    lisi| <span class="number">40</span>|</span><br><span class="line">+--------+---+</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-2-5-DataFrame转换为RDD"><a href="#2-2-5-DataFrame转换为RDD" class="headerlink" title="2.2.5 DataFrame转换为RDD"></a>2.2.5 DataFrame转换为RDD</h3><p>DataFrame其实就是对RDD的封装，所以可以直接获取内部的RDD</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> df = sc.makeRDD(<span class="type">List</span>((<span class="string">&quot;zhangsan&quot;</span>,<span class="number">30</span>), (<span class="string">&quot;lisi&quot;</span>,<span class="number">40</span>))).map(t=&gt;<span class="type">User</span>(t._1, t._2)).toDF</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [name: string, age: int]</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd = df.rdd</span><br><span class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[org.apache.spark.sql.<span class="type">Row</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">46</span>] at rdd at &lt;console&gt;:<span class="number">25</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> array = rdd.collect</span><br><span class="line">array: <span class="type">Array</span>[org.apache.spark.sql.<span class="type">Row</span>] = <span class="type">Array</span>([zhangsan,<span class="number">30</span>], [lisi,<span class="number">40</span>])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：此时得到的RDD存储类型为Row</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; array(<span class="number">0</span>)</span><br><span class="line">res28: org.apache.spark.sql.<span class="type">Row</span> = [zhangsan,<span class="number">30</span>]</span><br><span class="line">scala&gt; array(<span class="number">0</span>)(<span class="number">0</span>)</span><br><span class="line">res29: <span class="type">Any</span> = zhangsan</span><br><span class="line">scala&gt; array(<span class="number">0</span>).getAs[<span class="type">String</span>](<span class="string">&quot;name&quot;</span>)</span><br><span class="line">res30: <span class="type">String</span> = zhangsan</span><br></pre></td></tr></table></figure>

<h2 id="2-3-DataSet"><a href="#2-3-DataSet" class="headerlink" title="2.3 DataSet"></a>2.3 DataSet</h2><p>DataSet是具有强类型的数据集合，需要提供对应的类型信息。</p>
<h3 id="2-3-1-创建DataSet"><a href="#2-3-1-创建DataSet" class="headerlink" title="2.3.1 创建DataSet"></a>2.3.1 创建DataSet</h3><ol>
<li>使用样例类序列创建DataSet <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Long</span></span>)</span></span><br><span class="line">defined <span class="class"><span class="keyword">class</span> <span class="title">Person</span></span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> caseClassDS = <span class="type">Seq</span>(<span class="type">Person</span>(<span class="string">&quot;zhangsan&quot;</span>,<span class="number">2</span>)).toDS()</span><br><span class="line"></span><br><span class="line">caseClassDS: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">Person</span>] = [name: string, age: <span class="type">Long</span>]</span><br><span class="line"></span><br><span class="line">scala&gt; caseClassDS.show</span><br><span class="line">+---------+---+</span><br><span class="line">|     name|age|</span><br><span class="line">+---------+---+</span><br><span class="line">| zhangsan|  <span class="number">2</span>|</span><br><span class="line">+---------+---+</span><br></pre></td></tr></table></figure></li>
<li>使用基本类型的序列创建DataSet <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> ds = <span class="type">Seq</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>).toDS</span><br><span class="line">ds: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">Int</span>] = [value: int]</span><br><span class="line"></span><br><span class="line">scala&gt; ds.show</span><br><span class="line">+-----+</span><br><span class="line">|value|</span><br><span class="line">+-----+</span><br><span class="line">|    <span class="number">1</span>|</span><br><span class="line">|    <span class="number">2</span>|</span><br><span class="line">|    <span class="number">3</span>|</span><br><span class="line">|    <span class="number">4</span>|</span><br><span class="line">|    <span class="number">5</span>|</span><br><span class="line">+-----+</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：在实际使用的时候，很少用到把序列转换成DataSet，更多的是通过RDD来得到DataSet</p>
</blockquote>
</li>
</ol>
<h3 id="2-3-2-RDD转换为DataSet"><a href="#2-3-2-RDD转换为DataSet" class="headerlink" title="2.3.2 RDD转换为DataSet"></a>2.3.2 RDD转换为DataSet</h3><p>SparkSQL能够自动将包含有case类的RDD转换成DataSet，case类定义了table的结构，case类属性通过反射变成了表的列名。Case类可以包含诸如Seq或者Array等复杂的结构。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">name:<span class="type">String</span>, age:<span class="type">Int</span></span>)</span></span><br><span class="line">defined <span class="class"><span class="keyword">class</span> <span class="title">User</span></span></span><br><span class="line"></span><br><span class="line">scala&gt; sc.makeRDD(<span class="type">List</span>((<span class="string">&quot;zhangsan&quot;</span>,<span class="number">30</span>), (<span class="string">&quot;lisi&quot;</span>,<span class="number">49</span>))).map(t=&gt;<span class="type">User</span>(t._1, t._2)).toDS</span><br><span class="line">res11: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">User</span>] = [name: string, age: int]</span><br></pre></td></tr></table></figure>

<h3 id="2-3-3-DataSet转换为RDD"><a href="#2-3-3-DataSet转换为RDD" class="headerlink" title="2.3.3 DataSet转换为RDD"></a>2.3.3 DataSet转换为RDD</h3><p>DataSet其实也是对RDD的封装，所以可以直接获取内部的RDD</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">name:<span class="type">String</span>, age:<span class="type">Int</span></span>)</span></span><br><span class="line">defined <span class="class"><span class="keyword">class</span> <span class="title">User</span></span></span><br><span class="line"></span><br><span class="line">scala&gt; sc.makeRDD(<span class="type">List</span>((<span class="string">&quot;zhangsan&quot;</span>,<span class="number">30</span>), (<span class="string">&quot;lisi&quot;</span>,<span class="number">49</span>))).map(t=&gt;<span class="type">User</span>(t._1, t._2)).toDS</span><br><span class="line">res11: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">User</span>] = [name: string, age: int]</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd = res11.rdd</span><br><span class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">User</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">51</span>] at rdd at &lt;console&gt;:<span class="number">25</span></span><br><span class="line"></span><br><span class="line">scala&gt; rdd.collect</span><br><span class="line">res12: <span class="type">Array</span>[<span class="type">User</span>] = <span class="type">Array</span>(<span class="type">User</span>(zhangsan,<span class="number">30</span>), <span class="type">User</span>(lisi,<span class="number">49</span>))</span><br></pre></td></tr></table></figure>

<h2 id="2-4-DataFrame和DataSet转换"><a href="#2-4-DataFrame和DataSet转换" class="headerlink" title="2.4 DataFrame和DataSet转换"></a>2.4 DataFrame和DataSet转换</h2><p>DataFrame其实是DataSet的特例，所以它们之间是可以互相转换的。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">type</span> <span class="title">DataFrame</span> </span>= <span class="type">Dataset</span>[<span class="type">Row</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li>DataFrame转换为DataSet  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">name:<span class="type">String</span>, age:<span class="type">Int</span></span>)</span></span><br><span class="line">defined <span class="class"><span class="keyword">class</span> <span class="title">User</span></span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> df = sc.makeRDD(<span class="type">List</span>((<span class="string">&quot;zhangsan&quot;</span>,<span class="number">30</span>), (<span class="string">&quot;lisi&quot;</span>,<span class="number">49</span>))).toDF(<span class="string">&quot;name&quot;</span>,<span class="string">&quot;age&quot;</span>)</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [name: string, age: int]</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> ds = df.as[<span class="type">User</span>]</span><br><span class="line">ds: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">User</span>] = [name: string, age: int]</span><br></pre></td></tr></table></figure></li>
<li>DataSet转换为DataFrame  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> ds = df.as[<span class="type">User</span>]</span><br><span class="line">ds: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">User</span>] = [name: string, age: int]</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> df = ds.toDF</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [name: string, age: int]</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="2-5-RDD、DataFrame、DataSet三者的关系"><a href="#2-5-RDD、DataFrame、DataSet三者的关系" class="headerlink" title="2.5 RDD、DataFrame、DataSet三者的关系"></a>2.5 RDD、DataFrame、DataSet三者的关系</h2><p>在SparkSQL中Spark为我们提供了两个新的抽象，分别是DataFrame和DataSet。他们和RDD有什么区别呢？首先从版本的产生上来看：</p>
<ul>
<li>Spark1.0 =&gt; RDD </li>
<li>Spark1.3 =&gt; DataFrame</li>
<li>Spark1.6 =&gt; Dataset<br>如果同样的数据都给到这三个数据结构，他们分别计算之后，都会给出相同的结果。不同是的他们的执行效率和执行方式。在后期的Spark版本中，DataSet有可能会逐步取代RDD和DataFrame成为唯一的API接口。</li>
</ul>
<h3 id="2-5-1-三者的共性"><a href="#2-5-1-三者的共性" class="headerlink" title="2.5.1 三者的共性"></a>2.5.1 三者的共性</h3><ul>
<li>RDD、DataFrame、DataSet全都是spark平台下的分布式弹性数据集，为处理超大型数据提供便利;</li>
<li>三者都有惰性机制，在进行创建、转换，如map方法时，不会立即执行，只有在遇到Action如foreach时，三者才会开始遍历运算;</li>
<li>三者有许多共同的函数，如filter，排序等;</li>
<li>在对DataFrame和Dataset进行操作许多操作都需要这个包:import spark.implicits._（在创建好SparkSession对象后尽量直接导入）</li>
<li>三者都会根据 Spark 的内存情况自动缓存运算，这样即使数据量很大，也不用担心会内存溢出</li>
<li>三者都有partition的概念</li>
<li>DataFrame和DataSet均可使用模式匹配获取各个字段的值和类型</li>
</ul>
<h3 id="2-5-2-三者的区别"><a href="#2-5-2-三者的区别" class="headerlink" title="2.5.2 三者的区别"></a>2.5.2 三者的区别</h3><ol>
<li>RDD<ul>
<li>RDD一般和spark mllib同时使用</li>
<li>RDD不支持sparksql操作</li>
</ul>
</li>
<li>DataFrame<ul>
<li>与RDD和Dataset不同，DataFrame每一行的类型固定为Row，每一列的值没法直接访问，只有通过解析才能获取各个字段的值</li>
<li>DataFrame与DataSet一般不与 spark mllib 同时使用</li>
<li>DataFrame与DataSet均支持 SparkSQL 的操作，比如select，groupby之类，还能注册临时表/视窗，进行 sql 语句操作</li>
<li>DataFrame与DataSet支持一些特别方便的保存方式，比如保存成csv，可以带上表头，这样每一列的字段名一目了然(后面专门讲解)</li>
</ul>
</li>
<li>DataSet<ul>
<li>Dataset和DataFrame拥有完全相同的成员函数，区别只是每一行的数据类型不同。 DataFrame其实就是DataSet的一个特例  type DataFrame = Dataset[Row]</li>
<li>DataFrame也可以叫Dataset[Row],每一行的类型是Row，不解析，每一行究竟有哪些字段，各个字段又是什么类型都无从得知，只能用上面提到的getAS方法或者共性中的第七条提到的模式匹配拿出特定字段。而Dataset中，每一行是什么类型是不一定的，在自定义了case class之后可以很自由的获得每一行的信息</li>
</ul>
</li>
</ol>
<h3 id="2-5-3-三者的互相转换"><a href="#2-5-3-三者的互相转换" class="headerlink" title="2.5.3 三者的互相转换"></a>2.5.3 三者的互相转换</h3><p><img src="https://s2.loli.net/2021/12/13/Xl9isUamgIWY7MR.jpg"></p>
<h2 id="2-6-IDEA开发SparkSQL"><a href="#2-6-IDEA开发SparkSQL" class="headerlink" title="2.6 IDEA开发SparkSQL"></a>2.6 IDEA开发SparkSQL</h2><p>实际开发中，都是使用IDEA进行开发的。</p>
<h3 id="2-6-1-添加依赖"><a href="#2-6-1-添加依赖" class="headerlink" title="2.6.1 添加依赖"></a>2.6.1 添加依赖</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="2-6-2-代码实现"><a href="#2-6-2-代码实现" class="headerlink" title="2.6.2 代码实现"></a>2.6.2 代码实现</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkSQL01_Demo</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建上下文环境配置对象</span></span><br><span class="line">    <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;SparkSQL01_Demo&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建SparkSession对象</span></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder().config(conf).getOrCreate()</span><br><span class="line">    <span class="comment">//RDD=&gt;DataFrame=&gt;DataSet转换需要引入隐式转换规则，否则无法转换</span></span><br><span class="line">    <span class="comment">//spark不是包名，是上下文环境对象名</span></span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">    <span class="comment">//读取json文件 创建DataFrame  &#123;&quot;username&quot;: &quot;lisi&quot;,&quot;age&quot;: 18&#125;</span></span><br><span class="line">    <span class="keyword">val</span> df: <span class="type">DataFrame</span> = spark.read.json(<span class="string">&quot;input/test.json&quot;</span>)</span><br><span class="line">    <span class="comment">//df.show()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//SQL风格语法</span></span><br><span class="line">    df.createOrReplaceTempView(<span class="string">&quot;user&quot;</span>)</span><br><span class="line">    <span class="comment">//spark.sql(&quot;select avg(age) from user&quot;).show</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//DSL风格语法</span></span><br><span class="line">    <span class="comment">//df.select(&quot;username&quot;,&quot;age&quot;).show()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//*****RDD=&gt;DataFrame=&gt;DataSet*****</span></span><br><span class="line">    <span class="comment">//RDD</span></span><br><span class="line">    <span class="keyword">val</span> rdd1: <span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>, <span class="type">Int</span>)] = spark.sparkContext.makeRDD(<span class="type">List</span>((<span class="number">1</span>,<span class="string">&quot;zhangsan&quot;</span>,<span class="number">30</span>),(<span class="number">2</span>,<span class="string">&quot;lisi&quot;</span>,<span class="number">28</span>),(<span class="number">3</span>,<span class="string">&quot;wangwu&quot;</span>,<span class="number">20</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//DataFrame</span></span><br><span class="line">    <span class="keyword">val</span> df1: <span class="type">DataFrame</span> = rdd1.toDF(<span class="string">&quot;id&quot;</span>,<span class="string">&quot;name&quot;</span>,<span class="string">&quot;age&quot;</span>)</span><br><span class="line">    <span class="comment">//df1.show()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//DateSet</span></span><br><span class="line">    <span class="keyword">val</span> ds1: <span class="type">Dataset</span>[<span class="type">User</span>] = df1.as[<span class="type">User</span>]</span><br><span class="line">    <span class="comment">//ds1.show()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//*****DataSet=&gt;DataFrame=&gt;RDD*****</span></span><br><span class="line">    <span class="comment">//DataFrame</span></span><br><span class="line">    <span class="keyword">val</span> df2: <span class="type">DataFrame</span> = ds1.toDF()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//RDD  返回的RDD类型为Row，里面提供的getXXX方法可以获取字段值，类似jdbc处理结果集，但是索引从0开始</span></span><br><span class="line">    <span class="keyword">val</span> rdd2: <span class="type">RDD</span>[<span class="type">Row</span>] = df2.rdd</span><br><span class="line">    <span class="comment">//rdd2.foreach(a=&gt;println(a.getString(1)))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//*****RDD=&gt;DataSet*****</span></span><br><span class="line">    rdd1.map&#123;</span><br><span class="line">      <span class="keyword">case</span> (id,name,age)=&gt;<span class="type">User</span>(id,name,age)</span><br><span class="line">    &#125;.toDS()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//*****DataSet=&gt;=&gt;RDD*****</span></span><br><span class="line">    ds1.rdd</span><br><span class="line"></span><br><span class="line">    <span class="comment">//释放资源</span></span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">id:<span class="type">Int</span>,name:<span class="type">String</span>,age:<span class="type">Int</span></span>)</span></span><br></pre></td></tr></table></figure>

<h2 id="2-7-用户自定义函数"><a href="#2-7-用户自定义函数" class="headerlink" title="2.7 用户自定义函数"></a>2.7 用户自定义函数</h2><p>用户可以通过spark.udf功能添加自定义函数，实现自定义功能。</p>
<h3 id="2-7-1-UDF"><a href="#2-7-1-UDF" class="headerlink" title="2.7.1 UDF"></a>2.7.1 UDF</h3><ol>
<li>创建DataFrame <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> df = spark.read.json(<span class="string">&quot;data/user.json&quot;</span>)</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [age: bigint， username: string]</span><br></pre></td></tr></table></figure></li>
<li>注册UDF <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.udf.register(<span class="string">&quot;addName&quot;</span>,(x:<span class="type">String</span>)=&gt; <span class="string">&quot;Name:&quot;</span>+x)</span><br><span class="line">res9: org.apache.spark.sql.expressions.<span class="type">UserDefinedFunction</span> = <span class="type">UserDefinedFunction</span>(&lt;function1&gt;,<span class="type">StringType</span>,<span class="type">Some</span>(<span class="type">List</span>(<span class="type">StringType</span>)))</span><br></pre></td></tr></table></figure></li>
<li>创建临时表 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; df.createOrReplaceTempView(<span class="string">&quot;people&quot;</span>)</span><br></pre></td></tr></table></figure></li>
<li>应用UDF <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.sql(<span class="string">&quot;Select addName(name),age from people&quot;</span>).show()</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-7-2-UDAF"><a href="#2-7-2-UDAF" class="headerlink" title="2.7.2 UDAF"></a>2.7.2 UDAF</h3><p>强类型的Dataset和弱类型的DataFrame都提供了相关的聚合函数， 如 count()，countDistinct()，avg()，max()，min()。除此之外，用户可以设定自己的自定义聚合函数。通过继承UserDefinedAggregateFunction来实现用户自定义弱类型聚合函数。从Spark3.0版本后，UserDefinedAggregateFunction已经不推荐使用了。可以统一采用强类型聚合函数Aggregator<br>需求：计算平均工资<br>一个需求可以采用很多种不同的方法实现需求</p>
<ol>
<li><p>实现方式 - RDD</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;app&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> sc: <span class="type">SparkContext</span> = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"><span class="keyword">val</span> res: (<span class="type">Int</span>, <span class="type">Int</span>) = sc.makeRDD(<span class="type">List</span>((<span class="string">&quot;zhangsan&quot;</span>, <span class="number">20</span>), (<span class="string">&quot;lisi&quot;</span>, <span class="number">30</span>), (<span class="string">&quot;wangw&quot;</span>, <span class="number">40</span>))).map &#123;</span><br><span class="line">  <span class="keyword">case</span> (name, age) =&gt; &#123;</span><br><span class="line">    (age, <span class="number">1</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;.reduce &#123;</span><br><span class="line">  (t1, t2) =&gt; &#123;</span><br><span class="line">    (t1._1 + t2._1, t1._2 + t2._2)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">println(res._1/res._2)</span><br><span class="line"><span class="comment">// 关闭连接</span></span><br><span class="line">sc.stop()</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>实现方式 - 累加器</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyAC</span> <span class="keyword">extends</span> <span class="title">AccumulatorV2</span>[<span class="type">Int</span>,<span class="type">Int</span>]</span>&#123;</span><br><span class="line">  <span class="keyword">var</span> sum:<span class="type">Int</span> = <span class="number">0</span></span><br><span class="line">  <span class="keyword">var</span> count:<span class="type">Int</span> = <span class="number">0</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">isZero</span></span>: <span class="type">Boolean</span> = &#123;</span><br><span class="line">    <span class="keyword">return</span> sum ==<span class="number">0</span> &amp;&amp; count == <span class="number">0</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">copy</span></span>(): <span class="type">AccumulatorV2</span>[<span class="type">Int</span>, <span class="type">Int</span>] = &#123;</span><br><span class="line">    <span class="keyword">val</span> newMyAc = <span class="keyword">new</span> <span class="type">MyAC</span></span><br><span class="line">    newMyAc.sum = <span class="keyword">this</span>.sum</span><br><span class="line">    newMyAc.count = <span class="keyword">this</span>.count</span><br><span class="line">    newMyAc</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reset</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    sum =<span class="number">0</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(v: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    sum += v</span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(other: <span class="type">AccumulatorV2</span>[<span class="type">Int</span>, <span class="type">Int</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    other <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> o:<span class="type">MyAC</span>=&gt;&#123;</span><br><span class="line">        sum += o.sum</span><br><span class="line">        count += o.count</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">case</span> _=&gt;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">value</span></span>: <span class="type">Int</span> = sum/count</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>实现方式 - UDAF - 弱类型</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">udaf_avg</span> </span>= &#123;</span><br><span class="line">    println(<span class="string">&quot;*********udf**********&quot;</span>)</span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">//val spark = new SparkSession()</span></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder()</span><br><span class="line">        .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">        .appName(<span class="string">&quot;Word Count&quot;</span>)</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> userDF: <span class="type">DataFrame</span> = spark.read.json(<span class="string">&quot;data/user.json&quot;</span>)</span><br><span class="line">    println(<span class="string">&quot;*********userDF.show**********&quot;</span>)</span><br><span class="line">    userDF.show</span><br><span class="line"></span><br><span class="line">    userDF.createOrReplaceTempView(<span class="string">&quot;user&quot;</span>)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;*********select name from user**********&quot;</span>)</span><br><span class="line">    spark.sql(<span class="string">&quot;select id,age,name from user&quot;</span>).show</span><br><span class="line"></span><br><span class="line">    <span class="comment">//SQL中调用自定义函数 UDAF</span></span><br><span class="line">    spark.udf.register(<span class="string">&quot;udaf_avg&quot;</span>,functions.udaf(<span class="keyword">new</span> <span class="type">MyAveragUDAF</span>))</span><br><span class="line">    spark.sql(<span class="string">&quot;select udaf_avg(age) from user&quot;</span>).show</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">定义类继承UserDefinedAggregateFunction，并重写其中方法</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyAveragUDAF</span> <span class="keyword">extends</span> <span class="title">UserDefinedAggregateFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 聚合函数输入参数的数据类型</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">inputSchema</span></span>: <span class="type">StructType</span> = <span class="type">StructType</span>(<span class="type">Array</span>(<span class="type">StructField</span>(<span class="string">&quot;age&quot;</span>,<span class="type">IntegerType</span>)))</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 聚合函数缓冲区中值的数据类型(age,count)</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">bufferSchema</span></span>: <span class="type">StructType</span> = &#123;</span><br><span class="line">    <span class="type">StructType</span>(<span class="type">Array</span>(<span class="type">StructField</span>(<span class="string">&quot;sum&quot;</span>,<span class="type">LongType</span>),<span class="type">StructField</span>(<span class="string">&quot;count&quot;</span>,<span class="type">LongType</span>)))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 函数返回值的数据类型</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">dataType</span></span>: <span class="type">DataType</span> = <span class="type">DoubleType</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 稳定性：对于相同的输入是否一直返回相同的输出。</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">deterministic</span></span>: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 函数缓冲区初始化</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">initialize</span></span>(buffer: <span class="type">MutableAggregationBuffer</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 存年龄的总和</span></span><br><span class="line">    buffer(<span class="number">0</span>) = <span class="number">0</span>L</span><br><span class="line">    <span class="comment">// 存年龄的个数</span></span><br><span class="line">    buffer(<span class="number">1</span>) = <span class="number">0</span>L</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 更新缓冲区中的数据</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">update</span></span>(buffer: <span class="type">MutableAggregationBuffer</span>,input: <span class="type">Row</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (!input.isNullAt(<span class="number">0</span>)) &#123;</span><br><span class="line">      buffer(<span class="number">0</span>) = buffer.getLong(<span class="number">0</span>) + input.getInt(<span class="number">0</span>)</span><br><span class="line">      buffer(<span class="number">1</span>) = buffer.getLong(<span class="number">1</span>) + <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 合并缓冲区</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(buffer1: <span class="type">MutableAggregationBuffer</span>,buffer2: <span class="type">Row</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    buffer1(<span class="number">0</span>) = buffer1.getLong(<span class="number">0</span>) + buffer2.getLong(<span class="number">0</span>)</span><br><span class="line">    buffer1(<span class="number">1</span>) = buffer1.getLong(<span class="number">1</span>) + buffer2.getLong(<span class="number">1</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 计算最终结果</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">evaluate</span></span>(buffer: <span class="type">Row</span>): <span class="type">Double</span> = buffer.getLong(<span class="number">0</span>).toDouble / buffer.getLong(<span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>实现方式 - UDAF - 强类型</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">udaf_avg</span> </span>= &#123;</span><br><span class="line">    println(<span class="string">&quot;*********udf**********&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder()</span><br><span class="line">        .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">        .appName(<span class="string">&quot;Word Count&quot;</span>)</span><br><span class="line">        .getOrCreate()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> df: <span class="type">DataFrame</span> = spark.read.json(<span class="string">&quot;data/user.json&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//封装为DataSet</span></span><br><span class="line">    <span class="keyword">val</span> ds: <span class="type">Dataset</span>[<span class="type">User01</span>] = df.as[<span class="type">User01</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//创建聚合函数</span></span><br><span class="line">    <span class="keyword">var</span> myAgeUdaf1 = <span class="keyword">new</span> <span class="type">MyAveragUDAF1</span></span><br><span class="line">    <span class="comment">//将聚合函数转换为查询的列</span></span><br><span class="line">    <span class="keyword">val</span> col: <span class="type">TypedColumn</span>[<span class="type">User01</span>, <span class="type">Double</span>] = myAgeUdaf1.toColumn</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//查询</span></span><br><span class="line">    ds.select(col).show()</span><br><span class="line">    <span class="type">Spark3</span><span class="number">.0</span>版本可以采用强类型的<span class="type">Aggregate</span>方式代替<span class="type">UserDefinedAggregateFunction</span> </span><br><span class="line">    <span class="comment">// TODO 创建UDAF函数</span></span><br><span class="line">    <span class="keyword">val</span> udaf = <span class="keyword">new</span> <span class="type">MyAvgAgeUDAF</span></span><br><span class="line">    <span class="comment">// TODO 注册到SparkSQL中</span></span><br><span class="line">    spark.udf.register(<span class="string">&quot;avgAge&quot;</span>, functions.udaf(udaf))</span><br><span class="line">    <span class="comment">// TODO 在SQL中使用聚合函数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 定义用户的自定义聚合函数</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select avgAge(age) from user&quot;</span>).show</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// **************************************************</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Buff</span>(<span class="params"> var sum:<span class="type">Long</span>, var cnt:<span class="type">Long</span> </span>)</span></span><br><span class="line">    <span class="comment">// totalage, count</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">MyAvgAgeUDAF</span> <span class="keyword">extends</span> <span class="title">Aggregator</span>[<span class="type">Long</span>, <span class="type">Buff</span>, <span class="type">Double</span>]</span>&#123;</span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">zero</span></span>: <span class="type">Buff</span> = <span class="type">Buff</span>(<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(b: <span class="type">Buff</span>, a: <span class="type">Long</span>): <span class="type">Buff</span> = &#123;</span><br><span class="line">            b.sum += a</span><br><span class="line">            b.cnt += <span class="number">1</span></span><br><span class="line">            b</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(b1: <span class="type">Buff</span>, b2: <span class="type">Buff</span>): <span class="type">Buff</span> = &#123;</span><br><span class="line">            b1.sum += b2.sum</span><br><span class="line">            b1.cnt += b2.cnt</span><br><span class="line">            b1</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">finish</span></span>(reduction: <span class="type">Buff</span>): <span class="type">Double</span> = &#123;</span><br><span class="line">            reduction.sum.toDouble/reduction.cnt</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">bufferEncoder</span></span>: <span class="type">Encoder</span>[<span class="type">Buff</span>] = <span class="type">Encoders</span>.product</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">outputEncoder</span></span>: <span class="type">Encoder</span>[<span class="type">Double</span>] = <span class="type">Encoders</span>.scalaDouble</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    spark.stop()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//输入数据类型</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User01</span>(<span class="params">username:<span class="type">String</span>,age:<span class="type">Long</span></span>)</span></span><br><span class="line"><span class="comment">//缓存类型</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">AgeBuffer</span>(<span class="params">var sum:<span class="type">Long</span>,var count:<span class="type">Long</span></span>)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 定义类继承org.apache.spark.sql.expressions.Aggregator</span></span><br><span class="line"><span class="comment">  * 重写类中的方法</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyAveragUDAF1</span> <span class="keyword">extends</span> <span class="title">Aggregator</span>[<span class="type">User01</span>,<span class="type">AgeBuffer</span>,<span class="type">Double</span>]</span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">zero</span></span>: <span class="type">AgeBuffer</span> = &#123;</span><br><span class="line">    <span class="type">AgeBuffer</span>(<span class="number">0</span>L,<span class="number">0</span>L)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(b: <span class="type">AgeBuffer</span>, a: <span class="type">User01</span>): <span class="type">AgeBuffer</span> = &#123;</span><br><span class="line">    b.sum = b.sum + a.age</span><br><span class="line">    b.count = b.count + <span class="number">1</span></span><br><span class="line">    b</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(b1: <span class="type">AgeBuffer</span>, b2: <span class="type">AgeBuffer</span>): <span class="type">AgeBuffer</span> = &#123;</span><br><span class="line">    b1.sum = b1.sum + b2.sum</span><br><span class="line">    b1.count = b1.count + b2.count</span><br><span class="line">    b1</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">finish</span></span>(buff: <span class="type">AgeBuffer</span>): <span class="type">Double</span> = &#123;</span><br><span class="line">    buff.sum.toDouble/buff.count</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//DataSet默认额编解码器，用于序列化，固定写法</span></span><br><span class="line">  <span class="comment">//自定义类型就是product自带类型根据类型选择</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">bufferEncoder</span></span>: <span class="type">Encoder</span>[<span class="type">AgeBuffer</span>] = &#123;</span><br><span class="line">    <span class="type">Encoders</span>.product</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">outputEncoder</span></span>: <span class="type">Encoder</span>[<span class="type">Double</span>] = &#123;</span><br><span class="line">    <span class="type">Encoders</span>.scalaDouble</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="2-8-数据的加载和保存"><a href="#2-8-数据的加载和保存" class="headerlink" title="2.8 数据的加载和保存"></a>2.8 数据的加载和保存</h2><h3 id="2-8-1-通用的加载和保存方式"><a href="#2-8-1-通用的加载和保存方式" class="headerlink" title="2.8.1 通用的加载和保存方式"></a>2.8.1 通用的加载和保存方式</h3><p>SparkSQL提供了通用的保存数据和数据加载的方式。这里的通用指的是使用相同的API，根据不同的参数读取和保存不同格式的数据，SparkSQL默认读取和保存的文件格式为parquet</p>
<ol>
<li><p>加载数据</p>
<ul>
<li><p>spark.read.load 是加载数据的通用方法</p>
  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.read.</span><br><span class="line">csv   format   jdbc   json   load   option   options   orc   parquet   schema   table   text   textFile</span><br></pre></td></tr></table></figure></li>
<li><p>如果读取不同格式的数据，可以对不同的数据格式进行设定</p>
  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.read.format(<span class="string">&quot;…&quot;</span>)[.option(<span class="string">&quot;…&quot;</span>)].load(<span class="string">&quot;…&quot;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>format(“…”)：指定加载的数据类型，包括”csv”、”jdbc”、”json”、”orc”、”parquet”和”textFile”。</li>
<li>load(“…”)：在”csv”、”jdbc”、”json”、”orc”、”parquet”和”textFile”格式下需要传入加载数据的路径。</li>
<li>option(“…”)：在”jdbc”格式下需要传入JDBC相应参数，url、user、password和dbtable</li>
</ul>
</li>
<li><p>前面都是使用read API 先把文件加载到 DataFrame然后再查询，其实，我们也可以直接在文件上进行查询:  文件格式.<code>文件路径</code></p>
  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;spark.sql(<span class="string">&quot;select * from json.`/opt/module/data/user.json`&quot;</span>).show</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>保存数据</p>
<ul>
<li><p>df.write.save 是保存数据的通用方法</p>
  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;df.write.</span><br><span class="line">csv  jdbc   json  orc   parquet textFile… …</span><br></pre></td></tr></table></figure></li>
<li><p>如果保存不同格式的数据，可以对不同的数据格式进行设定</p>
  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;df.write.format(<span class="string">&quot;…&quot;</span>)[.option(<span class="string">&quot;…&quot;</span>)].save(<span class="string">&quot;…&quot;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>format(“…”)：指定保存的数据类型，包括”csv”、”jdbc”、”json”、”orc”、”parquet”和”textFile”。</li>
<li>save (“…”)：在”csv”、”orc”、”parquet”和”textFile”格式下需要传入保存数据的路径。</li>
<li>option(“…”)：在”jdbc”格式下需要传入JDBC相应参数，url、user、password和dbtable</li>
</ul>
</li>
<li><p>保存操作可以使用 SaveMode, 用来指明如何处理数据，使用mode()方法来设置。</p>
</li>
<li><p>有一点很重要: 这些 SaveMode 都是没有加锁的, 也不是原子操作。</p>
</li>
<li><p>SaveMode是一个枚举类，其中的常量包括：</p>
<table>
<thead>
<tr>
<th>Scala/Java</th>
<th>Any</th>
<th>Language</th>
<th>Meaning</th>
</tr>
</thead>
<tbody><tr>
<td>SaveMode.ErrorIfExists(default)</td>
<td>“error”(default)</td>
<td>如果文件已经存在则抛出异常</td>
<td></td>
</tr>
<tr>
<td>SaveMode.Append</td>
<td>“append”</td>
<td>如果文件已经存在则追加</td>
<td></td>
</tr>
<tr>
<td>SaveMode.Overwrite</td>
<td>“overwrite”</td>
<td>如果文件已经存在则覆盖</td>
<td></td>
</tr>
<tr>
<td>SaveMode.Ignore</td>
<td>“ignore”</td>
<td>如果文件已经存在则忽略</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.write.mode(<span class="string">&quot;append&quot;</span>).json(<span class="string">&quot;/opt/module/data/output&quot;</span>)</span><br></pre></td></tr></table></figure></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
</li>
</ul>
</li>
</ol>
<h3 id="2-8-2-Parquet"><a href="#2-8-2-Parquet" class="headerlink" title="2.8.2 Parquet"></a>2.8.2 Parquet</h3><p>Spark SQL的默认数据源为Parquet格式。Parquet是一种能够有效存储嵌套数据的列式存储格式。<br>数据源为Parquet文件时，Spark SQL可以方便的执行所有的操作，不需要使用format。修改配置项spark.sql.sources.default，可修改默认数据源格式。</p>
<ol>
<li>加载数据 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> df = spark.read.load(<span class="string">&quot;examples/src/main/resources/users.parquet&quot;</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; df.show</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>保存数据 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> df = spark.read.json(<span class="string">&quot;/opt/module/data/input/people.json&quot;</span>)</span><br><span class="line"><span class="comment">//保存为parquet格式</span></span><br><span class="line">scala&gt; df.write.mode(<span class="string">&quot;append&quot;</span>).save(<span class="string">&quot;/opt/module/data/output&quot;</span>)</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-8-3-JSON"><a href="#2-8-3-JSON" class="headerlink" title="2.8.3 JSON"></a>2.8.3 JSON</h3><p>Spark SQL 能够自动推测JSON数据集的结构，并将它加载为一个Dataset[Row]. 可以通过SparkSession.read.json()去加载JSON 文件。</p>
<blockquote>
<p>注意：Spark读取的JSON文件不是传统的JSON文件，每一行都应该是一个JSON串。格式如下：</p>
</blockquote>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">&quot;name&quot;</span>:<span class="string">&quot;Michael&quot;</span>&#125;</span><br><span class="line">&#123;<span class="attr">&quot;name&quot;</span>:<span class="string">&quot;Andy&quot;</span>, <span class="attr">&quot;age&quot;</span>:<span class="number">30</span>&#125;</span><br><span class="line">[&#123;<span class="attr">&quot;name&quot;</span>:<span class="string">&quot;Justin&quot;</span>, <span class="attr">&quot;age&quot;</span>:<span class="number">19</span>&#125;,&#123;<span class="attr">&quot;name&quot;</span>:<span class="string">&quot;Justin&quot;</span>, <span class="attr">&quot;age&quot;</span>:<span class="number">19</span>&#125;]</span><br></pre></td></tr></table></figure>
<ol>
<li>导入隐式转换 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spark.implicits._</span><br></pre></td></tr></table></figure></li>
<li>加载JSON文件 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> path = <span class="string">&quot;/opt/module/spark-local/people.json&quot;</span></span><br><span class="line"><span class="keyword">val</span> peopleDF = spark.read.json(path)</span><br></pre></td></tr></table></figure></li>
<li>创建临时表 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">peopleDF.createOrReplaceTempView(<span class="string">&quot;people&quot;</span>)</span><br></pre></td></tr></table></figure></li>
<li>数据查询 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> teenagerNamesDF = spark.sql(<span class="string">&quot;SELECT name FROM people WHERE age BETWEEN 13 AND 19&quot;</span>)</span><br><span class="line">teenagerNamesDF.show()</span><br><span class="line">+------+</span><br><span class="line">|  name|</span><br><span class="line">+------+</span><br><span class="line">|<span class="type">Justin</span>|</span><br><span class="line">+------+</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-8-4-CSV"><a href="#2-8-4-CSV" class="headerlink" title="2.8.4 CSV"></a>2.8.4 CSV</h3><p>Spark SQL可以配置CSV文件的列表信息，读取CSV文件,CSV文件的第一行设置为数据列</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spark.read</span><br><span class="line">    .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;;&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;inferSchema&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;header&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">    .load(<span class="string">&quot;data/user.csv&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-8-5-MySQL"><a href="#2-8-5-MySQL" class="headerlink" title="2.8.5 MySQL"></a>2.8.5 MySQL</h3><p>Spark SQL可以通过JDBC从关系型数据库中读取数据的方式创建DataFrame，通过对DataFrame一系列的计算后，还可以将数据再写回关系型数据库中。如果使用spark-shell操作，可在启动shell时指定相关的数据库驱动路径或者将相关的数据库驱动放到spark的类路径下。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-shell </span><br><span class="line">--jars mysql-connector-java-5.1.27-bin.jar</span><br></pre></td></tr></table></figure>
<p>我们这里只演示在Idea中通过JDBC对Mysql进行操作</p>
<ol>
<li><p>导入依赖</p>
 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.1.27<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>读取数据</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;SparkSQL&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建SparkSession对象</span></span><br><span class="line"><span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder().config(conf).getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line"><span class="comment">//方式1：通用的load方法读取</span></span><br><span class="line">spark.read.format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;url&quot;</span>, <span class="string">&quot;jdbc:mysql://linux1:3306/spark-sql&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;driver&quot;</span>, <span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;root&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;123123&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;dbtable&quot;</span>, <span class="string">&quot;user&quot;</span>)</span><br><span class="line">  .load().show</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//方式2:通用的load方法读取 参数另一种形式</span></span><br><span class="line">spark.read.format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">  .options(<span class="type">Map</span>(<span class="string">&quot;url&quot;</span>-&gt;<span class="string">&quot;jdbc:mysql://linux1:3306/spark-sql?user=root&amp;password=123123&quot;</span>,</span><br><span class="line">    <span class="string">&quot;dbtable&quot;</span>-&gt;<span class="string">&quot;user&quot;</span>,<span class="string">&quot;driver&quot;</span>-&gt;<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)).load().show</span><br><span class="line"></span><br><span class="line"><span class="comment">//方式3:使用jdbc方法读取</span></span><br><span class="line"><span class="keyword">val</span> props: <span class="type">Properties</span> = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">props.setProperty(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;root&quot;</span>)</span><br><span class="line">props.setProperty(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;123123&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> df: <span class="type">DataFrame</span> = spark.read.jdbc(<span class="string">&quot;jdbc:mysql://linux1:3306/spark-sql&quot;</span>, <span class="string">&quot;user&quot;</span>, props)</span><br><span class="line">df.show</span><br><span class="line"></span><br><span class="line"><span class="comment">//释放资源</span></span><br><span class="line">spark.stop()    </span><br></pre></td></tr></table></figure></li>
<li><p>写入数据</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User2</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Long</span></span>)</span></span><br><span class="line">。。。</span><br><span class="line"><span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;SparkSQL&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建SparkSession对象</span></span><br><span class="line"><span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder().config(conf).getOrCreate()</span><br><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">User2</span>] = spark.sparkContext.makeRDD(<span class="type">List</span>(<span class="type">User2</span>(<span class="string">&quot;lisi&quot;</span>, <span class="number">20</span>), <span class="type">User2</span>(<span class="string">&quot;zs&quot;</span>, <span class="number">30</span>)))</span><br><span class="line"><span class="keyword">val</span> ds: <span class="type">Dataset</span>[<span class="type">User2</span>] = rdd.toDS</span><br><span class="line"><span class="comment">//方式1：通用的方式  format指定写出类型</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">//方式2：通过jdbc方法</span></span><br><span class="line"><span class="keyword">val</span> props: <span class="type">Properties</span> = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">props.setProperty(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;root&quot;</span>)</span><br><span class="line">props.setProperty(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;123123&quot;</span>)</span><br><span class="line">ds.write.mode(<span class="type">SaveMode</span>.<span class="type">Append</span>).jdbc(<span class="string">&quot;jdbc:mysql://linux1:3306/spark-sql&quot;</span>, <span class="string">&quot;user&quot;</span>, props)</span><br><span class="line"></span><br><span class="line"><span class="comment">//释放资源</span></span><br><span class="line">spark.stop()</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-8-6-Hive"><a href="#2-8-6-Hive" class="headerlink" title="2.8.6 Hive"></a>2.8.6 Hive</h3><ul>
<li>Apache Hive 是 Hadoop 上的 SQL 引擎，Spark SQL编译时可以包含 Hive 支持，也可以不包含。包含 Hive 支持的 Spark SQL 可以支持 Hive 表访问、UDF (用户自定义函数)以及 Hive 查询语言(HiveQL/HQL)等。需要强调的一点是，如果要在 Spark SQL 中包含Hive 的库，并不需要事先安装 Hive。一般来说，最好还是在编译Spark SQL时引入Hive支持，这样就可以使用这些特性了。如果你下载的是二进制版本的 Spark，它应该已经在编译时添加了 Hive 支持。</li>
<li>若要把 Spark SQL 连接到一个部署好的 Hive 上，你必须把 hive-site.xml 复制到 Spark的配置文件目录中($SPARK_HOME/conf)。即使没有部署好 Hive，Spark SQL 也可以运行。 需要注意的是，如果你没有部署好Hive，Spark SQL 会在当前的工作目录中创建出自己的 Hive 元数据仓库，叫作 metastore_db。此外，如果你尝试使用 HiveQL 中的 CREATE TABLE (并非 CREATE EXTERNAL TABLE)语句来创建表，这些表会被放在你默认的文件系统中的 /user/hive/warehouse 目录中(如果你的 classpath 中有配好的 hdfs-site.xml，默认的文件系统就是 HDFS，否则就是本地文件系统)。</li>
<li>spark-shell默认是Hive支持的；代码中是默认不支持的，需要手动指定（加一个参数即可）。</li>
</ul>
<ol>
<li><p>内嵌的HIVE<br> 如果使用 Spark 内嵌的 Hive, 则什么都不用做, 直接使用即可.<br> Hive 的元数据存储在 derby 中, 默认仓库地址:$SPARK_HOME/spark-warehouse</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.sql(<span class="string">&quot;show tables&quot;</span>).show</span><br><span class="line">。。。</span><br><span class="line">+--------+---------+-----------+</span><br><span class="line">|database|tableName|isTemporary|</span><br><span class="line">+--------+---------+-----------+</span><br><span class="line">+--------+---------+-----------+</span><br><span class="line"></span><br><span class="line">scala&gt; spark.sql(<span class="string">&quot;create table aa(id int)&quot;</span>)</span><br><span class="line"></span><br><span class="line">。。。</span><br><span class="line"></span><br><span class="line">scala&gt; spark.sql(<span class="string">&quot;show tables&quot;</span>).show</span><br><span class="line">+--------+---------+-----------+</span><br><span class="line">|database|tableName|isTemporary|</span><br><span class="line">+--------+---------+-----------+</span><br><span class="line">| <span class="keyword">default</span>|       aa|      <span class="literal">false</span>|</span><br><span class="line">+--------+---------+-----------+</span><br></pre></td></tr></table></figure>
<p> 向表加载本地数据</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.sql(<span class="string">&quot;load data local inpath &#x27;input/ids.txt&#x27; into table aa&quot;</span>)</span><br><span class="line"></span><br><span class="line">。。。</span><br><span class="line"></span><br><span class="line">scala&gt; spark.sql(<span class="string">&quot;select * from aa&quot;</span>).show</span><br><span class="line">+---+</span><br><span class="line">| id|</span><br><span class="line">+---+</span><br><span class="line">|  <span class="number">1</span>|</span><br><span class="line">|  <span class="number">2</span>|</span><br><span class="line">|  <span class="number">3</span>|</span><br><span class="line">|  <span class="number">4</span>|</span><br><span class="line">+---+</span><br></pre></td></tr></table></figure>
<p> 在实际使用中, 几乎没有任何人会使用内置的 Hive</p>
</li>
<li><p>外部的HIVE<br> 如果想连接外部已经部署好的Hive，需要通过以下几个步骤：</p>
<ul>
<li>Spark要接管Hive需要把hive-site.xml拷贝到conf/目录下</li>
<li>把Mysql的驱动copy到jars/目录下</li>
<li>如果访问不到hdfs，则需要把core-site.xml和hdfs-site.xml拷贝到conf/目录下</li>
<li>重启spark-shell  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.sql(<span class="string">&quot;show tables&quot;</span>).show</span><br><span class="line"><span class="number">20</span>/<span class="number">04</span>/<span class="number">25</span> <span class="number">22</span>:<span class="number">05</span>:<span class="number">14</span> <span class="type">WARN</span> <span class="type">ObjectStore</span>: <span class="type">Failed</span> to get database global_temp, returning <span class="type">NoSuchObjectException</span></span><br><span class="line">+--------+--------------------+-----------+</span><br><span class="line">|database|           tableName|isTemporary|</span><br><span class="line">+--------+--------------------+-----------+</span><br><span class="line">| <span class="keyword">default</span>|                 emp|      <span class="literal">false</span>|</span><br><span class="line">| <span class="keyword">default</span>|hive_hbase_emp_table|      <span class="literal">false</span>|</span><br><span class="line">| <span class="keyword">default</span>| relevance_hbase_emp|      <span class="literal">false</span>|</span><br><span class="line">| <span class="keyword">default</span>|          staff_hive|      <span class="literal">false</span>|</span><br><span class="line">| <span class="keyword">default</span>|                 ttt|      <span class="literal">false</span>|</span><br><span class="line">| <span class="keyword">default</span>|   user_visit_action|      <span class="literal">false</span>|</span><br><span class="line">+--------+--------------------+-----------+</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>运行Spark SQL CLI<br> Spark SQL CLI可以很方便的在本地运行Hive元数据服务以及从命令行执行查询任务。在Spark目录下执行如下命令启动Spark SQL CLI，直接执行SQL语句，类似一Hive窗口bin/spark-sql</p>
</li>
<li><p>运行Spark beeline<br> Spark Thrift Server是Spark社区基于HiveServer2实现的一个Thrift服务。旨在无缝兼容HiveServer2。因为Spark Thrift Server的接口和协议都和HiveServer2完全一致，因此我们部署好Spark Thrift Server后，可以直接使用hive的beeline访问Spark Thrift Server执行相关语句。Spark Thrift Server的目的也只是取代HiveServer2，因此它依旧可以和Hive Metastore进行交互，获取到hive的元数据。<br> 如果想连接Thrift Server，需要通过以下几个步骤：</p>
<ul>
<li>Spark要接管Hive需要把hive-site.xml拷贝到conf/目录下</li>
<li>把Mysql的驱动copy到jars/目录下</li>
<li>如果访问不到hdfs，则需要把core-site.xml和hdfs-site.xml拷贝到conf/目录下</li>
<li>启动Thrift Server  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-thriftserver.sh</span><br></pre></td></tr></table></figure></li>
<li>使用beeline连接Thrift Server  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/beeline -u jdbc:hive2://linux1:10000 -n root</span><br></pre></td></tr></table></figure>
  <img src="https://s2.loli.net/2021/12/13/8Brzyl7RJUVqhba.jpg"></li>
</ul>
<p> 如果连接有问题，可以尝试在hive-site.xml文件中增加如下内容：</p>
 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.enable.doAs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>代码操作Hive</p>
<ol>
<li>导入依赖 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-hive_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-exec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.1.27<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>将hive-site.xml文件拷贝到项目的resources目录中，代码实现</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建SparkSession</span></span><br><span class="line"><span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">  .builder()</span><br><span class="line">  .enableHiveSupport()</span><br><span class="line">  .master(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">  .appName(<span class="string">&quot;sql&quot;</span>)</span><br><span class="line">  .getOrCreate()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：在开发工具中创建数据库默认是在本地仓库，通过参数修改数据库仓库的地址: </p>
   <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config(<span class="string">&quot;spark.sql.warehouse.dir&quot;</span>, <span class="string">&quot;hdfs://linux1:8020/user/hive/warehouse&quot;</span>)</span><br></pre></td></tr></table></figure>
<p> 如果在执行操作时，出现如下错误：<br> <img src="https://s2.loli.net/2021/12/13/ZmY8fq3BuMUjN16.jpg"><br> 可以代码最前面增加如下代码解决(此处的root改为hadoop用户名称)：</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">System</span>.setProperty(<span class="string">&quot;HADOOP_USER_NAME&quot;</span>, <span class="string">&quot;root&quot;</span>)</span><br></pre></td></tr></table></figure></blockquote>
</li>
</ol>
<h1 id="第3章-SparkSQL项目实战"><a href="#第3章-SparkSQL项目实战" class="headerlink" title="第3章 SparkSQL项目实战"></a>第3章 SparkSQL项目实战</h1><h3 id="3-1-数据准备"><a href="#3-1-数据准备" class="headerlink" title="3.1 数据准备"></a>3.1 数据准备</h3><p>我们这次 Spark-sql 操作中所有的数据均来自 Hive，首先在 Hive 中创建表,，并导入数据。<br>一共有3张表： 1张用户行为表，1张城市表，1 张产品表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 用户行为表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `user_visit_action`(</span><br><span class="line">  `<span class="type">date</span>` string,	</span><br><span class="line">  `user_id` <span class="type">bigint</span>,</span><br><span class="line">  `session_id` string,</span><br><span class="line">  `page_id` <span class="type">bigint</span>,</span><br><span class="line">  `action_time` string,</span><br><span class="line">  `search_keyword` string,</span><br><span class="line">  `click_category_id` <span class="type">bigint</span>,</span><br><span class="line">  `click_product_id` <span class="type">bigint</span>,</span><br><span class="line">  `order_category_ids` string,</span><br><span class="line">  `order_product_ids` string,</span><br><span class="line">  `pay_category_ids` string,</span><br><span class="line">  `pay_product_ids` string,</span><br><span class="line">  `city_id` <span class="type">bigint</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;input/user_visit_action.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> user_visit_action;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 城市表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `product_info`(</span><br><span class="line">  `product_id` <span class="type">bigint</span>,</span><br><span class="line">  `product_name` string,</span><br><span class="line">  `extend_info` string)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;input/product_info.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> product_info;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 产品表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `city_info`(</span><br><span class="line">  `city_id` <span class="type">bigint</span>,</span><br><span class="line">  `city_name` string,</span><br><span class="line">  `area` string)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;input/city_info.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> city_info;</span><br></pre></td></tr></table></figure>

<h2 id="3-2-需求：各区域热门商品-Top3"><a href="#3-2-需求：各区域热门商品-Top3" class="headerlink" title="3.2 需求：各区域热门商品 Top3"></a>3.2 需求：各区域热门商品 Top3</h2><h3 id="3-2-1-需求简介"><a href="#3-2-1-需求简介" class="headerlink" title="3.2.1 需求简介"></a>3.2.1 需求简介</h3><p> 这里的热门商品是从点击量的维度来看的，计算各个区域前三大热门商品，并备注上每个商品在主要城市中的分布比例，超过两个城市用其他显示。例如：<br>|地区        |商品名称      |点击次数      |城市备注       |<br>|———|———–|———–|————–|<br>|华北        |商品A         |100000      |北京21.2%，天津13.2%，其他65.6%    |<br>|华北        |商品P         |80200      |北京63.0%，太原10%，其他27.0%    |<br>|华北        |商品M         |40000         |北京63.0%，太原10%，其他27.0%    |<br>|东北        |商品J         |92000         |大连28%，辽宁17.0%，其他 55.0%   |</p>
<h3 id="3-2-2-需求分析"><a href="#3-2-2-需求分析" class="headerlink" title="3.2.2 需求分析"></a>3.2.2 需求分析</h3><ul>
<li>查询出来所有的点击记录，并与 city_info 表连接，得到每个城市所在的地区，与 Product_info 表连接得到产品名称</li>
<li>按照地区和商品 id 分组，统计出每个商品在每个地区的总点击次数</li>
<li>每个地区内按照点击次数降序排列</li>
<li>只取前三名</li>
<li>城市备注需要自定义 UDAF 函数</li>
</ul>
<h3 id="3-2-3-功能实现"><a href="#3-2-3-功能实现" class="headerlink" title="3.2.3 功能实现"></a>3.2.3 功能实现</h3><ul>
<li>连接三张表的数据，获取完整的数据（只有点击）</li>
<li>将数据根据地区，商品名称分组</li>
<li>统计商品点击次数总和,取Top3</li>
<li>实现自定义聚合函数显示备注<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bigdata.spark.sql</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Aggregator</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">Encoder</span>, <span class="type">Encoders</span>, <span class="type">SparkSession</span>, functions&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ListBuffer</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkSQL_Hive</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="type">System</span>.setProperty(<span class="string">&quot;HADOOP_USER_NAME&quot;</span>, <span class="string">&quot;atguigu&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//by_sql</span></span><br><span class="line">        by_sql_split</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">by_sql_split</span> </span>= &#123;</span><br><span class="line">        <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">            .builder()</span><br><span class="line">            .enableHiveSupport()</span><br><span class="line">            .master(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">            .appName(<span class="string">&quot;sql&quot;</span>)</span><br><span class="line">            .config(<span class="string">&quot;spark.sql.warehouse.dir&quot;</span>, <span class="string">&quot;hdfs://mycluster/user/hive/warehouse&quot;</span>)</span><br><span class="line">            .getOrCreate()</span><br><span class="line"></span><br><span class="line">        spark.sql(<span class="string">&quot;use spark_sql&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1. 关联三张表</span></span><br><span class="line">        spark.sql(</span><br><span class="line">            <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">              |select ac.*,</span></span><br><span class="line"><span class="string">              |       pi.product_name,</span></span><br><span class="line"><span class="string">              |       ci.area,</span></span><br><span class="line"><span class="string">              |       ci.city_name</span></span><br><span class="line"><span class="string">              |from user_visit_action ac</span></span><br><span class="line"><span class="string">              |         left join city_info ci on ac.city_id = ci.city_id</span></span><br><span class="line"><span class="string">              |         left join product_info pi on ac.click_product_id = pi.product_id</span></span><br><span class="line"><span class="string">              |where ac.click_product_id != -1</span></span><br><span class="line"><span class="string">              |&quot;&quot;&quot;</span>.stripMargin).createTempView(<span class="string">&quot;t1&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 商品区域作为整体，统计点击数量（（区域，商品），sum）</span></span><br><span class="line">        spark.udf.register(<span class="string">&quot;cityRemark&quot;</span>, functions.udaf(<span class="keyword">new</span> <span class="type">CityRemarkUDAF</span>()))</span><br><span class="line">        spark.sql(</span><br><span class="line">            <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">              |select area,</span></span><br><span class="line"><span class="string">              |       product_name,</span></span><br><span class="line"><span class="string">              |       count(*) as clickCount,</span></span><br><span class="line"><span class="string">              |       cityRemark(city_name)</span></span><br><span class="line"><span class="string">              |from t1</span></span><br><span class="line"><span class="string">              |group by area, product_name</span></span><br><span class="line"><span class="string">              |&quot;&quot;&quot;</span>.stripMargin).createTempView(<span class="string">&quot;t2&quot;</span>)</span><br><span class="line">        <span class="comment">//3. 将统计结果进行结构的转换（区域，（商品，sum））</span></span><br><span class="line">        <span class="comment">//4. 按区域进行分组（区域，Iter[（商品，sum）,（商品，sum）,（商品，sum）]）</span></span><br><span class="line">        spark.sql(</span><br><span class="line">            <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">              |select *,</span></span><br><span class="line"><span class="string">              |       rank() over (partition by area order by clickCount desc ) as rank</span></span><br><span class="line"><span class="string">              |from t2</span></span><br><span class="line"><span class="string">              |&quot;&quot;&quot;</span>.stripMargin).createTempView(<span class="string">&quot;t3&quot;</span>)</span><br><span class="line">        <span class="comment">//5. 分组后的数据根据点击量排序</span></span><br><span class="line">        spark.sql(</span><br><span class="line">            <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">              |select * from t3 where rank &lt;=3</span></span><br><span class="line"><span class="string">              |&quot;&quot;&quot;</span>.stripMargin)</span><br><span class="line">            .show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">        spark.stop()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">CityRemarkBuff</span>(<span class="params">var total: <span class="type">Long</span>, cityMap: mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Long</span>]</span>)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">CityRemarkUDAF</span> <span class="keyword">extends</span> <span class="title">Aggregator</span>[<span class="type">String</span>, <span class="type">CityRemarkBuff</span>, <span class="type">String</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">zero</span></span>: <span class="type">CityRemarkBuff</span> = &#123;</span><br><span class="line">            <span class="type">CityRemarkBuff</span>(<span class="number">0</span>L, mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Long</span>]())</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(buff: <span class="type">CityRemarkBuff</span>, city: <span class="type">String</span>): <span class="type">CityRemarkBuff</span> = &#123;</span><br><span class="line">            buff.total += <span class="number">1</span>L</span><br><span class="line">            buff.cityMap.update(city, buff.cityMap.getOrElse(city, <span class="number">0</span>L) + <span class="number">1</span>L)</span><br><span class="line">            buff</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(b1: <span class="type">CityRemarkBuff</span>, b2: <span class="type">CityRemarkBuff</span>): <span class="type">CityRemarkBuff</span> = &#123;</span><br><span class="line">            b1.total += b2.total</span><br><span class="line">            b2.cityMap.foreach &#123;</span><br><span class="line">                <span class="keyword">case</span> (city, count) =&gt; &#123;</span><br><span class="line">                    b1.cityMap.update(city, b1.cityMap.getOrElse(city, <span class="number">0</span>L) + count)</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            b1</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">finish</span></span>(reduction: <span class="type">CityRemarkBuff</span>): <span class="type">String</span> = &#123;</span><br><span class="line">            <span class="keyword">val</span> list: <span class="type">ListBuffer</span>[<span class="type">String</span>] = <span class="type">ListBuffer</span>[<span class="type">String</span>]()</span><br><span class="line">            <span class="keyword">val</span> total: <span class="type">Long</span> = reduction.total</span><br><span class="line">            <span class="keyword">val</span> sortCity: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Long</span>)] = reduction.cityMap.toList.sortBy(_._2)</span><br><span class="line">            <span class="keyword">val</span> top2: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Long</span>)] = sortCity.take(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">var</span> remain =<span class="number">100</span>L</span><br><span class="line"></span><br><span class="line">            top2.foreach &#123;</span><br><span class="line">                <span class="keyword">case</span> (city, count) =&gt; &#123;</span><br><span class="line">                    <span class="keyword">val</span> percent: <span class="type">Long</span> = count * <span class="number">100</span> / total</span><br><span class="line">                    remain -= percent</span><br><span class="line">                    list.append(<span class="string">s&quot;<span class="subst">$&#123;city&#125;</span> <span class="subst">$percent</span>%&quot;</span>)</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (sortCity.length&gt;<span class="number">2</span>) &#123;</span><br><span class="line">                list.append(<span class="string">s&quot;其他 <span class="subst">$&#123;remain&#125;</span>%&quot;</span>)</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            list.mkString(<span class="string">&quot;, &quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">bufferEncoder</span></span>: <span class="type">Encoder</span>[<span class="type">CityRemarkBuff</span>] = <span class="type">Encoders</span>.product</span><br><span class="line"></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">outputEncoder</span></span>: <span class="type">Encoder</span>[<span class="type">String</span>] = <span class="type">Encoders</span>.<span class="type">STRING</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">by_sql</span> </span>= &#123;</span><br><span class="line">        <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">            .builder()</span><br><span class="line">            .enableHiveSupport()</span><br><span class="line">            .master(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">            .appName(<span class="string">&quot;sql&quot;</span>)</span><br><span class="line">            .config(<span class="string">&quot;spark.sql.warehouse.dir&quot;</span>, <span class="string">&quot;hdfs://mycluster/user/hive/warehouse&quot;</span>)</span><br><span class="line">            .getOrCreate()</span><br><span class="line"></span><br><span class="line">        spark.sql(<span class="string">&quot;use spark_sql&quot;</span>)</span><br><span class="line"></span><br><span class="line">        spark.sql(</span><br><span class="line">            <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">              |select *</span></span><br><span class="line"><span class="string">              |from (</span></span><br><span class="line"><span class="string">              |         select *,</span></span><br><span class="line"><span class="string">              |                rank() over (partition by area order by clickCount desc ) as rank</span></span><br><span class="line"><span class="string">              |         from (</span></span><br><span class="line"><span class="string">              |                  select area,</span></span><br><span class="line"><span class="string">              |                         product_name,</span></span><br><span class="line"><span class="string">              |                         count(*) as clickCount</span></span><br><span class="line"><span class="string">              |                  from (</span></span><br><span class="line"><span class="string">              |                           select ac.*,</span></span><br><span class="line"><span class="string">              |                                  pi.product_name,</span></span><br><span class="line"><span class="string">              |                                  ci.area,</span></span><br><span class="line"><span class="string">              |                                  ci.city_name</span></span><br><span class="line"><span class="string">              |                           from user_visit_action ac</span></span><br><span class="line"><span class="string">              |                                    left join city_info ci on ac.city_id = ci.city_id</span></span><br><span class="line"><span class="string">              |                                    left join product_info pi on ac.click_product_id = pi.product_id</span></span><br><span class="line"><span class="string">              |                           where ac.click_product_id != -1</span></span><br><span class="line"><span class="string">              |                       ) t1</span></span><br><span class="line"><span class="string">              |                  group by area, product_name</span></span><br><span class="line"><span class="string">              |              ) t2</span></span><br><span class="line"><span class="string">              |     ) t3</span></span><br><span class="line"><span class="string">              |where rank &lt;= 3</span></span><br><span class="line"><span class="string">              |&quot;&quot;&quot;</span>.stripMargin).show()</span><br><span class="line"></span><br><span class="line">        spark.stop()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">by_rdd</span> </span>= &#123;</span><br><span class="line">        <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">            .builder()</span><br><span class="line">            .enableHiveSupport()</span><br><span class="line">            .master(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">            .appName(<span class="string">&quot;sql&quot;</span>)</span><br><span class="line">            .config(<span class="string">&quot;spark.sql.warehouse.dir&quot;</span>, <span class="string">&quot;hdfs://mycluster/user/hive/warehouse&quot;</span>)</span><br><span class="line">            .getOrCreate()</span><br><span class="line"></span><br><span class="line">        spark.sql(<span class="string">&quot;use spark_sql&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1. 关联三张表</span></span><br><span class="line">        <span class="comment">//2. 商品区域作为整体，统计点击数量（（区域，商品），sum）</span></span><br><span class="line">        <span class="comment">//3. 将统计结果进行结构的转换（区域，（商品，sum））</span></span><br><span class="line">        <span class="comment">//4. 按区域进行分组（区域，Iter[（商品，sum）,（商品，sum）,（商品，sum）]）</span></span><br><span class="line">        <span class="comment">//5. 分组后的数据根据点击量排序</span></span><br><span class="line">        spark.stop()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 导入数据</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">import_data</span> </span>= &#123;</span><br><span class="line">        <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">            .builder()</span><br><span class="line">            .enableHiveSupport()</span><br><span class="line">            .master(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">            .appName(<span class="string">&quot;sql&quot;</span>)</span><br><span class="line">            .config(<span class="string">&quot;spark.sql.warehouse.dir&quot;</span>, <span class="string">&quot;hdfs://mycluster/user/hive/warehouse&quot;</span>)</span><br><span class="line">            .getOrCreate()</span><br><span class="line"></span><br><span class="line">        spark.sql(<span class="string">&quot;use spark_sql&quot;</span>)</span><br><span class="line"></span><br><span class="line">        spark.sql(</span><br><span class="line">            <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">              |CREATE TABLE `user_visit_action`(</span></span><br><span class="line"><span class="string">              |  `date` string,</span></span><br><span class="line"><span class="string">              |  `user_id` bigint,</span></span><br><span class="line"><span class="string">              |  `session_id` string,</span></span><br><span class="line"><span class="string">              |  `page_id` bigint,</span></span><br><span class="line"><span class="string">              |  `action_time` string,</span></span><br><span class="line"><span class="string">              |  `search_keyword` string,</span></span><br><span class="line"><span class="string">              |  `click_category_id` bigint,</span></span><br><span class="line"><span class="string">              |  `click_product_id` bigint,</span></span><br><span class="line"><span class="string">              |  `order_category_ids` string,</span></span><br><span class="line"><span class="string">              |  `order_product_ids` string,</span></span><br><span class="line"><span class="string">              |  `pay_category_ids` string,</span></span><br><span class="line"><span class="string">              |  `pay_product_ids` string,</span></span><br><span class="line"><span class="string">              |  `city_id` bigint)</span></span><br><span class="line"><span class="string">              |row format delimited fields terminated by &#x27;\t&#x27;;</span></span><br><span class="line"><span class="string">              |&quot;&quot;&quot;</span>.stripMargin)</span><br><span class="line">        spark.sql(</span><br><span class="line">            <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">              |CREATE TABLE `city_info`(</span></span><br><span class="line"><span class="string">              |  `city_id` bigint,</span></span><br><span class="line"><span class="string">              |  `city_name` string,</span></span><br><span class="line"><span class="string">              |  `area` string)</span></span><br><span class="line"><span class="string">              |row format delimited fields terminated by &#x27;\t&#x27;;</span></span><br><span class="line"><span class="string">              |&quot;&quot;&quot;</span>.stripMargin)</span><br><span class="line">        spark.sql(</span><br><span class="line">            <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">              |CREATE TABLE `product_info`(</span></span><br><span class="line"><span class="string">              |  `product_id` bigint,</span></span><br><span class="line"><span class="string">              |  `product_name` string,</span></span><br><span class="line"><span class="string">              |  `extend_info` string)</span></span><br><span class="line"><span class="string">              |row format delimited fields terminated by &#x27;\t&#x27;;</span></span><br><span class="line"><span class="string">              |</span></span><br><span class="line"><span class="string">              |&quot;&quot;&quot;</span>.stripMargin)</span><br><span class="line">        spark.sql(<span class="string">&quot;load data local inpath &#x27;data/user_visit_action.txt&#x27; into table user_visit_action;&quot;</span>)</span><br><span class="line">        spark.sql(<span class="string">&quot;load data local inpath &#x27;data/city_info.txt&#x27; into table city_info;&quot;</span>)</span><br><span class="line">        spark.sql(<span class="string">&quot;load data local inpath &#x27;data/product_info.txt&#x27; into table product_info;&quot;</span>)</span><br><span class="line">        spark.sql(<span class="string">&quot;show tables&quot;</span>).show()</span><br><span class="line">        spark.sql(<span class="string">&quot;select * from  city_info&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">        spark.stop()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">init</span> </span>= &#123;</span><br><span class="line">        <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">            .builder()</span><br><span class="line">            .enableHiveSupport()</span><br><span class="line">            .master(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">            .appName(<span class="string">&quot;sql&quot;</span>)</span><br><span class="line">            .getOrCreate()</span><br><span class="line"></span><br><span class="line">        spark.stop()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SparkSQL/" rel="tag">SparkSQL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-SparkCore"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/12/11/SparkCore/"
    >SparkCore</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/12/11/SparkCore/" class="article-date">
  <time datetime="2021-12-11T12:44:25.000Z" itemprop="datePublished">2021-12-11</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Spark-Core"><a href="#Spark-Core" class="headerlink" title="Spark Core"></a>Spark Core</h1><h1 id="第1章-Spark概述"><a href="#第1章-Spark概述" class="headerlink" title="第1章 Spark概述"></a>第1章 Spark概述</h1><h2 id="1-1-Spark是什么"><a href="#1-1-Spark是什么" class="headerlink" title="1.1 Spark是什么"></a>1.1 Spark是什么</h2><p><img src="https://s2.loli.net/2021/12/11/PRpgQ1WYFbI9StM.jpg"><br><img src="https://s2.loli.net/2021/12/11/WqDcxak3HC26V8Y.jpg"><br>Spark是一种基于内存的快速、通用、可扩展的大数据分析计算引擎。</p>
<h2 id="1-2-Spark-and-Hadoop"><a href="#1-2-Spark-and-Hadoop" class="headerlink" title="1.2 Spark and Hadoop"></a>1.2 Spark and Hadoop</h2><p>在之前的学习中，Hadoop的MapReduce是大家广为熟知的计算框架，那为什么咱们还要学习新的计算框架Spark呢，这里就不得不提到Spark和Hadoop的关系。<br>首先从时间节点上来看:</p>
<ul>
<li>Hadoop<ul>
<li>2006年1月，Doug Cutting加入Yahoo，领导Hadoop的开发</li>
<li>2008年1月，Hadoop成为Apache顶级项目</li>
<li>2011年1.0正式发布</li>
<li>2012年3月稳定版发布</li>
<li>2013年10月发布2.X (Yarn)版本</li>
</ul>
</li>
<li>Spark<ul>
<li>2009年，Spark诞生于伯克利大学的AMPLab实验室</li>
<li>2010年，伯克利大学正式开源了Spark项目</li>
<li>2013年6月，Spark成为了Apache基金会下的项目</li>
<li>2014年2月，Spark以飞快的速度成为了Apache的顶级项目</li>
<li>2015年至今，Spark变得愈发火爆，大量的国内公司开始重点部署或者使用Spark<br>然后我们再从功能上来看:</li>
</ul>
</li>
<li>Hadoop<ul>
<li>Hadoop是由java语言编写的，在分布式服务器集群上存储海量数据并运行分布式分析应用的开源框架</li>
<li>作为Hadoop分布式文件系统，HDFS处于Hadoop生态圈的最下层，存储着所有的数据，支持着Hadoop的所有服务。它的理论基础源于Google的TheGoogleFileSystem这篇论文，它是GFS的开源实现。</li>
<li>MapReduce是一种编程模型，Hadoop根据Google的MapReduce论文将其实现，作为Hadoop的分布式计算模型，是Hadoop的核心。基于这个框架，分布式并行程序的编写变得异常简单。综合了HDFS的分布式存储和MapReduce的分布式计算，Hadoop在处理海量数据时，性能横向扩展变得非常容易。</li>
<li>HBase是对Google的Bigtable的开源实现，但又和Bigtable存在许多不同之处。HBase是一个基于HDFS的分布式数据库，擅长实时地随机读/写超大规模数据集。它也是Hadoop非常重要的组件。</li>
</ul>
</li>
<li>Spark<ul>
<li>Spark是一种由Scala语言开发的快速、通用、可扩展的大数据分析引擎</li>
<li>Spark Core中提供了Spark最基础与最核心的功能</li>
<li>Spark SQL是Spark用来操作结构化数据的组件。通过Spark SQL，用户可以使用SQL或者Apache Hive版本的SQL方言（HQL）来查询数据。</li>
<li>Spark Streaming是Spark平台上针对实时数据进行流式计算的组件，提供了丰富的处理数据流的API。</li>
<li>由上面的信息可以获知，Spark出现的时间相对较晚，并且主要功能主要是用于数据计算，所以其实Spark一直被认为是Hadoop 框架的升级版。</li>
</ul>
</li>
</ul>
<h2 id="1-3-Spark-or-Hadoop"><a href="#1-3-Spark-or-Hadoop" class="headerlink" title="1.3 Spark or Hadoop"></a>1.3 Spark or Hadoop</h2><p>Hadoop的MR框架和Spark框架都是数据处理框架，那么我们在使用时如何选择呢？</p>
<ul>
<li>Hadoop MapReduce由于其设计初衷并不是为了满足循环迭代式数据流处理，因此在多并行运行的数据可复用场景（如：机器学习、图挖掘算法、交互式数据挖掘算法）中存在诸多计算效率等问题。所以Spark应运而生，Spark就是在传统的MapReduce 计算框架的基础上，利用其计算过程的优化，从而大大加快了数据分析、挖掘的运行和读写速度，并将计算单元缩小到更适合并行计算和重复使用的RDD计算模型。</li>
<li>机器学习中ALS、凸优化梯度下降等。这些都需要基于数据集或者数据集的衍生数据反复查询反复操作。MR这种模式不太合适，即使多MR串行处理，性能和时间也是一个问题。数据的共享依赖于磁盘。另外一种是交互式数据挖掘，MR显然不擅长。而Spark所基于的scala语言恰恰擅长函数的处理。</li>
<li>Spark是一个分布式数据快速分析项目。它的核心技术是弹性分布式数据集（Resilient Distributed Datasets），提供了比MapReduce丰富的模型，可以快速在内存中对数据集进行多次迭代，来支持复杂的数据挖掘算法和图形计算算法。</li>
<li>Spark和Hadoop的根本差异是多个作业之间的数据通信问题 : Spark多个作业之间数据通信是基于内存，而Hadoop是基于磁盘。</li>
<li>Spark Task的启动时间快。Spark采用fork线程的方式，而Hadoop采用创建新的进程的方式。</li>
<li>Spark只有在shuffle的时候将数据写入磁盘，而Hadoop中多个MR作业之间的数据交互都要依赖于磁盘交互</li>
<li>Spark的缓存机制比HDFS的缓存机制高效。</li>
</ul>
<p>经过上面的比较，我们可以看出在绝大多数的数据计算场景中，Spark确实会比MapReduce更有优势。但是Spark是基于内存的，所以在实际的生产环境中，由于内存的限制，可能会由于内存资源不够导致Job执行失败，此时，MapReduce其实是一个更好的选择，所以Spark并不能完全替代MR。</p>
<h2 id="1-4-Spark-核心模块"><a href="#1-4-Spark-核心模块" class="headerlink" title="1.4 Spark 核心模块"></a>1.4 Spark 核心模块</h2><p><img src="https://s2.loli.net/2021/12/11/AdkW8MaIlSPyJxh.jpg"></p>
<ul>
<li>Spark Core<br>Spark Core中提供了Spark最基础与最核心的功能，Spark其他的功能如：Spark SQL，Spark Streaming，GraphX, MLlib都是在Spark Core的基础上进行扩展的</li>
<li>Spark SQL<br>Spark SQL是Spark用来操作结构化数据的组件。通过Spark SQL，用户可以使用SQL或者Apache Hive版本的SQL方言（HQL）来查询数据。</li>
<li>Spark Streaming<br>Spark Streaming是Spark平台上针对实时数据进行流式计算的组件，提供了丰富的处理数据流的API。</li>
<li>Spark MLlib<br>MLlib是Spark提供的一个机器学习算法库。MLlib不仅提供了模型评估、数据导入等额外的功能，还提供了一些更底层的机器学习原语。</li>
<li>Spark GraphX<br>GraphX是Spark面向图计算提供的框架与算法库。</li>
</ul>
<h1 id="第3章-Spark运行环境"><a href="#第3章-Spark运行环境" class="headerlink" title="第3章 Spark运行环境"></a>第3章 Spark运行环境</h1><p>Spark作为一个数据处理框架和计算引擎，被设计在所有常见的集群环境中运行, 在国内工作中主流的环境为Yarn，不过逐渐容器式环境也慢慢流行起来。接下来，我们就分别看看不同环境下Spark的运行<br><img src="https://s2.loli.net/2021/12/11/bnH9TZVF6WaSkjt.jpg"></p>
<h2 id="3-1-Local模式"><a href="#3-1-Local模式" class="headerlink" title="3.1  Local模式"></a>3.1  Local模式</h2><p>想啥呢，你之前一直在使用的模式可不是Local模式哟。所谓的Local模式，就是不需要其他任何节点资源就可以在本地执行Spark代码的环境，一般用于教学，调试，演示等，之前在IDEA中运行代码的环境我们称之为开发环境，不太一样。</p>
<h3 id="3-1-1-解压缩文件"><a href="#3-1-1-解压缩文件" class="headerlink" title="3.1.1 解压缩文件"></a>3.1.1 解压缩文件</h3><p>将spark-3.0.0-bin-hadoop3.2.tgz文件上传到Linux并解压缩，放置在指定位置，路径中不要包含中文或空格，课件后续如果涉及到解压缩操作，不再强调。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf spark-3.0.0-bin-hadoop3.2.tgz -C /opt/module</span><br><span class="line"><span class="built_in">cd</span> /opt/module </span><br><span class="line">mv spark-3.0.0-bin-hadoop3.2 spark-local</span><br></pre></td></tr></table></figure>

<h3 id="3-1-2-启动Local环境"><a href="#3-1-2-启动Local环境" class="headerlink" title="3.1.2 启动Local环境"></a>3.1.2 启动Local环境</h3><ol>
<li>进入解压缩后的路径，执行如下指令 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@bd-server-001 spark-local]$ bin/spark-shell</span><br><span class="line">21/12/01 08:26:41 WARN NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes <span class="built_in">where</span> applicable</span><br><span class="line">Using Spark<span class="string">&#x27;s default log4j profile: org/apache/spark/log4j-defaults.properties</span></span><br><span class="line"><span class="string">Setting default log level to &quot;WARN&quot;.</span></span><br><span class="line"><span class="string">To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).</span></span><br><span class="line"><span class="string">Spark context Web UI available at http://bd-server-001:4040</span></span><br><span class="line"><span class="string">Spark context available as &#x27;</span>sc<span class="string">&#x27; (master = local[*], app id = local-1638318406888).</span></span><br><span class="line"><span class="string">Spark session available as &#x27;</span>spark<span class="string">&#x27;.</span></span><br><span class="line"><span class="string">Welcome to</span></span><br><span class="line"><span class="string">      ____              __</span></span><br><span class="line"><span class="string">     / __/__  ___ _____/ /__</span></span><br><span class="line"><span class="string">    _\ \/ _ \/ _ `/ __/  &#x27;</span>_/</span><br><span class="line">   /___/ .__/\_,_/_/ /_/\_\   version 3.0.0</span><br><span class="line">      /_/</span><br><span class="line"></span><br><span class="line">Using Scala version 2.12.10 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_212)</span><br><span class="line">Type <span class="keyword">in</span> expressions to have them evaluated.</span><br><span class="line">Type :<span class="built_in">help</span> <span class="keyword">for</span> more information.</span><br><span class="line"></span><br><span class="line">scala&gt;</span><br></pre></td></tr></table></figure></li>
<li>启动成功后，可以输入网址进行Web UI监控页面访问<br> <img src="https://s2.loli.net/2021/12/11/rqa1YJvW2wfQKBP.jpg"></li>
</ol>
<h3 id="3-1-3-命令行工具"><a href="#3-1-3-命令行工具" class="headerlink" title="3.1.3 命令行工具"></a>3.1.3 命令行工具</h3><p>在解压缩文件夹下的data目录中，添加word.txt文件。在命令行工具中执行如下代码指令（和IDEA中代码简化版一致）</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sc</span><br><span class="line">    .textFile(<span class="string">&quot;data/word.txt&quot;</span>)</span><br><span class="line">    .flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line">    .map((_,<span class="number">1</span>))</span><br><span class="line">    .reduceByKey(_+_)</span><br><span class="line">    .collect</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; sc.textFile(<span class="string">&quot;data/word.txt&quot;</span>).flatMap(_.split(<span class="string">&quot; &quot;</span>)).map((_,1)).reduceByKey(_+_).collect</span><br><span class="line">res0: Array[(String, Int)] = Array((scala,1), (flink,1), (hello,3), (spark,1))</span><br><span class="line"></span><br><span class="line">scala&gt;</span><br></pre></td></tr></table></figure>

<h3 id="3-1-4-退出本地模式"><a href="#3-1-4-退出本地模式" class="headerlink" title="3.1.4 退出本地模式"></a>3.1.4 退出本地模式</h3><p>按键Ctrl+C或输入Scala指令<code>:quit</code></p>
<h3 id="3-1-5-提交应用"><a href="#3-1-5-提交应用" class="headerlink" title="3.1.5 提交应用"></a>3.1.5 提交应用</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master <span class="built_in">local</span>[2] \</span><br><span class="line">./examples/jars/spark-examples_2.12-3.0.0.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></figure>
<ol>
<li>–class表示要执行程序的主类，此处可以更换为咱们自己写的应用程序</li>
<li>–master local[2] 部署模式，默认为本地模式，数字表示分配的虚拟CPU核数量</li>
<li>spark-examples_2.12-3.0.0.jar 运行的应用类所在的jar包，实际使用时，可以设定为咱们自己打的jar包</li>
<li>数字10表示程序的入口参数，用于设定当前应用的任务数量</li>
</ol>
<p><img src="https://s2.loli.net/2021/12/11/UleCBVSxPaX8HkA.jpg"></p>
<h2 id="3-2-Standalone模式"><a href="#3-2-Standalone模式" class="headerlink" title="3.2  Standalone模式"></a>3.2  Standalone模式</h2><p>local本地模式毕竟只是用来进行练习演示的，真实工作中还是要将应用提交到对应的集群中去执行，这里我们来看看只使用Spark自身节点运行的集群模式，也就是我们所谓的独立部署（Standalone）模式。Spark的Standalone模式体现了经典的master-slave模式。<br>Spark有自己的资源调度框架：<br><img src="https://s2.loli.net/2021/12/11/9FdAabfSstQUqv4.jpg"></p>
<p>集群规划:<br>|Linux1    |Linux2    |Linux3 |<br>|——–|———|——|<br>|Spark    |Worker Master|Worker    |Worker    |</p>
<h3 id="3-2-1-解压缩文件"><a href="#3-2-1-解压缩文件" class="headerlink" title="3.2.1 解压缩文件"></a>3.2.1 解压缩文件</h3><p>将spark-3.0.0-bin-hadoop3.2.tgz文件上传到Linux并解压缩在指定位置</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf spark-3.0.0-bin-hadoop3.2.tgz -C /opt/module</span><br><span class="line"><span class="built_in">cd</span> /opt/module </span><br><span class="line">mv spark-3.0.0-bin-hadoop3.2 spark-standalone</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2-修改配置文件"><a href="#3-2-2-修改配置文件" class="headerlink" title="3.2.2 修改配置文件"></a>3.2.2 修改配置文件</h3><ol>
<li>进入解压缩后路径的conf目录，修改slaves.template文件名为slaves <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv slaves.template slaves</span><br></pre></td></tr></table></figure></li>
<li>修改slaves文件，添加worker节点 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bd-server-001</span><br><span class="line">bd-server-002</span><br><span class="line">bd-server-003</span><br><span class="line">bd-server-004</span><br><span class="line">bd-server-005</span><br></pre></td></tr></table></figure></li>
<li>修改spark-env.sh.template文件名为spark-env.sh <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv spark-env.sh.template spark-env.sh</span><br></pre></td></tr></table></figure></li>
<li>修改spark-env.sh文件，添加JAVA_HOME环境变量和集群对应的master节点 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_212</span><br><span class="line">SPARK_MASTER_HOST=bd-server-001</span><br><span class="line">SPARK_MASTER_PORT=7077</span><br></pre></td></tr></table></figure></li>
<li>分发spark-standalone目录 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync spark-standalone</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="3-2-3-启动集群"><a href="#3-2-3-启动集群" class="headerlink" title="3.2.3 启动集群"></a>3.2.3 启动集群</h3><ol>
<li>执行脚本命令：<code>sbin/start-all.sh</code> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@bd-server-001 spark-standalone]$ sbin/start-all.sh</span><br><span class="line">starting org.apache.spark.deploy.master.Master, logging to /opt/module/spark-standalone/logs/spark-atguigu-org.apache.spark.deploy.master.Master-1-bd-server-001.out</span><br><span class="line">bd-server-002: starting org.apache.spark.deploy.worker.Worker, logging to /opt/module/spark-standalone/logs/spark-atguigu-org.apache.spark.deploy.worker.Worker-1-bd-server-002.out</span><br><span class="line">bd-server-001: starting org.apache.spark.deploy.worker.Worker, logging to /opt/module/spark-standalone/logs/spark-atguigu-org.apache.spark.deploy.worker.Worker-1-bd-server-001.out</span><br><span class="line">bd-server-003: starting org.apache.spark.deploy.worker.Worker, logging to /opt/module/spark-standalone/logs/spark-atguigu-org.apache.spark.deploy.worker.Worker-1-bd-server-003.out</span><br><span class="line">bd-server-004: starting org.apache.spark.deploy.worker.Worker, logging to /opt/module/spark-standalone/logs/spark-atguigu-org.apache.spark.deploy.worker.Worker-1-bd-server-004.out</span><br><span class="line">bd-server-005: starting org.apache.spark.deploy.worker.Worker, logging to /opt/module/spark-standalone/logs/spark-atguigu-org.apache.spark.deploy.worker.Worker-1-bd-server-005.out</span><br><span class="line">[atguigu@bd-server-001 spark-standalone]$</span><br></pre></td></tr></table></figure>
</li>
<li>查看三台服务器运行进程 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@bd-server-001 spark-standalone]$ jpsall</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;  bd-server-001  &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span><br><span class="line"> <span class="string">37979 Master</span></span><br><span class="line"><span class="string"> 38070 Worker</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;  bd-server-002  &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span></span><br><span class="line"><span class="string"> 27011 Worker</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;  bd-server-003  &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span></span><br><span class="line"><span class="string"> 19210 Worker</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;  bd-server-004  &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span></span><br><span class="line"><span class="string"> 11267 Worker</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;  bd-server-005  &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span></span><br><span class="line"><span class="string"> 10646 Worker</span></span><br><span class="line"><span class="string">[atguigu@bd-server-001 spark-standalone]$</span></span><br></pre></td></tr></table></figure></li>
<li>查看Master资源监控Web UI界面: <a target="_blank" rel="noopener" href="http://bd-server-001:8080/">http://bd-server-001:8080/</a><br> <img src="https://s2.loli.net/2021/12/11/GM6EUpD5tJ7FckB.jpg"></li>
</ol>
<h3 id="3-2-4-提交应用"><a href="#3-2-4-提交应用" class="headerlink" title="3.2.4 提交应用"></a>3.2.4 提交应用</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master spark://bd-server-001:7077 \</span><br><span class="line">./examples/jars/spark-examples_2.12-3.0.0.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></figure>
<ol>
<li>–class表示要执行程序的主类</li>
<li>–master spark://linux1:7077 独立部署模式，连接到Spark集群</li>
<li>spark-examples_2.12-3.0.0.jar 运行类所在的jar包</li>
<li>数字10表示程序的入口参数，用于设定当前应用的任务数量<br><img src="https://s2.loli.net/2021/12/11/vBFDSG5PC6TrlcR.jpg"></li>
<li>执行任务时，会产生多个Java进程 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@bd-server-001 ~]$ jpsall</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;  bd-server-001  &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span><br><span class="line"> <span class="string">41170 Master</span></span><br><span class="line"><span class="string"> 41262 Worker</span></span><br><span class="line"><span class="string"> 41561 SparkSubmit</span></span><br><span class="line"><span class="string"> 41674 CoarseGrainedExecutorBackend</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;  bd-server-002  &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span></span><br><span class="line"><span class="string"> 29924 Worker</span></span><br><span class="line"><span class="string"> 30101 CoarseGrainedExecutorBackend</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;  bd-server-003  &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span></span><br><span class="line"><span class="string"> 21171 Worker</span></span><br><span class="line"><span class="string"> 21348 CoarseGrainedExecutorBackend</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;  bd-server-004  &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span></span><br><span class="line"><span class="string"> 12192 Worker</span></span><br><span class="line"><span class="string"> 12370 CoarseGrainedExecutorBackend</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;  bd-server-005  &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span></span><br><span class="line"><span class="string"> 11571 Worker</span></span><br><span class="line"><span class="string"> 11748 CoarseGrainedExecutorBackend</span></span><br></pre></td></tr></table></figure>
<ul>
<li>SparkSubmit：任务提交进程</li>
<li>CoarseGrainedExecutorBackend：任务执行进程</li>
</ul>
</li>
<li>执行任务时，默认采用服务器集群节点的总核数，每个节点内存1024M。<br> <img src="https://s2.loli.net/2021/12/11/3RpYmK5CPNJ7vda.jpg"></li>
</ol>
<h3 id="3-2-5-提交参数说明"><a href="#3-2-5-提交参数说明" class="headerlink" title="3.2.5 提交参数说明"></a>3.2.5 提交参数说明</h3><p>在提交应用中，一般会同时一些提交参数</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class &lt;main-class&gt;</span><br><span class="line">--master &lt;master-url&gt; \</span><br><span class="line">... <span class="comment"># other options</span></span><br><span class="line">&lt;application-jar&gt; \</span><br><span class="line">[application-arguments]</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>参数</th>
<th>解释</th>
<th>可选值举例</th>
</tr>
</thead>
<tbody><tr>
<td>–class</td>
<td>Spark程序中包含主函数的类</td>
<td></td>
</tr>
<tr>
<td>–master</td>
<td>Spark程序运行的模式(环境)</td>
<td>模式：local[*]、spark://linux1:7077、Yarn</td>
</tr>
<tr>
<td>–executor-memory 1G</td>
<td>指定每个executor可用内存为1G</td>
<td>符合集群内存配置即可，具体情况具体分析。</td>
</tr>
<tr>
<td>–total-executor-cores 2</td>
<td>指定所有executor使用的cpu核数为2个</td>
<td></td>
</tr>
<tr>
<td>–executor-cores</td>
<td>指定每个executor使用的cpu核数</td>
<td></td>
</tr>
<tr>
<td>application-jar</td>
<td>打包好的应用jar，包含依赖。这个URL在集群中全局可见。 比如hdfs:// 共享存储系统，如果是file:// path，那么所有的节点的path都包含同样的jar</td>
<td></td>
</tr>
<tr>
<td>application-arguments</td>
<td>传给main()方法的参数</td>
<td></td>
</tr>
</tbody></table>
<h3 id="3-2-6-配置历史服务"><a href="#3-2-6-配置历史服务" class="headerlink" title="3.2.6 配置历史服务"></a>3.2.6 配置历史服务</h3><p>由于spark-shell停止掉后，集群监控linux1:4040页面就看不到历史任务的运行情况，所以开发时都配置历史服务器记录任务运行情况。</p>
<ol>
<li><p>修改spark-defaults.conf.template文件名为spark-defaults.conf</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv spark-defaults.conf.template spark-defaults.conf</span><br></pre></td></tr></table></figure></li>
<li><p>修改spark-default.conf文件，配置日志存储路径</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.eventLog.enabled          true</span><br><span class="line">spark.eventLog.dir              hdfs://bd-server-002:9092/directory</span><br></pre></td></tr></table></figure>
<ul>
<li>注意：需要启动hadoop集群，HDFS上的directory目录需要提前存在。</li>
</ul>
</li>
<li><p>修改spark-env.sh文件, 添加日志配置</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_HISTORY_OPTS=<span class="string">&quot;</span></span><br><span class="line"><span class="string">-Dspark.history.ui.port=18080 </span></span><br><span class="line"><span class="string">-Dspark.history.fs.logDirectory=hdfs://bd-server-002:9092/directory </span></span><br><span class="line"><span class="string">-Dspark.history.retainedApplications=30&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>参数1含义：WEB UI访问的端口号为18080</li>
<li>参数2含义：指定历史服务器日志存储路径</li>
<li>参数3含义：指定保存Application历史记录的个数，如果超过这个值，旧的应用程序信息将被删除，这个是内存中的应用数，而不是页面上显示的应用数。</li>
</ul>
</li>
<li><p>分发配置文件</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">    xsync conf </span><br><span class="line">    ```    </span><br><span class="line">5. 重新启动集群和历史服务</span><br><span class="line">    ```bash</span><br><span class="line">    sbin/stop-all.sh</span><br><span class="line">    sbin/start-all.sh</span><br><span class="line">    sbin/start-history-server.sh</span><br></pre></td></tr></table></figure></li>
<li><p>重新执行任务</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master spark://bd-server-001:7077 \</span><br><span class="line">./examples/jars/spark-examples_2.12-3.0.0.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></figure>
<p> <img src="https://s2.loli.net/2021/12/11/CO3ZQe7rWwEvb1R.jpg"></p>
</li>
<li><p>查看历史服务：<a target="_blank" rel="noopener" href="http://bd-server-001:18080/">http://bd-server-001:18080</a><br> <img src="https://s2.loli.net/2021/12/11/j1xLsnyQ6hGpIlt.jpg"></p>
</li>
</ol>
<h3 id="3-2-7-配置高可用（HA）"><a href="#3-2-7-配置高可用（HA）" class="headerlink" title="3.2.7 配置高可用（HA）"></a>3.2.7 配置高可用（HA）</h3><p>所谓的高可用是因为当前集群中的Master节点只有一个，所以会存在单点故障问题。所以为了解决单点故障问题，需要在集群中配置多个Master节点，一旦处于活动状态的Master发生故障时，由备用Master提供服务，保证作业可以继续执行。这里的高可用一般采用Zookeeper设置<br>集群规划:<br>|      |Linux1     |Linux2    |Linux3  |<br>|—-|———|——-|———|<br>|Spark|    <font color ='red' >Master</font><br><font color ='blue' >Zookeeper</font><br>Worker|<font color ='red' >Master</font><br><font color ='blue' >Zookeeper</font><br>Worker|<br><font color ='blue' >Zookeeper</font><br>Worker|</p>
<ol>
<li><p>停止集群</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/stop-all.sh </span><br></pre></td></tr></table></figure></li>
<li><p>启动Zookeeper</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zookeeper_cluster.sh status</span><br></pre></td></tr></table></figure></li>
<li><p>修改spark-env.sh文件添加如下配置</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">注释如下内容：</span><br><span class="line"><span class="comment">#SPARK_MASTER_HOST=linux1</span></span><br><span class="line"><span class="comment">#SPARK_MASTER_PORT=7077</span></span><br><span class="line"></span><br><span class="line">添加如下内容:</span><br><span class="line"><span class="comment">#Master监控页面默认访问端口为8080，但是可能会和Zookeeper冲突，所以改成8989，也可以自定义，访问UI监控页面时请注意</span></span><br><span class="line">SPARK_MASTER_WEBUI_PORT=8989</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> SPARK_DAEMON_JAVA_OPTS=<span class="string">&quot;</span></span><br><span class="line"><span class="string">-Dspark.deploy.recoveryMode=ZOOKEEPER </span></span><br><span class="line"><span class="string">-Dspark.deploy.zookeeper.url=linux1,linux2,linux3 </span></span><br><span class="line"><span class="string">-Dspark.deploy.zookeeper.dir=/spark&quot;</span></span><br></pre></td></tr></table></figure></li>
<li><p>分发配置文件</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync conf/ </span><br></pre></td></tr></table></figure></li>
<li><p>启动集群</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-all.sh</span><br></pre></td></tr></table></figure>
<p> <img src="https://s2.loli.net/2021/12/11/JjywVYhLs78W3KT.jpg"></p>
</li>
<li><p>启动bd-server-002和bd-server-003的单独Master节点，这两个节点Master状态处于备用状态</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-master.sh</span><br></pre></td></tr></table></figure>
<p> <img src="https://s2.loli.net/2021/12/11/h69zTQAvVymeWZd.jpg"><br> <img src="https://s2.loli.net/2021/12/11/cm9lpOiIdFLvUCQ.jpg"></p>
</li>
<li><p>提交应用到高可用集群</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master spark://bd-server-001:7077,bd-server-002:7077,bd-server-003:7077 \</span><br><span class="line">./examples/jars/spark-examples_2.12-3.0.0.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></figure></li>
<li><p>停止linux1的Master资源监控进程</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@bd-server-001 spark-standalone]$ jps</span><br><span class="line">48129 JournalNode</span><br><span class="line">48466 ResourceManager</span><br><span class="line">47557 QuorumPeerMain</span><br><span class="line">49861 Worker</span><br><span class="line">49957 HistoryServer</span><br><span class="line">50405 Jps</span><br><span class="line">48569 NodeManager</span><br><span class="line">48378 DFSZKFailoverController</span><br><span class="line">47902 DataNode</span><br><span class="line">49758 Master</span><br><span class="line">47775 NameNode</span><br><span class="line">[atguigu@bd-server-001 spark-standalone]$ <span class="built_in">kill</span> -9 49758</span><br><span class="line">[atguigu@bd-server-001 spark-standalone]$</span><br></pre></td></tr></table></figure></li>
<li><p>查看linux2的Master 资源监控Web UI，稍等一段时间后，linux2节点的Master状态提升为活动状态<br> <img src="https://s2.loli.net/2021/12/11/kslxS6FLeTvny7d.jpg"></p>
</li>
</ol>
<h2 id="3-3-Yarn模式"><a href="#3-3-Yarn模式" class="headerlink" title="3.3  Yarn模式"></a>3.3  Yarn模式</h2><p>独立部署（Standalone）模式由Spark自身提供计算资源，无需其他框架提供资源。这种方式降低了和其他第三方资源框架的耦合性，独立性非常强。但是你也要记住，Spark主要是计算框架，而不是资源调度框架，所以本身提供的资源调度并不是它的强项，所以还是和其他专业的资源调度框架集成会更靠谱一些。所以接下来我们来学习在强大的Yarn环境下Spark是如何工作的（其实是因为在国内工作中，Yarn使用的非常多）。</p>
<h3 id="3-3-1-解压缩文件"><a href="#3-3-1-解压缩文件" class="headerlink" title="3.3.1 解压缩文件"></a>3.3.1 解压缩文件</h3><p>将spark-3.0.0-bin-hadoop3.2.tgz文件上传到linux并解压缩，放置在指定位置。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf spark-3.0.0-bin-hadoop3.2.tgz -C /opt/module</span><br><span class="line"><span class="built_in">cd</span> /opt/module </span><br><span class="line">mv spark-3.0.0-bin-hadoop3.2 spark-yarn</span><br></pre></td></tr></table></figure>


<h3 id="3-3-2-修改配置文件"><a href="#3-3-2-修改配置文件" class="headerlink" title="3.3.2 修改配置文件"></a>3.3.2 修改配置文件</h3><ol>
<li>修改hadoop配置文件/opt/module/hadoop/etc/hadoop/yarn-site.xml, 并分发 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<ol start="2">
<li>修改conf/spark-env.sh，添加JAVA_HOME和YARN_CONF_DIR配置 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mv spark-env.sh.template spark-env.sh</span><br><span class="line"></span><br><span class="line">export <span class="type">JAVA_HOME</span>=/opt/module/jdk1<span class="number">.8</span><span class="number">.0</span>_144</span><br><span class="line"><span class="type">YARN_CONF_DIR</span>=/opt/module/hadoop/etc/hadoop</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="3-3-3-启动HDFS以及YARN集群"><a href="#3-3-3-启动HDFS以及YARN集群" class="headerlink" title="3.3.3 启动HDFS以及YARN集群"></a>3.3.3 启动HDFS以及YARN集群</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zookeeper_cluster.sh start</span><br><span class="line">hadoop_cluster.sh start</span><br></pre></td></tr></table></figure>


<h3 id="3-3-4-提交应用"><a href="#3-3-4-提交应用" class="headerlink" title="3.3.4 提交应用"></a>3.3.4 提交应用</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--<span class="class"><span class="keyword">class</span> <span class="title">org</span>.<span class="title">apache</span>.<span class="title">spark</span>.<span class="title">examples</span>.<span class="title">SparkPi</span> <span class="title">\</span></span></span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">./examples/jars/spark-examples_2<span class="number">.12</span><span class="number">-3.0</span><span class="number">.0</span>.jar \</span><br><span class="line"><span class="number">10</span></span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/01/22/MkZTrcbmLfIdSj4.jpg"><br><img src="https://s2.loli.net/2022/01/22/4hMIgeWRdzQm3c6.jpg"></p>
<p>查看<a href="http://linux2:8088页面，点击History，查看历史页面">http://linux2:8088页面，点击History，查看历史页面</a><br><img src="https://s2.loli.net/2022/01/22/jesMriWz34o8StZ.jpg"><br><img src="https://s2.loli.net/2022/01/22/YfSAyeEh6XKcgrj.jpg"></p>
<h3 id="3-3-5-配置历史服务器"><a href="#3-3-5-配置历史服务器" class="headerlink" title="3.3.5 配置历史服务器"></a>3.3.5 配置历史服务器</h3><ol>
<li><p>修改spark-defaults.conf.template文件名为spark-defaults.conf</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv spark-defaults.conf.template spark-defaults.conf</span><br></pre></td></tr></table></figure></li>
<li><p>修改spark-default.conf文件，配置日志存储路径</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.eventLog.enabled          <span class="literal">true</span></span><br><span class="line">spark.eventLog.dir               hdfs:<span class="comment">//linux1:8020/directory</span></span><br></pre></td></tr></table></figure>
<p> 注意：需要启动hadoop集群，HDFS上的目录需要提前存在。</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@linux1 hadoop]<span class="comment"># sbin/start-dfs.sh</span></span><br><span class="line">[root@linux1 hadoop]<span class="comment"># hadoop fs -mkdir /directory</span></span><br></pre></td></tr></table></figure></li>
<li><p>修改spark-env.sh文件, 添加日志配置</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export <span class="type">SPARK_HISTORY_OPTS</span>=<span class="string">&quot;</span></span><br><span class="line"><span class="string">-Dspark.history.ui.port=18080 </span></span><br><span class="line"><span class="string">-Dspark.history.fs.logDirectory=hdfs://linux1:8020/directory </span></span><br><span class="line"><span class="string">-Dspark.history.retainedApplications=30&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>参数1含义：WEB UI访问的端口号为18080</li>
<li>参数2含义：指定历史服务器日志存储路径</li>
<li>参数3含义：指定保存Application历史记录的个数，如果超过这个值，旧的应用程序信息将被删除，这个是内存中的应用数，而不是页面上显示的应用数。</li>
</ul>
</li>
<li><p>修改spark-defaults.conf</p>
 <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spark.yarn.historyServer.address</span>=linux1:<span class="number">18080</span></span><br><span class="line"><span class="attr">spark.history.ui.port</span>=<span class="number">18080</span></span><br></pre></td></tr></table></figure></li>
<li><p>启动历史服务</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-history-server.sh </span><br></pre></td></tr></table></figure></li>
<li><p>重新提交应用</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode client \</span><br><span class="line">./examples/jars/spark-examples_2.12-3.0.0.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></figure>
<p> <img src="https://s2.loli.net/2022/01/22/YgUQu7FEVz9JTP2.jpg"><br> <img src="https://s2.loli.net/2022/01/22/bihJcluITaWKwA2.jpg"></p>
</li>
<li><p>Web页面查看日志：<a target="_blank" rel="noopener" href="http://linux2:8088/">http://linux2:8088</a><br> <img src="https://s2.loli.net/2022/01/22/BDFdKT2ocOu3x71.jpg"><br> <img src="https://s2.loli.net/2022/01/22/MdyXW6Kks5AJTEp.jpg"></p>
</li>
</ol>
<h2 id="3-4-K8S-amp-Mesos模式"><a href="#3-4-K8S-amp-Mesos模式" class="headerlink" title="3.4  K8S &amp; Mesos模式"></a>3.4  K8S &amp; Mesos模式</h2><p>Mesos是Apache下的开源分布式资源管理框架，它被称为是分布式系统的内核,在Twitter得到广泛使用,管理着Twitter超过30,0000台服务器上的应用部署，但是在国内，依然使用着传统的Hadoop大数据框架，所以国内使用Mesos框架的并不多，但是原理都差不多。</p>
<p>容器化部署是目前业界很流行的一项技术，基于Docker镜像运行能够让用户更加方便地对应用进行管理和运维。容器管理工具中最为流行的就是Kubernetes（k8s），而Spark也在最近的版本中支持了k8s部署模式。这里我们也不做过多的讲解。给个链接大家自己感受一下：<a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/running-on-kubernetes.html">https://spark.apache.org/docs/latest/running-on-kubernetes.html</a></p>
<h2 id="3-5-本地模式"><a href="#3-5-本地模式" class="headerlink" title="3.5  本地模式"></a>3.5  本地模式</h2><p>在同学们自己学习时，每次都需要启动虚拟机，启动集群，这是一个比较繁琐的过程，并且会占大量的系统资源，导致系统执行变慢，不仅仅影响学习效果，也影响学习进度，Spark非常暖心地提供了可以在本地操作系统下启动本地集群的方式，这样，在不使用虚拟机的情况下，也能学习Spark的基本使用</p>
<h2 id="3-5-1-解压缩文件"><a href="#3-5-1-解压缩文件" class="headerlink" title="3.5.1 解压缩文件"></a>3.5.1 解压缩文件</h2><p>将文件spark-3.0.0-bin-hadoop3.2.tgz解压缩到无中文无空格的路径中</p>
<h3 id="3-5-2-启动本地环境"><a href="#3-5-2-启动本地环境" class="headerlink" title="3.5.2 启动本地环境"></a>3.5.2 启动本地环境</h3><ol>
<li>执行解压缩文件路径下bin目录中的spark-shell文件，启动Spark本地环境 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&gt;bin  ./spark-shell</span><br><span class="line">CMD /Library/Java/JavaVirtualMachines/jdk1.8.0_291.jdk/Contents/Home//bin/java</span><br><span class="line">/Library/Java/JavaVirtualMachines/jdk1.8.0_291.jdk/Contents/Home//bin/java -cp /Users/zhenan/app/spark-3.0.0-bin-hadoop3.2/conf/:/Users/zhenan/app/spark-3.0.0-bin-hadoop3.2/jars/* -Dscala.usejavacp=<span class="literal">true</span> -Xmx1g org.apache.spark.deploy.SparkSubmit --class org.apache.spark.repl.Main --name Spark shell spark-shell</span><br><span class="line">21/12/18 20:44:00 WARN NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes <span class="built_in">where</span> applicable</span><br><span class="line">Using Spark<span class="string">&#x27;s default log4j profile: org/apache/spark/log4j-defaults.properties</span></span><br><span class="line"><span class="string">Setting default log level to &quot;WARN&quot;.</span></span><br><span class="line"><span class="string">To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).</span></span><br><span class="line"><span class="string">Spark context Web UI available at http://bogon:4040</span></span><br><span class="line"><span class="string">Spark context available as &#x27;</span>sc<span class="string">&#x27; (master = local[*], app id = local-1639831450687).</span></span><br><span class="line"><span class="string">Spark session available as &#x27;</span>spark<span class="string">&#x27;.</span></span><br><span class="line"><span class="string">Welcome to</span></span><br><span class="line"><span class="string">      ____              __</span></span><br><span class="line"><span class="string">     / __/__  ___ _____/ /__</span></span><br><span class="line"><span class="string">    _\ \/ _ \/ _ `/ __/  &#x27;</span>_/</span><br><span class="line">   /___/ .__/\_,_/_/ /_/\_\   version 3.0.0</span><br><span class="line">      /_/</span><br><span class="line"></span><br><span class="line">Using Scala version 2.12.10 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_291)</span><br><span class="line">Type <span class="keyword">in</span> expressions to have them evaluated.</span><br><span class="line">Type :<span class="built_in">help</span> <span class="keyword">for</span> more information.</span><br><span class="line"></span><br><span class="line">scala</span><br></pre></td></tr></table></figure></li>
<li>在bin目录中创建input目录，并添加word.txt文件, 在命令行中输入脚本代码 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)).map(_+<span class="number">1</span>).collect()</span><br><span class="line">res1: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">scala&gt;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="3-5-3-命令行提交应用"><a href="#3-5-3-命令行提交应用" class="headerlink" title="3.5.3 命令行提交应用"></a>3.5.3 命令行提交应用</h3><p>在命令行窗口中执行提交指令</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">☁  bin  ./spark-submit --<span class="class"><span class="keyword">class</span> <span class="title">org</span>.<span class="title">apache</span>.<span class="title">spark</span>.<span class="title">examples</span>.<span class="title">SparkPi</span> <span class="title">--master</span> &#x27;<span class="title">local</span>[2]&#x27; ..<span class="title">/examples/jars/spark-examples_2</span>.12<span class="title">-3</span>.0.0.<span class="title">jar</span> 10</span></span><br><span class="line"><span class="type">CMD</span> /<span class="type">Library</span>/<span class="type">Java</span>/<span class="type">JavaVirtualMachines</span>/jdk1<span class="number">.8</span><span class="number">.0</span>_291.jdk/<span class="type">Contents</span>/<span class="type">Home</span><span class="comment">//bin/java</span></span><br><span class="line">/<span class="type">Library</span>/<span class="type">Java</span>/<span class="type">JavaVirtualMachines</span>/jdk1<span class="number">.8</span><span class="number">.0</span>_291.jdk/<span class="type">Contents</span>/<span class="type">Home</span><span class="comment">//bin/java -cp /Users/zhenan/app/spark-3.0.0-bin-hadoop3.2/conf/:/Users/zhenan/app/spark-3.0.0-bin-hadoop3.2/jars/* -Xmx1g org.apache.spark.deploy.SparkSubmit --master local[2] --class org.apache.spark.examples.SparkPi ../examples/jars/spark-examples_2.12-3.0.0.jar 10</span></span><br><span class="line"><span class="number">21</span>/<span class="number">12</span>/<span class="number">18</span> <span class="number">20</span>:<span class="number">47</span>:<span class="number">19</span> <span class="type">WARN</span> <span class="type">NativeCodeLoader</span>: <span class="type">Unable</span> to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes where applicable</span><br><span class="line"><span class="type">Using</span> <span class="type">Spark</span><span class="symbol">&#x27;s</span> <span class="keyword">default</span> log4j profile: org/apache/spark/log4j-defaults.properties</span><br><span class="line"><span class="number">21</span>/<span class="number">12</span>/<span class="number">18</span> <span class="number">20</span>:<span class="number">47</span>:<span class="number">20</span> <span class="type">INFO</span> <span class="type">SparkContext</span>: <span class="type">Running</span> <span class="type">Spark</span> version <span class="number">3.0</span><span class="number">.0</span></span><br><span class="line"><span class="number">21</span>/<span class="number">12</span>/<span class="number">18</span> <span class="number">20</span>:<span class="number">47</span>:<span class="number">20</span> <span class="type">INFO</span> <span class="type">ResourceUtils</span>: ==============================================================</span><br><span class="line"><span class="number">21</span>/<span class="number">12</span>/<span class="number">18</span> <span class="number">20</span>:<span class="number">47</span>:<span class="number">20</span> <span class="type">INFO</span> <span class="type">ResourceUtils</span>: <span class="type">Resources</span> <span class="keyword">for</span> spark.driver:</span><br><span class="line">。。。</span><br><span class="line">。。。</span><br><span class="line">。。。</span><br><span class="line"><span class="type">Pi</span> is roughly <span class="number">3.140919140919141</span></span><br><span class="line"><span class="number">21</span>/<span class="number">12</span>/<span class="number">18</span> <span class="number">20</span>:<span class="number">47</span>:<span class="number">23</span> <span class="type">INFO</span> <span class="type">SparkUI</span>: <span class="type">Stopped</span> <span class="type">Spark</span> web <span class="type">UI</span> at http:<span class="comment">//bogon:4040</span></span><br><span class="line"><span class="number">21</span>/<span class="number">12</span>/<span class="number">18</span> <span class="number">20</span>:<span class="number">47</span>:<span class="number">23</span> <span class="type">INFO</span> <span class="type">MapOutputTrackerMasterEndpoint</span>: <span class="type">MapOutputTrackerMasterEndpoint</span> stopped!</span><br><span class="line"><span class="number">21</span>/<span class="number">12</span>/<span class="number">18</span> <span class="number">20</span>:<span class="number">47</span>:<span class="number">23</span> <span class="type">INFO</span> <span class="type">MemoryStore</span>: <span class="type">MemoryStore</span> cleared</span><br><span class="line"><span class="number">21</span>/<span class="number">12</span>/<span class="number">18</span> <span class="number">20</span>:<span class="number">47</span>:<span class="number">23</span> <span class="type">INFO</span> <span class="type">BlockManager</span>: <span class="type">BlockManager</span> stopped</span><br><span class="line"><span class="number">21</span>/<span class="number">12</span>/<span class="number">18</span> <span class="number">20</span>:<span class="number">47</span>:<span class="number">23</span> <span class="type">INFO</span> <span class="type">BlockManagerMaster</span>: <span class="type">BlockManagerMaster</span> stopped</span><br><span class="line"><span class="number">21</span>/<span class="number">12</span>/<span class="number">18</span> <span class="number">20</span>:<span class="number">47</span>:<span class="number">23</span> <span class="type">INFO</span> <span class="type">OutputCommitCoordinator</span>$<span class="type">OutputCommitCoordinatorEndpoint</span>: <span class="type">OutputCommitCoordinator</span> stopped!</span><br><span class="line"><span class="number">21</span>/<span class="number">12</span>/<span class="number">18</span> <span class="number">20</span>:<span class="number">47</span>:<span class="number">23</span> <span class="type">INFO</span> <span class="type">SparkContext</span>: <span class="type">Successfully</span> stopped <span class="type">SparkContext</span></span><br><span class="line"><span class="number">21</span>/<span class="number">12</span>/<span class="number">18</span> <span class="number">20</span>:<span class="number">47</span>:<span class="number">23</span> <span class="type">INFO</span> <span class="type">ShutdownHookManager</span>: <span class="type">Shutdown</span> hook called</span><br><span class="line"><span class="number">21</span>/<span class="number">12</span>/<span class="number">18</span> <span class="number">20</span>:<span class="number">47</span>:<span class="number">23</span> <span class="type">INFO</span> <span class="type">ShutdownHookManager</span>: <span class="type">Deleting</span> directory /<span class="keyword">private</span>/<span class="keyword">var</span>/folders/__/y015x_9s237711b3mcmf0t1c0000gn/<span class="type">T</span>/spark<span class="number">-49</span>b55761-b06e<span class="number">-43</span>a8<span class="number">-89</span>d3-f6ae77ed8e45</span><br><span class="line"><span class="number">21</span>/<span class="number">12</span>/<span class="number">18</span> <span class="number">20</span>:<span class="number">47</span>:<span class="number">23</span> <span class="type">INFO</span> <span class="type">ShutdownHookManager</span>: <span class="type">Deleting</span> directory /<span class="keyword">private</span>/<span class="keyword">var</span>/folders/__/y015x_9s237711b3mcmf0t1c0000gn/<span class="type">T</span>/spark<span class="number">-3</span>ec7edc0-eca2<span class="number">-4003</span>-ad13<span class="number">-6</span>febbc651e59</span><br></pre></td></tr></table></figure>

<h2 id="3-6-部署模式对比"><a href="#3-6-部署模式对比" class="headerlink" title="3.6  部署模式对比"></a>3.6  部署模式对比</h2><table>
<thead>
<tr>
<th>模式</th>
<th>Spark安装机器数</th>
<th>需启动的进程</th>
<th>所属者</th>
<th>应用场景</th>
</tr>
</thead>
<tbody><tr>
<td>Local</td>
<td>1</td>
<td>无</td>
<td>Spark</td>
<td>测试</td>
</tr>
<tr>
<td>Standalone</td>
<td>3</td>
<td>Master及Worker</td>
<td>Spark</td>
<td>单独部署</td>
</tr>
<tr>
<td>Yarn</td>
<td>1</td>
<td>Yarn及HDFS</td>
<td>Hadoop</td>
<td>混合部署</td>
</tr>
</tbody></table>
<h2 id="3-7-端口号"><a href="#3-7-端口号" class="headerlink" title="3.7  端口号"></a>3.7  端口号</h2><ul>
<li>Spark查看当前Spark-shell运行任务情况端口号：4040（计算）</li>
<li>Spark Master内部通信服务端口号：7077</li>
<li>Standalone模式下，Spark Master Web端口号：8080（资源）</li>
<li>Spark历史服务器端口号：18080</li>
<li>Hadoop YARN任务运行情况查看端口号：8088</li>
</ul>
<h1 id="第4章-Spark运行架构"><a href="#第4章-Spark运行架构" class="headerlink" title="第4章 Spark运行架构"></a>第4章 Spark运行架构</h1><h2 id="4-1-运行架构"><a href="#4-1-运行架构" class="headerlink" title="4.1 运行架构"></a>4.1 运行架构</h2><p>Spark框架的核心是一个计算引擎，整体来说，它采用了标准 master-slave 的结构。<br>如下图所示，它展示了一个 Spark执行时的基本结构。图形中的Driver表示master，负责管理整个集群中的作业任务调度。图形中的Executor 则是 slave，负责实际执行任务。<br><img src="https://s2.loli.net/2021/12/11/BjZFPrvakJHNEhI.jpg"></p>
<h2 id="4-2-核心组件"><a href="#4-2-核心组件" class="headerlink" title="4.2 核心组件"></a>4.2 核心组件</h2><p>由上图可以看出，对于Spark框架有两个核心组件：Driver和Executor</p>
<h3 id="4-2-1-Driver"><a href="#4-2-1-Driver" class="headerlink" title="4.2.1 Driver"></a>4.2.1 Driver</h3><p>Spark驱动器节点，用于执行Spark任务中的main方法，负责实际代码的执行工作。Driver在Spark作业执行时主要负责：</p>
<ul>
<li>将用户程序转化为作业（job）</li>
<li>在Executor之间调度任务(task)</li>
<li>跟踪Executor的执行情况</li>
<li>通过UI展示查询运行情况<br>实际上，我们无法准确地描述Driver的定义，因为在整个的编程过程中没有看到任何有关Driver的字眼。所以简单理解，所谓的Driver就是驱使整个应用运行起来的程序，也称之为Driver类。</li>
</ul>
<h3 id="4-2-2-Executor"><a href="#4-2-2-Executor" class="headerlink" title="4.2.2 Executor"></a>4.2.2 Executor</h3><p>Spark Executor是集群中工作节点（Worker）中的一个JVM进程，负责在 Spark 作业中运行具体任务（Task），任务彼此之间相互独立。Spark 应用启动时，Executor节点被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。如果有Executor节点发生了故障或崩溃，Spark 应用也可以继续执行，会将出错节点上的任务调度到其他Executor节点上继续运行。<br>Executor有两个核心功能：</p>
<ul>
<li>负责运行组成Spark应用的任务，并将结果返回给驱动器进程</li>
<li>它们通过自身的块管理器（Block Manager）为用户程序中要求缓存的 RDD 提供内存式存储。RDD 是直接缓存在Executor进程内的，因此任务可以在运行时充分利用缓存数据加速运算。</li>
</ul>
<h3 id="4-2-3-Master-amp-Worker"><a href="#4-2-3-Master-amp-Worker" class="headerlink" title="4.2.3 Master &amp; Worker"></a>4.2.3 Master &amp; Worker</h3><p>Spark集群的独立部署环境中，不需要依赖其他的资源调度框架，自身就实现了资源调度的功能，所以环境中还有其他两个核心组件：Master和Worker，这里的Master是一个进程，主要负责资源的调度和分配，并进行集群的监控等职责，类似于Yarn环境中的RM, 而Worker呢，也是进程，一个Worker运行在集群中的一台服务器上，由Master分配资源对数据进行并行的处理和计算，类似于Yarn环境中NM。</p>
<h3 id="4-2-4-ApplicationMaster"><a href="#4-2-4-ApplicationMaster" class="headerlink" title="4.2.4 ApplicationMaster"></a>4.2.4 ApplicationMaster</h3><p>Hadoop用户向YARN集群提交应用程序时,提交程序中应该包含ApplicationMaster，用于向资源调度器申请执行任务的资源容器Container，运行用户自己的程序任务job，监控整个任务的执行，跟踪整个任务的状态，处理任务失败等异常情况。<br>说的简单点就是，ResourceManager（资源）和Driver（计算）之间的解耦合靠的就是ApplicationMaster。</p>
<h2 id="4-3-核心概念"><a href="#4-3-核心概念" class="headerlink" title="4.3 核心概念"></a>4.3 核心概念</h2><h3 id="4-3-1-Executor与Core（核）"><a href="#4-3-1-Executor与Core（核）" class="headerlink" title="4.3.1 Executor与Core（核）"></a>4.3.1 Executor与Core（核）</h3><p>Spark Executor是集群中运行在工作节点（Worker）中的一个JVM进程，是整个集群中的专门用于计算的节点。在提交应用中，可以提供参数指定计算节点的个数，以及对应的资源。这里的资源一般指的是工作节点Executor的内存大小和使用的虚拟CPU核（Core）数量。</p>
<p>应用程序相关启动参数如下：<br>|名称                  |   说明                      |<br>|——————-|—————————-|<br>|–num-executors      |配置Executor的数量                   |<br>|–executor-memory  |    配置每个Executor的内存大小         |<br>|–executor-cores      |配置每个Executor的虚拟CPU core数量      |</p>
<h3 id="4-3-2-并行度（Parallelism）"><a href="#4-3-2-并行度（Parallelism）" class="headerlink" title="4.3.2 并行度（Parallelism）"></a>4.3.2 并行度（Parallelism）</h3><p>在分布式计算框架中一般都是多个任务同时执行，由于任务分布在不同的计算节点进行计算，所以能够真正地实现多任务并行执行，记住，这里是并行，而不是并发。这里我们将整个集群并行执行任务的数量称之为并行度。那么一个作业到底并行度是多少呢？这个取决于框架的默认配置。应用程序也可以在运行过程中动态修改。</p>
<h3 id="4-3-3-有向无环图（DAG）"><a href="#4-3-3-有向无环图（DAG）" class="headerlink" title="4.3.3 有向无环图（DAG）"></a>4.3.3 有向无环图（DAG）</h3><p>大数据计算引擎框架我们根据使用方式的不同一般会分为四类，其中第一类就是Hadoop所承载的MapReduce,它将计算分为两个阶段，分别为 Map阶段 和 Reduce阶段。对于上层应用来说，就不得不想方设法去拆分算法，甚至于不得不在上层应用实现多个 Job 的串联，以完成一个完整的算法，例如迭代计算。 由于这样的弊端，催生了支持 DAG 框架的产生。因此，支持 DAG 的框架被划分为第二代计算引擎。如 Tez 以及更上层的 Oozie。这里我们不去细究各种 DAG 实现之间的区别，不过对于当时的 Tez 和 Oozie 来说，大多还是批处理的任务。接下来就是以 Spark 为代表的第三代的计算引擎。第三代计算引擎的特点主要是 Job 内部的 DAG 支持（不跨越 Job），以及实时计算。<br>这里所谓的有向无环图，并不是真正意义的图形，而是由Spark程序直接映射成的数据流的高级抽象模型。简单理解就是将整个程序计算的执行过程用图形表示出来,这样更直观，更便于理解，可以用于表示程序的拓扑结构。<br>DAG（Directed Acyclic Graph）有向无环图是由点和线组成的拓扑图形，该图形具有方向，不会闭环。</p>
<h3 id="4-4-提交流程"><a href="#4-4-提交流程" class="headerlink" title="4.4 提交流程"></a>4.4 提交流程</h3><p>所谓的提交流程，其实就是我们开发人员根据需求写的应用程序通过Spark客户端提交给Spark运行环境执行计算的流程。在不同的部署环境中，这个提交过程基本相同，但是又有细微的区别，我们这里不进行详细的比较，但是因为国内工作中，将Spark引用部署到Yarn环境中会更多一些，所以本课程中的提交流程是基于Yarn环境的。</p>
<p>Spark应用程序提交到Yarn环境中执行的时候，一般会有两种部署执行的方式：Client和Cluster。两种模式主要区别在于：Driver程序的运行节点位置。</p>
<h3 id="4-2-1-Yarn-Client模式"><a href="#4-2-1-Yarn-Client模式" class="headerlink" title="4.2.1 Yarn Client模式"></a>4.2.1 Yarn Client模式</h3><p>Client模式将用于监控和调度的Driver模块在客户端执行，而不是在Yarn中，所以一般用于测试。</p>
<ul>
<li>Driver在任务提交的本地机器上运行</li>
<li>Driver启动后会和ResourceManager通讯申请启动ApplicationMaster</li>
<li>ResourceManager分配container，在合适的NodeManager上启动ApplicationMaster，负责向ResourceManager申请Executor内存</li>
<li>ResourceManager接到ApplicationMaster的资源申请后会分配container，然后ApplicationMaster在资源分配指定的NodeManager上启动Executor进程</li>
<li>Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数</li>
<li>之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分stage，每个stage生成对应的TaskSet，之后将task分发到各个Executor上执行。</li>
</ul>
<h3 id="4-2-2-Yarn-Cluster模式"><a href="#4-2-2-Yarn-Cluster模式" class="headerlink" title="4.2.2 Yarn Cluster模式"></a>4.2.2 Yarn Cluster模式</h3><p>Cluster模式将用于监控和调度的Driver模块启动在Yarn集群资源中执行。一般应用于实际生产环境。</p>
<ul>
<li>在YARN Cluster模式下，任务提交后会和ResourceManager通讯申请启动ApplicationMaster，</li>
<li>随后ResourceManager分配container，在合适的NodeManager上启动ApplicationMaster，此时的ApplicationMaster就是Driver。</li>
<li>Driver启动后向ResourceManager申请Executor内存，ResourceManager接到ApplicationMaster的资源申请后会分配container，然后在合适的NodeManager上启动Executor进程</li>
<li>Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数，</li>
<li>之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分stage，每个stage生成对应的TaskSet，之后将task分发到各个Executor上执行。</li>
</ul>
<h1 id="第5章-Spark核心编程"><a href="#第5章-Spark核心编程" class="headerlink" title="第5章 Spark核心编程"></a>第5章 Spark核心编程</h1><p>Spark计算框架为了能够进行高并发和高吞吐的数据处理，封装了三大数据结构，用于处理不同的应用场景。三大数据结构分别是：</p>
<ul>
<li>RDD : 弹性分布式数据集</li>
<li>累加器：分布式共享只写变量</li>
<li>广播变量：分布式共享只读变量</li>
</ul>
<h2 id="5-1-RDD"><a href="#5-1-RDD" class="headerlink" title="5.1 RDD"></a>5.1 RDD</h2><h3 id="5-1-1-什么是RDD"><a href="#5-1-1-什么是RDD" class="headerlink" title="5.1.1 什么是RDD"></a>5.1.1 什么是RDD</h3><p>RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据处理模型。代码中是一个抽象类，它代表一个弹性的、不可变、可分区、里面的元素可并行计算的集合。</p>
<ul>
<li>弹性<ul>
<li>存储的弹性：内存与磁盘的自动切换；</li>
<li>容错的弹性：数据丢失可以自动恢复；</li>
<li>计算的弹性：计算出错重试机制；</li>
<li>分片的弹性：可根据需要重新分片。</li>
</ul>
</li>
<li>分布式：数据存储在大数据集群不同节点上</li>
<li>数据集：RDD封装了计算逻辑，只处理数据，并不保存数据</li>
<li>数据抽象：RDD是一个抽象类，需要子类具体实现</li>
<li>不可变：RDD封装了计算逻辑，是不可以改变的，想要改变，只能产生新的RDD，在新的RDD里面封装计算逻辑</li>
<li>可分区、并行计算</li>
</ul>
<h3 id="5-1-2-核心属性"><a href="#5-1-2-核心属性" class="headerlink" title="5.1.2 核心属性"></a>5.1.2 核心属性</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">* Internally, each RDD is characterized by five main properties:</span><br><span class="line">*</span><br><span class="line">*  分区列表 - A list of partitions</span><br><span class="line">*  分区计算函数 - A function for computing each split  </span><br><span class="line">*  RDD之间的依赖关系 - A list of dependencies on other RDDs  </span><br><span class="line">*  分区器（可选） - Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)  </span><br><span class="line">*  首选位置（可选） - Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)           </span><br></pre></td></tr></table></figure>

<ul>
<li><p>分区列表<br>  RDD数据结构中存在分区列表，用于执行任务时并行计算，是实现分布式计算的重要属性。</p>
  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Implemented by subclasses to return the set of partitions in this RDD. This method will only</span></span><br><span class="line"><span class="comment"> * be called once, so it is safe to implement a time-consuming computation in it.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * The partitions in this array must satisfy the following property:</span></span><br><span class="line"><span class="comment"> *   `rdd.partitions.zipWithIndex.forall &#123; case (partition, index) =&gt; partition.index == index &#125;`</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">getPartitions</span></span>: <span class="type">Array</span>[<span class="type">Partition</span>]</span><br></pre></td></tr></table></figure></li>
<li><p>分区计算函数<br>  Spark在计算时，是使用分区函数对每一个分区进行计算</p>
  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * :: DeveloperApi ::</span></span><br><span class="line"><span class="comment"> * Implemented by subclasses to compute a given partition.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@DeveloperApi</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(split: <span class="type">Partition</span>, context: <span class="type">TaskContext</span>): <span class="type">Iterator</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></li>
<li><p>RDD之间的依赖关系<br>  RDD是计算模型的封装，当需求中需要将多个计算模型进行组合时，就需要将多个RDD建立依赖关系</p>
  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Implemented by subclasses to return how this RDD depends on parent RDDs. This method will only</span></span><br><span class="line"><span class="comment"> * be called once, so it is safe to implement a time-consuming computation in it.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">getDependencies</span></span>: <span class="type">Seq</span>[<span class="type">Dependency</span>[_]] = deps</span><br></pre></td></tr></table></figure></li>
<li><p>分区器（可选）<br>  当数据为KV类型数据时，可以通过设定分区器自定义数据的分区</p>
  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Optionally overridden by subclasses to specify how they are partitioned. */</span></span><br><span class="line"><span class="meta">@transient</span> <span class="keyword">val</span> partitioner: <span class="type">Option</span>[<span class="type">Partitioner</span>] = <span class="type">None</span></span><br></pre></td></tr></table></figure></li>
<li><p>首选位置（可选）</p>
<ul>
<li>计算数据时，可以根据计算节点的状态选择不同的节点位置进行计算  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Optionally overridden by subclasses to specify placement preferences.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">getPreferredLocations</span></span>(split: <span class="type">Partition</span>): <span class="type">Seq</span>[<span class="type">String</span>] = <span class="type">Nil</span></span><br></pre></td></tr></table></figure></li>
<li>数据计算本地化<ul>
<li>进程本地化：数据和计算在同一个进程中</li>
<li>节点本地化：数据和计算在同一个节点中</li>
<li>机架本地化：数据和计算在同一个机架中</li>
<li>任意：数据和计算在不同的任意节点</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="5-1-3-执行原理"><a href="#5-1-3-执行原理" class="headerlink" title="5.1.3 执行原理"></a>5.1.3 执行原理</h3><p>从计算的角度来讲，数据处理过程中需要计算资源（内存 &amp; CPU）和计算模型（逻辑）。执行时，需要将计算资源和计算模型进行协调和整合。<br>Spark框架在执行时，先申请资源，然后将应用程序的数据处理逻辑分解成一个一个的计算任务。然后将任务发到已经分配资源的计算节点上, 按照指定的计算模型进行数据计算。最后得到计算结果。<br>RDD是Spark框架中用于数据处理的核心模型，接下来我们看看，在Yarn环境中，RDD的工作原理:</p>
<ol>
<li>启动Yarn集群环境<pre><code> ![](https://s2.loli.net/2021/12/11/TRiUEOMQtA36CHn.jpg)
</code></pre>
</li>
<li>Spark通过申请资源创建调度节点和计算节点<br> <img src="https://s2.loli.net/2021/12/11/laJOMSj6m1BUeKG.jpg"></li>
<li>Spark框架根据需求将计算逻辑根据分区划分成不同的任务<br> <img src="https://s2.loli.net/2021/12/11/MRKL1gjPIN3ATo2.jpg"></li>
<li>调度节点将任务根据计算节点状态发送到对应的计算节点进行计算<br> <img src="https://s2.loli.net/2021/12/11/PC91pTKyi47RhzA.jpg"></li>
</ol>
<p>从以上流程可以看出RDD在整个流程中主要用于将逻辑进行封装，并生成Task发送给Executor节点执行计算，接下来我们就一起看看Spark框架中RDD是具体是如何进行数据处理的。</p>
<h3 id="5-1-4-基础编程"><a href="#5-1-4-基础编程" class="headerlink" title="5.1.4 基础编程"></a>5.1.4 基础编程</h3><h4 id="5-1-4-1-RDD创建"><a href="#5-1-4-1-RDD创建" class="headerlink" title="5.1.4.1 RDD创建"></a>5.1.4.1 RDD创建</h4><p>在Spark中创建RDD的创建方式可以分为四种：</p>
<ol>
<li>从集合（内存）中创建RDD<ul>
<li>从集合中创建RDD，Spark主要提供了两个方法：parallelize和makeRDD  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">    .setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    .setAppName(<span class="string">&quot;spark&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line"><span class="keyword">val</span> rdd1 = sparkContext.parallelize(</span><br><span class="line">    <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">)</span><br><span class="line"><span class="keyword">val</span> rdd2 = sparkContext.makeRDD(</span><br><span class="line">    <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">)</span><br><span class="line">rdd1.collect().foreach(println)</span><br><span class="line">rdd2.collect().foreach(println)</span><br><span class="line">sparkContext.stop()</span><br></pre></td></tr></table></figure></li>
<li>从底层代码实现来讲，makeRDD方法其实就是parallelize方法  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">makeRDD</span></span>[<span class="type">T</span>: <span class="type">ClassTag</span>](</span><br><span class="line">    seq: <span class="type">Seq</span>[<span class="type">T</span>],</span><br><span class="line">    numSlices: <span class="type">Int</span> = defaultParallelism): <span class="type">RDD</span>[<span class="type">T</span>] = withScope &#123;</span><br><span class="line">  parallelize(seq, numSlices)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>从外部存储（文件）创建RDD<ul>
<li>由外部存储系统的数据集创建RDD包括：本地的文件系统，所有Hadoop支持的数据集，比如HDFS、HBase等。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sparkConf =<span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">    .setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;spark&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line"><span class="keyword">val</span> fileRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sparkContext.textFile(<span class="string">&quot;input&quot;</span>)</span><br><span class="line">fileRDD.collect().foreach(println)</span><br><span class="line">sparkContext.stop()</span><br></pre></td></tr></table></figure></li>
<li>textFile 可以将文件作为数据源<ul>
<li>参数表示文件路径,可以为绝对路径也可以为相对路径<ul>
<li>绝对路径：不可改变的路径<ul>
<li>网络：网络协议://IP:Port//Path</li>
<li>文件系统：file://xx/xx/xx</li>
</ul>
</li>
<li>相对路径：可以改变的路径，一定存在一个基准路径</li>
</ul>
</li>
<li>返回结果为RDD数据模型，其中泛型标识文件中的每一行数据</li>
</ul>
</li>
</ul>
</li>
<li>从其他RDD创建<br> 主要是通过一个RDD运算完后，再产生新的RDD。详情请参考后续章节</li>
<li>直接创建RDD（new）<br> 使用new的方式直接构造RDD，一般由Spark框架自身使用。</li>
</ol>
<h4 id="5-1-4-2-RDD并行度与分区"><a href="#5-1-4-2-RDD并行度与分区" class="headerlink" title="5.1.4.2 RDD并行度与分区"></a>5.1.4.2 RDD并行度与分区</h4><p>默认情况下，Spark可以将一个作业切分多个任务后，发送给Executor节点并行计算，而能够并行计算的任务数量我们称之为并行度。这个数量可以在构建RDD时指定。记住，这里的并行执行的任务数量，并不是指的切分任务的数量，不要混淆了。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;spark&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line"><span class="keyword">val</span> dataRDD: <span class="type">RDD</span>[<span class="type">Int</span>] =</span><br><span class="line">    sparkContext.makeRDD(</span><br><span class="line">        <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>),</span><br><span class="line">        <span class="number">4</span>)</span><br><span class="line"><span class="keyword">val</span> fileRDD: <span class="type">RDD</span>[<span class="type">String</span>] =</span><br><span class="line">    sparkContext.textFile(</span><br><span class="line">        <span class="string">&quot;input&quot;</span>,</span><br><span class="line">        <span class="number">2</span>)</span><br><span class="line">fileRDD.collect().foreach(println)</span><br><span class="line">sparkContext.stop()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>读取内存数据时，数据可以按照并行度的设定进行数据的分区操作，数据分区规则的Spark核心源码如下：  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">positions</span></span>(length: <span class="type">Long</span>, numSlices: <span class="type">Int</span>): <span class="type">Iterator</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = &#123;</span><br><span class="line">  (<span class="number">0</span> until numSlices).iterator.map &#123; i =&gt;</span><br><span class="line">    <span class="keyword">val</span> start = ((i * length) / numSlices).toInt</span><br><span class="line">    <span class="keyword">val</span> end = (((i + <span class="number">1</span>) * length) / numSlices).toInt</span><br><span class="line">    (start, end)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>读取文件数据时，数据是按照Hadoop文件读取的规则进行切片分区，而切片规则和数据读取的规则有些差异，具体Spark核心源码如下  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> InputSplit[] getSplits(JobConf job, <span class="keyword">int</span> numSplits)</span><br><span class="line">    <span class="keyword">throws</span> IOException &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> totalSize = <span class="number">0</span>;                           <span class="comment">// compute total size</span></span><br><span class="line">    <span class="keyword">for</span> (FileStatus file: files) &#123;                <span class="comment">// check we have valid files</span></span><br><span class="line">      <span class="keyword">if</span> (file.isDirectory()) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">&quot;Not a file: &quot;</span>+ file.getPath());</span><br><span class="line">      &#125;</span><br><span class="line">      totalSize += file.getLen();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> goalSize = totalSize / (numSplits == <span class="number">0</span> ? <span class="number">1</span> : numSplits);</span><br><span class="line">    <span class="keyword">long</span> minSize = Math.max(job.getLong(org.apache.hadoop.mapreduce.lib.input.</span><br><span class="line">      FileInputFormat.SPLIT_MINSIZE, <span class="number">1</span>), minSplitSize);</span><br><span class="line">      </span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (FileStatus file: files) &#123;</span><br><span class="line">    </span><br><span class="line">        ...</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (isSplitable(fs, path)) &#123;</span><br><span class="line">          <span class="keyword">long</span> blockSize = file.getBlockSize();</span><br><span class="line">          <span class="keyword">long</span> splitSize = computeSplitSize(goalSize, minSize, blockSize);</span><br><span class="line"></span><br><span class="line">          ...</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">long</span> <span class="title">computeSplitSize</span><span class="params">(<span class="keyword">long</span> goalSize, <span class="keyword">long</span> minSize,</span></span></span><br><span class="line"><span class="params"><span class="function">                                       <span class="keyword">long</span> blockSize)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> Math.max(minSize, Math.min(goalSize, blockSize));</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Hadoop计算分区和读取分区数据的方式不一样<ol>
<li>计算分区按照字节来计算</li>
<li>读取分区不是按照字节，是按照行来读取（单次不能跨行）<ul>
<li>读取数据时，按照偏移量来计算，相同的偏移量不能被重复读取</li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
</ul>
<h4 id="5-1-4-3-RDD转换算子"><a href="#5-1-4-3-RDD转换算子" class="headerlink" title="5.1.4.3 RDD转换算子"></a>5.1.4.3 RDD转换算子</h4><p>RDD根据数据处理方式的不同将算子整体上分为Value类型、双Value类型和Key-Value类型</p>
<h5 id="5-1-4-3-1-Value类型"><a href="#5-1-4-3-1-Value类型" class="headerlink" title="5.1.4.3.1 Value类型"></a>5.1.4.3.1 Value类型</h5><ol>
<li><p>map</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](f: <span class="type">T</span> =&gt; <span class="type">U</span>): <span class="type">RDD</span>[<span class="type">U</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  将处理的数据逐条进行映射转换，这里的转换可以是类型的转换，也可以是值的转换。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD: <span class="type">RDD</span>[<span class="type">Int</span>] = sparkContext.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="keyword">val</span> dataRDD1: <span class="type">RDD</span>[<span class="type">Int</span>] = dataRDD.map(</span><br><span class="line">    num =&gt; &#123;</span><br><span class="line">        num * <span class="number">2</span></span><br><span class="line">    &#125;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">val</span> dataRDD2: <span class="type">RDD</span>[<span class="type">String</span>] = dataRDD1.map(</span><br><span class="line">    num =&gt; &#123;</span><br><span class="line">        <span class="string">&quot;&quot;</span> + num</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li>小功能：从服务器日志数据<a href="media/16382517322435/apache.log">apache.log</a>中获取用户请求URL资源路径  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apache_log</span> </span>= &#123;</span><br><span class="line">    <span class="comment">//构建环境</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    sparkContext.textFile(<span class="string">&quot;data/apache.log&quot;</span>)</span><br><span class="line">        .map(</span><br><span class="line">            line =&gt; &#123;</span><br><span class="line">                line.split(<span class="string">&quot; &quot;</span>)(<span class="number">6</span>)</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        .collect()</span><br><span class="line">        .toList</span><br><span class="line">        .distinct</span><br><span class="line">        .foreach(println)</span><br><span class="line">    </span><br><span class="line">    sparkContext.stop()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>mapPartitions</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapPartitions</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](</span><br><span class="line">    f: <span class="type">Iterator</span>[<span class="type">T</span>] =&gt; <span class="type">Iterator</span>[<span class="type">U</span>],</span><br><span class="line">    preservesPartitioning: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="type">RDD</span>[<span class="type">U</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  将待处理的数据以分区为单位发送到计算节点进行处理，这里的处理是指可以进行任意的处理，哪怕是过滤数据。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD1: <span class="type">RDD</span>[<span class="type">Int</span>] = dataRDD.mapPartitions(</span><br><span class="line">    datas =&gt; &#123;</span><br><span class="line">        datas.filter(_==<span class="number">2</span>)</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
</ul>
<blockquote>
<p>思考一个问题：map和mapPartitions的区别？</p>
<ul>
<li>数据处理角度<br>  Map算子是分区内一个数据一个数据的执行，类似于串行操作。而mapPartitions算子是以分区为单位进行批处理操作。</li>
<li>功能的角度<br>  Map算子主要目的将数据源中的数据进行转换和改变。但是不会减少或增多数据。MapPartitions算子需要传递一个迭代器，返回一个迭代器，没有要求的元素的个数保持不变，所以可以增加或减少数据</li>
<li>性能的角度<br>  Map算子因为类似于串行操作，所以性能比较低，而是mapPartitions算子类似于批处理，所以性能较高。但是mapPartitions算子会长时间占用内存，那么这样会导致内存可能不够用，出现内存溢出的错误。所以在内存有限的情况下，不推荐使用。使用map操作。</li>
</ul>
</blockquote>
</li>
</ol>
<ol start="3">
<li><p>mapPartitionsWithIndex</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapPartitionsWithIndex</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](</span><br><span class="line">  f: (<span class="type">Int</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">Iterator</span>[<span class="type">U</span>],</span><br><span class="line">  preservesPartitioning: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="type">RDD</span>[<span class="type">U</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  将待处理的数据以分区为单位发送到计算节点进行处理，这里的处理是指可以进行任意的处理，哪怕是过滤数据，在处理时同时可以获取当前分区索引。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD1 = dataRDD.mapPartitionsWithIndex(</span><br><span class="line">    (index, datas) =&gt; &#123;</span><br><span class="line">         datas.map(index, _)</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li>小功能：<ul>
<li>获取第二个数据分区的数据</li>
<li>获取每个数据分区的最大值<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    println(<span class="string">&quot;************分区最大值****************&quot;</span>)</span><br><span class="line">    <span class="comment">//构建环境</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="keyword">val</span> rdd = sparkContext.makeRDD(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">val</span> max = rdd.mapPartitions(iter =&gt; &#123;</span><br><span class="line">        <span class="type">List</span>(iter.max).iterator</span><br><span class="line">    &#125;)</span><br><span class="line">    println(max.collect().toList)</span><br><span class="line">    </span><br><span class="line">    println(<span class="string">&quot;************错误姿势****************&quot;</span>)</span><br><span class="line">    <span class="comment">//分布式环境，无法保证第一个执行的分区就是第一个分区</span></span><br><span class="line">    <span class="comment">//且分布式中没有顺序</span></span><br><span class="line">    <span class="keyword">var</span> partNum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">val</span> partitionMax = rdd.mapPartitions(iter =&gt; &#123;</span><br><span class="line">        <span class="keyword">if</span> (partNum == <span class="number">0</span>) &#123;</span><br><span class="line">            partNum += <span class="number">1</span></span><br><span class="line">            <span class="type">List</span>(iter.max).iterator</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            partNum += <span class="number">1</span></span><br><span class="line">            <span class="type">Nil</span>.iterator</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">    println(partitionMax.collect().toList)</span><br><span class="line">    </span><br><span class="line">    println(<span class="string">&quot;************正确姿势****************&quot;</span>)</span><br><span class="line">    <span class="comment">//分布式环境，无法保证第一个执行的分区就是第一个分区</span></span><br><span class="line">    <span class="comment">//且分布式中没有顺序</span></span><br><span class="line">    <span class="keyword">val</span> partitionMaxWithIndex = rdd.mapPartitionsWithIndex(</span><br><span class="line">        (index, iter) =&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span> (index == <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="type">List</span>(iter.max).iterator</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="type">Nil</span>.iterator</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    println(partitionMaxWithIndex.collect().toList)</span><br><span class="line">    </span><br><span class="line">    println(<span class="string">&quot;************第二个分区数据****************&quot;</span>)</span><br><span class="line">    <span class="comment">//分布式环境，无法保证第一个执行的分区就是第一个分区</span></span><br><span class="line">    <span class="comment">//且分布式中没有顺序</span></span><br><span class="line">    <span class="keyword">val</span> secondPartitionMaxWithIndex = rdd.mapPartitionsWithIndex(</span><br><span class="line">        (index, iter) =&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span> (index == <span class="number">1</span>) &#123;</span><br><span class="line">                iter</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="type">Nil</span>.iterator</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    println(secondPartitionMaxWithIndex.collect().toList)</span><br><span class="line">    </span><br><span class="line">    sparkContext.stop()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li><p>flatMap</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](f: <span class="type">T</span> =&gt; <span class="type">TraversableOnce</span>[<span class="type">U</span>]): <span class="type">RDD</span>[<span class="type">U</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  将处理的数据进行扁平化后再进行映射处理，所以算子也称之为扁平映射  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD = sparkContext.makeRDD(<span class="type">List</span>(</span><br><span class="line">    <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>),<span class="type">List</span>(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">),<span class="number">1</span>)</span><br><span class="line"><span class="keyword">val</span> dataRDD1 = dataRDD.flatMap(</span><br><span class="line">    list =&gt; list</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li>小功能：将List(List(1,2),3,List(4,5))进行扁平化操作  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatMapTest2</span> </span>= &#123;</span><br><span class="line">    println(<span class="string">&quot;************flatMapTest****************&quot;</span>)</span><br><span class="line">    <span class="comment">//构建环境</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="keyword">val</span> rdd = sparkContext.makeRDD(<span class="type">List</span>(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), <span class="number">4</span>, <span class="type">List</span>(<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>)), <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">val</span> flatMap = rdd.flatMap &#123;</span><br><span class="line">        <span class="keyword">case</span> seq: <span class="type">List</span>[_] =&gt; seq</span><br><span class="line">        <span class="keyword">case</span> other =&gt; <span class="type">List</span>(other)</span><br><span class="line">    &#125;</span><br><span class="line">    println(flatMap.collect().toList)</span><br><span class="line">    </span><br><span class="line">    sparkContext.stop()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>glom</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">glom</span></span>(): <span class="type">RDD</span>[<span class="type">Array</span>[<span class="type">T</span>]]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  将同一个分区的数据直接转换为相同类型的内存数组进行处理，分区不变  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD : <span class="type">RDD</span>[<span class="type">Int</span>] = sparkContext.makeRDD(<span class="type">List</span>(</span><br><span class="line">    <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span></span><br><span class="line">),<span class="number">1</span>)</span><br><span class="line"><span class="keyword">val</span> dataRDD1:<span class="type">RDD</span>[<span class="type">Array</span>[<span class="type">Int</span>]] = dataRDD.glom()</span><br></pre></td></tr></table></figure></li>
<li>小功能：计算所有分区最大值求和（分区内取最大值，分区间最大值求和）  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">glomTest3</span> </span>= &#123;</span><br><span class="line">    println(<span class="string">&quot;************glom****************&quot;</span>)</span><br><span class="line">    <span class="comment">//构建环境</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="keyword">val</span> summ: <span class="type">Int</span> = sparkContext</span><br><span class="line">        .makeRDD(<span class="type">List</span>(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="type">List</span>(<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>), <span class="type">List</span>(<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)), <span class="number">2</span>)</span><br><span class="line">        .glom()</span><br><span class="line">        .map(</span><br><span class="line">            array =&gt; &#123;</span><br><span class="line">                <span class="keyword">var</span> sum = <span class="number">0</span></span><br><span class="line">                array.foreach(</span><br><span class="line">                    list =&gt; &#123;</span><br><span class="line">                        list.foreach(</span><br><span class="line">                            num =&gt; &#123;</span><br><span class="line">                                sum += num</span><br><span class="line">                            &#125;</span><br><span class="line">                        )</span><br><span class="line">                    &#125;</span><br><span class="line">                )</span><br><span class="line">                sum</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        .collect()</span><br><span class="line">        .sum</span><br><span class="line">    println(summ)</span><br><span class="line">    sparkContext.stop()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>groupBy</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupBy</span></span>[<span class="type">K</span>](f: <span class="type">T</span> =&gt; <span class="type">K</span>)(<span class="keyword">implicit</span> kt: <span class="type">ClassTag</span>[<span class="type">K</span>]): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">Iterable</span>[<span class="type">T</span>])]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  将数据根据指定的规则进行分组, 分区默认不变，但是数据会被打乱重新组合，我们将这样的操作称之为shuffle。极限情况下，数据可能被分在同一个分区中<br>  一个组的数据在一个分区中，但是并不是说一个分区中只有一个组  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD = sparkContext.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>),<span class="number">1</span>)</span><br><span class="line"><span class="keyword">val</span> dataRDD1 = dataRDD.groupBy(</span><br><span class="line">    _%<span class="number">2</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li>小功能：<ul>
<li>将List(“Hello”, “hive”, “hbase”, “Hadoop”)根据单词首写字母进行分组。</li>
<li>从服务器日志数据apache.log中获取每个时间段访问量。</li>
<li>WordCount。<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByTest2</span> </span>= &#123;</span><br><span class="line">    println(<span class="string">&quot;****************************&quot;</span>)</span><br><span class="line">    <span class="comment">//构建环境</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="keyword">val</span> rdd = sparkContext.makeRDD(<span class="type">List</span>(<span class="string">&quot;Hello&quot;</span>, <span class="string">&quot;hive&quot;</span>, <span class="string">&quot;hbase&quot;</span>, <span class="string">&quot;Hadoop&quot;</span>))</span><br><span class="line">    <span class="keyword">val</span> groupBy: <span class="type">RDD</span>[(<span class="type">Char</span>, <span class="type">Iterable</span>[<span class="type">String</span>])] = rdd.groupBy(str =&gt; str.charAt(<span class="number">0</span>))</span><br><span class="line">    groupBy.collect().foreach(println)</span><br><span class="line">    sparkContext.stop()</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByTest_apache_log</span> </span>= &#123;</span><br><span class="line">    println(<span class="string">&quot;****************************&quot;</span>)</span><br><span class="line">    <span class="comment">//构建环境</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    </span><br><span class="line">    sparkContext</span><br><span class="line">        .textFile(<span class="string">&quot;data/apache.log&quot;</span>)</span><br><span class="line">        .map(</span><br><span class="line">            line=&gt;&#123;</span><br><span class="line">                line.split(<span class="string">&quot; &quot;</span>)(<span class="number">3</span>).split(<span class="string">&quot;:&quot;</span>)(<span class="number">1</span>)</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        .groupBy(hour=&gt;hour)</span><br><span class="line">        .map&#123;</span><br><span class="line">            <span class="keyword">case</span>(hour,list)=&gt;&#123;</span><br><span class="line">                (hour,list.toList.size)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        .collect()</span><br><span class="line">        .foreach(println)</span><br><span class="line">    sparkContext.stop()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li><p>filter</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(f: <span class="type">T</span> =&gt; <span class="type">Boolean</span>): <span class="type">RDD</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  将数据根据指定的规则进行筛选过滤，符合规则的数据保留，不符合规则的数据丢弃。<br>  当数据进行筛选过滤后，分区不变，但是分区内的数据可能不均衡，生产环境下，可能会出现数据倾斜。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD = sparkContext.makeRDD(<span class="type">List</span>(</span><br><span class="line">    <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span></span><br><span class="line">),<span class="number">1</span>)</span><br><span class="line"><span class="keyword">val</span> dataRDD1 = dataRDD.filter(_%<span class="number">2</span> == <span class="number">0</span>)</span><br></pre></td></tr></table></figure></li>
<li>小功能：从服务器日志数据apache.log中获取2015年5月17日的请求路径  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filterTest_log</span> </span>= &#123;</span><br><span class="line">    println(<span class="string">&quot;****************************&quot;</span>)</span><br><span class="line">    <span class="comment">//构建环境</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    sparkContext</span><br><span class="line">        .textFile(<span class="string">&quot;data/apache.log&quot;</span>)</span><br><span class="line">        .filter(line =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> datas = line.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">            <span class="keyword">val</span> time = datas(<span class="number">3</span>)</span><br><span class="line">            time.startsWith(<span class="string">&quot;17/05/2015&quot;</span>)</span><br><span class="line">        &#125;)</span><br><span class="line">        .map(line =&gt; &#123;</span><br><span class="line">            line.split(<span class="string">&quot; &quot;</span>)(<span class="number">6</span>)</span><br><span class="line">        &#125;)</span><br><span class="line">        .collect()</span><br><span class="line">        .toList</span><br><span class="line">        .distinct</span><br><span class="line">        .foreach(println)</span><br><span class="line">    sparkContext.stop()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>sample</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample</span></span>(</span><br><span class="line">  withReplacement: <span class="type">Boolean</span>,</span><br><span class="line">  fraction: <span class="type">Double</span>,</span><br><span class="line">  seed: <span class="type">Long</span> = <span class="type">Utils</span>.random.nextLong): <span class="type">RDD</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  根据指定的规则从数据集中抽取数据  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD = sparkContext.makeRDD(<span class="type">List</span>(</span><br><span class="line">    <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span></span><br><span class="line">),<span class="number">1</span>)</span><br><span class="line"><span class="comment">// 抽取数据不放回（伯努利算法）</span></span><br><span class="line"><span class="comment">// 伯努利算法：又叫0、1分布。例如扔硬币，要么正面，要么反面。</span></span><br><span class="line"><span class="comment">// 具体实现：根据种子和随机算法算出一个数和第二个参数设置几率比较，小于第二个参数要，大于不要</span></span><br><span class="line"><span class="comment">// 第一个参数：抽取的数据是否放回，false：不放回</span></span><br><span class="line"><span class="comment">// 第二个参数：抽取的几率，范围在[0,1]之间,0：全不取；1：全取；</span></span><br><span class="line"><span class="comment">// 第三个参数：随机数种子</span></span><br><span class="line"><span class="keyword">val</span> dataRDD1 = dataRDD.sample(<span class="literal">false</span>, <span class="number">0.5</span>)</span><br><span class="line"><span class="comment">// 抽取数据放回（泊松算法）</span></span><br><span class="line"><span class="comment">// 第一个参数：抽取的数据是否放回，true：放回；false：不放回</span></span><br><span class="line"><span class="comment">// 第二个参数：重复数据的几率，范围大于等于0.表示每一个元素被期望抽取到的次数</span></span><br><span class="line"><span class="comment">// 第三个参数：随机数种子</span></span><br><span class="line"><span class="keyword">val</span> dataRDD2 = dataRDD.sample(<span class="literal">true</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题：有啥用，抽奖吗？</p>
<ul>
<li>抽样  </li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><p>distinct</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distinct</span></span>()(<span class="keyword">implicit</span> ord: <span class="type">Ordering</span>[<span class="type">T</span>] = <span class="literal">null</span>): <span class="type">RDD</span>[<span class="type">T</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distinct</span></span>(numPartitions: <span class="type">Int</span>)(<span class="keyword">implicit</span> ord: <span class="type">Ordering</span>[<span class="type">T</span>] = <span class="literal">null</span>): <span class="type">RDD</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  将数据集中重复的数据去重  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD = sparkContext.makeRDD(<span class="type">List</span>(</span><br><span class="line">    <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span></span><br><span class="line">),<span class="number">1</span>)</span><br><span class="line"><span class="keyword">val</span> dataRDD1 = dataRDD.distinct()</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> dataRDD2 = dataRDD.distinct(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题：如果不用该算子，你有什么办法实现数据去重？</p>
<ul>
<li>map</li>
<li>set</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><p>coalesce</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">coalesce</span></span>(numPartitions: <span class="type">Int</span>, shuffle: <span class="type">Boolean</span> = <span class="literal">false</span>,</span><br><span class="line">           partitionCoalescer: <span class="type">Option</span>[<span class="type">PartitionCoalescer</span>] = <span class="type">Option</span>.empty)</span><br><span class="line">          (<span class="keyword">implicit</span> ord: <span class="type">Ordering</span>[<span class="type">T</span>] = <span class="literal">null</span>)</span><br><span class="line">  : <span class="type">RDD</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  根据数据量缩减分区，用于大数据集过滤后，提高小数据集的执行效率<br>  当spark程序中，存在过多的小任务的时候，可以通过coalesce方法，收缩合并分区，减少分区的个数，减小任务调度成本  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD = sparkContext.makeRDD(<span class="type">List</span>(</span><br><span class="line">    <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span></span><br><span class="line">),<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> dataRDD1 = dataRDD.coalesce(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题：我想要扩大分区，怎么办？</p>
<ul>
<li>repartition</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><p>repartition</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">repartition</span></span>(numPartitions: <span class="type">Int</span>)(<span class="keyword">implicit</span> ord: <span class="type">Ordering</span>[<span class="type">T</span>] = <span class="literal">null</span>): <span class="type">RDD</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  该操作内部其实执行的是coalesce操作，参数shuffle的默认值为true。无论是将分区数多的RDD转换为分区数少的RDD，还是将分区数少的RDD转换为分区数多的RDD，repartition操作都可以完成，因为无论如何都会经shuffle过程。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD = sparkContext.makeRDD(<span class="type">List</span>(</span><br><span class="line">    <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span></span><br><span class="line">),<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> dataRDD1 = dataRDD.repartition(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题：coalesce和repartition区别？</p>
</blockquote>
</li>
</ul>
</li>
<li><p>sortBy</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sortBy</span></span>[<span class="type">K</span>](</span><br><span class="line">  f: (<span class="type">T</span>) =&gt; <span class="type">K</span>,</span><br><span class="line">  ascending: <span class="type">Boolean</span> = <span class="literal">true</span>,</span><br><span class="line">  numPartitions: <span class="type">Int</span> = <span class="keyword">this</span>.partitions.length)</span><br><span class="line">  (<span class="keyword">implicit</span> ord: <span class="type">Ordering</span>[<span class="type">K</span>], ctag: <span class="type">ClassTag</span>[<span class="type">K</span>]): <span class="type">RDD</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  该操作用于排序数据。在排序之前，可以将数据通过f函数进行处理，之后按照f函数处理的结果进行排序，默认为升序排列。排序后新产生的RDD的分区数与原RDD的分区数一致。中间存在shuffle的过程  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD = sparkContext.makeRDD(<span class="type">List</span>(</span><br><span class="line">    <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span></span><br><span class="line">),<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> dataRDD1 = dataRDD.sortBy(num=&gt;num, <span class="literal">false</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h5 id="5-1-4-3-2-双Value类型"><a href="#5-1-4-3-2-双Value类型" class="headerlink" title="5.1.4.3.2 双Value类型"></a>5.1.4.3.2 双Value类型</h5><ol>
<li>intersection<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">intersection</span></span>(other: <span class="type">RDD</span>[<span class="type">T</span>]): <span class="type">RDD</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 对源RDD和参数RDD求交集后返回一个新的RDD</span></span><br><span class="line"><span class="keyword">val</span> dataRDD1 = sparkContext.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="keyword">val</span> dataRDD2 = sparkContext.makeRDD(<span class="type">List</span>(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>))</span><br><span class="line"><span class="keyword">val</span> dataRDD = dataRDD1.intersection(dataRDD2)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题：如果两个RDD数据类型不一致怎么办？</p>
<ul>
<li>Cannot resolve overloaded method ‘intersection’</li>
<li>方法声明的泛型，必须和调用方数据类型一致</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li>union<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">union</span></span>(other: <span class="type">RDD</span>[<span class="type">T</span>]): <span class="type">RDD</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//对源RDD和参数RDD求并集后返回一个新的RDD</span></span><br><span class="line"><span class="keyword">val</span> dataRDD1 = sparkContext.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="keyword">val</span> dataRDD2 = sparkContext.makeRDD(<span class="type">List</span>(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>))</span><br><span class="line"><span class="keyword">val</span> dataRDD = dataRDD1.union(dataRDD2)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题：如果两个RDD数据类型不一致怎么办？</p>
<ul>
<li>type mismatch;</li>
<li>方法声明的泛型，必须和调用方数据类型一致</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li>subtract<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">subtract</span></span>(other: <span class="type">RDD</span>[<span class="type">T</span>]): <span class="type">RDD</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//以一个RDD元素为主，去除两个RDD中重复元素，将其他元素保留下来。求差集</span></span><br><span class="line"><span class="keyword">val</span> dataRDD1 = sparkContext.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="keyword">val</span> dataRDD2 = sparkContext.makeRDD(<span class="type">List</span>(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>))</span><br><span class="line"><span class="keyword">val</span> dataRDD = dataRDD1.subtract(dataRDD2)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题：如果两个RDD数据类型不一致怎么办？</p>
<ul>
<li>Cannot resolve overloaded method ‘subtract’</li>
<li>方法声明的泛型，必须和调用方数据类型一致</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li>zip<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zip</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](other: <span class="type">RDD</span>[<span class="type">U</span>]): <span class="type">RDD</span>[(<span class="type">T</span>, <span class="type">U</span>)]</span><br></pre></td></tr></table></figure></li>
<li>函数说明  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//将两个RDD中的元素，以键值对的形式进行合并。其中，键值对中的Key为第1个RDD中的元素，Value为第2个RDD中的相同位置的元素。</span></span><br><span class="line"><span class="keyword">val</span> dataRDD1 = sparkContext.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="keyword">val</span> dataRDD2 = sparkContext.makeRDD(<span class="type">List</span>(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>))</span><br><span class="line"><span class="keyword">val</span> dataRDD = dataRDD1.zip(dataRDD2)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题：</p>
<ul>
<li>如果两个RDD数据类型不一致怎么办？<ul>
<li>没影响</li>
</ul>
</li>
<li>如果两个RDD数据分区不一致怎么办？<ul>
<li> Can only zip RDDs with same number of elements in each partition</li>
</ul>
</li>
<li>如果两个RDD分区数据数量不一致怎么办？<ul>
<li>Can’t zip RDDs with unequal numbers of partitions: List(2, 3)</li>
</ul>
</li>
</ul>
</blockquote>
</li>
</ul>
</li>
</ol>
<h5 id="5-1-4-3-3-Key-Value类型"><a href="#5-1-4-3-3-Key-Value类型" class="headerlink" title="5.1.4.3.3 Key-Value类型"></a>5.1.4.3.3 Key-Value类型</h5><ol>
<li><p>partitionBy</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partitionBy</span></span>(partitioner: <span class="type">Partitioner</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br></pre></td></tr></table></figure></li>
<li>函数说明  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//将数据按照指定Partitioner重新进行分区。Spark默认的分区器是HashPartitioner</span></span><br><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] =</span><br><span class="line">    sc.makeRDD(<span class="type">Array</span>((<span class="number">1</span>,<span class="string">&quot;aaa&quot;</span>),(<span class="number">2</span>,<span class="string">&quot;bbb&quot;</span>),(<span class="number">3</span>,<span class="string">&quot;ccc&quot;</span>)),<span class="number">3</span>)</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">HashPartitioner</span></span><br><span class="line"><span class="keyword">val</span> rdd2: <span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] =</span><br><span class="line">    rdd.partitionBy(<span class="keyword">new</span> <span class="type">HashPartitioner</span>(<span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题：</p>
<ul>
<li>如果重分区的分区器和当前RDD的分区器一样怎么办？<ul>
<li>不怎么办</li>
</ul>
</li>
<li>Spark还有其他分区器吗？<ul>
<li>Spark采用Hadoop的分区器</li>
</ul>
</li>
<li>如果想按照自己的方法进行数据分区怎么办？<ul>
<li>同Hadoop自定义分区器</li>
</ul>
</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><p>reduceByKey </p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduceByKey</span></span>(func: (<span class="type">V</span>, <span class="type">V</span>) =&gt; <span class="type">V</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduceByKey</span></span>(func: (<span class="type">V</span>, <span class="type">V</span>) =&gt; <span class="type">V</span>, numPartitions: <span class="type">Int</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  可以将数据按照相同的Key对Value进行聚合  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD1 = sparkContext.makeRDD(<span class="type">List</span>((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="keyword">val</span> dataRDD2 = dataRDD1.reduceByKey(_+_)</span><br><span class="line"><span class="keyword">val</span> dataRDD3 = dataRDD1.reduceByKey(_+_, <span class="number">2</span>)</span><br></pre></td></tr></table></figure></li>
<li>小功能：WordCount  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduceByKey</span> </span>= &#123;</span><br><span class="line">    println(<span class="string">&quot;*************reduceByKey***************&quot;</span>)</span><br><span class="line">    <span class="comment">//构建环境</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> rdd2: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = sparkContext.makeRDD(<span class="type">List</span>(</span><br><span class="line">        (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">3</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">4</span>)</span><br><span class="line">    ))</span><br><span class="line">    </span><br><span class="line">    rdd2</span><br><span class="line">        .reduceByKey(_ + _)</span><br><span class="line">        .collect()</span><br><span class="line">        .foreach(println)</span><br><span class="line">    sparkContext.stop()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>groupByKey </p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByKey</span></span>(): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">Iterable</span>[<span class="type">V</span>])]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByKey</span></span>(numPartitions: <span class="type">Int</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">Iterable</span>[<span class="type">V</span>])]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByKey</span></span>(partitioner: <span class="type">Partitioner</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">Iterable</span>[<span class="type">V</span>])]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  将数据源的数据根据key对value进行分组  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD1 =</span><br><span class="line">    sparkContext.makeRDD(<span class="type">List</span>((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="keyword">val</span> dataRDD2 = dataRDD1.groupByKey()</span><br><span class="line"><span class="keyword">val</span> dataRDD3 = dataRDD1.groupByKey(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">val</span> dataRDD4 = dataRDD1.groupByKey(<span class="keyword">new</span> <span class="type">HashPartitioner</span>(<span class="number">2</span>))</span><br></pre></td></tr></table></figure></li>
<li>小功能：WordCount  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByKey</span> </span>= &#123;</span><br><span class="line">    println(<span class="string">&quot;*************groupByKey***************&quot;</span>)</span><br><span class="line">    <span class="comment">//构建环境</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> rdd2: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = sparkContext.makeRDD(<span class="type">List</span>(</span><br><span class="line">        (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">3</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">4</span>)</span><br><span class="line">    ))</span><br><span class="line"></span><br><span class="line">    rdd2</span><br><span class="line">        .groupByKey()</span><br><span class="line">        .mapValues(iter =&gt; iter.sum)</span><br><span class="line">        .collect()</span><br><span class="line">        .foreach(println)</span><br><span class="line">    sparkContext.stop()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题：reduceByKey和groupByKey的区别？</p>
<ul>
<li>从shuffle的角度：reduceByKey和groupByKey都存在shuffle的操作，但是reduceByKey可以在shuffle前对分区内相同key的数据进行预聚合（combine）功能，这样会减少落盘的数据量，而groupByKey只是进行分组，不存在数据量减少的问题，所以reduceByKey性能比较高。</li>
<li>从功能的角度：reduceByKey其实包含分组和聚合的功能。groupByKey只能分组，不能聚合，所以在分组聚合的场合下，推荐使用reduceByKey，如果仅仅是分组而不需要聚合。那么还是只能使用groupByKey</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><p>aggregateByKey </p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">aggregateByKey</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](zeroValue: <span class="type">U</span>)(seqOp: (<span class="type">U</span>, <span class="type">V</span>) =&gt; <span class="type">U</span>,</span><br><span class="line">    combOp: (<span class="type">U</span>, <span class="type">U</span>) =&gt; <span class="type">U</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">U</span>)]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  将数据根据不同的规则进行分区内计算和分区间计算  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD1 =</span><br><span class="line">    sparkContext.makeRDD(<span class="type">List</span>((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="keyword">val</span> dataRDD2 =</span><br><span class="line">    dataRDD1.aggregateByKey(<span class="number">0</span>)(_+_,_+_)</span><br></pre></td></tr></table></figure>
  取出每个分区内相同key的最大值然后分区间相加  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TODO : 取出每个分区内相同key的最大值然后分区间相加</span></span><br><span class="line"><span class="comment">// aggregateByKey算子是函数柯里化，存在两个参数列表</span></span><br><span class="line"><span class="comment">// 1. 第一个参数列表中的参数表示初始值</span></span><br><span class="line"><span class="comment">// 2. 第二个参数列表中含有两个参数</span></span><br><span class="line"><span class="comment">//    2.1 第一个参数表示分区内的计算规则</span></span><br><span class="line"><span class="comment">//    2.2 第二个参数表示分区间的计算规则</span></span><br><span class="line"><span class="keyword">val</span> rdd =</span><br><span class="line">    sc.makeRDD(<span class="type">List</span>(</span><br><span class="line">        (<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;a&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>),</span><br><span class="line">        (<span class="string">&quot;b&quot;</span>,<span class="number">4</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">5</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">6</span>)</span><br><span class="line">    ),<span class="number">2</span>)</span><br><span class="line"><span class="comment">// 0:(&quot;a&quot;,1),(&quot;a&quot;,2),(&quot;c&quot;,3) =&gt; (a,10)(c,10)</span></span><br><span class="line"><span class="comment">//                                         =&gt; (a,10)(b,10)(c,20)</span></span><br><span class="line"><span class="comment">// 1:(&quot;b&quot;,4),(&quot;c&quot;,5),(&quot;c&quot;,6) =&gt; (b,10)(c,10)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultRDD =</span><br><span class="line">    rdd.aggregateByKey(<span class="number">10</span>)(</span><br><span class="line">        (x, y) =&gt; math.max(x,y),</span><br><span class="line">        (x, y) =&gt; x + y</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">resultRDD.collect().foreach(println)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题：分区内计算规则和分区间计算规则相同怎么办？（WordCount）</p>
<ul>
<li>不怎么办，等同于foldByKey</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><p>foldByKey </p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foldByKey</span></span>(zeroValue: <span class="type">V</span>)(func: (<span class="type">V</span>, <span class="type">V</span>) =&gt; <span class="type">V</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  当分区内计算规则和分区间计算规则相同时，aggregateByKey就可以简化为foldByKey  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD1 = sparkContext.makeRDD(<span class="type">List</span>((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="keyword">val</span> dataRDD2 = dataRDD1.foldByKey(<span class="number">0</span>)(_+_)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>combineByKey </p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">combineByKey</span></span>[<span class="type">C</span>](</span><br><span class="line">  createCombiner: <span class="type">V</span> =&gt; <span class="type">C</span>,</span><br><span class="line">  mergeValue: (<span class="type">C</span>, <span class="type">V</span>) =&gt; <span class="type">C</span>,</span><br><span class="line">  mergeCombiners: (<span class="type">C</span>, <span class="type">C</span>) =&gt; <span class="type">C</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">C</span>)]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  最通用的对key-value型rdd进行聚集操作的聚集函数（aggregation function）。类似于aggregate()，combineByKey()允许用户返回值的类型与输入不一致。</li>
<li>小功能：数据List((“a”, 88), (“b”, 95), (“a”, 91), (“b”, 93), (“a”, 95), (“b”, 98))求每个key的平均值  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> list: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">List</span>((<span class="string">&quot;a&quot;</span>, <span class="number">88</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">95</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">91</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">93</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">95</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">98</span>))</span><br><span class="line"><span class="keyword">val</span> input: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = sc.makeRDD(list, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> combineRdd: <span class="type">RDD</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Int</span>))] = input.combineByKey(</span><br><span class="line">    (_, <span class="number">1</span>),</span><br><span class="line">    (acc: (<span class="type">Int</span>, <span class="type">Int</span>), v) =&gt; (acc._1 + v, acc._2 + <span class="number">1</span>),</span><br><span class="line">    (acc1: (<span class="type">Int</span>, <span class="type">Int</span>), acc2: (<span class="type">Int</span>, <span class="type">Int</span>)) =&gt; (acc1._1 + acc2._1, acc1._2 + acc2._2)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题：reduceByKey、foldByKey、aggregateByKey、combineByKey的区别？</p>
<ul>
<li>reduceByKey: 相同key的第一个数据不进行任何计算，分区内和分区间计算规则相同</li>
<li>foldByKey: 相同key的第一个数据和初始值进行分区内计算，分区内和分区间计算规则相同</li>
<li>aggregateByKey：相同key的第一个数据和初始值进行分区内计算，分区内和分区间计算规则可以不相同</li>
<li>combineByKey:当计算时，发现数据结构不满足要求时，可以让第一个数据转换结构。分区内和分区间计算规则不相同。</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><p>sortByKey</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sortByKey</span></span>(ascending: <span class="type">Boolean</span> = <span class="literal">true</span>, numPartitions: <span class="type">Int</span> = self.partitions.length)</span><br><span class="line">  : <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  在一个(K,V)的RDD上调用，K必须实现Ordered接口(特质)，返回一个按照key进行排序的  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD1 = sparkContext.makeRDD(<span class="type">List</span>((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="keyword">val</span> sortRDD1: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = dataRDD1.sortByKey(<span class="literal">true</span>)</span><br><span class="line"><span class="keyword">val</span> sortRDD1: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = dataRDD1.sortByKey(<span class="literal">false</span>)</span><br></pre></td></tr></table></figure></li>
<li>小功能：设置key为自定义类User  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sortByKey_user</span> </span>= &#123;</span><br><span class="line">    println(<span class="string">&quot;*************sortByKey***************&quot;</span>)</span><br><span class="line">    <span class="comment">//构建环境</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> rdd: <span class="type">RDD</span>[(<span class="type">User</span>, <span class="type">Int</span>)] = sparkContext.makeRDD(<span class="type">List</span>(</span><br><span class="line">        (<span class="keyword">new</span> <span class="type">User</span>(), <span class="number">1</span>), (<span class="keyword">new</span> <span class="type">User</span>(), <span class="number">2</span>), (<span class="keyword">new</span> <span class="type">User</span>(), <span class="number">3</span>), (<span class="keyword">new</span> <span class="type">User</span>(), <span class="number">4</span>)</span><br><span class="line">    ))</span><br><span class="line">    rdd</span><br><span class="line">        .sortByKey()</span><br><span class="line">        .collect()</span><br><span class="line">        .foreach(println)</span><br><span class="line">    sparkContext.stop()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">extends</span> <span class="title">Ordered</span>[<span class="type">User</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compare</span></span>(that: <span class="type">User</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">        <span class="number">0</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>join</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">join</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)]): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">V</span>, <span class="type">W</span>))]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  在类型为(K,V)和(K,W)的RDD上调用，返回一个相同key对应的所有元素连接在一起的(K,(V,W))的RDD  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = sc.makeRDD(<span class="type">Array</span>((<span class="number">1</span>, <span class="string">&quot;a&quot;</span>), (<span class="number">2</span>, <span class="string">&quot;b&quot;</span>), (<span class="number">3</span>, <span class="string">&quot;c&quot;</span>)))</span><br><span class="line"><span class="keyword">val</span> rdd1: <span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = sc.makeRDD(<span class="type">Array</span>((<span class="number">1</span>, <span class="number">4</span>), (<span class="number">2</span>, <span class="number">5</span>), (<span class="number">3</span>, <span class="number">6</span>)))</span><br><span class="line">rdd.join(rdd1).collect().foreach(println)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题：如果key存在不相等呢？</p>
<ul>
<li>不相等的关联不到</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><p>leftOuterJoin</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leftOuterJoin</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)]): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">V</span>, <span class="type">Option</span>[<span class="type">W</span>]))]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  类似于SQL语句的左外连接  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD1 = sparkContext.makeRDD(<span class="type">List</span>((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="keyword">val</span> dataRDD2 = sparkContext.makeRDD(<span class="type">List</span>((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Option</span>[<span class="type">Int</span>]))] = dataRDD1.leftOuterJoin(dataRDD2)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>cogroup</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cogroup</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)]): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">Iterable</span>[<span class="type">V</span>], <span class="type">Iterable</span>[<span class="type">W</span>]))]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  在类型为(K,V)和(K,W)的RDD上调用，返回一个(K,(Iterable<V>,Iterable<W>))类型的RDD  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD1 = sparkContext.makeRDD(<span class="type">List</span>((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;a&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="keyword">val</span> dataRDD2 = sparkContext.makeRDD(<span class="type">List</span>((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> value: <span class="type">RDD</span>[(<span class="type">String</span>, (<span class="type">Iterable</span>[<span class="type">Int</span>], <span class="type">Iterable</span>[<span class="type">Int</span>]))] = </span><br><span class="line"></span><br><span class="line">dataRDD1.cogroup(dataRDD2)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h4 id="5-1-4-4-案例实操"><a href="#5-1-4-4-案例实操" class="headerlink" title="5.1.4.4 案例实操"></a>5.1.4.4 案例实操</h4><ol>
<li>数据准备<ul>
<li><a href="media/16382517322435/agent.log">agent.log</a></li>
<li>时间戳，省份，城市，用户，广告，中间字段使用空格分隔。</li>
</ul>
</li>
<li>需求描述<ul>
<li>统计出每一个省份每个广告被点击数量排行的Top3</li>
</ul>
</li>
<li>需求分析<ul>
<li>转换数据结构line =&gt;（（省份，广告），1） </li>
<li>聚合数据（（省份，广告），1） =&gt; （（省份，广告），count）</li>
<li>转换数据结构（（省份，广告），count）=&gt;（省份，（广告，count））</li>
<li>分组（省份，（广告，count））=&gt;（省份，List（（广告，count），（广告，count），·····））</li>
<li>排序取前三</li>
</ul>
</li>
<li>功能实现 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">agent_log</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;*************agent.log***************&quot;</span>)</span><br><span class="line">    <span class="comment">//构建环境</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">    sparkContext</span><br><span class="line">        .textFile(<span class="string">&quot;data/agent.log&quot;</span>)</span><br><span class="line">        .map(line =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> datas: <span class="type">Array</span>[<span class="type">String</span>] = line.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">            ((datas(<span class="number">1</span>), datas(<span class="number">4</span>)), <span class="number">1</span>)</span><br><span class="line">        &#125;)</span><br><span class="line">        .reduceByKey(_ + _)</span><br><span class="line">        .map &#123;</span><br><span class="line">            <span class="keyword">case</span> ((p, a), s) =&gt; (p, (a, s))</span><br><span class="line">        &#125;</span><br><span class="line">        .groupByKey()</span><br><span class="line">        .mapValues(</span><br><span class="line">            iter =&gt; &#123;</span><br><span class="line">                iter.toList.sortBy(_._2)(<span class="type">Ordering</span>.<span class="type">Int</span>.reverse).take(<span class="number">3</span>)</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        .collect()</span><br><span class="line">        .foreach(println)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    sparkContext.stop()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="5-1-4-5-RDD行动算子"><a href="#5-1-4-5-RDD行动算子" class="headerlink" title="5.1.4.5 RDD行动算子"></a>5.1.4.5 RDD行动算子</h4><ul>
<li>所谓行动算子就是通过调用RDD的方法，让RDD的计算开始执行，执行时会让整个RDD模型的逻辑全部执行；如果不调用行动算子，那么逻辑不会启动</li>
<li>转换算子是将旧的RDD转换为新的RDD，返回结果一定为RDD</li>
<li>行动算子是让RDD逻辑开始执行，返回结果为具体的值<ul>
<li>一个Spark程序中，可以生成作业，然后通过算子执行作业（Job），触发行动算子，一定会产生一个新的作业（Job）</li>
</ul>
</li>
</ul>
<ol>
<li><p>reduce</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(f: (<span class="type">T</span>, <span class="type">T</span>) =&gt; <span class="type">T</span>): <span class="type">T</span></span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  聚集RDD中的所有元素，先聚合分区内数据，再聚合分区间数据<br>  简化，规约，聚合  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">    </span><br><span class="line"><span class="comment">// 聚合数据</span></span><br><span class="line"><span class="keyword">val</span> reduceResult: <span class="type">Int</span> = rdd.reduce(_+_)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>collect</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collect</span></span>(): <span class="type">Array</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  在驱动程序（Driver）中，以数组Array的形式返回数据集的所有元素  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">    </span><br><span class="line"><span class="comment">// 收集数据到Driver</span></span><br><span class="line">rdd.collect().foreach(println)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>count</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count</span></span>(): <span class="type">Long</span></span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  返回RDD中元素的个数  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">    </span><br><span class="line"><span class="comment">// 返回RDD中元素的个数</span></span><br><span class="line"><span class="keyword">val</span> countResult: <span class="type">Long</span> = rdd.count()</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>first</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">first</span></span>(): <span class="type">T</span></span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  返回RDD中的第一个元素  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回RDD中元素的个数</span></span><br><span class="line"><span class="keyword">val</span> firstResult: <span class="type">Int</span> = rdd.first()</span><br><span class="line">println(firstResult)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>take</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">take</span></span>(num: <span class="type">Int</span>): <span class="type">Array</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  返回一个由RDD的前n个元素组成的数组  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vval rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回RDD中元素的个数</span></span><br><span class="line"><span class="keyword">val</span> takeResult: <span class="type">Array</span>[<span class="type">Int</span>] = rdd.take(<span class="number">2</span>)</span><br><span class="line">println(takeResult.mkString(<span class="string">&quot;,&quot;</span>))</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>takeOrdered</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">takeOrdered</span></span>(num: <span class="type">Int</span>)(<span class="keyword">implicit</span> ord: <span class="type">Ordering</span>[<span class="type">T</span>]): <span class="type">Array</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  返回该RDD排序后的前n个元素组成的数组  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回RDD中元素的个数</span></span><br><span class="line"><span class="keyword">val</span> result: <span class="type">Array</span>[<span class="type">Int</span>] = rdd.takeOrdered(<span class="number">2</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>aggregate</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">aggregate</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](zeroValue: <span class="type">U</span>)(seqOp: (<span class="type">U</span>, <span class="type">T</span>) =&gt; <span class="type">U</span>, combOp: (<span class="type">U</span>, <span class="type">U</span>) =&gt; <span class="type">U</span>): <span class="type">U</span></span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  分区的数据通过初始值和分区内的数据进行聚合，然后再和初始值进行分区间的数据聚合  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将该RDD所有元素相加得到结果</span></span><br><span class="line"><span class="comment">//val result: Int = rdd.aggregate(0)(_ + _, _ + _)</span></span><br><span class="line"><span class="keyword">val</span> result: <span class="type">Int</span> = rdd.aggregate(<span class="number">10</span>)(_ + _, _ + _)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>fold</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fold</span></span>(zeroValue: <span class="type">T</span>)(op: (<span class="type">T</span>, <span class="type">T</span>) =&gt; <span class="type">T</span>): <span class="type">T</span></span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  折叠操作，aggregate的简化版操作  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> foldResult: <span class="type">Int</span> = rdd.fold(<span class="number">0</span>)(_+_)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>countByKey</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">countByKey</span></span>(): <span class="type">Map</span>[<span class="type">K</span>, <span class="type">Long</span>]</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  统计每种key的个数  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = sc.makeRDD(<span class="type">List</span>((<span class="number">1</span>, <span class="string">&quot;a&quot;</span>), (<span class="number">1</span>, <span class="string">&quot;a&quot;</span>), (<span class="number">1</span>, <span class="string">&quot;a&quot;</span>), (<span class="number">2</span>, <span class="string">&quot;b&quot;</span>), (<span class="number">3</span>, <span class="string">&quot;c&quot;</span>), (<span class="number">3</span>, <span class="string">&quot;c&quot;</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 统计每种key的个数</span></span><br><span class="line"><span class="keyword">val</span> result: collection.<span class="type">Map</span>[<span class="type">Int</span>, <span class="type">Long</span>] = rdd.countByKey()</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<ol start="10">
<li><p>save相关算子</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveAsTextFile</span></span>(path: <span class="type">String</span>): <span class="type">Unit</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveAsObjectFile</span></span>(path: <span class="type">String</span>): <span class="type">Unit</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveAsSequenceFile</span></span>(</span><br><span class="line">  path: <span class="type">String</span>,</span><br><span class="line">  codec: <span class="type">Option</span>[<span class="type">Class</span>[_ &lt;: <span class="type">CompressionCodec</span>]] = <span class="type">None</span>): <span class="type">Unit</span></span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  将数据保存到不同格式的文件中  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 保存成Text文件</span></span><br><span class="line">rdd.saveAsTextFile(<span class="string">&quot;output&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 序列化成对象保存到文件</span></span><br><span class="line">rdd.saveAsObjectFile(<span class="string">&quot;output1&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 保存成Sequencefile文件</span></span><br><span class="line">rdd.map((_,<span class="number">1</span>)).saveAsSequenceFile(<span class="string">&quot;output2&quot;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>foreach</p>
<ul>
<li>函数签名  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foreach</span></span>(f: <span class="type">T</span> =&gt; <span class="type">Unit</span>): <span class="type">Unit</span> = withScope &#123;</span><br><span class="line">    <span class="keyword">val</span> cleanF = sc.clean(f)</span><br><span class="line">    sc.runJob(<span class="keyword">this</span>, (iter: <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; iter.foreach(cleanF))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>函数说明<br>  分布式遍历RDD中的每一个元素，调用指定函数  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 收集后打印</span></span><br><span class="line">rdd.map(num=&gt;num).collect().foreach(println)</span><br><span class="line"></span><br><span class="line">println(<span class="string">&quot;****************&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 分布式打印</span></span><br><span class="line">rdd.foreach(println)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h4 id="5-1-4-6-RDD序列化"><a href="#5-1-4-6-RDD序列化" class="headerlink" title="5.1.4.6 RDD序列化"></a>5.1.4.6 RDD序列化</h4><ol>
<li>闭包检查<br> 从计算的角度, 算子以外的代码都是在Driver端执行, 算子里面的代码都是在Executor端执行。那么在scala的函数式编程中，就会导致算子内经常会用到算子外的数据，这样就形成了闭包的效果，如果使用的算子外的数据无法序列化，就意味着无法传值给Executor端执行，就会发生错误，所以需要在执行任务计算前，检测闭包内的对象是否可以进行序列化，这个操作我们称之为闭包检测。Scala2.12版本后闭包编译方式发生了改变</li>
<li>序列化方法和属性<br> 从计算的角度, 算子以外的代码都是在Driver端执行, 算子里面的代码都是在Executor端执行，看如下代码： <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">serializable02_function</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">//1.创建SparkConf并设置App名称</span></span><br><span class="line">        <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;SparkCoreTest&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.创建SparkContext，该对象是提交Spark App的入口</span></span><br><span class="line">        <span class="keyword">val</span> sc: <span class="type">SparkContext</span> = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.创建一个RDD</span></span><br><span class="line">        <span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">String</span>] = sc.makeRDD(<span class="type">Array</span>(<span class="string">&quot;hello world&quot;</span>, <span class="string">&quot;hello spark&quot;</span>, <span class="string">&quot;hive&quot;</span>, <span class="string">&quot;atguigu&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.1创建一个Search对象</span></span><br><span class="line">        <span class="keyword">val</span> search = <span class="keyword">new</span> <span class="type">Search</span>(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.2 函数传递，打印：ERROR Task not serializable</span></span><br><span class="line">        search.getMatch1(rdd).collect().foreach(println)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.3 属性传递，打印：ERROR Task not serializable</span></span><br><span class="line">        search.getMatch2(rdd).collect().foreach(println)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.关闭连接</span></span><br><span class="line">        sc.stop()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Search</span>(<span class="params">query:<span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isMatch</span></span>(s: <span class="type">String</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">        s.contains(query)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 函数序列化案例</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getMatch1</span> </span>(rdd: <span class="type">RDD</span>[<span class="type">String</span>]): <span class="type">RDD</span>[<span class="type">String</span>] = &#123;</span><br><span class="line">        <span class="comment">//rdd.filter(this.isMatch)</span></span><br><span class="line">        rdd.filter(isMatch)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 属性序列化案例</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getMatch2</span></span>(rdd: <span class="type">RDD</span>[<span class="type">String</span>]): <span class="type">RDD</span>[<span class="type">String</span>] = &#123;</span><br><span class="line">        <span class="comment">//rdd.filter(x =&gt; x.contains(this.query))</span></span><br><span class="line">        rdd.filter(x =&gt; x.contains(query))</span><br><span class="line">        <span class="comment">//val q = query</span></span><br><span class="line">        <span class="comment">//rdd.filter(x =&gt; x.contains(q))</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>Kryo序列化框架<br> 参考地址: <a target="_blank" rel="noopener" href="https://github.com/EsotericSoftware/kryo">https://github.com/EsotericSoftware/kryo</a><br> Java的序列化能够序列化任何的类。但是比较重（字节多），序列化后，对象的提交也比较大。Spark出于性能的考虑，Spark2.0开始支持另外一种Kryo序列化机制。Kryo速度是Serializable的10倍。当RDD在Shuffle数据的时候，简单数据类型、数组和字符串类型已经在Spark内部使用Kryo来序列化。<br> 注意：即使使用Kryo序列化，也要继承Serializable接口。 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">serializable_Kryo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">                .setAppName(<span class="string">&quot;SerDemo&quot;</span>)</span><br><span class="line">                .setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">                <span class="comment">// 替换默认的序列化机制</span></span><br><span class="line">                .set(<span class="string">&quot;spark.serializer&quot;</span>, <span class="string">&quot;org.apache.spark.serializer.KryoSerializer&quot;</span>)</span><br><span class="line">                <span class="comment">// 注册需要使用 kryo 序列化的自定义类</span></span><br><span class="line">                .registerKryoClasses(<span class="type">Array</span>(classOf[<span class="type">Searcher</span>]))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">String</span>] = sc.makeRDD(<span class="type">Array</span>(<span class="string">&quot;hello world&quot;</span>, <span class="string">&quot;hello atguigu&quot;</span>, <span class="string">&quot;atguigu&quot;</span>, <span class="string">&quot;hahah&quot;</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> searcher = <span class="keyword">new</span> <span class="type">Searcher</span>(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> result: <span class="type">RDD</span>[<span class="type">String</span>] = searcher.getMatchedRDD1(rdd)</span><br><span class="line"></span><br><span class="line">        result.collect.foreach(println)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Searcher</span>(<span class="params">val query: <span class="type">String</span></span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isMatch</span></span>(s: <span class="type">String</span>) = &#123;</span><br><span class="line">        s.contains(query)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getMatchedRDD1</span></span>(rdd: <span class="type">RDD</span>[<span class="type">String</span>]) = &#123;</span><br><span class="line">        rdd.filter(isMatch) </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getMatchedRDD2</span></span>(rdd: <span class="type">RDD</span>[<span class="type">String</span>]) = &#123;</span><br><span class="line">        <span class="keyword">val</span> q = query</span><br><span class="line">        rdd.filter(_.contains(q))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="5-1-4-7-RDD依赖关系"><a href="#5-1-4-7-RDD依赖关系" class="headerlink" title="5.1.4.7 RDD依赖关系"></a>5.1.4.7 RDD依赖关系</h4><ol>
<li><p>RDD 血缘关系<br> RDD只支持粗粒度转换，即在大量记录上执行的单个操作。将创建RDD的一系列Lineage（血统）记录下来，以便恢复丢失的分区。RDD的Lineage会记录RDD的元数据信息和转换行为，当该RDD的部分分区数据丢失时，它可以根据这些信息来重新运算和恢复丢失的数据分区。</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> fileRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;input/1.txt&quot;</span>)</span><br><span class="line">println(fileRDD.toDebugString)</span><br><span class="line">println(<span class="string">&quot;----------------------&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> wordRDD: <span class="type">RDD</span>[<span class="type">String</span>] = fileRDD.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line">println(wordRDD.toDebugString)</span><br><span class="line">println(<span class="string">&quot;----------------------&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> mapRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordRDD.map((_,<span class="number">1</span>))</span><br><span class="line">println(mapRDD.toDebugString)</span><br><span class="line">println(<span class="string">&quot;----------------------&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = mapRDD.reduceByKey(_+_)</span><br><span class="line">println(resultRDD.toDebugString)</span><br><span class="line"></span><br><span class="line">resultRDD.collect()</span><br></pre></td></tr></table></figure></li>
<li><p>RDD 依赖关系<br> 这里所谓的依赖关系，其实就是两个相邻RDD之间的关系</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sc: <span class="type">SparkContext</span> = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> fileRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;input/1.txt&quot;</span>)</span><br><span class="line">println(fileRDD.dependencies)</span><br><span class="line">println(<span class="string">&quot;----------------------&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> wordRDD: <span class="type">RDD</span>[<span class="type">String</span>] = fileRDD.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line">println(wordRDD.dependencies)</span><br><span class="line">println(<span class="string">&quot;----------------------&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> mapRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordRDD.map((_,<span class="number">1</span>))</span><br><span class="line">println(mapRDD.dependencies)</span><br><span class="line">println(<span class="string">&quot;----------------------&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = mapRDD.reduceByKey(_+_)</span><br><span class="line">println(resultRDD.dependencies)</span><br><span class="line"></span><br><span class="line">resultRDD.collect()</span><br></pre></td></tr></table></figure></li>
<li><p>RDD 窄依赖<br> 窄依赖表示每一个父(上游)RDD的Partition最多被子（下游）RDD的一个Partition使用，窄依赖我们形象的比喻为独生子女。</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OneToOneDependency</span>[<span class="type">T</span>](<span class="params">rdd: <span class="type">RDD</span>[<span class="type">T</span>]</span>) <span class="keyword">extends</span> <span class="title">NarrowDependency</span>[<span class="type">T</span>](<span class="params">rdd</span>) </span></span><br></pre></td></tr></table></figure></li>
<li><p>RDD 宽依赖<br> 宽依赖表示同一个父（上游）RDD的Partition被多个子（下游）RDD的Partition依赖，会引起Shuffle，总结：宽依赖我们形象的比喻为多生。</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ShuffleDependency</span>[<span class="type">K</span>: <span class="type">ClassTag</span>, <span class="type">V</span>: <span class="type">ClassTag</span>, <span class="type">C</span>: <span class="type">ClassTag</span>](<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="class">    @transient private val _rdd: <span class="type">RDD</span>[_ &lt;: <span class="type">Product2</span>[<span class="type">K</span>, <span class="type">V</span>]],</span></span></span><br><span class="line"><span class="params"><span class="class">    val partitioner: <span class="type">Partitioner</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">    val serializer: <span class="type">Serializer</span> = <span class="type">SparkEnv</span>.get.serializer,</span></span></span><br><span class="line"><span class="params"><span class="class">    val keyOrdering: <span class="type">Option</span>[<span class="type">Ordering</span>[<span class="type">K</span>]] = <span class="type">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">    val aggregator: <span class="type">Option</span>[<span class="type">Aggregator</span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">C</span>]] = <span class="type">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">    val mapSideCombine: <span class="type">Boolean</span> = false</span>)</span></span><br><span class="line">  <span class="keyword">extends</span> <span class="type">Dependency</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">V</span>]] </span><br></pre></td></tr></table></figure></li>
<li><p>RDD 阶段划分<br> DAG（Directed Acyclic Graph）有向无环图是由点和线组成的拓扑图形，该图形具有方向，不会闭环。例如，DAG记录了RDD的转换过程和任务的阶段。<br> <img src="https://s2.loli.net/2021/12/11/ki2LpfesH4xmbhW.jpg"></p>
</li>
<li><p>RDD 阶段划分源码</p>
<ul>
<li>SparkContext对象包含有一个私有属性DAGScheduler阶段调度器，主要用于阶段的划分。在一个应用程序中，任务的提交都是从行动算子触发的。行动算子的方法内部会调用一个runJob方法，其中就有DAG调度器发挥运行Job的作用：  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get)</span><br></pre></td></tr></table></figure></li>
<li>runJob方法中，会执行submitJob方法：  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> waiter = submitJob(rdd, func, partitions, callSite, resultHandler, properties)</span><br></pre></td></tr></table></figure></li>
<li>继续查看这个方法的源码，其内部的重点代码区域如下：  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> func2 = func.asInstanceOf[(<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _]</span><br><span class="line"><span class="keyword">val</span> waiter = <span class="keyword">new</span> <span class="type">JobWaiter</span>[<span class="type">U</span>](<span class="keyword">this</span>, jobId, partitions.size, resultHandler)</span><br><span class="line">eventProcessLoop.post(<span class="type">JobSubmitted</span>(</span><br><span class="line">    jobId, rdd, func2, partitions.toArray, callSite, waiter,</span><br><span class="line">    <span class="type">Utils</span>.cloneProperties(properties)))</span><br><span class="line">waiter</span><br></pre></td></tr></table></figure></li>
<li>此处有一个JobSubmitted事件，这个事件作为post方法的参数，该post方法主要用于将事件放入到一个队列中，然后等待事件线程执行队列中的事件：  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">post</span></span>(event: <span class="type">E</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (!stopped.get) &#123;</span><br><span class="line">    <span class="keyword">if</span> (eventThread.isAlive) &#123;</span><br><span class="line">      eventQueue.put(event)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      onError(<span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">s&quot;<span class="subst">$name</span> has already been stopped accidentally.&quot;</span>))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>查看这个事件线程eventThread，当这个事件线程执行的时候，会运行run方法，在方法的内部会取出事件队列中的事件。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="keyword">val</span> eventThread = <span class="keyword">new</span> <span class="type">Thread</span>(name) &#123;</span><br><span class="line">  setDaemon(<span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">while</span> (!stopped.get) &#123;</span><br><span class="line">        <span class="keyword">val</span> event = eventQueue.take()</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          onReceive(event)</span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">          <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">              onError(e)</span><br><span class="line">            &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">              <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt; logError(<span class="string">&quot;Unexpected error in &quot;</span> + name, e)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> ie: <span class="type">InterruptedException</span> =&gt; <span class="comment">// exit even if eventQueue is not empty</span></span><br><span class="line">      <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt; logError(<span class="string">&quot;Unexpected error in &quot;</span> + name, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>事件取出之后，会将事件传给一个onReceive方法，继续查看该方法的源码，直接点进去会看到显示的是一个抽象的方法，这个抽象方法是位于EventLoop这个抽象类中的，真正执行的onReceive方法是实现这个抽象类的DAGSchedulerEventProcessLoop类中的onReceive方法。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onReceive</span></span>(event: <span class="type">DAGSchedulerEvent</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> timerContext = timer.time()</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    doOnReceive(event)</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    timerContext.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>这是阶段调度器的主要事件循环。该方法又将事件传给了doOnReceive方法，  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">doOnReceive</span></span>(event: <span class="type">DAGSchedulerEvent</span>): <span class="type">Unit</span> = event <span class="keyword">match</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="type">JobSubmitted</span>(jobId, rdd, func, partitions, callSite, listener, properties) =&gt;</span><br><span class="line">    dagScheduler.handleJobSubmitted(jobId, rdd, func, partitions, callSite, listener, properties)</span><br><span class="line"></span><br><span class="line">	……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>该方法中包含模式匹配，JobSubmitted事件正好可以匹配到第一项，说白了就是DAGScheduler类会向事件队列发送一个消息，消息中包含的是事件，然后事件线程收到消息之后会对消息进行匹配。此处会执行handleJobSubmitted方法，查看其源码，其中  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[scheduler] <span class="function"><span class="keyword">def</span> <span class="title">handleJobSubmitted</span></span>(jobId: <span class="type">Int</span>,</span><br><span class="line">    finalRDD: <span class="type">RDD</span>[_],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</span><br><span class="line">    partitions: <span class="type">Array</span>[<span class="type">Int</span>],</span><br><span class="line">    callSite: <span class="type">CallSite</span>,</span><br><span class="line">    listener: <span class="type">JobListener</span>,</span><br><span class="line">    properties: <span class="type">Properties</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">var</span> finalStage: <span class="type">ResultStage</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// New stage creation may throw an exception if, for example, jobs are run on a</span></span><br><span class="line">    <span class="comment">// HadoopRDD whose underlying HDFS files have been deleted.</span></span><br><span class="line">    finalStage = createResultStage(finalRDD, func, partitions, jobId, callSite)</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">	……</span><br></pre></td></tr></table></figure></li>
<li>这部分区域是对阶段进行划分。createResultStage方法用于ResultStage阶段。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createResultStage</span></span>(</span><br><span class="line">    rdd: <span class="type">RDD</span>[_],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</span><br><span class="line">    partitions: <span class="type">Array</span>[<span class="type">Int</span>],</span><br><span class="line">    jobId: <span class="type">Int</span>,</span><br><span class="line">    callSite: <span class="type">CallSite</span>): <span class="type">ResultStage</span> = &#123;</span><br><span class="line">  checkBarrierStageWithDynamicAllocation(rdd)</span><br><span class="line">  checkBarrierStageWithNumSlots(rdd)</span><br><span class="line">  checkBarrierStageWithRDDChainPattern(rdd, partitions.toSet.size)</span><br><span class="line">  <span class="keyword">val</span> parents = getOrCreateParentStages(rdd, jobId)</span><br><span class="line">  <span class="keyword">val</span> id = nextStageId.getAndIncrement()</span><br><span class="line">  <span class="keyword">val</span> stage = <span class="keyword">new</span> <span class="type">ResultStage</span>(id, rdd, func, partitions, parents, jobId, callSite)</span><br><span class="line">  stageIdToStage(id) = stage</span><br><span class="line">  updateJobIdStageIdMaps(jobId, stage)</span><br><span class="line">  stage</span><br><span class="line">&#125;</span><br><span class="line">​ <span class="type">ResultStage</span>中包含的rdd就是执行行动算子的那个rdd（下图中黄色表示的那个），也就是最后的那个rdd（下图中黄色图表示的rdd）。parents是<span class="type">ResultStage</span>的上一级阶段，parents是getOrCreateParentStages方法的返回值。getOrCreateParentStages用于获取或者创建给定<span class="type">RDD</span>的父阶段列表。</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getOrCreateParentStages</span></span>(rdd: <span class="type">RDD</span>[_], firstJobId: <span class="type">Int</span>): <span class="type">List</span>[<span class="type">Stage</span>] = &#123;</span><br><span class="line">  getShuffleDependencies(rdd).map &#123; shuffleDep =&gt;</span><br><span class="line">    getOrCreateShuffleMapStage(shuffleDep, firstJobId)</span><br><span class="line">  &#125;.toList</span><br><span class="line">&#125;</span><br><span class="line">​ getShuffleDependencies方法用于获取给定rdd的shuffle依赖，其核心代码如下：</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[scheduler] <span class="function"><span class="keyword">def</span> <span class="title">getShuffleDependencies</span></span>(</span><br><span class="line">    rdd: <span class="type">RDD</span>[_]): <span class="type">HashSet</span>[<span class="type">ShuffleDependency</span>[_, _, _]] = &#123;</span><br><span class="line"> 		……</span><br><span class="line">  <span class="keyword">while</span> (waitingForVisit.nonEmpty) &#123;</span><br><span class="line">    <span class="keyword">val</span> toVisit = waitingForVisit.remove(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">if</span> (!visited(toVisit)) &#123;</span><br><span class="line">      visited += toVisit</span><br><span class="line">      toVisit.dependencies.foreach &#123;</span><br><span class="line">        <span class="keyword">case</span> shuffleDep: <span class="type">ShuffleDependency</span>[_, _, _] =&gt;</span><br><span class="line">          parents += shuffleDep</span><br><span class="line">        <span class="keyword">case</span> dependency =&gt;</span><br><span class="line">          waitingForVisit.prepend(dependency.rdd)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  parents</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>核心代码用于判断给定rdd的依赖关系是不是shuffle依赖，如果是则加入结果列表。最终返回的结果列表，会通过map方法将列表中的每一个元素执行getOrCreateShuffleMapStage方法，该方法用于获取或者创建ShuffleMap阶段（写磁盘之前的阶段）。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">getOrCreateShuffleMapStage(shuffleDep, firstJobId) =&gt; createShuffleMapStage(shuffleDep, firstJobId)</span><br></pre></td></tr></table></figure></li>
<li>createShuffleMapStage方法中会创建ShuffleMapStage对象，并当前rdd（调用行动算子的那个）依赖的rdd（下图紫色那个rdd）传给这个对象。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createShuffleMapStage</span></span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">C</span>](</span><br><span class="line">    shuffleDep: <span class="type">ShuffleDependency</span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">C</span>], jobId: <span class="type">Int</span>): <span class="type">ShuffleMapStage</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> rdd = shuffleDep.rdd</span><br><span class="line">	……</span><br><span class="line">  <span class="keyword">val</span> numTasks = rdd.partitions.length</span><br><span class="line">  <span class="keyword">val</span> parents = getOrCreateParentStages(rdd, jobId)</span><br><span class="line">  <span class="keyword">val</span> id = nextStageId.getAndIncrement()</span><br><span class="line">  <span class="keyword">val</span> stage = <span class="keyword">new</span> <span class="type">ShuffleMapStage</span>(</span><br><span class="line">    id, rdd, numTasks, parents, jobId, rdd.creationSite, shuffleDep, mapOutputTracker)</span><br><span class="line"></span><br><span class="line">	……</span><br></pre></td></tr></table></figure></li>
<li>此时，ShuffleMap阶段（下图红色区域）就是Result阶段（蓝色区域）的上一级阶段。在上面的代码中，我们还可以看到，如果当前ShuffleMap阶段还有上一级阶段，那么getOrCreateParentStages(rdd, jobId)方法还是会获取它的上一级阶段的，此时这个方法中的rdd就不再是最后一个rdd，而是最后一个rdd的前一个rdd，也就是紫色表示的那个rdd。也就是说，阶段的寻找是一个不断往前的过程，只要含有shuffle过程，那么就会有新的阶段。<br>  <img src="https://s2.loli.net/2021/12/11/rvgSydiUjZf3pst.jpg"></li>
</ul>
</li>
<li><p>RDD 任务划分<br>RDD任务切分中间分为：Application、Job、Stage和Task</p>
</li>
</ol>
<ul>
<li>Application：初始化一个SparkContext即生成一个Application；</li>
<li>Job：一个Action算子就会生成一个Job；</li>
<li>Stage：Stage等于宽依赖(ShuffleDependency)的个数加1；</li>
<li>Task：一个Stage阶段中，最后一个RDD的分区个数就是Task的个数。<br><font color ='red' >注意：Application-&gt;Job-&gt;Stage-&gt;Task每一层都是1对n的关系。 </font></li>
</ul>
<ol start="8">
<li>RDD 任务划分源码<ul>
<li>DAGScheduler类的handleJobSubmitted方法中，有一个提交阶段的的方法：  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> finalStage: <span class="type">ResultStage</span> = <span class="literal">null</span></span><br><span class="line">	……</span><br><span class="line">finalStage = createResultStage(finalRDD, func, partitions, jobId, callSite)</span><br><span class="line">	……</span><br><span class="line">submitStage(finalStage)</span><br></pre></td></tr></table></figure></li>
<li>submitStage方法用于提交最终的ResultStage阶段，由于在最终的ResultStage可能包含了多个上级阶段，所以此处就相当于是提交整个应用程序的全部阶段。查看一下该方法的源码：  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitStage</span></span>(stage: <span class="type">Stage</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> jobId = activeJobForStage(stage)</span><br><span class="line">  <span class="keyword">if</span> (jobId.isDefined) &#123;</span><br><span class="line">    logDebug(<span class="string">s&quot;submitStage(<span class="subst">$stage</span> (name=<span class="subst">$&#123;stage.name&#125;</span>;&quot;</span> +</span><br><span class="line">      <span class="string">s&quot;jobs=<span class="subst">$&#123;stage.jobIds.toSeq.sorted.mkString(&quot;,&quot;)&#125;</span>))&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> (!waitingStages(stage) &amp;&amp; !runningStages(stage) &amp;&amp; !failedStages(stage)) &#123;</span><br><span class="line">      <span class="keyword">val</span> missing = getMissingParentStages(stage).sortBy(_.id)</span><br><span class="line">      logDebug(<span class="string">&quot;missing: &quot;</span> + missing)</span><br><span class="line">      <span class="keyword">if</span> (missing.isEmpty) &#123;</span><br><span class="line">        logInfo(<span class="string">&quot;Submitting &quot;</span> + stage + <span class="string">&quot; (&quot;</span> + stage.rdd + <span class="string">&quot;), which has no missing parents&quot;</span>)</span><br><span class="line">        submitMissingTasks(stage, jobId.get)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (parent &lt;- missing) &#123;</span><br><span class="line">          submitStage(parent)</span><br><span class="line">        &#125;</span><br><span class="line">        waitingStages += stage</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    abortStage(stage, <span class="string">&quot;No active job for stage &quot;</span> + stage.id, <span class="type">None</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>该方法的内部核心逻辑是先获取当前阶段的的所有父级阶段，如果其父级阶段为空那么直接执行submitMissingTasks方法，如果不为空，那么递归执行submitStage方法，只不过传入的参数是当前阶段的父级阶段，一直递归直到找到没有上级阶段的阶段，最终没有上级阶段的那个阶段会执行submitMissingTasks方法。下面查看一下该方法的核心源码部分：  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitMissingTasks</span></span>(stage: <span class="type">Stage</span>, jobId: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    	 ……</span><br><span class="line">  <span class="keyword">val</span> partitionsToCompute: <span class="type">Seq</span>[<span class="type">Int</span>] = stage.findMissingPartitions()</span><br><span class="line">		 ……</span><br><span class="line">  <span class="keyword">val</span> tasks: <span class="type">Seq</span>[<span class="type">Task</span>[_]] = <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">val</span> serializedTaskMetrics = closureSerializer.serialize(stage.latestInfo.taskMetrics).array()</span><br><span class="line">    stage <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">        stage.pendingPartitions.clear()</span><br><span class="line">        partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">          <span class="keyword">val</span> locs = taskIdToLocations(id)</span><br><span class="line">          <span class="keyword">val</span> part = partitions(id)</span><br><span class="line">          stage.pendingPartitions += id</span><br><span class="line">          <span class="keyword">new</span> <span class="type">ShuffleMapTask</span>(stage.id, stage.latestInfo.attemptNumber,</span><br><span class="line">            taskBinary, part, locs, properties, serializedTaskMetrics, <span class="type">Option</span>(jobId),</span><br><span class="line">            <span class="type">Option</span>(sc.applicationId), sc.applicationAttemptId, stage.rdd.isBarrier())</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</span><br><span class="line">        partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">          <span class="keyword">val</span> p: <span class="type">Int</span> = stage.partitions(id)</span><br><span class="line">          <span class="keyword">val</span> part = partitions(p)</span><br><span class="line">          <span class="keyword">val</span> locs = taskIdToLocations(id)</span><br><span class="line">          <span class="keyword">new</span> <span class="type">ResultTask</span>(stage.id, stage.latestInfo.attemptNumber,</span><br><span class="line">            taskBinary, part, locs, id, properties, serializedTaskMetrics,</span><br><span class="line">            <span class="type">Option</span>(jobId), <span class="type">Option</span>(sc.applicationId), sc.applicationAttemptId,</span><br><span class="line">            stage.rdd.isBarrier())</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">      abortStage(stage, <span class="string">s&quot;Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;Utils.exceptionString(e)&#125;</span>&quot;</span>, <span class="type">Some</span>(e))</span><br><span class="line">      runningStages -= stage</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> 	……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>核心代码的逻辑在于根据传入的stage进行模式匹配，会根据不同类型的Satge创建的不同的Task，那么首先会计算分区得到分区索引集合，然后使用map方法将根据分区id创建xxxMapTask对象，有几个分区id就创建几个xxxMapTask对象。partitionsToCompute是stage.findMissingPartitions()的返回值，那么查看其源码，stage是一个抽象类的引用，调用的这个方法具体的实现在具体的xxxMapStage类中。分别查看一下在resultstage和中的源码：<ul>
<li>ResultStage：  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">findMissingPartitions</span></span>(): <span class="type">Seq</span>[<span class="type">Int</span>] = &#123;</span><br><span class="line">  <span class="keyword">val</span> job = activeJob.get</span><br><span class="line">  (<span class="number">0</span> until job.numPartitions).filter(id =&gt; !job.finished(id))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>ShuffleMapStage：  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">findMissingPartitions</span></span>(): <span class="type">Seq</span>[<span class="type">Int</span>] = &#123;</span><br><span class="line">  mapOutputTrackerMaster</span><br><span class="line">    .findMissingPartitions(shuffleDep.shuffleId)</span><br><span class="line">    .getOrElse(<span class="number">0</span> until numPartitions)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>所以可以看出，partitionsToCompute就是一个分区索引的集合。ResultStage和ShuffleMapStage的numPartitions的值计算方式一样，都是来自于它们所处阶段的最后一个rdd的分区数量值：<ul>
<li>job.numPartitions值：  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> numPartitions = finalStage <span class="keyword">match</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> r: <span class="type">ResultStage</span> =&gt; r.partitions.length</span><br><span class="line">  <span class="keyword">case</span> m: <span class="type">ShuffleMapStage</span> =&gt; m.rdd.partitions.length</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>numPartitions：  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> numPartitions = rdd.partitions.length</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>所以总结一下，应用程序的总任务数量等于每个阶段的最后一个rdd的分区数量之和。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="5-1-4-8-RDD持久化"><a href="#5-1-4-8-RDD持久化" class="headerlink" title="5.1.4.8 RDD持久化"></a>5.1.4.8 RDD持久化</h4><ol>
<li><p>RDD Cache缓存<br> RDD通过Cache或者Persist方法将前面的计算结果缓存，默认情况下会把数据以缓存在JVM的堆内存中。但是并不是这两个方法被调用时立即缓存，而是触发后面的action算子时，该RDD将会被缓存在计算节点的内存中，并供后面重用。</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// cache操作会增加血缘关系，不改变原有的血缘关系</span></span><br><span class="line">println(wordToOneRdd.toDebugString)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 数据缓存。</span></span><br><span class="line">wordToOneRdd.cache()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 可以更改存储级别</span></span><br><span class="line"><span class="comment">//mapRdd.persist(StorageLevel.MEMORY_AND_DISK_2)</span></span><br><span class="line">存储级别</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">StorageLevel</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> <span class="type">NONE</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">DISK_ONLY</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">DISK_ONLY_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>, <span class="number">2</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY_SER</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY_SER_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>, <span class="number">2</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_SER</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_SER_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">OFF_HEAP</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p> <img src="https://s2.loli.net/2021/12/11/lf4FvbAzEqIcYTn.jpg"><br> 缓存有可能丢失，或者存储于内存的数据由于内存不足而被删除，RDD的缓存容错机制保证了即使缓存丢失也能保证计算的正确执行。通过基于RDD的一系列转换，丢失的数据会被重算，由于RDD的各个Partition是相对独立的，因此只需要计算丢失的部分即可，并不需要重算全部Partition。<br> Spark会自动对一些Shuffle操作的中间数据做持久化操作(比如：reduceByKey)。这样做的目的是为了当一个节点Shuffle失败了避免重新计算整个输入。但是，在实际使用的时候，如果想重用数据，仍然建议调用persist或cache。</p>
</li>
<li><p>RDD CheckPoint检查点<br> 所谓的检查点其实就是将RDD中间结果写入磁盘<br> 由于血缘依赖过长会造成容错成本过高，这样就不如在中间阶段做检查点容错，如果检查点之后有节点出现问题，可以从检查点开始重做血缘，减少了开销。<br> 对RDD进行checkpoint操作并不会马上被执行，必须执行Action操作才能触发。</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置检查点路径</span></span><br><span class="line">sc.setCheckpointDir(<span class="string">&quot;./checkpoint1&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一个RDD，读取指定位置文件:hello atguigu atguigu</span></span><br><span class="line"><span class="keyword">val</span> lineRdd: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;input/1.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 业务逻辑</span></span><br><span class="line"><span class="keyword">val</span> wordRdd: <span class="type">RDD</span>[<span class="type">String</span>] = lineRdd.flatMap(line =&gt; line.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> wordToOneRdd: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Long</span>)] = wordRdd.map &#123;</span><br><span class="line">    word =&gt; &#123;</span><br><span class="line">        (word, <span class="type">System</span>.currentTimeMillis())</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 增加缓存,避免再重新跑一个job做checkpoint</span></span><br><span class="line">wordToOneRdd.cache()</span><br><span class="line"><span class="comment">// 数据检查点：针对wordToOneRdd做检查点计算</span></span><br><span class="line">wordToOneRdd.checkpoint()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 触发执行逻辑</span></span><br><span class="line">wordToOneRdd.collect().foreach(println)</span><br></pre></td></tr></table></figure></li>
<li><p>缓存和检查点区别</p>
<ul>
<li>Cache缓存只是将数据保存起来，不切断血缘依赖。Checkpoint检查点切断血缘依赖。</li>
<li>Cache缓存的数据通常存储在磁盘、内存等地方，可靠性低。Checkpoint的数据通常存储在HDFS等容错、高可用的文件系统，可靠性高。</li>
<li>建议对checkpoint()的RDD使用Cache缓存，这样checkpoint的job只需从Cache缓存中读取数据即可，否则需要再从头计算一次RDD。</li>
</ul>
</li>
</ol>
<h4 id="5-1-4-9-RDD分区器"><a href="#5-1-4-9-RDD分区器" class="headerlink" title="5.1.4.9 RDD分区器"></a>5.1.4.9 RDD分区器</h4><p>Spark目前支持Hash分区和Range分区，和用户自定义分区。Hash分区为当前的默认分区。分区器直接决定了RDD中分区的个数、RDD中每条数据经过Shuffle后进入哪个分区，进而决定了Reduce的个数。</p>
<ul>
<li>只有Key-Value类型的RDD才有分区器，非Key-Value类型的RDD分区的值是None</li>
<li>每个RDD的分区ID范围：0 ~ (numPartitions - 1)，决定这个值是属于那个分区的。</li>
</ul>
<ol>
<li>Hash分区：对于给定的key，计算其hashCode,并除以分区个数取余 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HashPartitioner</span>(<span class="params">partitions: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line">  require(partitions &gt;= <span class="number">0</span>, <span class="string">s&quot;Number of partitions (<span class="subst">$partitions</span>) cannot be negative.&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">numPartitions</span></span>: <span class="type">Int</span> = partitions</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getPartition</span></span>(key: <span class="type">Any</span>): <span class="type">Int</span> = key <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="literal">null</span> =&gt; <span class="number">0</span></span><br><span class="line">    <span class="keyword">case</span> _ =&gt; <span class="type">Utils</span>.nonNegativeMod(key.hashCode, numPartitions)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">equals</span></span>(other: <span class="type">Any</span>): <span class="type">Boolean</span> = other <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> h: <span class="type">HashPartitioner</span> =&gt;</span><br><span class="line">      h.numPartitions == numPartitions</span><br><span class="line">    <span class="keyword">case</span> _ =&gt;</span><br><span class="line">      <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">hashCode</span></span>: <span class="type">Int</span> = numPartitions</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>Range分区：将一定范围内的数据映射到一个分区中，尽量保证每个分区数据均匀，而且分区间有序 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RangePartitioner</span>[<span class="type">K</span> : <span class="type">Ordering</span> : <span class="type">ClassTag</span>, <span class="type">V</span>](<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="class">    partitions: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">    rdd: <span class="type">RDD</span>[_ &lt;: <span class="type">Product2</span>[<span class="type">K</span>, <span class="type">V</span>]],</span></span></span><br><span class="line"><span class="params"><span class="class">    private var ascending: <span class="type">Boolean</span> = true</span>)</span></span><br><span class="line">  <span class="keyword">extends</span> <span class="type">Partitioner</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// We allow partitions = 0, which happens when sorting an empty RDD under the default settings.</span></span><br><span class="line">  require(partitions &gt;= <span class="number">0</span>, <span class="string">s&quot;Number of partitions cannot be negative but found <span class="subst">$partitions</span>.&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> ordering = implicitly[<span class="type">Ordering</span>[<span class="type">K</span>]]</span><br><span class="line"></span><br><span class="line">  <span class="comment">// An array of upper bounds for the first (partitions - 1) partitions</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> rangeBounds: <span class="type">Array</span>[<span class="type">K</span>] = &#123;</span><br><span class="line">  ...</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">numPartitions</span></span>: <span class="type">Int</span> = rangeBounds.length + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> binarySearch: ((<span class="type">Array</span>[<span class="type">K</span>], <span class="type">K</span>) =&gt; <span class="type">Int</span>) = <span class="type">CollectionsUtils</span>.makeBinarySearch[<span class="type">K</span>]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getPartition</span></span>(key: <span class="type">Any</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> k = key.asInstanceOf[<span class="type">K</span>]</span><br><span class="line">    <span class="keyword">var</span> partition = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> (rangeBounds.length &lt;= <span class="number">128</span>) &#123;</span><br><span class="line">      <span class="comment">// If we have less than 128 partitions naive search</span></span><br><span class="line">      <span class="keyword">while</span> (partition &lt; rangeBounds.length &amp;&amp; ordering.gt(k, rangeBounds(partition))) &#123;</span><br><span class="line">        partition += <span class="number">1</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// Determine which binary search method to use only once.</span></span><br><span class="line">      partition = binarySearch(rangeBounds, k)</span><br><span class="line">      <span class="comment">// binarySearch either returns the match location or -[insertion point]-1</span></span><br><span class="line">      <span class="keyword">if</span> (partition &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        partition = -partition<span class="number">-1</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (partition &gt; rangeBounds.length) &#123;</span><br><span class="line">        partition = rangeBounds.length</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (ascending) &#123;</span><br><span class="line">      partition</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      rangeBounds.length - partition</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">equals</span></span>(other: <span class="type">Any</span>): <span class="type">Boolean</span> = other <span class="keyword">match</span> &#123;</span><br><span class="line">  ...</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">hashCode</span></span>(): <span class="type">Int</span> = &#123;</span><br><span class="line">  ...</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@throws</span>(classOf[<span class="type">IOException</span>])</span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">writeObject</span></span>(out: <span class="type">ObjectOutputStream</span>): <span class="type">Unit</span> = <span class="type">Utils</span>.tryOrIOException &#123;</span><br><span class="line">  ...</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@throws</span>(classOf[<span class="type">IOException</span>])</span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">readObject</span></span>(in: <span class="type">ObjectInputStream</span>): <span class="type">Unit</span> = <span class="type">Utils</span>.tryOrIOException &#123;</span><br><span class="line">  ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="5-1-4-10-RDD文件读取与保存"><a href="#5-1-4-10-RDD文件读取与保存" class="headerlink" title="5.1.4.10 RDD文件读取与保存"></a>5.1.4.10 RDD文件读取与保存</h4><p>Spark的数据读取及数据保存可以从两个维度来作区分：文件格式以及文件系统。</p>
<ul>
<li>文件格式分为：text文件、csv文件、sequence文件以及Object文件；</li>
<li>文件系统分为：本地文件系统、HDFS、HBASE以及数据库。<ul>
<li>text文件  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 读取输入文件</span></span><br><span class="line"><span class="keyword">val</span> inputRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;input/1.txt&quot;</span>)</span><br><span class="line"><span class="comment">// 保存数据</span></span><br><span class="line">inputRDD.saveAsTextFile(<span class="string">&quot;output&quot;</span>)</span><br></pre></td></tr></table></figure></li>
<li>sequence文件<br>  SequenceFile文件是Hadoop用来存储二进制形式的key-value对而设计的一种平面文件(Flat File)。在SparkContext中，可以调用sequenceFile<a href="path">keyClass, valueClass</a>。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 保存数据为SequenceFile</span></span><br><span class="line">dataRDD.saveAsSequenceFile(<span class="string">&quot;output&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读取SequenceFile文件</span></span><br><span class="line">sc.sequenceFile[<span class="type">Int</span>,<span class="type">Int</span>](<span class="string">&quot;output&quot;</span>).collect().foreach(println)</span><br></pre></td></tr></table></figure></li>
<li>object对象文件<br>  对象文件是将对象序列化后保存的文件，采用Java的序列化机制。可以通过objectFile<a href="path">T: ClassTag</a>函数接收一个路径，读取对象文件，返回对应的RDD，也可以通过调用saveAsObjectFile()实现对对象文件的输出。因为是序列化所以要指定类型。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 保存数据</span></span><br><span class="line">dataRDD.saveAsObjectFile(<span class="string">&quot;output&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读取数据</span></span><br><span class="line">sc.objectFile[<span class="type">Int</span>](<span class="string">&quot;output&quot;</span>).collect().foreach(println)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h2 id="5-2-累加器"><a href="#5-2-累加器" class="headerlink" title="5.2 累加器"></a>5.2 累加器</h2><h3 id="5-2-1-实现原理"><a href="#5-2-1-实现原理" class="headerlink" title="5.2.1 实现原理"></a>5.2.1 实现原理</h3><p>累加器用来把Executor端变量信息聚合到Driver端。在Driver程序中定义的变量，在Executor端的每个Task都会得到这个变量的一份新的副本，每个task更新这些副本的值后，传回Driver端进行merge。</p>
<h3 id="5-2-2-基础编程"><a href="#5-2-2-基础编程" class="headerlink" title="5.2.2 基础编程"></a>5.2.2 基础编程</h3><h4 id="5-2-2-1-系统累加器"><a href="#5-2-2-1-系统累加器" class="headerlink" title="5.2.2.1 系统累加器"></a>5.2.2.1 系统累加器</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>))</span><br><span class="line"><span class="comment">// 声明累加器</span></span><br><span class="line"><span class="keyword">var</span> sum = sc.longAccumulator(<span class="string">&quot;sum&quot;</span>);</span><br><span class="line">rdd.foreach(</span><br><span class="line">  num =&gt; &#123;</span><br><span class="line">    <span class="comment">// 使用累加器</span></span><br><span class="line">    sum.add(num)</span><br><span class="line">  &#125;</span><br><span class="line">)</span><br><span class="line"><span class="comment">// 获取累加器的值</span></span><br><span class="line">println(<span class="string">&quot;sum = &quot;</span> + sum.value)</span><br></pre></td></tr></table></figure>

<h4 id="5-2-2-2-自定义累加器"><a href="#5-2-2-2-自定义累加器" class="headerlink" title="5.2.2.2 自定义累加器"></a>5.2.2.2 自定义累加器</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 自定义累加器</span></span><br><span class="line"><span class="comment">// 1. 继承AccumulatorV2，并设定泛型</span></span><br><span class="line"><span class="comment">// 2. 重写累加器的抽象方法</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WordCountAccumulator</span> <span class="keyword">extends</span> <span class="title">AccumulatorV2</span>[<span class="type">String</span>, mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Long</span>]]</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> map : mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Long</span>] = mutable.<span class="type">Map</span>()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 累加器是否为初始状态</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">isZero</span></span>: <span class="type">Boolean</span> = &#123;</span><br><span class="line">      map.isEmpty</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 复制累加器</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">copy</span></span>(): <span class="type">AccumulatorV2</span>[<span class="type">String</span>, mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Long</span>]] = &#123;</span><br><span class="line">      <span class="keyword">new</span> <span class="type">WordCountAccumulator</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 重置累加器</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reset</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">      map.clear()</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 向累加器中增加数据 (In)</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(word: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 查询map中是否存在相同的单词</span></span><br><span class="line">        <span class="comment">// 如果有相同的单词，那么单词的数量加1</span></span><br><span class="line">        <span class="comment">// 如果没有相同的单词，那么在map中增加这个单词</span></span><br><span class="line">        map(word) = map.getOrElse(word, <span class="number">0</span>L) + <span class="number">1</span>L</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 合并累加器</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(other: <span class="type">AccumulatorV2</span>[<span class="type">String</span>, mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Long</span>]]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    </span><br><span class="line">      <span class="keyword">val</span> map1 = map</span><br><span class="line">      <span class="keyword">val</span> map2 = other.value</span><br><span class="line">    </span><br><span class="line">      <span class="comment">// 两个Map的合并</span></span><br><span class="line">      map = map1.foldLeft(map2)(</span><br><span class="line">        ( innerMap, kv ) =&gt; &#123;</span><br><span class="line">          innerMap(kv._1) = innerMap.getOrElse(kv._1, <span class="number">0</span>L) + kv._2</span><br><span class="line">          innerMap</span><br><span class="line">        &#125;</span><br><span class="line">      )</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 返回累加器的结果 （Out）</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">value</span></span>: mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Long</span>] = map</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="5-3-广播变量"><a href="#5-3-广播变量" class="headerlink" title="5.3 广播变量"></a>5.3 广播变量</h2><h3 id="5-3-1-实现原理"><a href="#5-3-1-实现原理" class="headerlink" title="5.3.1 实现原理"></a>5.3.1 实现原理</h3><p>广播变量用来高效分发较大的对象。向所有工作节点发送一个较大的只读值，以供一个或多个Spark操作使用。比如，如果你的应用需要向所有节点发送一个较大的只读查询表，广播变量用起来都很顺手。在多个并行操作中使用同一个变量，但是 Spark会为每个任务分别发送。</p>
<h3 id="5-3-2-基础编程"><a href="#5-3-2-基础编程" class="headerlink" title="5.3.2 基础编程"></a>5.3.2 基础编程</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1 = sc.makeRDD(<span class="type">List</span>( (<span class="string">&quot;a&quot;</span>,<span class="number">1</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;c&quot;</span>, <span class="number">3</span>), (<span class="string">&quot;d&quot;</span>, <span class="number">4</span>) ),<span class="number">4</span>)</span><br><span class="line"><span class="keyword">val</span> list = <span class="type">List</span>( (<span class="string">&quot;a&quot;</span>,<span class="number">4</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">5</span>), (<span class="string">&quot;c&quot;</span>, <span class="number">6</span>), (<span class="string">&quot;d&quot;</span>, <span class="number">7</span>) )</span><br><span class="line"><span class="comment">// 声明广播变量</span></span><br><span class="line"><span class="keyword">val</span> broadcast: <span class="type">Broadcast</span>[<span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]] = sc.broadcast(list)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultRDD: <span class="type">RDD</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Int</span>))] = rdd1.map &#123;</span><br><span class="line">  <span class="keyword">case</span> (key, num) =&gt; &#123;</span><br><span class="line">    <span class="keyword">var</span> num2 = <span class="number">0</span></span><br><span class="line">    <span class="comment">// 使用广播变量</span></span><br><span class="line">    <span class="keyword">for</span> ((k, v) &lt;- broadcast.value) &#123;</span><br><span class="line">      <span class="keyword">if</span> (k == key) &#123;</span><br><span class="line">        num2 = v</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    (key, (num, num2))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h1 id="第6章-Spark案例实操"><a href="#第6章-Spark案例实操" class="headerlink" title="第6章 Spark案例实操"></a>第6章 Spark案例实操</h1><p>在实际的工作中如何使用这些API实现具体的需求。这些需求是电商网站的真实需求，所以在实现功能前，必须先将数据准备好。<br><img src="https://s2.loli.net/2021/12/11/TLAMWjC5Ybc4a19.jpg"></p>
<p>上面的数据图是从数据文件中截取的一部分内容，表示为电商网站的用户行为数据，主要包含用户的4种行为：搜索，点击，下单，支付。数据规则如下：</p>
<ul>
<li>数据文件中每行数据采用下划线分隔数据</li>
<li>每一行数据表示用户的一次行为，这个行为只能是4种行为的一种</li>
<li>如果搜索关键字为null,表示数据不是搜索数据</li>
<li>如果点击的品类ID和产品ID为-1，表示数据不是点击数据</li>
<li>针对于下单行为，一次可以下单多个商品，所以品类ID和产品ID可以是多个，id之间采用逗号分隔，如果本次不是下单行为，则数据采用null表示</li>
<li>支付行为和下单行为类似</li>
</ul>
<p>详细字段说明：<br>|编号        |字段名称      |字段类型      |字段含义       |<br>|——– |———–|———–|————-|<br>|1|  date| String|  用户点击行为的日期|<br>|2|  user_id|  Long| 用户的ID|<br>|3|  session_id|   String|    Session的ID|<br>|4|  page_id|  Long| 某个页面的ID|<br>|5|  action_time|  String|   动作的时间点|<br>|6|  search_keyword|   String|    用户搜索的关键词|<br>|7|  click_category_id|    Long|   某一个商品品类的ID|<br>|8|  click_product_id| Long|    某一个商品的ID|<br>|9|  order_category_ids|   String|    一次订单中所有品类的ID集合|<br>|10| order_product_ids|   String|    一次订单中所有商品的ID集合|<br>|11| pay_category_ids|    String| 一次支付中所有品类的ID集合|<br>|12| pay_product_ids| String|  一次支付中所有商品的ID集合|<br>|13| city_id| Long|    城市 id|</p>
<p>样例类：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//用户访问动作表</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">UserVisitAction</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="class">    date: <span class="type">String</span>,//用户点击行为的日期</span></span></span><br><span class="line"><span class="params"><span class="class">    user_id: <span class="type">Long</span>,//用户的<span class="type">ID</span></span></span></span><br><span class="line"><span class="params"><span class="class">    session_id: <span class="type">String</span>,//<span class="type">Session</span>的<span class="type">ID</span></span></span></span><br><span class="line"><span class="params"><span class="class">    page_id: <span class="type">Long</span>,//某个页面的<span class="type">ID</span></span></span></span><br><span class="line"><span class="params"><span class="class">    action_time: <span class="type">String</span>,//动作的时间点</span></span></span><br><span class="line"><span class="params"><span class="class">    search_keyword: <span class="type">String</span>,//用户搜索的关键词</span></span></span><br><span class="line"><span class="params"><span class="class">    click_category_id: <span class="type">Long</span>,//某一个商品品类的<span class="type">ID</span></span></span></span><br><span class="line"><span class="params"><span class="class">    click_product_id: <span class="type">Long</span>,//某一个商品的<span class="type">ID</span></span></span></span><br><span class="line"><span class="params"><span class="class">    order_category_ids: <span class="type">String</span>,//一次订单中所有品类的<span class="type">ID</span>集合</span></span></span><br><span class="line"><span class="params"><span class="class">    order_product_ids: <span class="type">String</span>,//一次订单中所有商品的<span class="type">ID</span>集合</span></span></span><br><span class="line"><span class="params"><span class="class">    pay_category_ids: <span class="type">String</span>,//一次支付中所有品类的<span class="type">ID</span>集合</span></span></span><br><span class="line"><span class="params"><span class="class">    pay_product_ids: <span class="type">String</span>,//一次支付中所有商品的<span class="type">ID</span>集合</span></span></span><br><span class="line"><span class="params"><span class="class">    city_id: <span class="type">Long</span>//城市 id</span></span></span><br><span class="line"><span class="params"><span class="class"></span>)</span></span><br></pre></td></tr></table></figure>

<h2 id="6-1-需求1：Top10热门品类"><a href="#6-1-需求1：Top10热门品类" class="headerlink" title="6.1 需求1：Top10热门品类"></a>6.1 需求1：Top10热门品类</h2><p><img src="https://s2.loli.net/2021/12/11/NHbitm2oXMDEnqZ.jpg"></p>
<h3 id="6-1-1-需求说明"><a href="#6-1-1-需求说明" class="headerlink" title="6.1.1 需求说明"></a>6.1.1 需求说明</h3><p>品类是指产品的分类，大型电商网站品类分多级，咱们的项目中品类只有一级，不同的公司可能对热门的定义不一样。我们按照每个品类的点击、下单、支付的量来统计热门品类。</p>
<p>鞋            点击数 下单数  支付数<br>衣服        点击数 下单数  支付数<br>电脑        点击数 下单数  支付数</p>
<p>例如，综合排名 = 点击数<em>20%+下单数</em>30%+支付数*50%</p>
<p>本项目需求优化为：<font color ='red' >先按照点击数排名，靠前的就排名高；如果点击数相同，再比较下单数；下单数再相同，就比较支付数。</font></p>
<h3 id="6-1-2-实现方案一"><a href="#6-1-2-实现方案一" class="headerlink" title="6.1.2 实现方案一"></a>6.1.2 实现方案一</h3><h4 id="6-1-2-1-需求分析"><a href="#6-1-2-1-需求分析" class="headerlink" title="6.1.2.1 需求分析"></a>6.1.2.1 需求分析</h4><p>分别统计每个品类点击的次数，下单的次数和支付的次数：<br>（品类，点击总数）（品类，下单总数）（品类，支付总数）</p>
<h4 id="6-1-2-2-需求实现"><a href="#6-1-2-2-需求实现" class="headerlink" title="6.1.2.2 需求实现"></a>6.1.2.2 需求实现</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">top10_1</span> </span>= &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//读取文件</span></span><br><span class="line">    <span class="keyword">val</span> userVisitRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sparkContext.textFile(<span class="string">&quot;data/user_visit_action.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//统计品类的点击数量</span></span><br><span class="line">    <span class="keyword">val</span> clickCountRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = userVisitRDD.filter(</span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">            (line.split(<span class="string">&quot;_&quot;</span>)(<span class="number">6</span>) != <span class="string">&quot;-1&quot;</span>) &amp;&amp; (line.split(<span class="string">&quot;_&quot;</span>)(<span class="number">7</span>) != <span class="string">&quot;-1&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    ).map(</span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> datas: <span class="type">Array</span>[<span class="type">String</span>] = line.split(<span class="string">&quot;_&quot;</span>)</span><br><span class="line">            (datas(<span class="number">6</span>), <span class="number">1</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    ).reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//统计品类的下单数量</span></span><br><span class="line">    <span class="keyword">val</span> orderCountRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = userVisitRDD.filter(</span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> datas = line.split(<span class="string">&quot;_&quot;</span>)</span><br><span class="line">            datas(<span class="number">8</span>) != <span class="string">&quot;null&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ).flatMap(</span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> datas: <span class="type">Array</span>[<span class="type">String</span>] = line.split(<span class="string">&quot;_&quot;</span>)</span><br><span class="line">            <span class="keyword">val</span> ids: <span class="type">Array</span>[<span class="type">String</span>] = datas(<span class="number">8</span>).split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">            ids.map((_, <span class="number">1</span>))</span><br><span class="line">        &#125;</span><br><span class="line">    ).reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//统计品类的支付数量</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> payCountRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = userVisitRDD.filter(</span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> datas = line.split(<span class="string">&quot;_&quot;</span>)</span><br><span class="line">            datas(<span class="number">10</span>) != <span class="string">&quot;null&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ).flatMap(</span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> datas = line.split(<span class="string">&quot;_&quot;</span>)</span><br><span class="line">            <span class="keyword">val</span> ids = datas(<span class="number">10</span>).split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">            ids.map((_, <span class="number">1</span>))</span><br><span class="line">        &#125;</span><br><span class="line">    ).reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> mergeRDD: <span class="type">RDD</span>[(<span class="type">String</span>, (<span class="type">Iterable</span>[<span class="type">Int</span>], <span class="type">Iterable</span>[<span class="type">Int</span>], <span class="type">Iterable</span>[<span class="type">Int</span>]))] = clickCountRDD.cogroup(orderCountRDD, payCountRDD)</span><br><span class="line">    <span class="keyword">val</span> resultRDD: <span class="type">RDD</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Int</span>, <span class="type">Int</span>))] = mergeRDD.mapValues &#123;</span><br><span class="line">        <span class="keyword">case</span> (click, order, pay) =&gt; &#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">var</span> clickCnt = <span class="number">0</span></span><br><span class="line">            <span class="keyword">var</span> orderCnt = <span class="number">0</span></span><br><span class="line">            <span class="keyword">var</span> payCnt = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">val</span> iterator1: <span class="type">Iterator</span>[<span class="type">Int</span>] = click.iterator</span><br><span class="line">            <span class="keyword">if</span> (iterator1.hasNext) &#123;</span><br><span class="line">                clickCnt = iterator1.next()</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">val</span> iterator2: <span class="type">Iterator</span>[<span class="type">Int</span>] = order.iterator</span><br><span class="line">            <span class="keyword">if</span> (iterator2.hasNext) &#123;</span><br><span class="line">                orderCnt = iterator2.next()</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">val</span> iterator3: <span class="type">Iterator</span>[<span class="type">Int</span>] = pay.iterator</span><br><span class="line">            <span class="keyword">if</span> (iterator3.hasNext) &#123;</span><br><span class="line">                payCnt = iterator3.next()</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            (clickCnt, orderCnt, payCnt)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> top10 = resultRDD.sortBy(_._2, <span class="literal">false</span>).take(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    top10.foreach(println)</span><br><span class="line"></span><br><span class="line">    sparkContext.stop()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="6-1-3-实现方案二"><a href="#6-1-3-实现方案二" class="headerlink" title="6.1.3 实现方案二"></a>6.1.3 实现方案二</h3><h4 id="6-1-3-1-需求分析"><a href="#6-1-3-1-需求分析" class="headerlink" title="6.1.3.1 需求分析"></a>6.1.3.1 需求分析</h4><p>一次性统计每个品类点击的次数，下单的次数和支付的次数：<br>（品类，（点击总数，下单总数，支付总数））</p>
<h4 id="6-1-3-2-需求实现"><a href="#6-1-3-2-需求实现" class="headerlink" title="6.1.3.2 需求实现"></a>6.1.3.2 需求实现</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//方式一</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">top10_2</span> </span>= &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//读取文件</span></span><br><span class="line">    <span class="keyword">val</span> userVisitRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sparkContext.textFile(<span class="string">&quot;data/user_visit_action.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//统计品类的点击数量</span></span><br><span class="line">    <span class="keyword">val</span> clickCountRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = userVisitRDD.filter(</span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">            (line.split(<span class="string">&quot;_&quot;</span>)(<span class="number">6</span>) != <span class="string">&quot;-1&quot;</span>) &amp;&amp; (line.split(<span class="string">&quot;_&quot;</span>)(<span class="number">7</span>) != <span class="string">&quot;-1&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    ).map(</span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> datas: <span class="type">Array</span>[<span class="type">String</span>] = line.split(<span class="string">&quot;_&quot;</span>)</span><br><span class="line">            (datas(<span class="number">6</span>), <span class="number">1</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    ).reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//统计品类的下单数量</span></span><br><span class="line">    <span class="keyword">val</span> orderCountRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = userVisitRDD.filter(</span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> datas = line.split(<span class="string">&quot;_&quot;</span>)</span><br><span class="line">            datas(<span class="number">8</span>) != <span class="string">&quot;null&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ).flatMap(</span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> datas: <span class="type">Array</span>[<span class="type">String</span>] = line.split(<span class="string">&quot;_&quot;</span>)</span><br><span class="line">            <span class="keyword">val</span> ids: <span class="type">Array</span>[<span class="type">String</span>] = datas(<span class="number">8</span>).split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">            ids.map((_, <span class="number">1</span>))</span><br><span class="line">        &#125;</span><br><span class="line">    ).reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//统计品类的支付数量</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> payCountRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = userVisitRDD.filter(</span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> datas = line.split(<span class="string">&quot;_&quot;</span>)</span><br><span class="line">            datas(<span class="number">10</span>) != <span class="string">&quot;null&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ).flatMap(</span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> datas = line.split(<span class="string">&quot;_&quot;</span>)</span><br><span class="line">            <span class="keyword">val</span> ids = datas(<span class="number">10</span>).split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">            ids.map((_, <span class="number">1</span>))</span><br><span class="line">        &#125;</span><br><span class="line">    ).reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> unionRDD: <span class="type">RDD</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Int</span>, <span class="type">Int</span>))] = clickCountRDD.map &#123;</span><br><span class="line">        <span class="keyword">case</span> (cid, clickCount) =&gt; &#123;</span><br><span class="line">            (cid, (clickCount, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;.union(</span><br><span class="line">        orderCountRDD.map &#123;</span><br><span class="line">            <span class="keyword">case</span> (cid, orderCount) =&gt; &#123;</span><br><span class="line">                (cid, (<span class="number">0</span>, orderCount, <span class="number">0</span>))</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ).union(</span><br><span class="line">        payCountRDD.map &#123;</span><br><span class="line">            <span class="keyword">case</span> (cid, payCount) =&gt; &#123;</span><br><span class="line">                (cid, (<span class="number">0</span>, <span class="number">0</span>, payCount))</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">val</span> top10: <span class="type">Array</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Int</span>, <span class="type">Int</span>))] = unionRDD.reduceByKey(</span><br><span class="line">        (t1, t2) =&gt; &#123;</span><br><span class="line">            (t1._1 + t2._1, t1._2 + t2._2, t1._3 + t2._3)</span><br><span class="line">        &#125;</span><br><span class="line">    ).sortBy(_._2, <span class="literal">false</span>).take(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    top10.foreach(println)</span><br><span class="line"></span><br><span class="line">    sparkContext.stop()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//方式二</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">top10_3</span> </span>= &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="comment">//读取文件</span></span><br><span class="line">    <span class="keyword">val</span> userVisitRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sparkContext.textFile(<span class="string">&quot;data/user_visit_action.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> top10: <span class="type">Array</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Int</span>, <span class="type">Int</span>))] = userVisitRDD.flatMap(</span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> datas = line.split(<span class="string">&quot;_&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> ((line.split(<span class="string">&quot;_&quot;</span>)(<span class="number">6</span>) != <span class="string">&quot;-1&quot;</span>) &amp;&amp; (line.split(<span class="string">&quot;_&quot;</span>)(<span class="number">7</span>) != <span class="string">&quot;-1&quot;</span>)) &#123;</span><br><span class="line">                <span class="type">List</span>((datas(<span class="number">6</span>), (<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>)))</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (datas(<span class="number">8</span>) != <span class="string">&quot;null&quot;</span>) &#123;</span><br><span class="line">                <span class="keyword">val</span> ids: <span class="type">Array</span>[<span class="type">String</span>] = datas(<span class="number">8</span>).split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">                ids.map((_, (<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)))</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (datas(<span class="number">10</span>) != <span class="string">&quot;null&quot;</span>) &#123;</span><br><span class="line">                <span class="keyword">val</span> ids: <span class="type">Array</span>[<span class="type">String</span>] = datas(<span class="number">10</span>).split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">                ids.map((_, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>)))</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="type">Nil</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ).reduceByKey(</span><br><span class="line">        (t1, t2) =&gt; &#123;</span><br><span class="line">            (t1._1 + t2._1, t1._2 + t2._2, t1._3 + t2._3)</span><br><span class="line">        &#125;</span><br><span class="line">    ).sortBy(_._2, <span class="literal">false</span>).take(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    top10.foreach(println)</span><br><span class="line"></span><br><span class="line">    sparkContext.stop()</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="6-1-4-实现方案三"><a href="#6-1-4-实现方案三" class="headerlink" title="6.1.4 实现方案三"></a>6.1.4 实现方案三</h3><h4 id="6-1-4-1-需求分析"><a href="#6-1-4-1-需求分析" class="headerlink" title="6.1.4.1 需求分析"></a>6.1.4.1 需求分析</h4><p>使用累加器的方式聚合数据</p>
<h4 id="6-1-4-2-需求实现"><a href="#6-1-4-2-需求实现" class="headerlink" title="6.1.4.2 需求实现"></a>6.1.4.2 需求实现</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">top10_4</span> </span>= &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="comment">//创建累加器</span></span><br><span class="line">    <span class="keyword">val</span> accumulator = <span class="keyword">new</span> <span class="type">HotCategoryAccumulator</span>()</span><br><span class="line">    <span class="comment">//注册累加器</span></span><br><span class="line">    sparkContext.register(accumulator, <span class="string">&quot;HotCategoryAccumulator&quot;</span>)</span><br><span class="line">    <span class="comment">//读取文件</span></span><br><span class="line">    <span class="keyword">val</span> userVisitRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sparkContext.textFile(<span class="string">&quot;data/user_visit_action.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//遍历数据</span></span><br><span class="line">    userVisitRDD.foreach(</span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> datas = line.split(<span class="string">&quot;_&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> ((datas(<span class="number">6</span>) != <span class="string">&quot;-1&quot;</span>) &amp;&amp; (datas(<span class="number">7</span>) != <span class="string">&quot;-1&quot;</span>)) &#123;</span><br><span class="line">                accumulator.add(datas(<span class="number">6</span>), <span class="string">&quot;click&quot;</span>)</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (datas(<span class="number">8</span>) != <span class="string">&quot;null&quot;</span>) &#123;</span><br><span class="line">                <span class="keyword">val</span> ids: <span class="type">Array</span>[<span class="type">String</span>] = datas(<span class="number">8</span>).split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">                ids.foreach(</span><br><span class="line">                    id =&gt; &#123;</span><br><span class="line">                        accumulator.add(id, <span class="string">&quot;order&quot;</span>)</span><br><span class="line">                    &#125;</span><br><span class="line">                )</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (datas(<span class="number">10</span>) != <span class="string">&quot;null&quot;</span>) &#123;</span><br><span class="line">                <span class="keyword">val</span> ids: <span class="type">Array</span>[<span class="type">String</span>] = datas(<span class="number">10</span>).split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">                ids.foreach(</span><br><span class="line">                    id =&gt; &#123;</span><br><span class="line">                        accumulator.add(id, <span class="string">&quot;pay&quot;</span>)</span><br><span class="line">                    &#125;</span><br><span class="line">                )</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="type">Nil</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line">    <span class="comment">//获取累加器的值</span></span><br><span class="line">    <span class="keyword">val</span> accResult: mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">HotCategory</span>] = accumulator.value</span><br><span class="line">    <span class="keyword">val</span> top10: <span class="type">List</span>[<span class="type">HotCategory</span>] = accResult.toList.map(_._2).sortBy(</span><br><span class="line">        obj =&gt; &#123;</span><br><span class="line">            (obj.clickCnt, obj.orderCnt, obj.payCnt)</span><br><span class="line">        &#125;</span><br><span class="line">    )(<span class="type">Ordering</span>.<span class="type">Tuple3</span>(<span class="type">Ordering</span>.<span class="type">Int</span>.reverse, <span class="type">Ordering</span>.<span class="type">Int</span>.reverse, <span class="type">Ordering</span>.<span class="type">Int</span>.reverse)).take(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    top10.foreach(println)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    sparkContext.stop()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//累加器</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">HotCategory</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="class">                          var cid: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          var clickCnt: <span class="type">Int</span> = 0,</span></span></span><br><span class="line"><span class="params"><span class="class">                          var orderCnt: <span class="type">Int</span> = 0,</span></span></span><br><span class="line"><span class="params"><span class="class">                          var payCnt: <span class="type">Int</span> = 0</span></span></span><br><span class="line"><span class="params"><span class="class">                      </span>)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HotCategoryAccumulator</span> <span class="keyword">extends</span> <span class="title">AccumulatorV2</span>[(<span class="type">String</span>, <span class="type">String</span>), mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">HotCategory</span>]] </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">val</span> hcMap = mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">HotCategory</span>]()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">isZero</span></span>: <span class="type">Boolean</span> = &#123;</span><br><span class="line">        hcMap.isEmpty</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">copy</span></span>(): <span class="type">AccumulatorV2</span>[(<span class="type">String</span>, <span class="type">String</span>), mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">HotCategory</span>]] = &#123;</span><br><span class="line">        <span class="keyword">new</span> <span class="type">HotCategoryAccumulator</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reset</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">        hcMap.clear()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(v: (<span class="type">String</span>, <span class="type">String</span>)): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> (cid, actionType) = v</span><br><span class="line">        <span class="keyword">val</span> hotCategory: <span class="type">HotCategory</span> = hcMap.getOrElse(cid, <span class="type">HotCategory</span>(cid))</span><br><span class="line">        actionType <span class="keyword">match</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;click&quot;</span> =&gt; &#123;</span><br><span class="line">                hotCategory.clickCnt += <span class="number">1</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;order&quot;</span> =&gt; &#123;</span><br><span class="line">                hotCategory.orderCnt += <span class="number">1</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;pay&quot;</span> =&gt; &#123;</span><br><span class="line">                hotCategory.payCnt += <span class="number">1</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        hcMap.update(cid, hotCategory)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(other: <span class="type">AccumulatorV2</span>[(<span class="type">String</span>, <span class="type">String</span>), mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">HotCategory</span>]]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> otherMap: mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">HotCategory</span>] = other.value</span><br><span class="line">        otherMap.foreach &#123;</span><br><span class="line">            <span class="keyword">case</span> (cid, accumulator) =&gt; &#123;</span><br><span class="line">                <span class="keyword">val</span> hotCategory: <span class="type">HotCategory</span> = hcMap.getOrElse(cid, <span class="type">HotCategory</span>(cid))</span><br><span class="line">                hotCategory.clickCnt += accumulator.clickCnt</span><br><span class="line">                hotCategory.orderCnt += accumulator.orderCnt</span><br><span class="line">                hotCategory.payCnt += accumulator.payCnt</span><br><span class="line">                hcMap.update(cid, hotCategory)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">value</span></span>: mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">HotCategory</span>] = &#123;</span><br><span class="line">        hcMap</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="6-2-需求2：Top10热门品类中每个品类的Top10活跃Session统计"><a href="#6-2-需求2：Top10热门品类中每个品类的Top10活跃Session统计" class="headerlink" title="6.2 需求2：Top10热门品类中每个品类的Top10活跃Session统计"></a>6.2 需求2：Top10热门品类中每个品类的Top10活跃Session统计</h2><h3 id="6-2-1-需求说明"><a href="#6-2-1-需求说明" class="headerlink" title="6.2.1 需求说明"></a>6.2.1 需求说明</h3><p>在需求一的基础上，增加每个品类用户session的点击统计</p>
<h3 id="6-2-2-需求分析"><a href="#6-2-2-需求分析" class="headerlink" title="6.2.2 需求分析"></a>6.2.2 需求分析</h3><ol>
<li>按照需求一的逻辑获取Top10品类id</li>
<li>过滤Top10品类相关数据</li>
<li>结构转换line =&gt; ((品类, session), 1) =&gt; ((品类, session), sum)</li>
<li>结构转换(品类, (session, sum)) =&gt; (品类, Iter[(session1, sum), (session2, sum), (session3, sum)])</li>
<li>将分组后的数据进行排序(降序)，取 Top10</li>
</ol>
<h3 id="6-2-3-功能实现"><a href="#6-2-3-功能实现" class="headerlink" title="6.2.3 功能实现"></a>6.2.3 功能实现</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HotCategoryTop10Analysis_feature2</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">        <span class="comment">//读取文件</span></span><br><span class="line">        <span class="keyword">val</span> userVisitRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sparkContext.textFile(<span class="string">&quot;data/user_visit_action.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">        userVisitRDD.cache()</span><br><span class="line"></span><br><span class="line">        <span class="comment">//需求1</span></span><br><span class="line">        <span class="keyword">val</span> top10: <span class="type">Array</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Int</span>, <span class="type">Int</span>))] = userVisitRDD.flatMap(</span><br><span class="line">            line =&gt; &#123;</span><br><span class="line">                <span class="keyword">val</span> datas: <span class="type">Array</span>[<span class="type">String</span>] = line.split(<span class="string">&quot;_&quot;</span>)</span><br><span class="line">                <span class="keyword">if</span> ((line.split(<span class="string">&quot;_&quot;</span>)(<span class="number">6</span>) != <span class="string">&quot;-1&quot;</span>) &amp;&amp; (line.split(<span class="string">&quot;_&quot;</span>)(<span class="number">7</span>) != <span class="string">&quot;-1&quot;</span>)) &#123;</span><br><span class="line">                    <span class="type">List</span>((datas(<span class="number">6</span>), (<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>)))</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (datas(<span class="number">8</span>) != <span class="string">&quot;null&quot;</span>) &#123;</span><br><span class="line">                    <span class="keyword">val</span> ids: <span class="type">Array</span>[<span class="type">String</span>] = datas(<span class="number">8</span>).split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">                    ids.map((_, (<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)))</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (datas(<span class="number">10</span>) != <span class="string">&quot;null&quot;</span>) &#123;</span><br><span class="line">                    <span class="keyword">val</span> ids: <span class="type">Array</span>[<span class="type">String</span>] = datas(<span class="number">10</span>).split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">                    ids.map((_, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>)))</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="type">Nil</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        ).reduceByKey(</span><br><span class="line">            (t1, t2) =&gt; &#123;</span><br><span class="line">                (t1._1 + t2._1, t1._2 + t2._2, t1._3 + t2._3)</span><br><span class="line">            &#125;</span><br><span class="line">        ).sortBy(_._2, <span class="literal">false</span>).take(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//top10.foreach(println)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> top10Ids: <span class="type">Array</span>[<span class="type">String</span>] = top10.map(_._1)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 将数据进行筛选过滤，只保留 Top10 的热门品类的数据</span></span><br><span class="line">        <span class="comment">// 1.1 将数据转换为样例类</span></span><br><span class="line">        <span class="keyword">val</span> actionRDD: <span class="type">RDD</span>[<span class="type">UserVisitAction</span>] = userVisitRDD.map(</span><br><span class="line">            line =&gt; &#123;</span><br><span class="line">                <span class="keyword">val</span> datas: <span class="type">Array</span>[<span class="type">String</span>] = line.split(<span class="string">&quot;_&quot;</span>)</span><br><span class="line">                <span class="type">UserVisitAction</span>(</span><br><span class="line">                    datas(<span class="number">0</span>),</span><br><span class="line">                    datas(<span class="number">1</span>).toLong,</span><br><span class="line">                    datas(<span class="number">2</span>),</span><br><span class="line">                    datas(<span class="number">3</span>).toLong,</span><br><span class="line">                    datas(<span class="number">4</span>),</span><br><span class="line">                    datas(<span class="number">5</span>),</span><br><span class="line">                    datas(<span class="number">6</span>).toLong,</span><br><span class="line">                    datas(<span class="number">7</span>).toLong,</span><br><span class="line">                    datas(<span class="number">8</span>),</span><br><span class="line">                    datas(<span class="number">9</span>),</span><br><span class="line">                    datas(<span class="number">10</span>),</span><br><span class="line">                    datas(<span class="number">11</span>),</span><br><span class="line">                    datas(<span class="number">12</span>).toLong)</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        <span class="comment">// 1.2 将数据进行过滤</span></span><br><span class="line">        <span class="keyword">val</span> filterRDD: <span class="type">RDD</span>[<span class="type">UserVisitAction</span>] = actionRDD.filter(</span><br><span class="line">            action =&gt; &#123;</span><br><span class="line">                <span class="keyword">if</span> (action.click_category_id != <span class="number">-1</span>) &#123;</span><br><span class="line">                    top10Ids.contains(action.click_category_id.toString)</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="literal">false</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        <span class="comment">// 2. 将数据进行结构的转换</span></span><br><span class="line">        <span class="comment">//    line =&gt; ((品类, session), 1)</span></span><br><span class="line">        <span class="comment">// 3. 将转换结构后的数据进行统计</span></span><br><span class="line">        <span class="comment">//    line =&gt; ((品类, session), 1) =&gt; ((品类, session), sum)</span></span><br><span class="line">        <span class="keyword">val</span> reduceByKeyRDD: <span class="type">RDD</span>[((<span class="type">Long</span>, <span class="type">String</span>), <span class="type">Int</span>)] = filterRDD.map(</span><br><span class="line">            action =&gt; &#123;</span><br><span class="line">                ((action.click_category_id, action.session_id), <span class="number">1</span>)</span><br><span class="line">            &#125;</span><br><span class="line">        ).reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 将统计结果进行结构的转换</span></span><br><span class="line">        <span class="comment">// ((品类, session), sum) =&gt; (品类, (session, sum))</span></span><br><span class="line">        <span class="comment">// 5. 将转换结构后的数据按照品类进行分组</span></span><br><span class="line">        <span class="comment">// (品类, (session, sum)) =&gt; (品类, Iter[(session1, sum), (session2, sum), (session3, sum)])</span></span><br><span class="line">        <span class="keyword">val</span> groupRDD: <span class="type">RDD</span>[(<span class="type">Long</span>, <span class="type">Iterable</span>[(<span class="type">String</span>, <span class="type">Int</span>)])] = reduceByKeyRDD.map &#123;</span><br><span class="line">            <span class="keyword">case</span> ((cid, sessionid), sum) =&gt; (cid, (sessionid, sum))</span><br><span class="line">        &#125;.groupByKey()</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6. 将分组后的数据进行排序(降序)，取 Top10</span></span><br><span class="line">        <span class="keyword">val</span> result: <span class="type">RDD</span>[(<span class="type">Long</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)])] = groupRDD.mapValues(</span><br><span class="line">            iter =&gt; &#123;</span><br><span class="line">                iter.toList.sortBy(_._2)(<span class="type">Ordering</span>.<span class="type">Int</span>.reverse).take(<span class="number">10</span>)</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7. 将结果采集后打印在控制台</span></span><br><span class="line">        result.collect().sortBy(_._1).foreach(println)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        sparkContext.stop()</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//用户访问动作表</span></span><br><span class="line">    <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">UserVisitAction</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="class">                                  date: <span class="type">String</span>, //用户点击行为的日期</span></span></span><br><span class="line"><span class="params"><span class="class">                                  user_id: <span class="type">Long</span>, //用户的<span class="type">ID</span></span></span></span><br><span class="line"><span class="params"><span class="class">                                  session_id: <span class="type">String</span>, //<span class="type">Session</span>的<span class="type">ID</span></span></span></span><br><span class="line"><span class="params"><span class="class">                                  page_id: <span class="type">Long</span>, //某个页面的<span class="type">ID</span></span></span></span><br><span class="line"><span class="params"><span class="class">                                  action_time: <span class="type">String</span>, //动作的时间点</span></span></span><br><span class="line"><span class="params"><span class="class">                                  search_keyword: <span class="type">String</span>, //用户搜索的关键词</span></span></span><br><span class="line"><span class="params"><span class="class">                                  click_category_id: <span class="type">Long</span>, //某一个商品品类的<span class="type">ID</span></span></span></span><br><span class="line"><span class="params"><span class="class">                                  click_product_id: <span class="type">Long</span>, //某一个商品的<span class="type">ID</span></span></span></span><br><span class="line"><span class="params"><span class="class">                                  order_category_ids: <span class="type">String</span>, //一次订单中所有品类的<span class="type">ID</span>集合</span></span></span><br><span class="line"><span class="params"><span class="class">                                  order_product_ids: <span class="type">String</span>, //一次订单中所有商品的<span class="type">ID</span>集合</span></span></span><br><span class="line"><span class="params"><span class="class">                                  pay_category_ids: <span class="type">String</span>, //一次支付中所有品类的<span class="type">ID</span>集合</span></span></span><br><span class="line"><span class="params"><span class="class">                                  pay_product_ids: <span class="type">String</span>, //一次支付中所有商品的<span class="type">ID</span>集合</span></span></span><br><span class="line"><span class="params"><span class="class">                                  city_id: <span class="type">Long</span> //城市 id</span></span></span><br><span class="line"><span class="params"><span class="class">                              </span>)</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="6-3-需求3：页面单跳转换率统计"><a href="#6-3-需求3：页面单跳转换率统计" class="headerlink" title="6.3 需求3：页面单跳转换率统计"></a>6.3 需求3：页面单跳转换率统计</h2><h3 id="6-3-1-需求说明"><a href="#6-3-1-需求说明" class="headerlink" title="6.3.1 需求说明"></a>6.3.1 需求说明</h3><ol>
<li><p>页面单跳转化率<br> 计算页面单跳转化率，什么是页面单跳转换率，比如一个用户在一次 Session 过程中访问的页面路径 3,5,7,9,10,21，那么页面 3 跳到页面 5 叫一次单跳，7-9 也叫一次单跳，那么单跳转化率就是要统计页面点击的概率。<br> 比如：计算 3-5 的单跳转化率，先获取符合条件的 Session 对于页面 3 的访问次数（PV）为 A，然后获取符合条件的 Session 中访问了页面 3 又紧接着访问了页面 5 的次数为 B，那么 B/A 就是 3-5 的页面单跳转化率。</p>
</li>
<li><p>统计页面单跳转化率意义<br> 产品经理和运营总监，可以根据这个指标，去尝试分析，整个网站，产品，各个页面的表现怎么样，是不是需要去优化产品的布局；吸引用户最终可以进入最后的支付页面。<br> 数据分析师，可以此数据做更深一步的计算和分析。<br> 企业管理层，可以看到整个公司的网站，各个页面的之间的跳转的表现如何，可以适当调整公司的经营战略或策略。</p>
</li>
</ol>
<h3 id="6-3-2-需求分析"><a href="#6-3-2-需求分析" class="headerlink" title="6.3.2 需求分析"></a>6.3.2 需求分析</h3><ol>
<li>计算页面累计点击数量</li>
<li>根据session对访问数据分组</li>
<li>排序后出去所有单跳页面的组合</li>
<li>对组合执行wordCount统计</li>
<li>计算</li>
</ol>
<h3 id="6-3-3-功能实现"><a href="#6-3-3-功能实现" class="headerlink" title="6.3.3 功能实现"></a>6.3.3 功能实现</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HotCategoryTop10Analysis_feature3</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;WordCount&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">        <span class="comment">//读取文件</span></span><br><span class="line">        <span class="keyword">val</span> userVisitRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sparkContext.textFile(<span class="string">&quot;data/user_visit_action.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">        userVisitRDD.cache()</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 将数据进行筛选过滤，只保留 Top10 的热门品类的数据</span></span><br><span class="line">        <span class="comment">// 1.1 将数据转换为样例类</span></span><br><span class="line">        <span class="keyword">val</span> actionRDD: <span class="type">RDD</span>[<span class="type">UserVisitAction</span>] = userVisitRDD.map(</span><br><span class="line">            line =&gt; &#123;</span><br><span class="line">                <span class="keyword">val</span> datas: <span class="type">Array</span>[<span class="type">String</span>] = line.split(<span class="string">&quot;_&quot;</span>)</span><br><span class="line">                <span class="type">UserVisitAction</span>(</span><br><span class="line">                    datas(<span class="number">0</span>),</span><br><span class="line">                    datas(<span class="number">1</span>).toLong,</span><br><span class="line">                    datas(<span class="number">2</span>),</span><br><span class="line">                    datas(<span class="number">3</span>).toLong,</span><br><span class="line">                    datas(<span class="number">4</span>),</span><br><span class="line">                    datas(<span class="number">5</span>),</span><br><span class="line">                    datas(<span class="number">6</span>).toLong,</span><br><span class="line">                    datas(<span class="number">7</span>).toLong,</span><br><span class="line">                    datas(<span class="number">8</span>),</span><br><span class="line">                    datas(<span class="number">9</span>),</span><br><span class="line">                    datas(<span class="number">10</span>),</span><br><span class="line">                    datas(<span class="number">11</span>),</span><br><span class="line">                    datas(<span class="number">12</span>).toLong)</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        actionRDD.cache()</span><br><span class="line">        <span class="keyword">val</span> pageIdDistinct: <span class="type">Array</span>[<span class="type">Long</span>] = actionRDD.map(_.page_id).distinct().collect()</span><br><span class="line"></span><br><span class="line">        <span class="comment">//0. 计算分母(word(页面),count(数量))</span></span><br><span class="line">        <span class="keyword">val</span> pageCount: <span class="type">Array</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] = actionRDD</span><br><span class="line">            .filter(</span><br><span class="line">                action =&gt; &#123;</span><br><span class="line">                    pageIdDistinct.contains(action.page_id)</span><br><span class="line">                &#125;</span><br><span class="line">            )</span><br><span class="line">            .map(</span><br><span class="line">                action =&gt; (action.page_id, <span class="number">1</span>)</span><br><span class="line">            ).reduceByKey(_ + _).collect()</span><br><span class="line">        <span class="keyword">val</span> pageCountMap: <span class="type">Map</span>[<span class="type">Long</span>, <span class="type">Int</span>] = pageCount.toMap</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//1. 按照Session分组</span></span><br><span class="line">        <span class="keyword">val</span> sessionGroupRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Iterable</span>[<span class="type">UserVisitAction</span>])] = actionRDD.groupBy(_.session_id)</span><br><span class="line">        <span class="comment">//2. 按时间排序</span></span><br><span class="line">        <span class="keyword">val</span> mapRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">List</span>[(<span class="type">Long</span>, <span class="type">Long</span>)])] = sessionGroupRDD.mapValues(</span><br><span class="line">            iter =&gt; &#123;</span><br><span class="line">                <span class="keyword">val</span> sortAction: <span class="type">List</span>[<span class="type">UserVisitAction</span>] = iter.toList.sortBy(_.action_time)</span><br><span class="line">                <span class="keyword">val</span> pageIdList: <span class="type">List</span>[<span class="type">Long</span>] = sortAction.map(_.page_id)</span><br><span class="line">                <span class="comment">//val sliding: Iterator[List[Long]] = pageIdList.sliding(2)</span></span><br><span class="line">                <span class="comment">//sliding.map(</span></span><br><span class="line">                <span class="comment">//    list=&gt;&#123;</span></span><br><span class="line">                <span class="comment">//        list(0)+&quot;_&quot;+list(1)</span></span><br><span class="line">                <span class="comment">//    &#125;</span></span><br><span class="line">                <span class="comment">//)</span></span><br><span class="line">                <span class="keyword">val</span> zipList: <span class="type">List</span>[(<span class="type">Long</span>, <span class="type">Long</span>)] = pageIdList.zip(pageIdList.tail)</span><br><span class="line">                zipList</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        <span class="comment">//3. 计算分子</span></span><br><span class="line">        <span class="comment">//  转换数据格式</span></span><br><span class="line">        <span class="comment">//  转换数据结构 3,5 =&gt; 3-5</span></span><br><span class="line">        <span class="comment">//  将连续页面跳转统计数量</span></span><br><span class="line">        <span class="keyword">val</span> pageListRDD: <span class="type">RDD</span>[<span class="type">List</span>[(<span class="type">Long</span>, <span class="type">Long</span>)]] = mapRDD.map(_._2)</span><br><span class="line">        <span class="keyword">val</span> pageRedirect: <span class="type">RDD</span>[(<span class="type">Long</span>, <span class="type">Long</span>)] = pageListRDD.flatMap(list =&gt; list)</span><br><span class="line">        <span class="keyword">val</span> pageRedirectCount: <span class="type">RDD</span>[((<span class="type">Long</span>, <span class="type">Long</span>), <span class="type">Int</span>)] = pageRedirect.map((_, <span class="number">1</span>)).reduceByKey(_ + _)</span><br><span class="line">        <span class="keyword">val</span> pageCountResult: <span class="type">Array</span>[((<span class="type">Long</span>, <span class="type">Long</span>), <span class="type">Int</span>)] = pageRedirectCount.collect()</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4 计算</span></span><br><span class="line">        pageCountResult.foreach&#123;</span><br><span class="line">            <span class="keyword">case</span> ((page1,page2), count) =&gt;&#123;</span><br><span class="line">                println(<span class="string">s&quot;页面id:<span class="subst">$&#123;page1&#125;</span>-&gt;<span class="subst">$&#123;page2&#125;</span> 单跳转换率:&quot;</span>+(count.toDouble/pageCountMap.getOrElse(page1,<span class="number">0</span>)))</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        sparkContext.stop()</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//用户访问动作表</span></span><br><span class="line">    <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">UserVisitAction</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="class">          date: <span class="type">String</span>, //用户点击行为的日期</span></span></span><br><span class="line"><span class="params"><span class="class">          user_id: <span class="type">Long</span>, //用户的<span class="type">ID</span></span></span></span><br><span class="line"><span class="params"><span class="class">          session_id: <span class="type">String</span>, //<span class="type">Session</span>的<span class="type">ID</span></span></span></span><br><span class="line"><span class="params"><span class="class">          page_id: <span class="type">Long</span>, //某个页面的<span class="type">ID</span></span></span></span><br><span class="line"><span class="params"><span class="class">          action_time: <span class="type">String</span>, //动作的时间点</span></span></span><br><span class="line"><span class="params"><span class="class">          search_keyword: <span class="type">String</span>, //用户搜索的关键词</span></span></span><br><span class="line"><span class="params"><span class="class">          click_category_id: <span class="type">Long</span>, //某一个商品品类的<span class="type">ID</span></span></span></span><br><span class="line"><span class="params"><span class="class">          click_product_id: <span class="type">Long</span>, //某一个商品的<span class="type">ID</span></span></span></span><br><span class="line"><span class="params"><span class="class">          order_category_ids: <span class="type">String</span>, //一次订单中所有品类的<span class="type">ID</span>集合</span></span></span><br><span class="line"><span class="params"><span class="class">          order_product_ids: <span class="type">String</span>, //一次订单中所有商品的<span class="type">ID</span>集合</span></span></span><br><span class="line"><span class="params"><span class="class">          pay_category_ids: <span class="type">String</span>, //一次支付中所有品类的<span class="type">ID</span>集合</span></span></span><br><span class="line"><span class="params"><span class="class">          pay_product_ids: <span class="type">String</span>, //一次支付中所有商品的<span class="type">ID</span>集合</span></span></span><br><span class="line"><span class="params"><span class="class">          city_id: <span class="type">Long</span> //城市 id</span></span></span><br><span class="line"><span class="params"><span class="class">      </span>)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h1 id="第7章-Spark-Core-源码解析"><a href="#第7章-Spark-Core-源码解析" class="headerlink" title="第7章 Spark Core 源码解析"></a>第7章 Spark Core 源码解析</h1><p><img src="https://s2.loli.net/2022/01/22/E5xmZGhjOsIqJ4M.png" alt="源码图解"></p>
<h2 id="7-1-提交任务源码"><a href="#7-1-提交任务源码" class="headerlink" title="7.1 提交任务源码"></a>7.1 提交任务源码</h2><ul>
<li>提交任务入口  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master <span class="built_in">local</span>[2] \</span><br><span class="line">./examples/jars/spark-examples_2.12-3.0.0.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></figure>
<ul>
<li>跟进spark-submit脚本  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">。。。</span><br><span class="line">。。。</span><br><span class="line"><span class="built_in">exec</span> <span class="string">&quot;<span class="variable">$&#123;SPARK_HOME&#125;</span>&quot;</span>/bin/spark-class org.apache.spark.deploy.SparkSubmit <span class="string">&quot;<span class="variable">$@</span>&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>关注 类名为<code>org.apache.spark.deploy.SparkSubmit</code>  </li>
</ul>
</li>
<li>跟进spark-class脚本  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">。。。</span><br><span class="line">。。。</span><br><span class="line">CMD=(<span class="string">&quot;<span class="variable">$&#123;CMD[@]:0:$LAST&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$&#123;CMD[@]&#125;</span>&quot;</span></span><br><span class="line"><span class="built_in">exec</span> <span class="string">&quot;<span class="variable">$&#123;CMD[@]&#125;</span>&quot;</span></span><br><span class="line">。。。</span><br><span class="line">。。。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>添加echo打印执行命令为  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$JAVA_HOME</span>/bin/java -cp <span class="variable">$SPARK_HOME</span>/conf/:/Users/zhenan/app/spark-3.0.0-bin-hadoop3.2/jars/* -Xmx1g org.apache.spark.deploy.SparkSubmit --master <span class="built_in">local</span>[2] --class org.apache.spark.examples.SparkPi ./examples/jars/spark-examples_2.12-3.0.0.jar 10</span><br></pre></td></tr></table></figure></li>
<li>确定执行类为<code>org.apache.spark.deploy.SparkSubmit</code>  </li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="7-1-1-SparkSubmit源码"><a href="#7-1-1-SparkSubmit源码" class="headerlink" title="7.1.1 SparkSubmit源码"></a>7.1.1 SparkSubmit源码</h3><ul>
<li>跟进<code>org.apache.spark.deploy.SparkSubmit</code>  </li>
<li>进入伴生对象的main方法<code>org.apache.spark.deploy.SparkSubmit#main</code>  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> submit = <span class="keyword">new</span> <span class="type">SparkSubmit</span>() &#123;</span><br><span class="line">    self =&gt;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">override</span> <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">parseArguments</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">SparkSubmitArguments</span> = &#123;</span><br><span class="line">      <span class="keyword">new</span> <span class="type">SparkSubmitArguments</span>(args) &#123;</span><br><span class="line">        <span class="keyword">override</span> <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">logInfo</span></span>(msg: =&gt; <span class="type">String</span>): <span class="type">Unit</span> = self.logInfo(msg)</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">override</span> <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">logWarning</span></span>(msg: =&gt; <span class="type">String</span>): <span class="type">Unit</span> = self.logWarning(msg)</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">override</span> <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">logError</span></span>(msg: =&gt; <span class="type">String</span>): <span class="type">Unit</span> = self.logError(msg)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">override</span> <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">logInfo</span></span>(msg: =&gt; <span class="type">String</span>): <span class="type">Unit</span> = printMessage(msg)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">override</span> <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">logWarning</span></span>(msg: =&gt; <span class="type">String</span>): <span class="type">Unit</span> = printMessage(<span class="string">s&quot;Warning: <span class="subst">$msg</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">override</span> <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">logError</span></span>(msg: =&gt; <span class="type">String</span>): <span class="type">Unit</span> = printMessage(<span class="string">s&quot;Error: <span class="subst">$msg</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">doSubmit</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">super</span>.doSubmit(args)</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">SparkUserAppException</span> =&gt;</span><br><span class="line">          exitFn(e.exitCode)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">  &#125;</span><br><span class="line">    </span><br><span class="line">  submit.doSubmit(args)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>跟进<code>super.doSubmit(args)</code> </li>
<li>-&gt; 解析参数：<code>val appArgs = parseArguments(args)</code> <ul>
<li>-&gt; <code>new SparkSubmitArguments(args)</code></li>
<li>-&gt; <code>parse(args.asJava)</code>  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Set parameters from command line arguments</span></span><br><span class="line">parse(args.asJava)</span><br></pre></td></tr></table></figure></li>
<li>-&gt; 参数校验：由具体实现类提供逻辑  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (!handle(name, value)) &#123;</span><br><span class="line">  <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
  <img src="https://s2.loli.net/2022/01/22/UOB4kK3TzWZSvtp.jpg"><ul>
<li>-&gt;实现类: <code>org.apache.spark.deploy.SparkSubmitArguments#handle</code></li>
<li>获取到   <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--master  =&gt; master    =&gt; yarn</span><br><span class="line">--class   =&gt; mainClass =&gt; SparkPI(WordCount)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li>-&gt; 执行action动作  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">appArgs.action <span class="keyword">match</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">SUBMIT</span> =&gt; submit(appArgs, uninitLog)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">KILL</span> =&gt; kill(appArgs)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">REQUEST_STATUS</span> =&gt; requestStatus(appArgs)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">PRINT_VERSION</span> =&gt; printVersion()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>-&gt; 跟进appArgs.action赋值  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Action should be SUBMIT unless otherwise specified</span></span><br><span class="line">action = <span class="type">Option</span>(action).getOrElse(<span class="type">SUBMIT</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>默认值为<code>SUBMIT</code></li>
</ul>
</li>
<li>-&gt; 跟进任务提交方法<code>case SparkSubmitAction.SUBMIT =&gt; submit(appArgs, uninitLog)</code><ul>
<li>-&gt; <code>doRunMain</code></li>
<li>-&gt; <code>runMain</code><ul>
<li>-&gt; 准备提交环境的参数，跟进<code>val (childArgs, childClasspath, sparkConf, childMainClass) = prepareSubmitEnvironment(args)</code><ul>
<li>-&gt; 跟进childMainClass取值,查找赋值的位置</li>
<li>-&gt; <code>val isYarnCluster = clusterManager == YARN &amp;&amp; deployMode == CLUSTER</code></li>
<li>-&gt; 确定类型childMainClass  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (isYarnCluster) &#123;</span><br><span class="line">  childMainClass = <span class="type">YARN_CLUSTER_SUBMIT_CLASS</span></span><br><span class="line">  。。。</span><br><span class="line">  。。。</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>-&gt; <code>private[deploy] val YARN_CLUSTER_SUBMIT_CLASS = &quot;org.apache.spark.deploy.yarn.YarnClusterApplication&quot;</code></li>
</ul>
</li>
<li>-&gt; 添加依赖jar  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> loader = getSubmitClassLoader(sparkConf)</span><br><span class="line"><span class="keyword">for</span> (jar &lt;- childClasspath) &#123;</span><br><span class="line">  addJarToClasspath(jar, loader)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>-&gt; <code>mainClass = Utils.classForName(childMainClass)</code></li>
<li>-&gt; 判断类型，创建Spark应用程序，<font color ='red' >SparkApplication</font>  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> app: <span class="type">SparkApplication</span> = <span class="keyword">if</span> (classOf[<span class="type">SparkApplication</span>].isAssignableFrom(mainClass)) &#123;</span><br><span class="line">  mainClass.getConstructor().newInstance().asInstanceOf[<span class="type">SparkApplication</span>]</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="keyword">new</span> <span class="type">JavaMainApplication</span>(mainClass)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>-&gt; 启动应用程序<code>app.start</code>,具体逻辑由childMainClass实现，Yarn模式为<code>org.apache.spark.deploy.yarn.YarnClusterApplication</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="7-1-2-YarnClusterApplication-源码"><a href="#7-1-2-YarnClusterApplication-源码" class="headerlink" title="7.1.2 YarnClusterApplication 源码"></a>7.1.2 YarnClusterApplication 源码</h3><ul>
<li>跟进YarnClusterApplication  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">YarnClusterApplication</span> <span class="keyword">extends</span> <span class="title">SparkApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">start</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>], conf: <span class="type">SparkConf</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// SparkSubmit would use yarn cache to distribute files &amp; jars in yarn mode,</span></span><br><span class="line">    <span class="comment">// so remove them from sparkConf here for yarn mode.</span></span><br><span class="line">    conf.remove(<span class="type">JARS</span>)</span><br><span class="line">    conf.remove(<span class="type">FILES</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">new</span> <span class="type">Client</span>(<span class="keyword">new</span> <span class="type">ClientArguments</span>(args), conf, <span class="literal">null</span>).run()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>-&gt; 定位start方法  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="type">Client</span>(<span class="keyword">new</span> <span class="type">ClientArguments</span>(args), conf, <span class="literal">null</span>).run()</span><br></pre></td></tr></table></figure>
<ul>
<li>-&gt; 跟进ClientArguments：<code>--class =&gt; userClass =&gt; SparkPi(WordCount)</code>  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> (<span class="string">&quot;--class&quot;</span>) :: value :: tail =&gt;</span><br><span class="line"> userClass = value</span><br><span class="line"> args = tail</span><br></pre></td></tr></table></figure></li>
<li>-&gt; 跟进<code>new Client()</code><ul>
<li>-&gt;创建YarnClient  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> yarnClient = <span class="type">YarnClient</span>.createYarnClient</span><br></pre></td></tr></table></figure>
<ul>
<li>-&gt; 跟进 <code>createYarnClient</code>  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public static <span class="type">YarnClient</span> createYarnClient() &#123;</span><br><span class="line">  <span class="type">YarnClient</span> client = <span class="keyword">new</span> <span class="type">YarnClientImpl</span>();</span><br><span class="line">  <span class="keyword">return</span> client;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>-&gt; 查找rmClient<code>org.apache.hadoop.yarn.client.api.impl.YarnClientImpl#rmClient</code>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> ApplicationClientProtocol rmClient;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li>-&gt; 跟进<code>org.apache.spark.deploy.yarn.Client#run</code><ul>
<li>-&gt; 跟进<code>org.apache.spark.deploy.yarn.Client#submitApplication</code><ul>
<li>创建Yran客户端,建立连接<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">submitApplication</span></span>(): <span class="type">ApplicationId</span> = &#123;</span><br><span class="line"><span class="type">ResourceRequestHelper</span>.validateResources(sparkConf)</span><br><span class="line">  。。。</span><br><span class="line">  。。。</span><br><span class="line">  launcherBackend.connect()</span><br><span class="line">  yarnClient.init(hadoopConf)</span><br><span class="line">  yarnClient.start()</span><br><span class="line">  。。。</span><br><span class="line">  。。。</span><br><span class="line">  <span class="comment">// Set up the appropriate contexts to launch our AM</span></span><br><span class="line">  <span class="keyword">val</span> containerContext = createContainerLaunchContext(newAppResponse)</span><br><span class="line">  <span class="keyword">val</span> appContext = createApplicationSubmissionContext(newApp, containerContext)</span><br><span class="line">  。。。</span><br><span class="line">  。。。</span><br><span class="line">  logInfo(<span class="string">s&quot;Submitting application <span class="subst">$appId</span> to ResourceManager&quot;</span>)</span><br><span class="line">  yarnClient.submitApplication(appContext)</span><br><span class="line">  。。。</span><br><span class="line">  。。。</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>-&gt; 跟进 <code>createContainerLaunchContext</code> <code>Set up a ContainerLaunchContext to launch our ApplicationMaster container. This sets up the launch environment, java options, and the command for launching the AM.</code><ul>
<li>-&gt; java虚拟机配置  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">javaOpts += <span class="string">&quot;-Xmx&quot;</span> + amMemory + <span class="string">&quot;m&quot;</span></span><br></pre></td></tr></table></figure></li>
<li>-&gt; 垃圾回收  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (useConcurrentAndIncrementalGC) &#123;</span><br><span class="line">  <span class="comment">// In our expts, using (default) throughput collector has severe perf ramifications in</span></span><br><span class="line">  <span class="comment">// multi-tenant machines</span></span><br><span class="line">  javaOpts += <span class="string">&quot;-XX:+UseConcMarkSweepGC&quot;</span></span><br><span class="line">  javaOpts += <span class="string">&quot;-XX:MaxTenuringThreshold=31&quot;</span></span><br><span class="line">  javaOpts += <span class="string">&quot;-XX:SurvivorRatio=8&quot;</span></span><br><span class="line">  javaOpts += <span class="string">&quot;-XX:+CMSIncrementalMode&quot;</span></span><br><span class="line">  javaOpts += <span class="string">&quot;-XX:+CMSIncrementalPacing&quot;</span></span><br><span class="line">  javaOpts += <span class="string">&quot;-XX:CMSIncrementalDutyCycleMin=0&quot;</span></span><br><span class="line">  javaOpts += <span class="string">&quot;-XX:CMSIncrementalDutyCycle=10&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>-&gt; 拼接容器运行命令<ul>
<li>-&gt; 确定amClass  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> amClass =</span><br><span class="line">  <span class="keyword">if</span> (isClusterMode) &#123;</span><br><span class="line">    <span class="type">Utils</span>.classForName(<span class="string">&quot;org.apache.spark.deploy.yarn.ApplicationMaster&quot;</span>).getName</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="type">Utils</span>.classForName(<span class="string">&quot;org.apache.spark.deploy.yarn.ExecutorLauncher&quot;</span>).getName</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Cluster:org.apache.spark.deploy.yarn.ApplicationMaster</li>
<li>Client:org.apache.spark.deploy.yarn.ExecutorLauncher</li>
</ul>
</li>
<li>-&gt; 拼接amArgs  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> amArgs =</span><br><span class="line">  <span class="type">Seq</span>(amClass) ++ userClass ++ userJar ++ primaryPyFile ++ primaryRFile ++ userArgs ++</span><br><span class="line">  <span class="type">Seq</span>(<span class="string">&quot;--properties-file&quot;</span>,</span><br><span class="line">    buildPath(<span class="type">Environment</span>.<span class="type">PWD</span>.$$(), <span class="type">LOCALIZED_CONF_DIR</span>, <span class="type">SPARK_CONF_FILE</span>)) ++</span><br><span class="line">  <span class="type">Seq</span>(<span class="string">&quot;--dist-cache-conf&quot;</span>,</span><br><span class="line">    buildPath(<span class="type">Environment</span>.<span class="type">PWD</span>.$$(), <span class="type">LOCALIZED_CONF_DIR</span>, <span class="type">DIST_CACHE_CONF_FILE</span>))</span><br></pre></td></tr></table></figure></li>
<li>-&gt; 拼接Command 最终结果为<code>bin/java org.apache.spark.deploy.yarn.ApplicationMaster</code><ul>
<li>此时启动的是AM(<code>ApplicationMaster</code>),位于NodeManager<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Command for the ApplicationMaster</span></span><br><span class="line"><span class="keyword">val</span> commands = prefixEnv ++</span><br><span class="line">  <span class="type">Seq</span>(<span class="type">Environment</span>.<span class="type">JAVA_HOME</span>.$$() + <span class="string">&quot;/bin/java&quot;</span>, <span class="string">&quot;-server&quot;</span>) ++</span><br><span class="line">  javaOpts ++ amArgs ++</span><br><span class="line">  <span class="type">Seq</span>(</span><br><span class="line">    <span class="string">&quot;1&gt;&quot;</span>, <span class="type">ApplicationConstants</span>.<span class="type">LOG_DIR_EXPANSION_VAR</span> + <span class="string">&quot;/stdout&quot;</span>,</span><br><span class="line">    <span class="string">&quot;2&gt;&quot;</span>, <span class="type">ApplicationConstants</span>.<span class="type">LOG_DIR_EXPANSION_VAR</span> + <span class="string">&quot;/stderr&quot;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="7-1-3-ApplicationMaster-源码"><a href="#7-1-3-ApplicationMaster-源码" class="headerlink" title="7.1.3 ApplicationMaster 源码"></a>7.1.3 ApplicationMaster 源码</h3><ul>
<li>跟进伴生对象<code>org.apache.spark.deploy.yarn.ApplicationMaster</code></li>
<li>定位main方法<ul>
<li>-&gt; 跟进参数封装 <code>val amArgs = new ApplicationMasterArguments(args)</code><ul>
<li>-&gt; 定位<code>parseArgs</code></li>
<li>-&gt; <code>--class =&gt; userClass =&gt; SparkPi/WordCount</code>  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> (<span class="string">&quot;--class&quot;</span>) :: value :: tail =&gt;</span><br><span class="line">  userClass = value</span><br><span class="line">  args = tail</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>-&gt; 跟进创建ApplicationMaster  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">master = <span class="keyword">new</span> <span class="type">ApplicationMaster</span>(amArgs, sparkConf, yarnConf)</span><br></pre></td></tr></table></figure>
<ul>
<li>-&gt; 创建YarnRMClient  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> val client = <span class="keyword">new</span> YarnRMClient()</span><br></pre></td></tr></table></figure></li>
<li>-&gt; 定位 run方法<code>org.apache.spark.deploy.yarn.ApplicationMaster#run</code>  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">。。。</span><br><span class="line">。。。</span><br><span class="line"><span class="keyword">if</span> (isClusterMode) &#123;</span><br><span class="line">    runDriver()</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    runExecutorLauncher()</span><br><span class="line">&#125;</span><br><span class="line">。。。</span><br><span class="line">。。。</span><br></pre></td></tr></table></figure>
<ul>
<li>Cluster:runDriver</li>
<li>Client:runExecutorLauncher</li>
</ul>
</li>
<li>-&gt;跟进 <code>org.apache.spark.deploy.yarn.ApplicationMaster#runDriver</code></li>
<li>-&gt; 定位<code>userClassThread = startUserApplication()</code></li>
<li>-&gt; 跟进 <code>startUserApplication</code></li>
<li>-&gt; 获取main方法(–class =&gt; userClass =&gt; SparkPi/WordCount 的main)  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> mainMethod = userClassLoader.loadClass(args.userClass)</span><br><span class="line">    .getMethod(<span class="string">&quot;main&quot;</span>, classOf[<span class="type">Array</span>[<span class="type">String</span>]])</span><br></pre></td></tr></table></figure></li>
<li>启动线程执行main(<font color ='red' >启动Driver</font>)  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> userThread = <span class="keyword">new</span> <span class="type">Thread</span> &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">          。。。</span><br><span class="line">          。。。  </span><br><span class="line">          mainMethod.invoke(<span class="literal">null</span>, userArgs.toArray)</span><br><span class="line">          。。。</span><br><span class="line">          。。。</span><br><span class="line">      &#125;</span><br><span class="line">    userThread.setContextClassLoader(userClassLoader)</span><br><span class="line">    userThread.setName(<span class="string">&quot;Driver&quot;</span>)</span><br><span class="line">    userThread.start()</span><br><span class="line">    userThread</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>此处启动的线程就是Driver</li>
<li>run方法调动的内容为应用程序的main方法(SparkPi/WordCount 的main)</li>
</ul>
</li>
<li>-&gt; ApplicationMaster中<font color ='red' >资源线程阻塞等待</font>  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sc = <span class="type">ThreadUtils</span>.awaitResult(sparkContextPromise.future,</span><br><span class="line"><span class="type">Duration</span>(totalWaitTime, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>))</span><br></pre></td></tr></table></figure></li>
<li>-&gt; 计算线程初始化SparkContext完成后退出阻塞状态继续执行<ul>
<li><code>mainMethod.invoke(null, userArgs.toArray)</code>启动SparkPi/WordCount 的main<ul>
<li>new SparkContext()</li>
<li><code>org.apache.spark.scheduler.cluster.YarnClusterScheduler#postStartHook</code>  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">postStartHook</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="type">ApplicationMaster</span>.sparkContextInitialized(sc)</span><br><span class="line">  <span class="keyword">super</span>.postStartHook()</span><br><span class="line">  logInfo(<span class="string">&quot;YarnClusterScheduler.postStartHook done&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><font color ='red' >计算线程进入阻塞状态</font>  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">sparkContextInitialized</span></span>(sc: <span class="type">SparkContext</span>) = &#123;</span><br><span class="line">  sparkContextPromise.synchronized &#123;</span><br><span class="line">    <span class="comment">// Notify runDriver function that SparkContext is available</span></span><br><span class="line">    sparkContextPromise.success(sc)</span><br><span class="line">    <span class="comment">// Pause the user class thread in order to make proper initialization in runDriver function.</span></span><br><span class="line">     sparkContextPromise.wait()</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>此时资源线程条件满足继续执行</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>-&gt; 注册AM 定位 <code>registerAM(host, port, userConf, sc.ui.map(_.webUrl), appAttemptId)</code><ul>
<li>由Client反馈ResourceManager，注册AM的信息</li>
</ul>
</li>
<li>-&gt; 跟进<code>createAllocator(driverRef, userConf, rpcEnv, appAttemptId, distCacheConf)</code><ul>
<li>申请计算资源   <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">。。。</span><br><span class="line">。。。</span><br><span class="line">。。。</span><br><span class="line">allocator = client.createAllocator(</span><br><span class="line">yarnConf,</span><br><span class="line">_sparkConf,</span><br><span class="line">appAttemptId,</span><br><span class="line">driverUrl,</span><br><span class="line">driverRef,</span><br><span class="line">securityMgr,</span><br><span class="line">localResources)</span><br><span class="line">。。。</span><br><span class="line">。。。</span><br><span class="line">。。。</span><br></pre></td></tr></table></figure></li>
<li>分配资源   <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allocator.allocateResources()</span><br></pre></td></tr></table></figure>
<ul>
<li>获取运行容器  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> allocatedContainers = allocateResponse.getAllocatedContainers()</span><br></pre></td></tr></table></figure></li>
<li>处理容器 跟进<code>handleAllocatedContainers(allocatedContainers.asScala)</code></li>
<li>分配容器  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Assign remaining that are neither node-local nor rack-local</span></span><br><span class="line"><span class="keyword">val</span> remainingAfterOffRackMatches = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">Container</span>]</span><br><span class="line"><span class="keyword">for</span> (allocatedContainer &lt;- remainingAfterRackMatches) &#123;</span><br><span class="line">  matchContainerToRequest(allocatedContainer, <span class="type">ANY_HOST</span>, containersToUse,</span><br><span class="line">    remainingAfterOffRackMatches)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>启动容器 跟进  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">runAllocatedContainers(containersToUse)</span><br></pre></td></tr></table></figure></li>
<li><font color ='red' >启动Executors</font>  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">new</span> <span class="type">ExecutorRunnable</span>(</span><br><span class="line">    <span class="type">Some</span>(container),</span><br><span class="line">    conf,</span><br><span class="line">    sparkConf,</span><br><span class="line">    driverUrl,</span><br><span class="line">    executorId,</span><br><span class="line">    executorHostname,</span><br><span class="line">    executorMemory,</span><br><span class="line">    executorCores,</span><br><span class="line">    appAttemptId.getApplicationId.toString,</span><br><span class="line">    securityMgr,</span><br><span class="line">    localResources,</span><br><span class="line">    <span class="type">ResourceProfile</span>.<span class="type">DEFAULT_RESOURCE_PROFILE_ID</span> <span class="comment">// use until fully supported</span></span><br><span class="line">  ).run()</span><br><span class="line">    ```  </span><br><span class="line">- -&gt; 跟进 run方法 &lt;font color =<span class="symbol">&#x27;re</span>d&#x27; &gt;nmClient启动&lt;/font&gt;</span><br><span class="line">    - `org.apache.spark.deploy.yarn.<span class="type">ExecutorRunnable</span>#run`</span><br><span class="line">    - -&gt; nmClient启动容器 `org.apache.spark.deploy.yarn.<span class="type">ExecutorRunnable</span>#startContainer` </span><br><span class="line">        ```scala</span><br><span class="line">        <span class="comment">// Send the start request to the ContainerManager</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          nmClient.startContainer(container.get, ctx)</span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">          <span class="keyword">case</span> ex: <span class="type">Exception</span> =&gt;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s&quot;Exception while starting container <span class="subst">$&#123;container.get.getId&#125;</span>&quot;</span> +</span><br><span class="line">              <span class="string">s&quot; on host <span class="subst">$hostname</span>&quot;</span>, ex)</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>-&gt; 准备运行命令<code>org.apache.spark.deploy.yarn.ExecutorRunnable#prepareCommand</code></li>
<li>确定执行命令  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">val</span> commands = prefixEnv ++</span><br><span class="line"><span class="type">Seq</span>(<span class="type">Environment</span>.<span class="type">JAVA_HOME</span>.$$() + <span class="string">&quot;/bin/java&quot;</span>, <span class="string">&quot;-server&quot;</span>) ++</span><br><span class="line">javaOpts ++</span><br><span class="line"><span class="type">Seq</span>(<span class="string">&quot;org.apache.spark.executor.YarnCoarseGrainedExecutorBackend&quot;</span>,</span><br><span class="line">  <span class="string">&quot;--driver-url&quot;</span>, masterAddress,</span><br><span class="line">  <span class="string">&quot;--executor-id&quot;</span>, executorId,</span><br><span class="line">  <span class="string">&quot;--hostname&quot;</span>, hostname,</span><br><span class="line">  <span class="string">&quot;--cores&quot;</span>, executorCores.toString,</span><br><span class="line">  <span class="string">&quot;--app-id&quot;</span>, appId,</span><br><span class="line">  <span class="string">&quot;--resourceProfileId&quot;</span>, resourceProfileId.toString) ++</span><br><span class="line">userClassPath ++</span><br><span class="line"><span class="type">Seq</span>(</span><br><span class="line">  <span class="string">s&quot;1&gt;<span class="subst">$&#123;ApplicationConstants.LOG_DIR_EXPANSION_VAR&#125;</span>/stdout&quot;</span>,</span><br><span class="line">  <span class="string">s&quot;2&gt;<span class="subst">$&#123;ApplicationConstants.LOG_DIR_EXPANSION_VAR&#125;</span>/stderr&quot;</span>)</span><br></pre></td></tr></table></figure></li>
<li><font color ='red' >容器执行类</font><code>org.apache.spark.executor.YarnCoarseGrainedExecutorBackend</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Driver中mainMethod即为用户程序的main方法入口，workCount的main方法<ul>
<li>-&gt; 跟进<code>new SparkContext(conf)</code></li>
<li>-&gt; 定位<code>Post init</code>  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">_taskScheduler.postStartHook()</span><br></pre></td></tr></table></figure></li>
<li>-&gt; 跟进 <code>org.apache.spark.scheduler.cluster.YarnClusterScheduler#postStartHook</code></li>
<li>-&gt; 跟进 (注意：这里的方法为半生对象的静态方法)<code>org.apache.spark.deploy.yarn.ApplicationMaster#sparkContextInitialized</code></li>
<li>-&gt; 跟进 (注意：这里的方法为类的成员方法)<code>org.apache.spark.deploy.yarn.ApplicationMaster#sparkContextInitialized</code>  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">sparkContextInitialized</span></span>(sc: <span class="type">SparkContext</span>) = &#123;</span><br><span class="line">      sparkContextPromise.synchronized &#123;</span><br><span class="line">      <span class="comment">// Notify runDriver function that SparkContext is available</span></span><br><span class="line">      sparkContextPromise.success(sc)</span><br><span class="line">      <span class="comment">// Pause the user class thread in order to make proper initialization in runDriver function.</span></span><br><span class="line">      sparkContextPromise.wait()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>通知runDriver方法SparkContext可用，退出阻塞状态</li>
<li>当前计算线程进入阻塞状态，Driver执行准备工作</li>
</ul>
</li>
</ul>
</li>
<li> 资源申请结束 恢复Driver <code>resumeDriver()</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="7-1-4-ExecutorBackend-源码"><a href="#7-1-4-ExecutorBackend-源码" class="headerlink" title="7.1.4 ExecutorBackend 源码"></a>7.1.4 ExecutorBackend 源码</h3><ul>
<li>入口<code>org.apache.spark.executor.YarnCoarseGrainedExecutorBackend</code></li>
<li>伴生对象的main方法<code>org.apache.spark.executor.YarnCoarseGrainedExecutorBackend#main</code></li>
<li>跟进run方法  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">CoarseGrainedExecutorBackend</span>.run(backendArgs, createFn)</span><br></pre></td></tr></table></figure></li>
<li>定位 Executor  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">env.rpcEnv.setupEndpoint(<span class="string">&quot;Executor&quot;</span>,</span><br><span class="line">    backendCreateFn(env.rpcEnv, arguments, env, cfg.resourceProfile))</span><br></pre></td></tr></table></figure>
<ul>
<li>Backend：后台</li>
<li>Endpoint：终端</li>
<li>RpcEnv：rpc通信环境</li>
<li>RpcEndpoint：rpc通信终端  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">The life-cycle of an endpoint is:</span><br><span class="line">constructor -&gt; onStart -&gt; receive* -&gt; onStop</span><br></pre></td></tr></table></figure>
<ul>
<li>YarnCoarseGrainedExecutorBackend父类 -&gt; CoarseGrainedExecutorBackend  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onStart</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  logInfo(<span class="string">&quot;Connecting to driver: &quot;</span> + driverUrl)</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    _resources = parseOrFindResources(resourcesFileOpt)</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">      exitExecutor(<span class="number">1</span>, <span class="string">&quot;Unable to create executor due to &quot;</span> + e.getMessage, e)</span><br><span class="line">  &#125;</span><br><span class="line">  rpcEnv.asyncSetupEndpointRefByURI(driverUrl).flatMap &#123; ref =&gt;</span><br><span class="line">    <span class="comment">// This is a very fast action so we can use &quot;ThreadUtils.sameThread&quot;</span></span><br><span class="line">    driver = <span class="type">Some</span>(ref)</span><br><span class="line">    ref.ask[<span class="type">Boolean</span>](<span class="type">RegisterExecutor</span>(executorId, self, hostname, cores, extractLogUrls,</span><br><span class="line">      extractAttributes, _resources, resourceProfile.id))</span><br><span class="line">  &#125;(<span class="type">ThreadUtils</span>.sameThread).onComplete &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Success</span>(_) =&gt;</span><br><span class="line">      self.send(<span class="type">RegisteredExecutor</span>)</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Failure</span>(e) =&gt;</span><br><span class="line">      exitExecutor(<span class="number">1</span>, <span class="string">s&quot;Cannot register with driver: <span class="subst">$driverUrl</span>&quot;</span>, e, notifyDriver = <span class="literal">false</span>)</span><br><span class="line">  &#125;(<span class="type">ThreadUtils</span>.sameThread)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Backend和Driver通讯<code>rpcEnv.asyncSetupEndpointRefByURI</code><ul>
<li>注册Executor  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ref.ask[<span class="type">Boolean</span>](<span class="type">RegisterExecutor</span>(executorId, self, hostname, cores, extractLogUrls,</span><br><span class="line">    extractAttributes, _resources, resourceProfile.id))</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>Driver应答<code>org.apache.spark.SparkContext#_schedulerBackend</code><ul>
<li><code>org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.DriverEndpoint#receiveAndReply</code>  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">  listenerBus.post(</span><br><span class="line">  <span class="type">SparkListenerExecutorAdded</span>(<span class="type">System</span>.currentTimeMillis(), executorId, data))</span><br><span class="line"><span class="comment">// Note: some tests expect the reply to come after we put the executor in the map</span></span><br><span class="line">context.reply(<span class="literal">true</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SparkCore/" rel="tag">SparkCore</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Scala入门"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/12/04/Scala%E5%85%A5%E9%97%A8/"
    >Scala入门</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/12/04/Scala%E5%85%A5%E9%97%A8/" class="article-date">
  <time datetime="2021-12-04T11:24:33.000Z" itemprop="datePublished">2021-12-04</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Scala/">Scala</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Scala"><a href="#Scala" class="headerlink" title="Scala"></a>Scala</h1><h1 id="第1章-Scala入门"><a href="#第1章-Scala入门" class="headerlink" title="第1章 Scala入门"></a>第1章 Scala入门</h1><h2 id="1-1-概述"><a href="#1-1-概述" class="headerlink" title="1.1 概述"></a>1.1 概述</h2><p><img src="https://s2.loli.net/2021/12/04/snWwTjmo2i7ZCFt.jpg"></p>
<h3 id="1-1-1-什么是Scala"><a href="#1-1-1-什么是Scala" class="headerlink" title="1.1.1 什么是Scala"></a>1.1.1 什么是Scala</h3><ul>
<li>从英文的角度来讲，Scala并不是一个单词，而是Scalable Language两个单词的缩写，表示可伸缩语言的意思。从计算机的角度来讲，Scala是一门完整的软件编程语言，那么连在一起就表示Scala是一门可伸缩的软件编程语言。之所以说它是可伸缩，是因为这门语言体现了面向对象，函数式编程等多种不同的语言范式，且融合了不同语言新的特性。</li>
<li>Scala编程语言是由联邦理工学院洛桑（EPFL）的Martin Odersky于2001年基于Funnel的工作开始设计并开发的。由于Martin Odersky之前的工作是开发通用Java和Javac（Sun公司的Java编译器），所以基于Java平台的Scala语言于2003年底/2004年初发布。</li>
<li>截至到2020年8月，Scala最新版本为2.13.3，支持JVM和JavaScript</li>
<li>Scala官网：<a target="_blank" rel="noopener" href="https://www.scala-lang.org/">https://www.scala-lang.org/</a></li>
</ul>
<h3 id="1-1-2-为什么学习Scala"><a href="#1-1-2-为什么学习Scala" class="headerlink" title="1.1.2 为什么学习Scala"></a>1.1.2 为什么学习Scala</h3><p>在之前的学习中，我们已经学习了很长时间的Java语言，为什么此时要学习一门新的语言呢？主要基于以下几个原因：</p>
<ol>
<li>大数据主要的批处理计算引擎框架Spark是基于Scala语言开发的</li>
<li>大数据主要的流式计算引擎框架Flink也提供了Scala相应的API</li>
<li>大数据领域中函数式编程的开发效率更高，更直观，更容易理解</li>
</ol>
<h3 id="1-1-3-Java-and-Scala"><a href="#1-1-3-Java-and-Scala" class="headerlink" title="1.1.3 Java and Scala"></a>1.1.3 Java and Scala</h3><p>Martin Odersky是狂热的编译器爱好者，长时间的编程后，希望开发一种语言，能够让写程序的过程变得简单，高效，所以当接触到Java语言后，感受到了这门语言的魅力，决定将函数式编程语言的特性融合到Java语言中，由此产生了2门语言（Pizza &amp; Scala）,这两种语言极大地推动了Java语言的发展</p>
<ul>
<li>JDK1.5的泛型，增强for循环，自动类型转换等都是从Pizza语言引入的新特性</li>
<li>JDK1.8的类型推断，λ（lambda）表达式是从Scala语言引入的新特性</li>
</ul>
<p>由上可知，Scala语言是基于Java开发的，所以其编译后的文件也是字节码文件，并可以运行在JVM中。</p>
<h2 id="1-2-快速上手"><a href="#1-2-快速上手" class="headerlink" title="1.2 快速上手"></a>1.2 快速上手</h2><h3 id="1-2-1-Scala环境安装"><a href="#1-2-1-Scala环境安装" class="headerlink" title="1.2.1 Scala环境安装"></a>1.2.1 Scala环境安装</h3><ol>
<li>安装JDK 1.8（略）</li>
<li>安装Scala2.12<ol>
<li>下载scala-2.12.11.zip</li>
<li>配置环境变量 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#SCALA_HOME</span></span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/usr/<span class="built_in">local</span>/etc/scala-2.11.12</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SCALA_HOME</span>/bin</span><br></pre></td></tr></table></figure></li>
<li>环境测试 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ scala</span><br><span class="line">Welcome to Scala 2.11.12 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_291).</span><br><span class="line">Type <span class="keyword">in</span> expressions <span class="keyword">for</span> evaluation. Or try :<span class="built_in">help</span>.</span><br><span class="line"></span><br><span class="line">scala&gt; 1+1</span><br><span class="line">res0: Int = 2</span><br><span class="line"></span><br><span class="line">scala&gt;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h3 id="1-2-2-Scala插件安装"><a href="#1-2-2-Scala插件安装" class="headerlink" title="1.2.2 Scala插件安装"></a>1.2.2 Scala插件安装</h3><p>默认情况下IDEA不支持Scala的开发，需要安装Scala插件。<br><img src="https://s2.loli.net/2021/12/04/2pyYvDoeamgQH4w.jpg"></p>
<h3 id="1-2-3-Hello-Scala案例"><a href="#1-2-3-Hello-Scala案例" class="headerlink" title="1.2.3 Hello Scala案例"></a>1.2.3 Hello Scala案例</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.bigdata.scala</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HelloScala</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="type">System</span>.out.println(<span class="string">&quot;Hello Scala&quot;</span>)</span><br><span class="line">       println(<span class="string">&quot;Hello Scala&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li>代码解析<ul>
<li>object</li>
<li>def</li>
<li>args : Array[String]</li>
<li>Unit</li>
<li>System.out.println</li>
<li>println</li>
</ul>
</li>
</ol>
<p>如果只是通过代码来进行语法的解析，并不能了解其真正的实现原理。scala语言是基于Java语言开发的，所以也会编译为class文件，那么我们可以通过反编译指令javap</p>
<ul>
<li>字节码：javap -c -l 类名  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">➜  scala git:(master) ✗ javap -c -l HelloScala\$ </span><br><span class="line">警告: 二进制文件HelloScala$包含com.bigdata.scala.HelloScala$</span><br><span class="line">Compiled from <span class="string">&quot;HelloScala.scala&quot;</span></span><br><span class="line">public final class com.bigdata.scala.HelloScala$ &#123;</span><br><span class="line">  public static final com.bigdata.scala.HelloScala$ MODULE$;</span><br><span class="line"></span><br><span class="line">  public static &#123;&#125;;</span><br><span class="line">    Code:</span><br><span class="line">       0: new           <span class="comment">#2                  // class com/bigdata/scala/HelloScala$</span></span><br><span class="line">       3: invokespecial <span class="comment">#12                 // Method &quot;&lt;init&gt;&quot;:()V</span></span><br><span class="line">       6: <span class="built_in">return</span></span><br><span class="line"></span><br><span class="line">  public void main(java.lang.String[]);</span><br><span class="line">    Code:</span><br><span class="line">       0: getstatic     <span class="comment">#20                 // Field java/lang/System.out:Ljava/io/PrintStream;</span></span><br><span class="line">       3: ldc           <span class="comment">#22                 // String Hello Scala</span></span><br><span class="line">       5: invokevirtual <span class="comment">#28                 // Method java/io/PrintStream.println:(Ljava/lang/String;)V</span></span><br><span class="line">       8: getstatic     <span class="comment">#33                 // Field scala/Predef$.MODULE$:Lscala/Predef$;</span></span><br><span class="line">      11: ldc           <span class="comment">#22                 // String Hello Scala</span></span><br><span class="line">      13: invokevirtual <span class="comment">#36                 // Method scala/Predef$.println:(Ljava/lang/Object;)V</span></span><br><span class="line">      16: <span class="built_in">return</span></span><br><span class="line">    LineNumberTable:</span><br><span class="line">      line 5: 0</span><br><span class="line">      line 6: 8</span><br><span class="line">    LocalVariableTable:</span><br><span class="line">      Start  Length  Slot  Name   Signature</span><br><span class="line">          0      17     0  this   Lcom/bigdata/scala/HelloScala$;</span><br><span class="line">          0      17     1  args   [Ljava/lang/String;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>反编译  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//decompiled from HelloScala$.class</span></span><br><span class="line"><span class="keyword">package</span> com.bigdata.scala;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.Predef.;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloScala</span>$ </span>&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> HelloScala$ MODULE$;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">static</span> &#123;</span><br><span class="line">      <span class="keyword">new</span> HelloScala$();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;Hello Scala&quot;</span>);</span><br><span class="line">      .MODULE$.println(<span class="string">&quot;Hello Scala&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">private</span> HelloScala$() &#123;</span><br><span class="line">      MODULE$ = <span class="keyword">this</span>;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//decompiled from HelloScala.class</span></span><br><span class="line"><span class="keyword">package</span> com.bigdata.scala;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.reflect.ScalaSignature;</span><br><span class="line"></span><br><span class="line"><span class="meta">@ScalaSignature(</span></span><br><span class="line"><span class="meta">   bytes = &quot;\u0006\u0001!:Q!\u0001\u0002\t\u0002%\t!\u0002S3mY&gt;\u001c6-\u00197b\u0015\t\u0019A!A\u0003tG\u0006d\u0017M\u0003\u0002\u0006\r\u00059!-[4eCR\f&#x27;\&quot;A\u0004\u0002\u0007\r|Wn\u0001\u0001\u0011\u0005)</span>YQ\<span class="string">&quot;\u0001\u0002\u0007\u000b1\u0011\u0001\u0012A\u0007\u0003\u0015!+G\u000e\\8TG\u0006d\u0017m\u0005\u0002\f\u001dA\u0011q\&quot;E\u0007\u0002!)\t1!\u0003\u0002\u0013!\t1\u0011I\\=SK\u001aDQ\u0001F\u0006\u0005\u0002U\ta\u0001P5oSRtD#A\u0005\t\u000b]YA\u0011\u0001\r\u0002\t5\f\u0017N\u001c\u000b\u00033q\u0001\&quot;a\u0004\u000e\n\u0005m\u0001\&quot;\u0001B+oSRDQ!\b\fA\u0002y\tA!\u0019:hgB\u0019qbH\u0011\n\u0005\u0001\u0002\&quot;!B!se\u0006L\bC\u0001\u0012&amp;\u001d\ty1%\u0003\u0002%!\u00051\u0001K]3eK\u001aL!AJ\u0014\u0003\rM#(/\u001b8h\u0015\t!\u0003\u0003&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloScala</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] var0)</span> </span>&#123;</span><br><span class="line">      HelloScala$.MODULE$.main(var0);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="第2章-变量和数据类型"><a href="#第2章-变量和数据类型" class="headerlink" title="第2章 变量和数据类型"></a>第2章 变量和数据类型</h1><h2 id="2-1-注释"><a href="#2-1-注释" class="headerlink" title="2.1 注释"></a>2.1 注释</h2><p>Scala注释使用和Java完全一样。注释是一个程序员必须要具有的良好编程习惯。将自己的思想通过注释先整理出来，再用代码去体现。</p>
<h3 id="2-1-1-单行注释"><a href="#2-1-1-单行注释" class="headerlink" title="2.1.1 单行注释"></a>2.1.1 单行注释</h3><pre><code><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.bigdata.scala</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaComment</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 单行注释</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</code></pre>
<h3 id="2-1-2-多行注释"><a href="#2-1-2-多行注释" class="headerlink" title="2.1.2 多行注释"></a>2.1.2 多行注释</h3><pre><code><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.bigdata.scala</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaComment</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">           多行注释</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</code></pre>
<h3 id="2-1-3-文档注释"><a href="#2-1-3-文档注释" class="headerlink" title="2.1.3 文档注释"></a>2.1.3 文档注释</h3><pre><code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">package com.atguigu.bigdata.scala</span><br><span class="line">/**</span><br><span class="line">  * doc注释</span><br><span class="line">  */</span><br><span class="line">object ScalaComment&#123;</span><br><span class="line">    def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</code></pre>
<h2 id="2-2-变量"><a href="#2-2-变量" class="headerlink" title="2.2 变量"></a>2.2 变量</h2><p>变量是一种使用方便的占位符，用于引用计算机内存地址，变量创建后会占用一定的内存空间。基于变量的数据类型，操作系统会进行内存分配并且决定什么将被储存在保留内存中。因此，通过给变量分配不同的数据类型，你可以在这些变量中存储整数，小数或者字母。</p>
<h3 id="2-2-1-语法声明"><a href="#2-2-1-语法声明" class="headerlink" title="2.2.1 语法声明"></a>2.2.1 语法声明</h3><ul>
<li>变量的类型在变量名之后等号之前声明。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaVariable</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// var | val 变量名 ：变量类型 = 变量值</span></span><br><span class="line">        <span class="comment">// 用户名称</span></span><br><span class="line">        <span class="keyword">var</span> username : <span class="type">String</span> = <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">        <span class="comment">// 用户密码</span></span><br><span class="line">        <span class="keyword">val</span> userpswd : <span class="type">String</span> = <span class="string">&quot;000000&quot;</span> </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>变量的类型如果能够通过变量值推断出来，那么可以省略类型声明，这里的省略，并不是不声明，而是由Scala编译器在编译时自动声明编译的。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaVariable</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 因为变量值为字符串，又因为Scala是静态类型语言，所以即使不声明类型</span></span><br><span class="line">        <span class="comment">// Scala也能在编译时正确的判断出变量的类型，这体现了Scala语言的简洁特性。</span></span><br><span class="line">        <span class="keyword">var</span> username = <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">        <span class="keyword">val</span> userpswd = <span class="string">&quot;000000&quot;</span> </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-2-2-变量初始化"><a href="#2-2-2-变量初始化" class="headerlink" title="2.2.2 变量初始化"></a>2.2.2 变量初始化</h3><ul>
<li>Java语法中变量在使用前进行初始化就可以，但是Scala语法中是不允许的，必须显示进行初始化操作。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaVariable</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">var</span> username <span class="comment">// Error</span></span><br><span class="line">        <span class="keyword">val</span> username = <span class="string">&quot;zhangsan&quot;</span> <span class="comment">// OK</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-2-3-可变变量"><a href="#2-2-3-可变变量" class="headerlink" title="2.2.3 可变变量"></a>2.2.3 可变变量</h3><ul>
<li>值可以改变的变量，称之为可变变量，但是变量类型无法发生改变, Scala中可变变量使用关键字var进行声明  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaVariable</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 用户名称</span></span><br><span class="line">        <span class="keyword">var</span> username : <span class="type">String</span> = <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">        username = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line">        username = <span class="literal">true</span> <span class="comment">// Error</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-2-4-不可变变量"><a href="#2-2-4-不可变变量" class="headerlink" title="2.2.4 不可变变量"></a>2.2.4 不可变变量</h3><ul>
<li>值一旦初始化后无法改变的变量，称之为不可变变量。Scala中不可变变量使用关键字val进行声明, 类似于Java语言中的final关键字</li>
<li>变量申明后修改的可能性比较低  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaVariable</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 用户名称</span></span><br><span class="line">        <span class="keyword">val</span> username : <span class="type">String</span> = <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">        username = <span class="string">&quot;lisi&quot;</span> <span class="comment">// Error</span></span><br><span class="line">        username = <span class="literal">true</span> <span class="comment">// Error</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-2-5-强类型、弱类型"><a href="#2-2-5-强类型、弱类型" class="headerlink" title="2.2.5 强类型、弱类型"></a>2.2.5 强类型、弱类型</h3><ul>
<li>强类型：在执行之前，必须明确变量类型，而且类型确定后无法发生改变，取值的类型也不能发生变化；变量的类型和取值是统一的</li>
<li>弱类型：语言是在运行时决定数据类型，可以根据数据本身的类型动态的调整变量的类型</li>
<li>思考两个问题：<ul>
<li>val和var两个修饰符，哪一个会推荐使用？<ul>
<li>val</li>
</ul>
</li>
<li>Java中的字符串为何称之为不可变字符串？<ul>
<li>声明之后无法更改</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="2-3-标识符"><a href="#2-3-标识符" class="headerlink" title="2.3 标识符"></a>2.3 标识符</h2><p>Scala 可以使用两种形式的标志符，字符数字和符号。</p>
<ul>
<li>字符数字使用字母或是下划线开头，后面可以接字母或是数字，符号”$”在 Scala 中也看作为字母。然而以”$”开头的标识符为保留的 Scala 编译器产生的标志符使用，应用程序应该避免使用”$”开始的标识符，以免造成冲突。</li>
<li>Scala 的命名规范采用和 Java 类似的 camel 命名规范，首字符小写，比如 toString。类名的首字符还是使用大写。此外也应该避免使用以下划线结尾的标志符以避免冲突。</li>
<li>Scala 内部实现时会使用转义的标志符，比如:-&gt; 使用 $colon$minus$greater 来表示这个符号。</li>
<li>Scala 中的标识符也不能是关键字或保留字，那么Scala中有多少关键字或保留字呢？<br>   <img src="https://s2.loli.net/2021/12/04/GnNkOwfJSloHX2q.jpg"></li>
<li>注意<ol>
<li>可以使用字母、数字、美元符号$、下划线_</li>
<li>数字不能开头</li>
<li>不能使用关键字，保留字</li>
<li>长度没有限制，最好见名知意（驼峰规范）</li>
<li>区分大小写</li>
<li>基础标识符命名，Scala和Java一致</li>
<li>Java是Unicode编码，所以能使用Unicode转换的内容都可以作为标识符（中文）<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 和Java一样的标识符命名规则</span></span><br><span class="line"><span class="keyword">val</span> name = <span class="string">&quot;zhangsan&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> name1 = <span class="string">&quot;zhangsan0&quot;</span>   <span class="comment">// OK</span></span><br><span class="line"><span class="comment">//val 1name = &quot;zhangsan0&quot; // Error</span></span><br><span class="line"><span class="keyword">val</span> name$ = <span class="string">&quot;zhangsan1&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> $name = <span class="string">&quot;zhangsan2&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> name_ = <span class="string">&quot;zhangsan3&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> _name = <span class="string">&quot;zhangsan4&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> $ = <span class="string">&quot;zhangsan5&quot;</span>     <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> _ = <span class="string">&quot;zhangsan6&quot;</span>     <span class="comment">// OK</span></span><br><span class="line"><span class="comment">//val 1 = &quot;zhangsan6&quot;     // Error</span></span><br><span class="line"><span class="comment">//val true = &quot;zhangsan6&quot;  // Error</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 和Java不一样的标识符命名规则</span></span><br><span class="line"><span class="keyword">val</span> + = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> - = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> * = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> / = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> ! = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="comment">//val @ = &quot;lisi&quot; // Error</span></span><br><span class="line"><span class="keyword">val</span> @@ = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="comment">//val # = &quot;lisi&quot; // Error</span></span><br><span class="line"><span class="keyword">val</span> ## = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> % = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> ^ = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> &amp; = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="comment">//val ( = &quot;lisi&quot; // Error</span></span><br><span class="line"><span class="comment">//val ( = &quot;lisi&quot; // Error</span></span><br><span class="line"><span class="comment">//val ) = &quot;lisi&quot; // Error</span></span><br><span class="line"><span class="comment">//val = = &quot;lisi&quot; // Error</span></span><br><span class="line"><span class="keyword">val</span> == = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="comment">//val [ = &quot;lisi&quot; // Error</span></span><br><span class="line"><span class="comment">//val ] = &quot;lisi&quot; // Error</span></span><br><span class="line"><span class="comment">//val : = &quot;lisi&quot; // Error</span></span><br><span class="line"><span class="keyword">val</span> :: = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="comment">//val ; = &quot;lisi&quot; // Error</span></span><br><span class="line"><span class="comment">//val &#x27; = &quot;lisi&quot; // Error</span></span><br><span class="line"><span class="comment">//val &quot; = &quot;lisi&quot; // Error</span></span><br><span class="line"><span class="keyword">val</span> <span class="string">&quot;&quot;</span> = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> &lt; = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> &gt; = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> ? = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> | = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> \ = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="comment">//val ` = &quot;lisi&quot; // Error</span></span><br><span class="line"><span class="keyword">val</span> ~ = <span class="string">&quot;lisi&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> :-&gt; = <span class="string">&quot;wangwu&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="keyword">val</span> :-&lt; = <span class="string">&quot;wangwu&quot;</span> <span class="comment">// OK</span></span><br><span class="line"><span class="comment">// 切记，能声明和能使用是两回事</span></span><br><span class="line"><span class="comment">// 能用</span></span><br><span class="line"><span class="keyword">val</span> 国家 = <span class="string">&quot;中国&quot;</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li>Scala语言不仅是面向对象的语言，本身也融合了函数式编程，函数的命名也是用标识符<ul>
<li>函数式编程更注重功能</li>
<li>面向对象的变成语言更注重关系<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> name</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaMethodName</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> a = <span class="number">1</span></span><br><span class="line">        <span class="keyword">val</span> b = <span class="number">2</span></span><br><span class="line">        <span class="keyword">val</span> sum = a + b</span><br><span class="line">        print(sum)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">+</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">        <span class="keyword">return</span> a + b</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h2 id="2-4-字符串"><a href="#2-4-字符串" class="headerlink" title="2.4 字符串"></a>2.4 字符串</h2><ul>
<li>在 Scala 中，字符串的类型实际上就是 Java中的 String类，它本身是没有 String 类的。</li>
<li>在 Scala 中，String 是一个不可变的字符串对象，所以该对象不可被修改。这就意味着你如果修改字符串就会产生一个新的字符串对象。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaString</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> name : <span class="type">String</span> = <span class="string">&quot;scala&quot;</span></span><br><span class="line">        <span class="keyword">val</span> subname : <span class="type">String</span> = name.substring(<span class="number">0</span>,<span class="number">2</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-4-1-字符串连接"><a href="#2-4-1-字符串连接" class="headerlink" title="2.4.1 字符串连接"></a>2.4.1 字符串连接</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaString</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 字符串连接</span></span><br><span class="line">        println(<span class="string">&quot;Hello &quot;</span> + name)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-4-2-传值字符串"><a href="#2-4-2-传值字符串" class="headerlink" title="2.4.2 传值字符串"></a>2.4.2 传值字符串</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaString</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 传值字符串(格式化字符串)</span></span><br><span class="line">        printf(<span class="string">&quot;name=%s\n&quot;</span>, name)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-4-3-插值字符串"><a href="#2-4-3-插值字符串" class="headerlink" title="2.4.3 插值字符串"></a>2.4.3 插值字符串</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaString</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 插值字符串</span></span><br><span class="line">        <span class="comment">// 将变量值插入到字符串</span></span><br><span class="line">        println(<span class="string">s&quot;name=<span class="subst">$&#123;name&#125;</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-4-4-多行字符串"><a href="#2-4-4-多行字符串" class="headerlink" title="2.4.4 多行字符串"></a>2.4.4 多行字符串</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaString</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 多行格式化字符串</span></span><br><span class="line">        <span class="comment">// 在封装JSON或SQL时比较常用</span></span><br><span class="line">        <span class="comment">// | 默认顶格符</span></span><br><span class="line">        println(</span><br><span class="line">                    <span class="string">s&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">                      | Hello</span></span><br><span class="line"><span class="string">                      | $&#123;name&#125;</span></span><br><span class="line"><span class="string">        &quot;</span><span class="string">&quot;&quot;</span>.stripMargin)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="2-5-输入输出"><a href="#2-5-输入输出" class="headerlink" title="2.5 输入输出"></a>2.5 输入输出</h2><h3 id="2-5-1-输入"><a href="#2-5-1-输入" class="headerlink" title="2.5.1 输入"></a>2.5.1 输入</h3><ul>
<li>从屏幕（控制台）中获取输入  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaIn</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 标准化屏幕输入</span></span><br><span class="line">        <span class="keyword">val</span> age : <span class="type">Int</span> = scala.io.<span class="type">StdIn</span>.readInt()</span><br><span class="line">        println(age)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>从文件中获取输入  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaIn</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 请注意文件路径的位置</span></span><br><span class="line">        scala.io.<span class="type">Source</span>.fromFile(<span class="string">&quot;input/user.json&quot;</span>).foreach(</span><br><span class="line">            line =&gt; &#123;</span><br><span class="line">                print(line)</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        scala.io.<span class="type">Source</span>.fromFile(<span class="string">&quot;input/user.json&quot;</span>).getLines()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-5-2-输出"><a href="#2-5-2-输出" class="headerlink" title="2.5.2 输出"></a>2.5.2 输出</h3><ul>
<li>Scala进行文件写操作，用的都是 java中的I/O类  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaOut</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> writer = <span class="keyword">new</span> <span class="type">PrintWriter</span>(<span class="keyword">new</span> <span class="type">File</span>(<span class="string">&quot;output/test.txt&quot;</span> ))</span><br><span class="line">      writer.write(<span class="string">&quot;Hello Scala&quot;</span>)</span><br><span class="line">      writer.close()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-5-3-网络"><a href="#2-5-3-网络" class="headerlink" title="2.5.3 网络"></a>2.5.3 网络</h3><ul>
<li>Scala进行网络数据交互时，采用的也依然是 java中的I/O类</li>
<li>服务端  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TestServer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> server = <span class="keyword">new</span> <span class="type">ServerSocket</span>(<span class="number">9999</span>)</span><br><span class="line">        <span class="keyword">while</span> ( <span class="literal">true</span> ) &#123;</span><br><span class="line">            <span class="keyword">val</span> socket: <span class="type">Socket</span> = server.accept()</span><br><span class="line">            <span class="keyword">val</span> reader = <span class="keyword">new</span> <span class="type">BufferedReader</span>(</span><br><span class="line">                <span class="keyword">new</span> <span class="type">InputStreamReader</span>(</span><br><span class="line">                    socket.getInputStream,</span><br><span class="line">                    <span class="string">&quot;UTF-8&quot;</span></span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">var</span> s : <span class="type">String</span> = <span class="string">&quot;&quot;</span></span><br><span class="line">            <span class="keyword">var</span> flg = <span class="literal">true</span></span><br><span class="line">            <span class="keyword">while</span> ( flg  ) &#123;</span><br><span class="line">                s = reader.readLine()</span><br><span class="line">                <span class="keyword">if</span> ( s != <span class="literal">null</span> ) &#123;</span><br><span class="line">                    println(s)</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    flg = <span class="literal">false</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>客户端  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TestClient</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> client = <span class="keyword">new</span> <span class="type">Socket</span>(<span class="string">&quot;localhost&quot;</span>, <span class="number">9999</span>)</span><br><span class="line">        <span class="keyword">val</span> out = <span class="keyword">new</span> <span class="type">PrintWriter</span>(</span><br><span class="line">            <span class="keyword">new</span> <span class="type">OutputStreamWriter</span>(</span><br><span class="line">                client.getOutputStream,</span><br><span class="line">                <span class="string">&quot;UTF-8&quot;</span></span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">        out.print(<span class="string">&quot;hello Scala&quot;</span>)</span><br><span class="line">        out.flush()</span><br><span class="line">        out.close()</span><br><span class="line">        client.close()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>思考：java的序列化怎么回事？<ol>
<li>java将内存中的对象存储到磁盘文件中，要求对象必须实现可序列化接口</li>
<li>在网络中想要传递对象，这个对象需要序列化。</li>
</ol>
</li>
</ul>
<h2 id="2-6-数据类型"><a href="#2-6-数据类型" class="headerlink" title="2.6 数据类型"></a>2.6 数据类型</h2><p>Scala与Java有着相同的数据类型，但是又有不一样的地方</p>
<h3 id="2-6-1-Java数据类型"><a href="#2-6-1-Java数据类型" class="headerlink" title="2.6.1 Java数据类型"></a>2.6.1 Java数据类型</h3><p>Java的数据类型包含基本类型和引用类型</p>
<ul>
<li>基本类型：byte,short,char,int,long,float,double,boolean</li>
<li>引用类型：Object，数组，字符串，包装类，集合，POJO对象等</li>
</ul>
<h3 id="2-6-2-Scala数据类型"><a href="#2-6-2-Scala数据类型" class="headerlink" title="2.6.2 Scala数据类型"></a>2.6.2 Scala数据类型</h3><ol>
<li>基本数据类型（byte short int long float double char boolean）<ul>
<li>基本数据类型使用时，直接分配在栈内存空间</li>
</ul>
</li>
<li>引用数据类型 Object<ul>
<li>引用数据类型分配在堆内存中，引用在栈内存中，所以栈内存引用堆内存 </li>
</ul>
</li>
</ol>
<p>Scala是完全面向对象的语言，所以不存在基本数据类型的概念，有的只是任意值对象类型（AnyVal）和任意引用对象类型(AnyRef)</p>
<ul>
<li>任意值对象类型AnyVal: 将基本数据类型用面向对象的方式进行转换处理</li>
<li>任意引用对象类型AnyRef: Scala集合，Java类，Scala类</li>
<li><img src="https://s2.loli.net/2021/12/04/KxEZ1sJcnFoPQt9.jpg"><br><img src="https://s2.loli.net/2021/12/04/sPpcDVK6B5l92Mg.jpg"></li>
</ul>
<h2 id="2-7-类型转换"><a href="#2-7-类型转换" class="headerlink" title="2.7 类型转换"></a>2.7 类型转换</h2><h3 id="2-7-1-自动类型转化（隐式转换）"><a href="#2-7-1-自动类型转化（隐式转换）" class="headerlink" title="2.7.1 自动类型转化（隐式转换）"></a>2.7.1 自动类型转化（隐式转换）</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaDataType</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> b : <span class="type">Byte</span> = <span class="number">10</span></span><br><span class="line">        <span class="keyword">val</span> s : <span class="type">Short</span> = b</span><br><span class="line">        <span class="keyword">val</span> i : <span class="type">Int</span> = s</span><br><span class="line">        <span class="keyword">val</span> lon : <span class="type">Long</span> = i</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>思考：如下代码是否正确？  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> c : <span class="type">Char</span> = &#x27;<span class="type">A</span>&#x27; + <span class="number">1</span></span><br><span class="line">println(c)</span><br></pre></td></tr></table></figure>
<ul>
<li>可以，ASCII运行</li>
</ul>
</li>
</ul>
<h3 id="2-7-2-强制类型转化"><a href="#2-7-2-强制类型转化" class="headerlink" title="2.7.2 强制类型转化"></a>2.7.2 强制类型转化</h3><ol>
<li>Java语言<ul>
<li>基本数据类型转换-&gt;精度的提升或者截取</li>
<li>引用数据类型转换-&gt;参与运算的两个类型必须有关联，子类等 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a = <span class="number">10</span></span><br><span class="line"><span class="keyword">byte</span> b = (<span class="keyword">byte</span>)a</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>Scala语言 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a : Int = <span class="number">10</span></span><br><span class="line"><span class="keyword">var</span> b : Byte = a.toByte</span><br><span class="line"><span class="comment">// 基本上Scala的AnyVal类型之间都提供了相应转换的方法。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-7-3-字符串类型转化"><a href="#2-7-3-字符串类型转化" class="headerlink" title="2.7.3 字符串类型转化"></a>2.7.3 字符串类型转化</h3><ul>
<li>Scala是完全面向对象的语言，所有的类型都提供了toString方法，可以直接转换为字符串lon.toString</li>
<li>任意类型都提供了和字符串进行拼接的方法  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> i = <span class="number">10</span></span><br><span class="line"><span class="keyword">val</span> s = <span class="string">&quot;hello &quot;</span> + i</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="第3章-运算符"><a href="#第3章-运算符" class="headerlink" title="第3章 运算符"></a>第3章 运算符</h1><p>scala运算符的使用和Java运算符的使用基本相同，只有个别细节上不同。</p>
<h2 id="3-1-算数运算符"><a href="#3-1-算数运算符" class="headerlink" title="3.1 算数运算符"></a>3.1 算数运算符</h2><ul>
<li>加+，字符串拼接</li>
<li>减-</li>
<li>乘*</li>
<li>除/</li>
<li>取模%</li>
</ul>
<h2 id="3-2-关系运算符"><a href="#3-2-关系运算符" class="headerlink" title="3.2 关系运算符"></a>3.2 关系运算符</h2><ul>
<li>等于： ==</li>
<li>不等于：！=</li>
<li>大于：&gt;</li>
<li>小于：&lt;</li>
<li>大于等于：&gt;=</li>
<li>小于等于：&lt;=</li>
</ul>
<h2 id="思考：如下代码执行结果如何？"><a href="#思考：如下代码执行结果如何？" class="headerlink" title="思考：如下代码执行结果如何？"></a>思考：如下代码执行结果如何？</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> a = <span class="keyword">new</span> <span class="type">String</span>(<span class="string">&quot;abc&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> b = <span class="keyword">new</span> <span class="type">String</span>(<span class="string">&quot;abc&quot;</span>)</span><br><span class="line"></span><br><span class="line">println(a == b)      <span class="comment">//true 非空的equals</span></span><br><span class="line">println(a.equals(b)) <span class="comment">//true </span></span><br><span class="line">println(a.eq(b))     <span class="comment">//false等价于java的==</span></span><br></pre></td></tr></table></figure>

<h2 id="3-3-赋值运算符"><a href="#3-3-赋值运算符" class="headerlink" title="3.3 赋值运算符"></a>3.3 赋值运算符</h2><ul>
<li>简单赋值：=</li>
<li>相加后赋值：+=</li>
<li>相减后赋值：-=</li>
<li>相乘后赋值：*=</li>
<li>相除后赋值：/=</li>
<li>取模后赋值：%=</li>
<li>按位左移后赋值：&lt;&lt;=</li>
<li>按位右移后赋值：&gt;&gt;=</li>
<li>按位与运算后复制：$=</li>
<li>按位异运算后复制：^=</li>
<li>按位或运算后复制：|=</li>
<li>思考一个问题：为什么在上面的运算符中没有看到 ++， –？<ul>
<li>++运算有歧义，容易理解出现错误，所以scala中没有这样的语法，所以采用 +=的方式来代替。</li>
<li>++运算符放置在数据后面，标识先赋值（临时变量），再加一</li>
<li>++运算符放置在数据前面，标识先加一，再赋值</li>
<li>类似i=i++（i=(temp=i=0)(i=i+1)）含义模糊</li>
</ul>
</li>
</ul>
<h2 id="3-4-逻辑运算符"><a href="#3-4-逻辑运算符" class="headerlink" title="3.4 逻辑运算符"></a>3.4 逻辑运算符</h2><ul>
<li>逻辑与：&amp;&amp;</li>
<li>逻辑或：||</li>
<li>逻辑非：！</li>
</ul>
<h2 id="3-5-位运算符"><a href="#3-5-位运算符" class="headerlink" title="3.5 位运算符"></a>3.5 位运算符</h2><p>如果指定 A = 60; 及 B = 13; 两个变量对应的二进制为<br>A = 0011 1100<br>B = 0000 1101</p>
<ul>
<li>按位与</li>
<li>按位或</li>
<li>按位异或</li>
<li>按位取反</li>
<li>左移运算</li>
<li>右移运算</li>
<li>无符号右移</li>
</ul>
<ol>
<li>JDK1.8 HashMap 数据如何存储（定位）<ul>
<li>hash(key.hashCode()) &amp; length</li>
</ul>
</li>
<li>JDK1.8 HashMap 极限情况放置多少数据会转换成红黑二叉树（在链表上放多少条数据会转换成红黑二叉树）<ul>
<li>11条</li>
<li></li>
</ul>
</li>
<li>JDK1.8 HashMap 扩容为什么是2倍</li>
</ol>
<h2 id="3-6-运算符本质"><a href="#3-6-运算符本质" class="headerlink" title="3.6 运算符本质"></a>3.6 运算符本质</h2><p>在Scala中其实是没有运算符的，所有运算符都是方法。</p>
<ul>
<li>scala是完全面向对象的语言，所以数字其实也是对象</li>
<li>当调用对象的方法时，点.可以省略</li>
<li>如果函数参数只有一个，或者没有参数，()可以省略  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaOper</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> i : <span class="type">Int</span> = <span class="number">10</span></span><br><span class="line">        <span class="keyword">val</span> j : <span class="type">Int</span> = i.+(<span class="number">10</span>)</span><br><span class="line">        <span class="keyword">val</span> k : <span class="type">Int</span> = j +(<span class="number">20</span>)</span><br><span class="line">        <span class="keyword">val</span> m : <span class="type">Int</span> = k + <span class="number">30</span></span><br><span class="line">        println(m)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="第4章-流程控制"><a href="#第4章-流程控制" class="headerlink" title="第4章 流程控制"></a>第4章 流程控制</h1>Scala程序代码和所有编程语言代码一样，都会有特定的执行流程顺序，默认情况下是顺序执行，上一条逻辑执行完成后才会执行下一条逻辑，执行期间也可以根据某些条件执行不同的分支逻辑代码。</li>
</ul>
<h2 id="4-1-分支控制"><a href="#4-1-分支控制" class="headerlink" title="4.1 分支控制"></a>4.1 分支控制</h2><p>让程序有选择的的执行，分支控制有三种：单分支、双分支、多分支</p>
<h2 id="4-1-1-单分支"><a href="#4-1-1-单分支" class="headerlink" title="4.1.1 单分支"></a>4.1.1 单分支</h2><p>IF…ELSE 语句是通过一条或多条语句的执行结果（true或者false）来决定执行的代码块</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if(布尔表达式) &#123;</span><br><span class="line">   // 如果布尔表达式为 true 则执行该语句块</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果布尔表达式为 true 则执行大括号内的语句块，否则跳过大括号内的语句块，执行大括号之后的语句块。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaBranch</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> b = <span class="literal">true</span></span><br><span class="line">        <span class="keyword">if</span> ( b ) &#123;</span><br><span class="line">            println(<span class="string">&quot;true&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-1-2-双分支"><a href="#4-1-2-双分支" class="headerlink" title="4.1.2 双分支"></a>4.1.2 双分支</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if(布尔表达式) &#123;</span><br><span class="line">   // 如果布尔表达式为 true 则执行该语句块</span><br><span class="line">&#125; else &#123;</span><br><span class="line">   // 如果布尔表达式为 false 则执行该语句块</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果布尔表达式为 true 则执行接着的大括号内的语句块，否则执行else后的大括号内的语句块。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaBranch</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> b = <span class="literal">true</span></span><br><span class="line">        <span class="keyword">if</span> ( b ) &#123;</span><br><span class="line">            println(<span class="string">&quot;true&quot;</span>)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            println(<span class="string">&quot;false&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-1-3-多分支"><a href="#4-1-3-多分支" class="headerlink" title="4.1.3 多分支"></a>4.1.3 多分支</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">if(布尔表达式1) &#123;</span><br><span class="line">   // 如果布尔表达式1为 true，则执行该语句块</span><br><span class="line">&#125; else if ( 布尔表达式2 ) &#123;</span><br><span class="line">   // 如果布尔表达式2为 true，则执行该语句块</span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line">else &#123;</span><br><span class="line">   // 上面条件都不满足的场合，则执行该语句块</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实现一个小功能：输入年龄，如果年龄小于18岁，则输出“童年”。如果年龄大于等于18且小于等于30，则输出“青年”，如果年龄大于30小于等于50，则输出”中年”，否则，输出“老年”。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaBranch</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> age = <span class="number">30</span></span><br><span class="line">        <span class="keyword">if</span> ( age &lt; <span class="number">18</span> ) &#123;</span><br><span class="line">            println(<span class="string">&quot;童年&quot;</span>)</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> ( age &lt;= <span class="number">30</span> ) &#123;</span><br><span class="line">            println(<span class="string">&quot;青年&quot;</span>)</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> ( age &lt;= <span class="number">50</span> ) &#123;</span><br><span class="line">            println(<span class="string">&quot;中年&quot;</span>)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            println(<span class="string">&quot;老年&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实际上，Scala中的表达式都是有返回值的，所以上面的小功能还有其他的实现方式</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaBranch</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> age = <span class="number">30</span></span><br><span class="line">        <span class="keyword">val</span> result = <span class="keyword">if</span> ( age &lt; <span class="number">18</span> ) &#123;</span><br><span class="line">            <span class="string">&quot;童年&quot;</span></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> ( age &lt;= <span class="number">30</span> ) &#123;</span><br><span class="line">            <span class="string">&quot;青年&quot;</span></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> ( age &lt;= <span class="number">50</span> ) &#123;</span><br><span class="line">            <span class="string">&quot;中年&quot;</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="string">&quot;老年&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        println(result)</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>思考一个问题: 怎么没有讲三元运算符？<br>Scala语言中没有三元运算符的，使用if分支判断来代替三元运算符</p>
</blockquote>
<h2 id="4-2-循环控制"><a href="#4-2-循环控制" class="headerlink" title="4.2 循环控制"></a>4.2 循环控制</h2><p>有的时候，我们可能需要多次执行同一块代码。一般情况下，语句是按顺序执行的：函数中的第一个语句先执行，接着是第二个语句，依此类推。编程语言提供了更为复杂执行路径的多种控制结构。循环语句允许我们多次执行一个语句或语句组<br>Scala语言提供了以下几种循环类型</p>
<ul>
<li><code>while</code>循环</li>
<li><code>do···while</code>循环</li>
<li><code>for</code>循环</li>
</ul>
<h3 id="4-2-1-for循环"><a href="#4-2-1-for循环" class="headerlink" title="4.2.1 for循环"></a>4.2.1 for循环</h3><ol>
<li><p>基本语法</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for ( 循环变量 &lt;- 数据集 ) &#123;</span><br><span class="line">    循环体</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> 这里的数据集可以是任意类型的数据集合，如字符串，集合，数组等。</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaLoop</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">for</span> ( i &lt;- <span class="type">Range</span>(<span class="number">1</span>,<span class="number">5</span>) ) &#123; <span class="comment">// 范围集合</span></span><br><span class="line">            println(<span class="string">&quot;i = &quot;</span> + i )</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> ( i &lt;- <span class="number">1</span> to <span class="number">5</span> ) &#123; <span class="comment">// 包含5</span></span><br><span class="line">            println(<span class="string">&quot;i = &quot;</span> + i )</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> ( i &lt;- <span class="number">1</span> until <span class="number">5</span> ) &#123; <span class="comment">// 不包含5</span></span><br><span class="line">            println(<span class="string">&quot;i = &quot;</span> + i )</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>循环守卫<br> 循环时可以增加条件来决定是否继续循环体的执行,这里的判断条件我们称之为循环守卫</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaLoop</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">for</span> ( i &lt;- <span class="type">Range</span>(<span class="number">1</span>,<span class="number">5</span>) <span class="keyword">if</span> i != <span class="number">3</span>  ) &#123;</span><br><span class="line">            println(<span class="string">&quot;i = &quot;</span> + i )</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>循环步长<br> scala的集合也可以设定循环的增长幅度，也就是所谓的步长step</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaLoop</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">for</span> ( i &lt;- <span class="type">Range</span>(<span class="number">1</span>,<span class="number">5</span>,<span class="number">2</span>) ) &#123;</span><br><span class="line">            println(<span class="string">&quot;i = &quot;</span> + i )</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> ( i &lt;- <span class="number">1</span> to <span class="number">5</span> by <span class="number">2</span> ) &#123;</span><br><span class="line">            println(<span class="string">&quot;i = &quot;</span> + i )</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>循环嵌套</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaLoop</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">for</span> ( i &lt;- <span class="type">Range</span>(<span class="number">1</span>,<span class="number">5</span>); j &lt;- <span class="type">Range</span>(<span class="number">1</span>,<span class="number">4</span>) ) &#123;</span><br><span class="line">            println(<span class="string">&quot;i = &quot;</span> + i + <span class="string">&quot;,j = &quot;</span> + j )</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> ( i &lt;- <span class="type">Range</span>(<span class="number">1</span>,<span class="number">5</span>) ) &#123;</span><br><span class="line">            <span class="keyword">for</span> ( j &lt;- <span class="type">Range</span>(<span class="number">1</span>,<span class="number">4</span>) ) &#123;</span><br><span class="line">                println(<span class="string">&quot;i = &quot;</span> + i + <span class="string">&quot;,j = &quot;</span> + j )</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>引入变量</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaLoop</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">for</span> ( i &lt;- <span class="type">Range</span>(<span class="number">1</span>,<span class="number">5</span>); j = i - <span class="number">1</span> ) &#123;</span><br><span class="line">            println(<span class="string">&quot;j = &quot;</span> + j )</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题: 那如何只使用一次for循环实现九层妖塔</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">        *</span><br><span class="line">       ***</span><br><span class="line">      *****</span><br><span class="line">     *******</span><br><span class="line">    *********</span><br><span class="line">   ***********</span><br><span class="line">  *************</span><br><span class="line"> ***************</span><br><span class="line">*****************</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> total = <span class="number">9</span></span><br><span class="line"><span class="keyword">for</span> (level &lt;- <span class="number">1</span> to total) &#123;</span><br><span class="line">    println((<span class="string">&quot; &quot;</span> * (total - level)) + (<span class="string">&quot;*&quot;</span> * (level * <span class="number">2</span> - <span class="number">1</span>)))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>循环返回值<br>scala所有的表达式都是有返回值的。但是这里的返回值并不一定都是有值的。<br>如果希望for循环表达式的返回值有具体的值，需要使用关键字yield</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaLoop</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> result = <span class="keyword">for</span> ( i &lt;- <span class="type">Range</span>(<span class="number">1</span>,<span class="number">5</span>) ) <span class="keyword">yield</span> &#123;</span><br><span class="line">            i * <span class="number">2</span></span><br><span class="line">        &#125;</span><br><span class="line">        println(result)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考:<br>Java中的线程有yield方法，Scala中该如何调用？<br>  线程的yield调用 <code>Thread.`yield`() </code></p>
</blockquote>
</li>
</ol>
<h3 id="4-2-2-while循环"><a href="#4-2-2-while循环" class="headerlink" title="4.2.2 while循环"></a>4.2.2 while循环</h3><ol>
<li>基本语法<br>当循环条件表达式返回值为true时，执行循环体代码<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">while( 循环条件表达式 ) &#123;</span><br><span class="line">    循环体</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
一种特殊的while循环就是，先执行循环体，再判断循环条件是否成立<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">do &#123;</span><br><span class="line">    循环体</span><br><span class="line">&#125; while ( 循环条件表达式 )</span><br></pre></td></tr></table></figure></li>
<li>while循环<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaLoop</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">var</span> i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> ( i &lt; <span class="number">5</span> ) &#123;</span><br><span class="line">            println(i)</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>do…while循环<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaLoop</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">var</span> i = <span class="number">5</span></span><br><span class="line">        do &#123;</span><br><span class="line">            println(i)</span><br><span class="line">        &#125; <span class="keyword">while</span> ( i &lt; <span class="number">5</span> )</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="4-2-3-循环中断"><a href="#4-2-3-循环中断" class="headerlink" title="4.2.3 循环中断"></a>4.2.3 循环中断</h3><p>scala是完全面向对象的语言，所以无法使用break，continue关键字这样的方式来中断，或继续循环逻辑，而是采用了函数式编程的方式代替了循环语法中的break和continue</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaLoop</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        scala.util.control.<span class="type">Breaks</span>.breakable &#123;</span><br><span class="line">            <span class="keyword">for</span> ( i &lt;- <span class="number">1</span> to <span class="number">5</span> ) &#123;</span><br><span class="line">                <span class="keyword">if</span> ( i == <span class="number">3</span> ) &#123;</span><br><span class="line">                    scala.util.control.<span class="type">Breaks</span>.<span class="keyword">break</span></span><br><span class="line">                &#125;</span><br><span class="line">                println(i)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Breaks.break原理是抛出异常</li>
<li>Breaks.breakable原理是try-catch</li>
<li>使用静态导入简化代码  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import scala.util.control.Breaks._</span><br><span class="line"></span><br><span class="line">breakable&#123;</span><br><span class="line">    for (i&lt;-1 to 5) &#123;</span><br><span class="line">        if (i==3)&#123;</span><br><span class="line">            break</span><br><span class="line">        &#125;</span><br><span class="line">        println(&quot;break &quot; + i)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="4-2-4-嵌套循环"><a href="#4-2-4-嵌套循环" class="headerlink" title="4.2.4 嵌套循环"></a>4.2.4 嵌套循环</h3><p>循环中有循环，就是嵌套循环。通过嵌套循环可以实现特殊的功能，比如说九九乘法表</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (x &lt;- <span class="number">1</span> to <span class="number">9</span>; y &lt;- <span class="number">1</span> to x) &#123;</span><br><span class="line">    print(y + <span class="string">&quot; * &quot;</span> + x + <span class="string">&quot; = &quot;</span> + (x * y) + <span class="string">&quot;\t&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> (x == y) &#123;</span><br><span class="line">        println()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="第5章-函数式编程"><a href="#第5章-函数式编程" class="headerlink" title="第5章 函数式编程"></a>第5章 函数式编程</h1><p>在Java中，采用面向对象编程，所以解决问题都是按照面向对象的方式来处理的。比如用户登陆等业务功能，但是Scala采用函数式编程，使用函数式编程的思路来解决问题。scala编程语言将函数式编程和面向对象编程完美地融合在一起了。</p>
<ul>
<li>面向对象编程<br>  分解对象，行为，属性，然后通过对象的关系以及行为的调用来解决问题</li>
<li>函数式编程<br>  将问题分解成一个一个的步骤，将每个步骤进行封装（函数），通过调用这些封装好的功能按照指定的步骤，解决问题。</li>
</ul>
<h2 id="5-1-基础函数编程"><a href="#5-1-基础函数编程" class="headerlink" title="5.1 基础函数编程"></a>5.1 基础函数编程</h2><h3 id="5-1-1-基本语法"><a href="#5-1-1-基本语法" class="headerlink" title="5.1.1 基本语法"></a>5.1.1 基本语法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[修饰符] def 函数名 (参数名称: 参数类型 ···) [:返回值类型] = &#123;</span><br><span class="line">    函数体</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>示例：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">test</span></span>( s : <span class="type">String</span> ) : <span class="type">Unit</span> = &#123;</span><br><span class="line">    println(s)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-1-2-函数-amp-方法"><a href="#5-1-2-函数-amp-方法" class="headerlink" title="5.1.2 函数&amp;方法"></a>5.1.2 函数&amp;方法</h3><ul>
<li>scala 中存在方法与函数两个不同的概念，二者在语义上的区别很小。scala 方法是类的一部分，而函数是一个对象，可以赋值给一个变量。换句话来说在类中定义的函数即是方法。scala 中的方法跟 Java 的类似，方法是组成类的一部分。scala 中的函数则是一个完整的对象。</li>
<li>Scala中的方法和函数从语法概念上来讲，一般不好区分，所以简单的理解就是：方法也是函数。只不过类中声明的函数称之为方法，其他场合声明的就是函数了。类中的方法是有重载和重写的。而函数可就没有重载和重写的概念了，但是函数可以嵌套声明使用，方法就没有这个能力了。</li>
</ul>
<h3 id="5-1-3-函数定义"><a href="#5-1-3-函数定义" class="headerlink" title="5.1.3 函数定义"></a>5.1.3 函数定义</h3><ol>
<li>无参，无返回值 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun1</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">            println(<span class="string">&quot;函数体&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        fun1()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>无参，有返回值 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun2</span></span>(): <span class="type">String</span> = &#123;</span><br><span class="line">            <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        println( fun2() )</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>有参，无返回值 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun3</span></span>( name:<span class="type">String</span> ): <span class="type">Unit</span> = &#123;</span><br><span class="line">            println( name )</span><br><span class="line">        &#125;</span><br><span class="line">        fun3(<span class="string">&quot;zhangsan&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>有参，有返回值 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun4</span></span>(name:<span class="type">String</span>): <span class="type">String</span> = &#123;</span><br><span class="line">            <span class="string">&quot;Hello &quot;</span> + name</span><br><span class="line">        &#125;</span><br><span class="line">        println( fun4(<span class="string">&quot;zhangsan&quot;</span>) )</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>多参，无返回值 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun5</span></span>(hello:<span class="type">String</span>, name:<span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">            println( hello + <span class="string">&quot; &quot;</span> + name )</span><br><span class="line">        &#125;</span><br><span class="line">        fun5(<span class="string">&quot;Hello&quot;</span>, <span class="string">&quot;zhangsan&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>多参，有返回值 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun6</span></span>(hello:<span class="type">String</span>, name:<span class="type">String</span>): <span class="type">String</span> = &#123;</span><br><span class="line">            hello + <span class="string">&quot; &quot;</span> + name</span><br><span class="line">        &#125;</span><br><span class="line">        println( fun6(<span class="string">&quot;Hello&quot;</span>, <span class="string">&quot;zhangsan&quot;</span>))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="5-1-4-函数参数"><a href="#5-1-4-函数参数" class="headerlink" title="5.1.4 函数参数"></a>5.1.4 函数参数</h3><ol>
<li>可变参数 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun7</span></span>(names:<span class="type">String</span>*): <span class="type">Unit</span> = &#123;</span><br><span class="line">            println(names)</span><br><span class="line">        &#125;</span><br><span class="line">        fun7()</span><br><span class="line">        fun7( <span class="string">&quot;zhangsan&quot;</span> )</span><br><span class="line">        fun7( <span class="string">&quot;zhangsan&quot;</span>, <span class="string">&quot;lisi&quot;</span> )</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
 可变参数不能放置在参数列表的前面，一般放置在参数列表的最后 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">oobject <span class="type">ScalaFunction</span> &#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// Error</span></span><br><span class="line">        <span class="comment">//def fun77(names:String*, name:String): Unit = &#123;</span></span><br><span class="line">            </span><br><span class="line">        <span class="comment">//&#125;</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun777</span></span>( name:<span class="type">String</span>, names:<span class="type">String</span>* ): <span class="type">Unit</span> = &#123;</span><br><span class="line">            println( name )</span><br><span class="line">            println( names )</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>参数默认值 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun8</span></span>( name:<span class="type">String</span>, password:<span class="type">String</span> = <span class="string">&quot;000000&quot;</span> ): <span class="type">Unit</span> = &#123;</span><br><span class="line">            println( name + <span class="string">&quot;,&quot;</span> + password )</span><br><span class="line">        &#125;</span><br><span class="line">        fun8(<span class="string">&quot;zhangsan&quot;</span>, <span class="string">&quot;123123&quot;</span>)</span><br><span class="line">        fun8(<span class="string">&quot;zhangsan&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>带名参数 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun9</span></span>( password:<span class="type">String</span> = <span class="string">&quot;000000&quot;</span>, name:<span class="type">String</span> ): <span class="type">Unit</span> = &#123;</span><br><span class="line">            println( name + <span class="string">&quot;,&quot;</span> + password )</span><br><span class="line">        &#125;</span><br><span class="line">        fun9(<span class="string">&quot;123123&quot;</span>, <span class="string">&quot;zhangsan&quot;</span> )</span><br><span class="line">        fun9(name=<span class="string">&quot;zhangsan&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="5-1-5-函数至简原则"><a href="#5-1-5-函数至简原则" class="headerlink" title="5.1.5 函数至简原则"></a>5.1.5 函数至简原则</h3><p>所谓的至简原则，其实就是Scala的作者为了开发人员能够大幅度提高开发效率。通过编译器的动态判定功能，帮助我们将函数声明中能简化的地方全部都进行了简化。也就是说将函数声明中那些能省的地方全部都省掉。所以这里的至简原则，简单来说就是：能省则省。</p>
<ol>
<li>省略return关键字 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun1</span></span>(): <span class="type">String</span> = &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun11</span></span>(): <span class="type">String</span> = &#123;</span><br><span class="line">            <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>省略花括号 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun2</span></span>(): <span class="type">String</span> = <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>省略返回值类型 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun3</span></span>() = <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>省略参数列表 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun4</span> </span>= <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">        fun4<span class="comment">// OK</span></span><br><span class="line">        fun4()<span class="comment">//(ERROR)</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>省略等号</li>
</ol>
<ul>
<li>如果函数体中有明确的return语句，那么返回值类型不能省略  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun5</span></span>(): <span class="type">String</span> = &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        println(fun5())</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>如果函数体返回值类型明确为Unit, 那么函数体中即使有return关键字也不起作用  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun5</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        println(fun5())</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>如果函数体返回值类型声明为Unit, 但是又想省略，那么此时就必须连同等号一起省略，同时，return不起作用  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun5</span></span>() &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        println(fun5())</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<ol start="6">
<li>省略名称和关键字<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        () =&gt; &#123;</span><br><span class="line">            println(<span class="string">&quot;zhangsan&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="5-2-高阶函数编程"><a href="#5-2-高阶函数编程" class="headerlink" title="5.2 高阶函数编程"></a>5.2 高阶函数编程</h2><p>所谓的高阶函数，其实就是将函数当成一个类型来使用，而不是当成特定的语法结构。</p>
<h3 id="5-2-1-函数作为值"><a href="#5-2-1-函数作为值" class="headerlink" title="5.2.1 函数作为值"></a>5.2.1 函数作为值</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun1</span></span>(): <span class="type">String</span> = &#123;</span><br><span class="line">            <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">val</span> a = fun1</span><br><span class="line">        <span class="keyword">val</span> b = fun1 _</span><br><span class="line">        <span class="keyword">val</span> c : ()=&gt;<span class="type">Unit</span> = fun1</span><br><span class="line">        println(a)</span><br><span class="line">        println(b)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>函数类型：默认情况下，函数类型为FunctionX,X表示参数的个数，最多22个</p>
<h3 id="5-2-2-函数作为参数"><a href="#5-2-2-函数作为参数" class="headerlink" title="5.2.2 函数作为参数"></a>5.2.2 函数作为参数</h3><p>函数作为参数使用的目的，是为了灵活改变实现逻辑，而不是固定写死</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun2</span></span>( i:<span class="type">Int</span> ): <span class="type">Int</span> = &#123;</span><br><span class="line">            i * <span class="number">2</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun22</span></span>( f : <span class="type">Int</span> =&gt; <span class="type">Int</span> ): <span class="type">Int</span> = &#123;</span><br><span class="line">            f(<span class="number">10</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        println(fun22(fun2))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-2-3-函数作为返回值"><a href="#5-2-3-函数作为返回值" class="headerlink" title="5.2.3 函数作为返回值"></a>5.2.3 函数作为返回值</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun3</span></span>( i:<span class="type">Int</span> ): <span class="type">Int</span> = &#123;</span><br><span class="line">            i * <span class="number">2</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun33</span></span>( ) = &#123;</span><br><span class="line">            fun3 _</span><br><span class="line">        &#125;</span><br><span class="line">        println(fun33()(<span class="number">10</span>))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-2-4-匿名函数"><a href="#5-2-4-匿名函数" class="headerlink" title="5.2.4 匿名函数"></a>5.2.4 匿名函数</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun4</span></span>( f:<span class="type">Int</span> =&gt; <span class="type">Int</span> ): <span class="type">Int</span> = &#123;</span><br><span class="line">            f(<span class="number">10</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        println(fun4((x:<span class="type">Int</span>)=&gt;&#123;x * <span class="number">20</span>&#125;))</span><br><span class="line">        println(fun4((x)=&gt;&#123;x * <span class="number">20</span>&#125;))</span><br><span class="line">        println(fun4((x)=&gt;x * <span class="number">20</span>))</span><br><span class="line">        println(fun4(x=&gt;x * <span class="number">20</span>))</span><br><span class="line">        println(fun4(_ * <span class="number">20</span>))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-2-7-控制抽象"><a href="#5-2-7-控制抽象" class="headerlink" title="5.2.7 控制抽象"></a>5.2.7 控制抽象</h3><ul>
<li>所谓控制抽象, 就意味着直接传递代码</li>
<li>一般传递代码都是多行传递，所以小括号会改为花括号</li>
<li><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun7</span></span>(op: =&gt; <span class="type">Unit</span>) = &#123;</span><br><span class="line">            op</span><br><span class="line">        &#125;</span><br><span class="line">        fun7&#123;</span><br><span class="line">            println(<span class="string">&quot;xx&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="5-2-5-闭包"><a href="#5-2-5-闭包" class="headerlink" title="5.2.5 闭包"></a>5.2.5 闭包</h3><ul>
<li>一个函数使用到函数之外的变量，但是考虑变量的生命周期问题，需要改变（延长）变量的生命周期，那么需要将变量包含到函数的内部，形成闭合的环境，这个环境成称为闭包环境，简称闭包（closu）</li>
<li>将函数作为对象使用的时候都会有闭包</li>
<li>匿名函数使用会有闭包<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun5</span></span>() = &#123;</span><br><span class="line">            <span class="keyword">val</span> i = <span class="number">20</span></span><br><span class="line">            <span class="function"><span class="keyword">def</span> <span class="title">fun55</span></span>() = &#123;</span><br><span class="line">                i * <span class="number">2</span></span><br><span class="line">            &#125;</span><br><span class="line">            fun55 _</span><br><span class="line">        &#125;</span><br><span class="line">        fun5()()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<blockquote>
<p>思考一个问题: 没有使用外部变量还能称之为闭包吗？ </p>
</blockquote>
<h3 id="5-2-6-函数柯里化"><a href="#5-2-6-函数柯里化" class="headerlink" title="5.2.6 函数柯里化"></a>5.2.6 函数柯里化</h3><ul>
<li>将无关参数分离开，降低参数和方法的耦合性<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun6</span></span>(i:<span class="type">Int</span>)(j:<span class="type">Int</span>) = &#123;</span><br><span class="line">            i * j</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="5-2-7-递归函数"><a href="#5-2-7-递归函数" class="headerlink" title="5.2.7 递归函数"></a>5.2.7 递归函数</h3><ul>
<li>自己调用自己就是递归</li>
<li>递归需要包含跳出条件</li>
<li>递归传递的参数应该有规律</li>
<li>尾递归<ul>
<li>最后实现方法的递归操作</li>
<li>不能影响输出和返回（不受到其他逻辑代码的限制）</li>
<li>Scala中的尾递归会被优化成while死循环，所以称为伪递归<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun8</span></span>(j:<span class="type">Int</span>):<span class="type">Int</span> = &#123;</span><br><span class="line">            <span class="keyword">if</span> ( j &lt;= <span class="number">1</span> ) &#123;</span><br><span class="line">                <span class="number">1</span></span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                j * fun8(j<span class="number">-1</span>)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        println(fun8(<span class="number">5</span>))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h3 id="5-2-9-惰性函数"><a href="#5-2-9-惰性函数" class="headerlink" title="5.2.9 惰性函数"></a>5.2.9 惰性函数</h3><p>当函数返回值被声明为lazy时，函数的执行将被推迟，直到我们首次对此取值，该函数才会执行。这种函数我们称之为惰性函数。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaFunction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">fun9</span></span>(): <span class="type">String</span> = &#123;</span><br><span class="line">            println(<span class="string">&quot;function...&quot;</span>)</span><br><span class="line">            <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">lazy</span> <span class="keyword">val</span> a = fun9()</span><br><span class="line">        println(<span class="string">&quot;----------&quot;</span>)</span><br><span class="line">        println(a)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="第6章-面向对象编程"><a href="#第6章-面向对象编程" class="headerlink" title="第6章 面向对象编程"></a>第6章 面向对象编程</h1><p>Scala是一门完全面向对象的语言，摒弃了Java中很多不是面向对象的语法。虽然如此，但其面向对象思想和Java的面向对象思想还是一致的</p>
<h2 id="6-1-基础面向对象编程"><a href="#6-1-基础面向对象编程" class="headerlink" title="6.1 基础面向对象编程"></a>6.1 基础面向对象编程</h2><h3 id="6-1-1-包"><a href="#6-1-1-包" class="headerlink" title="6.1.1 包"></a>6.1.1 包</h3><ol>
<li>基本语法<br>Scala中基本的package包语法和Java完全一致<br>package com.atguigu.bigdata.scala</li>
<li>扩展语法<br>Java中package包的语法比较单一，Scala对此进行扩展<ul>
<li>Scala中的包和类的物理路径没有关系</li>
<li>package关键字可以嵌套声明使用  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com</span><br><span class="line"><span class="keyword">package</span> atguigu &#123;</span><br><span class="line">    <span class="keyword">package</span> bigdata &#123;</span><br><span class="line">        <span class="keyword">package</span> scala &#123;</span><br><span class="line">            <span class="class"><span class="keyword">object</span> <span class="title">ScalaPackage</span> </span>&#123;</span><br><span class="line">                <span class="function"><span class="keyword">def</span> <span class="title">test</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">                    println(<span class="string">&quot;test...&quot;</span>)</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>同一个源码文件中子包可以直接访问父包中的内容，而无需import  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com</span><br><span class="line"><span class="keyword">package</span> atguigu &#123;</span><br><span class="line">    <span class="keyword">package</span> bigdata &#123;</span><br><span class="line">        <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">package</span> scala &#123;</span><br><span class="line">            <span class="class"><span class="keyword">object</span> <span class="title">ScalaPackage</span> </span>&#123;</span><br><span class="line">                <span class="function"><span class="keyword">def</span> <span class="title">test</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">                    <span class="keyword">new</span> <span class="type">Test</span>()</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>Scala中package也可以看作对象，并声明属性和函数  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com</span><br><span class="line"><span class="keyword">package</span> <span class="class"><span class="keyword">object</span> <span class="title">atguigu</span> </span>&#123;</span><br><span class="line">    <span class="keyword">val</span> name : <span class="type">String</span> = <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">        println( name )</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">package</span> atguigu &#123;</span><br><span class="line">    <span class="keyword">package</span> bigdata &#123;</span><br><span class="line">        <span class="keyword">package</span> scala &#123;</span><br><span class="line">            <span class="class"><span class="keyword">object</span> <span class="title">ScalaPackage</span> </span>&#123;</span><br><span class="line">                <span class="function"><span class="keyword">def</span> <span class="title">test</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h3 id="6-1-2-导入"><a href="#6-1-2-导入" class="headerlink" title="6.1.2 导入"></a>6.1.2 导入</h3><ol>
<li>基本语法<br>Scala中基本的import导入语法和Java完全一致<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.<span class="type">List</span></span><br><span class="line"><span class="keyword">import</span> java.util._ <span class="comment">// Scala中使用下划线代替Java中的星号</span></span><br></pre></td></tr></table></figure></li>
<li>扩展语法<br>Java中import导入的语法比较单一，Scala对此进行扩展<ul>
<li>Scala中的import语法可以在任意位置使用  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaImport</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">import</span> java.util.<span class="type">ArrayList</span></span><br><span class="line">        <span class="keyword">new</span>  <span class="type">ArrayList</span>()   </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>Scala中可以导包，而不是导类  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaImport</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">import</span> java.util</span><br><span class="line">        <span class="keyword">new</span> util.<span class="type">ArrayList</span>()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>Scala中可以在同一行中导入相同包中的多个类，简化代码  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.&#123;<span class="type">List</span>, <span class="type">ArrayList</span>&#125;</span><br></pre></td></tr></table></figure></li>
<li>Scala中可以屏蔽某个包中的类  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util._</span><br><span class="line"><span class="keyword">import</span> java.sql.&#123; <span class="type">Date</span>=&gt;_, <span class="type">Array</span>=&gt;_, _ &#125;</span><br></pre></td></tr></table></figure></li>
<li>Scala中可以给类起别名，简化使用  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.&#123;<span class="type">ArrayList</span>=&gt;<span class="type">AList</span>&#125;</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaImport</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">new</span> <span class="type">AList</span>()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>Scala中可以使用类的绝对路径而不是相对路径  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> _root_.java.util.<span class="type">ArrayList</span></span><br></pre></td></tr></table></figure></li>
<li>默认情况下，Scala中会导入如下包和对象  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.lang._</span><br><span class="line"><span class="keyword">import</span> scala._</span><br><span class="line"><span class="keyword">import</span> scala.<span class="type">Predef</span>._</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h3 id="6-1-3-类"><a href="#6-1-3-类" class="headerlink" title="6.1.3 类"></a>6.1.3 类</h3><p>面向对象编程中类可以看成一个模板，而对象可以看成是根据模板所创建的具体事物</p>
<ol>
<li>基本语法 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 声明类：访问权限 class 类名 &#123; 类主体内容 &#125; </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 类的主体内容</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 对象：new 类名(参数列表)</span></span><br><span class="line"><span class="keyword">new</span> <span class="type">User</span>()</span><br></pre></td></tr></table></figure></li>
<li>扩展语法<ul>
<li>Scala中一个源文件中可以声明多个公共类</li>
</ul>
</li>
</ol>
<h3 id="6-1-4-属性"><a href="#6-1-4-属性" class="headerlink" title="6.1.4 属性"></a>6.1.4 属性</h3><ul>
<li>属性和变量的声明和初始化必须放置在一起</li>
<li>Scala使用下划线<code>_</code>实现先声明后初始化的功能<ul>
<li>必须使用var声明才生效</li>
</ul>
</li>
</ul>
<ol>
<li>基本语法 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> name : <span class="type">String</span> = _ <span class="comment">// 类属性其实就是类变量</span></span><br><span class="line">    <span class="keyword">var</span> age : <span class="type">Int</span> = _ <span class="comment">// 下划线表示类的属性默认初始化</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>扩展语法<ul>
<li>Scala中的属性其实在编译后也会生成对应的set(赋值)，get(取值)方法</li>
<li>访问属性其实是访问对应属性的方法，而不是访问属性本身</li>
<li>使用@BeanProperty 生成和Java统一的getter setter方法</li>
<li>属性使用val声明，编译时生成的属性是final修饰<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> name : <span class="type">String</span> = _</span><br><span class="line">    <span class="keyword">val</span> age : <span class="type">Int</span> = <span class="number">30</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">val</span> email : <span class="type">String</span> = _</span><br><span class="line">    <span class="meta">@BeanProperty</span> <span class="keyword">var</span> address : <span class="type">String</span> = _</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h3 id="6-1-5-访问权限"><a href="#6-1-5-访问权限" class="headerlink" title="6.1.5 访问权限"></a>6.1.5 访问权限</h3><p>Scala中的访问权限和Java中的访问权限类似，但是又有区别：</p>
<ul>
<li>private : 私有访问权限</li>
<li>private[包名]: 包访问权限</li>
<li>protected : 受保护权限，不能同包</li>
<li>（default,不指定访问权限） : 公共访问权限</li>
</ul>
<h3 id="6-1-6-方法"><a href="#6-1-6-方法" class="headerlink" title="6.1.6 方法"></a>6.1.6 方法</h3><ul>
<li>Scala中的类的方法其实就是函数，所以声明方式完全一样，但是必须通过使用对象进行调用</li>
<li>方法能否使用取决于声明类型而不是对象</li>
<li>方法具体如何执行，由对象确定<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaMethod</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> user = <span class="keyword">new</span> <span class="type">User</span></span><br><span class="line">        user.login(<span class="string">&quot;zhangsan&quot;</span>, <span class="string">&quot;000000&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">login</span></span>( name:<span class="type">String</span>, password:<span class="type">String</span> ): <span class="type">Boolean</span> = &#123;</span><br><span class="line">        <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考两个问题: 还记得方法的重写和重载吗？ 你真的明白吗？</p>
<ol>
<li>双亲委派机制：JDK中的类和自定义类冲突，使用哪一个</li>
<li>动态绑定机制：JVM调用对象的成员方法，会将方法和实际内存对象进行绑定，然后调用<br>属性不存在动态绑定，在哪声明，在哪使用</li>
</ol>
</blockquote>
</li>
</ul>
<h3 id="6-1-7-对象"><a href="#6-1-7-对象" class="headerlink" title="6.1.7 对象"></a>6.1.7 对象</h3><p>Scala中的对象和Java是类似的</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> | <span class="keyword">var</span> 对象名 [：类型]  = <span class="keyword">new</span> 类型()</span><br><span class="line"><span class="keyword">var</span> user : <span class="type">User</span> = <span class="keyword">new</span> <span class="type">User</span>()</span><br></pre></td></tr></table></figure>

<h3 id="6-1-8-构造方法"><a href="#6-1-8-构造方法" class="headerlink" title="6.1.8 构造方法"></a>6.1.8 构造方法</h3><ul>
<li>和Java一样，Scala中构造对象也需要调用类的构造方法来创建。并且一个类中可以有任意多个不相同的构造方法。这些构造方法可以分为2大类：主构造函数和辅助构造函数。<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params"></span>) </span>&#123; <span class="comment">// 主构造函数</span></span><br><span class="line">    <span class="keyword">var</span> username : <span class="type">String</span> = _ </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>( name:<span class="type">String</span> ) &#123; <span class="comment">// 辅助构造函数，使用this关键字声明</span></span><br><span class="line">        <span class="keyword">this</span>() <span class="comment">// 辅助构造函数应该直接或间接调用主构造函数</span></span><br><span class="line">        username = name</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>( name:<span class="type">String</span>, password:<span class="type">String</span> ) &#123;</span><br><span class="line">        <span class="keyword">this</span>(name) <span class="comment">// 构造器调用其他另外的构造器，要求被调用构造器必须提前声明</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="6-2-高阶面向对象编程"><a href="#6-2-高阶面向对象编程" class="headerlink" title="6.2 高阶面向对象编程"></a>6.2 高阶面向对象编程</h2><h3 id="6-2-1-继承"><a href="#6-2-1-继承" class="headerlink" title="6.2.1 继承"></a>6.2.1 继承</h3><ol>
<li>和Java一样，Scala中的继承也是单继承，且使用extends关键字。 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">extends</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>构造对象时需要考虑构造方法的执行顺序</p>
</blockquote>
</li>
<li>使用overwrite关键字重写方法 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">say</span></span>(): <span class="type">Unit</span> =&#123;</span><br><span class="line">    println(<span class="string">&quot;Person.say。。。。。。&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>构建子类对象时，父类对象会先构建出来，所有父类构造方法先执行，并先初始化</li>
<li>如果继承父类后，父类的构造方法有参数，那么需要在继承的时候，传递参数；一般不会写死，一般是从子类传递过来 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> <span class="title">private</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    println(<span class="string">&quot;Person init......&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(name: <span class="type">String</span>) &#123;</span><br><span class="line">        <span class="keyword">this</span>()</span><br><span class="line">        println(<span class="string">&quot;Person this&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">say</span></span>(): <span class="type">Unit</span> =&#123;</span><br><span class="line">        println(<span class="string">&quot;Person.say。。。。。。&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">var name: <span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">Person</span>(<span class="params">name</span>) </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>() &#123;</span><br><span class="line">        <span class="keyword">this</span>(<span class="string">&quot;母鸡&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">say</span></span>(): <span class="type">Unit</span> =&#123;</span><br><span class="line">        println(<span class="string">&quot;Person.say。。。。。。&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;User init......&quot;</span>)</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="6-2-2-封装"><a href="#6-2-2-封装" class="headerlink" title="6.2.2 封装"></a>6.2.2 封装</h3><p>封装就是把抽象出的数据和对数据的操作封装在一起，数据被保护在内部，程序的其它部分只有通过被授权的操作（成员方法），才能对数据进行访问。</p>
<ul>
<li>将属性进行私有化</li>
<li>提供一个公共的set方法，用于对属性赋值</li>
<li>提供一个公共的get方法，用于获取属性的值</li>
</ul>
<h3 id="6-2-3-抽象"><a href="#6-2-3-抽象" class="headerlink" title="6.2.3 抽象"></a>6.2.3 抽象</h3><ul>
<li>Scala将一个不完整的类称之为抽象类。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>Scala中如果一个方法<font color ='red' >只有声明而没有实现</font>，那么是抽象方法，因为它不完整。<ul>
<li>Scala中抽象方法不需要使用关键字abstract<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaAbstractClass</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> user:<span class="type">Person</span> = <span class="keyword">new</span> <span class="type">User</span>()</span><br><span class="line">        user.eat()</span><br><span class="line">        <span class="keyword">val</span> person = <span class="keyword">new</span> <span class="type">Person</span> &#123;</span><br><span class="line">            <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">eat</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">                println(<span class="string">&quot;anonymous Person.eat&quot;</span>)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        person.eat()</span><br><span class="line">        user.drink()</span><br><span class="line">        person.drink()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">        <span class="comment">//抽象方法</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">eat</span></span>(): <span class="type">Unit</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">drink</span></span>(): <span class="type">Unit</span> =&#123;</span><br><span class="line">            println(<span class="string">&quot;Person.drink&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">extends</span> <span class="title">Person</span></span>&#123;</span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">eat</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">            println(<span class="string">&quot;User.eat&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">drink</span></span>(): <span class="type">Unit</span> =&#123;</span><br><span class="line">            println(<span class="string">&quot;User.drink&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>Scala中如果一个属性只有声明没有初始化，那么是抽象属性，因为它不完整。<ul>
<li>抽象属性编译后并不会生成java类的属性，而是生成属性对应的set,get方法，且是抽象的</li>
<li>子类通过override补全父类抽象属性</li>
<li>可变变量不能被冲重写，不可变变量可以被重写，Scala中访问一个对象的属性，并不是访问这个属性本身，而是访问这个属性的get方法，而get方法是成员方法，所以会遵循动态绑定机制<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaAbstractField</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> user = <span class="keyword">new</span> <span class="type">User</span>()</span><br><span class="line">        user.sex = <span class="string">&quot;男&quot;</span></span><br><span class="line">        println(user.sex)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> sex: <span class="type">String</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">extends</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">        <span class="keyword">override</span> <span class="keyword">var</span> sex: <span class="type">String</span> = _</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>子类如果继承抽象类，必须实现抽象方法或补全抽象属性，否则也必须声明为抽象的，因为依然不完整。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> name:<span class="type">String</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">extends</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> name : <span class="type">String</span> = <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="6-2-4-单例对象"><a href="#6-2-4-单例对象" class="headerlink" title="6.2.4 单例对象"></a>6.2.4 单例对象</h3><ul>
<li>所谓的单例对象，就是在程序运行过程中，指定类的对象只能创建一个，而不能创建多个。这样的对象可以由特殊的设计方式获得，也可以由语言本身设计得到，比如object伴生对象</li>
<li>Scala语言是完全面向对象的语言，所以并没有静态的操作（即在Scala中没有静态的概念）。但是为了能够和Java语言交互（因为Java中有静态概念），就产生了一种特殊的对象来模拟类对象，该对象为单例对象。若单例对象名与类名一致，则称该单例对象这个类的伴生对象，这个类的所有“静态”内容都可以放置在它的伴生对象中声明，然后通过伴生对象名称直接调用</li>
<li>如果类名和伴生对象名称保持一致，那么这个类称之为伴生类。Scala编译器可以通过伴生对象的apply方法创建伴生类对象。apply方法可以重载，并传递参数，且可由Scala编译器自动识别。所以在使用时，其实是可以省略的。  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123; <span class="comment">// 伴生类</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">User</span> </span>&#123; <span class="comment">// 伴生对象</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>() = <span class="keyword">new</span> <span class="type">User</span>() <span class="comment">// 构造伴生类对象</span></span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line"><span class="keyword">val</span> user1 = <span class="keyword">new</span> <span class="type">User</span>()<span class="comment">// 通过构造方法创建对象</span></span><br><span class="line"><span class="type">Val</span> user2 = <span class="type">User</span>.apply() <span class="comment">// 通过伴生对象的apply方法构造伴生类对象 </span></span><br><span class="line"><span class="keyword">val</span> user3 = <span class="type">User</span>() <span class="comment">// scala编译器省略apply方法，自动完成调用</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题: Thread线程中wait方法和sleep方法的区别？</p>
<ol>
<li>sleep是Thread类的静态方法</li>
</ol>
<ul>
<li>静态方法和对象无关，所以跟锁无关</li>
</ul>
<ol start="2">
<li>wait是Object类的成员方法</li>
</ol>
</blockquote>
</li>
</ul>
<h3 id="6-2-5-特质"><a href="#6-2-5-特质" class="headerlink" title="6.2.5 特质"></a>6.2.5 特质</h3><p>Scala将多个类的相同特征从类中剥离出来，形成一个独立的语法结构，称之为“特质”（特征）。这种方式在Java中称之为接口，但是Scala中没有接口的概念。所以scala中没有interface关键字，而是采用特殊的关键字trait来声明特质, 如果一个类符合某一个特征（特质），那么就可以将这个特征（特质）“混入”到类中。这种混入的操作可以在声明类时使用，也可以在创建类对象时动态使用。</p>
<ol>
<li>基本语法 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">特质名称</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">类名</span> <span class="keyword">extends</span> <span class="title">父类（特质1）</span> <span class="keyword">with</span> <span class="title">特质2</span> <span class="keyword">with</span><span class="title">特质3</span></span></span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Operator</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">DB</span></span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySQL</span> <span class="keyword">extends</span> <span class="title">Operator</span> <span class="keyword">with</span> <span class="title">DB</span></span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题: 特质到底是什么？为什么又可以使用extends，又可以使用with？</p>
<ol>
<li>如果一个类没有父类，但是符合特征，trait相当于抽象类</li>
<li>如果一个类有父类，且符合特征，trait相当于接口</li>
</ol>
</blockquote>
</li>
<li>动态混入：<code>with trait</code> <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaTrait</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> mysql = <span class="keyword">new</span> <span class="type">MySQL</span> <span class="keyword">with</span> <span class="type">Operator</span></span><br><span class="line">        mysql.insert()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Operator</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">        println(<span class="string">&quot;insert data...&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySQL</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>初始化叠加 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaTrait</span></span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> mysql = <span class="keyword">new</span> <span class="type">MySQL</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Operator</span> </span>&#123;</span><br><span class="line">    println(<span class="string">&quot;operator...&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">DB</span> </span>&#123;</span><br><span class="line">    println(<span class="string">&quot;db...&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySQL</span> <span class="keyword">extends</span> <span class="title">DB</span> <span class="keyword">with</span> <span class="title">Operator</span></span>&#123;</span><br><span class="line">    println(<span class="string">&quot;mysql...&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>功能叠加 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaTrait</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> mysql: <span class="type">MySQL</span> = <span class="keyword">new</span> <span class="type">MySQL</span></span><br><span class="line">        mysql.operData()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Operate</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">operData</span></span>():<span class="type">Unit</span>=&#123;</span><br><span class="line">        println(<span class="string">&quot;操作数据。。&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">DB</span> <span class="keyword">extends</span> <span class="title">Operate</span></span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">operData</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">        print(<span class="string">&quot;向数据库中。。&quot;</span>)</span><br><span class="line">        <span class="keyword">super</span>.operData()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Log</span> <span class="keyword">extends</span> <span class="title">Operate</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">operData</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">super</span>.operData()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySQL</span> <span class="keyword">extends</span> <span class="title">DB</span> <span class="keyword">with</span> <span class="title">Log</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题: scala中的super是什么？<br>上一个层级</p>
</blockquote>
</li>
</ol>
<h3 id="6-2-6-扩展"><a href="#6-2-6-扩展" class="headerlink" title="6.2.6 扩展"></a>6.2.6 扩展</h3><ul>
<li><p>类型检查和转换</p>
  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span></span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> person = <span class="keyword">new</span> <span class="type">Person</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//（1）判断对象是否为某个类型的实例</span></span><br><span class="line">        <span class="keyword">val</span> bool: <span class="type">Boolean</span> = person.isInstanceOf[<span class="type">Person</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ( bool ) &#123;</span><br><span class="line">            <span class="comment">//（2）将对象转换为某个类型的实例</span></span><br><span class="line">            <span class="keyword">val</span> p1: <span class="type">Person</span> = person.asInstanceOf[<span class="type">Person</span>]</span><br><span class="line">            println(p1)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//（3）获取类的信息</span></span><br><span class="line">        <span class="keyword">val</span> pClass: <span class="type">Class</span>[<span class="type">Person</span>] = classOf[<span class="type">Person</span>]</span><br><span class="line">        println(pClass)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考一个问题: 字符串真的不可变吗？</p>
<ol>
<li>字节数组引用不可变</li>
<li>字节数组内容可变</li>
</ol>
</blockquote>
</li>
<li><p>枚举类和应用类</p>
  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        println(<span class="type">Color</span>.<span class="type">RED</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 枚举类</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Color</span> <span class="keyword">extends</span> <span class="title">Enumeration</span> </span>&#123;</span><br><span class="line">    <span class="keyword">val</span> <span class="type">RED</span> = <span class="type">Value</span>(<span class="number">1</span>, <span class="string">&quot;red&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> <span class="type">YELLOW</span> = <span class="type">Value</span>(<span class="number">2</span>, <span class="string">&quot;yellow&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> <span class="type">BLUE</span> = <span class="type">Value</span>(<span class="number">3</span>, <span class="string">&quot;blue&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 应用类</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">AppTest</span> <span class="keyword">extends</span> <span class="title">App</span> </span>&#123;</span><br><span class="line">    println(<span class="string">&quot;application&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>Type定义新类型<br>使用type关键字可以定义新的数据数据类型名称，本质上就是类型的一个别名</p>
  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="class"><span class="keyword">type</span> <span class="title">S</span> </span>= <span class="type">String</span></span><br><span class="line">        <span class="keyword">var</span> v : <span class="type">S</span> = <span class="string">&quot;abc&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="第7章-集合"><a href="#第7章-集合" class="headerlink" title="第7章 集合"></a>第7章 集合</h1><h3 id="7-1-简介"><a href="#7-1-简介" class="headerlink" title="7.1 简介"></a>7.1 简介</h3><ul>
<li>Scala的集合有三大类：序列Seq、集Set、映射Map，所有的集合都扩展自Iterable特质。对于几乎所有的集合类，Scala都同时提供了可变和不可变的版本。</li>
<li>可变集合可以在适当的地方被更新或扩展。这意味着你可以修改，添加，移除一个集合的元素。而不可变集合类，相比之下，永远不会改变。不过，你仍然可以模拟添加，移除或更新操作。但是这些操作将在每一种情况下都返回一个新的集合，同时使原来的集合不发生改变，所以这里的不可变并不是变量本身的值不可变，而是变量指向的那个内存地址不可变</li>
<li>可变集合和不可变集合，在scala中该如何进行区分呢？我们一般可以根据集合所在包名进行区分:</li>
<li>scala.collection.immutable</li>
<li>scala.collection.mutable</li>
</ul>
<h2 id="7-2-数组"><a href="#7-2-数组" class="headerlink" title="7.2 数组"></a>7.2 数组</h2><h3 id="7-2-1-不可变数组"><a href="#7-2-1-不可变数组" class="headerlink" title="7.2.1 不可变数组"></a>7.2.1 不可变数组</h3><ol>
<li>基本语法 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">//（1）数组定义</span></span><br><span class="line">        <span class="keyword">val</span> arr01 = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Int</span>](<span class="number">4</span>)</span><br><span class="line">        println(arr01.length) <span class="comment">// 4</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//（2）数组赋值</span></span><br><span class="line">        <span class="comment">//（2.1）修改某个元素的值</span></span><br><span class="line">        arr01(<span class="number">3</span>) = <span class="number">10</span></span><br><span class="line">        <span class="keyword">val</span> i = <span class="number">10</span></span><br><span class="line">        arr01(i/<span class="number">3</span>) = <span class="number">20</span></span><br><span class="line">        <span class="comment">//（2.2）采用方法的形式修改数组的值</span></span><br><span class="line">        arr01.update(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//（3）遍历数组</span></span><br><span class="line">        <span class="comment">//（3.1）查看数组</span></span><br><span class="line">        println(arr01.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">//（3.2）普通遍历</span></span><br><span class="line">        <span class="keyword">for</span> (i &lt;- arr01) &#123;</span><br><span class="line">            println(i)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//（3.3）简化遍历</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">printx</span></span>(elem:<span class="type">Int</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">            println(elem)</span><br><span class="line">        &#125;</span><br><span class="line">        arr01.foreach(printx)</span><br><span class="line">        arr01.foreach((x)=&gt;&#123;println(x)&#125;)</span><br><span class="line">        arr01.foreach(println(_))</span><br><span class="line">        arr01.foreach(println)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>基本操作 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 创建数组的另外一种方式</span></span><br><span class="line">        <span class="keyword">val</span> arr1 = <span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">        <span class="keyword">val</span> arr2 = <span class="type">Array</span>(<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>)</span><br><span class="line">        <span class="comment">// 添加数组元素，创建新数组</span></span><br><span class="line">        <span class="keyword">val</span> arr3: <span class="type">Array</span>[<span class="type">Int</span>] = arr1 :+ <span class="number">5</span></span><br><span class="line">        println( arr1 eq arr3 ) <span class="comment">// false</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> arr4: <span class="type">Array</span>[<span class="type">Int</span>] = arr1 ++: arr2</span><br><span class="line">        <span class="comment">// 添加集合</span></span><br><span class="line">        <span class="keyword">val</span> arr5: <span class="type">Array</span>[<span class="type">Int</span>] = arr1 ++ arr2</span><br><span class="line"></span><br><span class="line">        arr4.foreach(println)</span><br><span class="line">        println(<span class="string">&quot;****************&quot;</span>)</span><br><span class="line">        arr5.foreach(println)</span><br><span class="line">        println(<span class="string">&quot;****************&quot;</span>)</span><br><span class="line">        <span class="comment">// 多维数组</span></span><br><span class="line">        <span class="keyword">var</span> myMatrix = <span class="type">Array</span>.ofDim[<span class="type">Int</span>](<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">        myMatrix.foreach(list=&gt;list.foreach(println))</span><br><span class="line">        <span class="comment">// 合并数组</span></span><br><span class="line">        <span class="keyword">val</span> arr6: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>.concat(arr1, arr2)</span><br><span class="line">        arr6.foreach(println)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建指定范围的数组</span></span><br><span class="line">        <span class="keyword">val</span> arr7: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>.range(<span class="number">0</span>,<span class="number">2</span>)</span><br><span class="line">        arr7.foreach(println)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建并填充指定数量的数组</span></span><br><span class="line">        <span class="keyword">val</span> arr8:<span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>.fill[<span class="type">Int</span>](<span class="number">5</span>)(<span class="number">-1</span>)</span><br><span class="line">        arr8.foreach(println)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="7-2-2-可变数组"><a href="#7-2-2-可变数组" class="headerlink" title="7.2.2 可变数组"></a>7.2.2 可变数组</h3><ol>
<li>基本语法 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ArrayBuffer</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> buffer = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]</span><br><span class="line">        <span class="comment">// 增加数据</span></span><br><span class="line">        buffer.append(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">        <span class="comment">// 修改数据</span></span><br><span class="line">        buffer.update(<span class="number">0</span>,<span class="number">5</span>)</span><br><span class="line">        buffer(<span class="number">1</span>) = <span class="number">6</span></span><br><span class="line">        <span class="comment">// 删除数据</span></span><br><span class="line">        <span class="keyword">val</span> i: <span class="type">Int</span> = buffer.remove(<span class="number">2</span>)</span><br><span class="line">        buffer.remove(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">        <span class="comment">// 查询数据</span></span><br><span class="line">        println(buffer(<span class="number">3</span>))</span><br><span class="line">        <span class="comment">// 循环集合</span></span><br><span class="line">        <span class="keyword">for</span> ( i &lt;- buffer ) &#123;</span><br><span class="line">            println(i)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>基本操作 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ArrayBuffer</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> buffer1 = <span class="type">ArrayBuffer</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">        <span class="keyword">val</span> buffer2 = <span class="type">ArrayBuffer</span>(<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> buffer3: <span class="type">ArrayBuffer</span>[<span class="type">Int</span>] = buffer1 += <span class="number">5</span></span><br><span class="line">        println( buffer1 eq buffer3 ) <span class="comment">// true</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 使用 ++ 运算符会产生新的集合数组</span></span><br><span class="line">        <span class="keyword">val</span> buffer4: <span class="type">ArrayBuffer</span>[<span class="type">Int</span>] = buffer1 ++ buffer2</span><br><span class="line">        <span class="comment">// 使用 ++= 运算符会更新之前的集合，不会产生新的数组</span></span><br><span class="line">        <span class="keyword">val</span> buffer5: <span class="type">ArrayBuffer</span>[<span class="type">Int</span>] = buffer1 ++= buffer2</span><br><span class="line">        println( buffer1 eq buffer4 ) <span class="comment">// false</span></span><br><span class="line">        println( buffer1 eq buffer5 ) <span class="comment">// true</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="7-2-3-可变数组和不可变数组转换"><a href="#7-2-3-可变数组和不可变数组转换" class="headerlink" title="7.2.3 可变数组和不可变数组转换"></a>7.2.3 可变数组和不可变数组转换</h3><pre><code><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ArrayBuffer</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> buffer = <span class="type">ArrayBuffer</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">        <span class="keyword">val</span> array = <span class="type">Array</span>(<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将不可变数组转换为可变数组</span></span><br><span class="line">        <span class="keyword">val</span> buffer1: mutable.<span class="type">Buffer</span>[<span class="type">Int</span>] = array.toBuffer</span><br><span class="line">        <span class="comment">// 将可变数组转换为不可变数组</span></span><br><span class="line">        <span class="keyword">val</span> array1: <span class="type">Array</span>[<span class="type">Int</span>] = buffer.toArray</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</code></pre>
<h2 id="7-3-Seq集合"><a href="#7-3-Seq集合" class="headerlink" title="7.3 Seq集合"></a>7.3 Seq集合</h2><h3 id="7-3-1-不可变List"><a href="#7-3-1-不可变List" class="headerlink" title="7.3.1 不可变List"></a>7.3.1 不可变List</h3><ol>
<li>基本语法 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Seq集合</span></span><br><span class="line">        <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 增加数据</span></span><br><span class="line">        <span class="keyword">val</span> list1: <span class="type">List</span>[<span class="type">Int</span>] = list :+ <span class="number">1</span></span><br><span class="line">        println(list1 eq list)</span><br><span class="line">        list1.foreach(println)</span><br><span class="line">        <span class="keyword">val</span> list2: <span class="type">List</span>[<span class="type">Int</span>] = <span class="number">1</span> +: list</span><br><span class="line">        list2.foreach(println)</span><br><span class="line">        println(<span class="string">&quot;*****************&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> list3: <span class="type">List</span>[<span class="type">Int</span>] = list.updated(<span class="number">1</span>,<span class="number">5</span>)</span><br><span class="line">        println(list eq list3)</span><br><span class="line">        <span class="type">List3</span>.foreach(println)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>基本操作 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Seq集合</span></span><br><span class="line">        <span class="keyword">val</span> list1 = <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">        <span class="comment">// 空集合</span></span><br><span class="line">        <span class="keyword">val</span> list2: <span class="type">List</span>[<span class="type">Nothing</span>] = <span class="type">List</span>()</span><br><span class="line">        <span class="keyword">val</span> nil  = <span class="type">Nil</span></span><br><span class="line">        println(list2 eq nil)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建集合</span></span><br><span class="line">        <span class="keyword">val</span> list3: <span class="type">List</span>[<span class="type">Int</span>]  = <span class="number">1</span>::<span class="number">2</span>::<span class="number">3</span>::<span class="type">Nil</span></span><br><span class="line">        <span class="keyword">val</span> list4: <span class="type">List</span>[<span class="type">Int</span>] = list1 ::: <span class="type">Nil</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 连接集合</span></span><br><span class="line">        <span class="keyword">val</span> list5: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>.concat(list3, list4)</span><br><span class="line">        list5.foreach(println)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建一个指定重复数量的元素列表</span></span><br><span class="line">        <span class="keyword">val</span> list6: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">List</span>.fill[<span class="type">String</span>](<span class="number">3</span>)(<span class="string">&quot;a&quot;</span>)</span><br><span class="line">        list6.foreach(println)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="7-3-2-可变List"><a href="#7-3-2-可变List" class="headerlink" title="7.3.2 可变List"></a>7.3.2 可变List</h3><ol>
<li>基本语法 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ListBuffer</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 可变集合</span></span><br><span class="line">        <span class="keyword">val</span> buffer = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">Int</span>]()</span><br><span class="line">        <span class="comment">// 增加数据</span></span><br><span class="line">        buffer.append(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">        <span class="comment">// 修改数据</span></span><br><span class="line">        buffer.update(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">        <span class="comment">// 删除数据</span></span><br><span class="line">        buffer.remove(<span class="number">2</span>)</span><br><span class="line">        buffer.remove(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">        <span class="comment">// 获取数据</span></span><br><span class="line">        println(buffer(<span class="number">1</span>))</span><br><span class="line">        <span class="comment">// 遍历集合</span></span><br><span class="line">        buffer.foreach(println)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>基本操作 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ListBuffer</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 可变集合</span></span><br><span class="line">        <span class="keyword">val</span> buffer1 = <span class="type">ListBuffer</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">        <span class="keyword">val</span> buffer2 = <span class="type">ListBuffer</span>(<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 增加数据</span></span><br><span class="line">        <span class="keyword">val</span> buffer3: <span class="type">ListBuffer</span>[<span class="type">Int</span>] = buffer1 :+ <span class="number">5</span></span><br><span class="line">        <span class="keyword">val</span> buffer4: <span class="type">ListBuffer</span>[<span class="type">Int</span>] = buffer1 += <span class="number">5</span></span><br><span class="line">        <span class="keyword">val</span> buffer5: <span class="type">ListBuffer</span>[<span class="type">Int</span>] = buffer1 ++ buffer2</span><br><span class="line">        <span class="keyword">val</span> buffer6: <span class="type">ListBuffer</span>[<span class="type">Int</span>] = buffer1 ++= buffer2</span><br><span class="line"></span><br><span class="line">        println( buffer5 eq buffer1 )</span><br><span class="line">        println( buffer6 eq buffer1 )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> buffer7: <span class="type">ListBuffer</span>[<span class="type">Int</span>] = buffer1 - <span class="number">2</span></span><br><span class="line">        <span class="keyword">val</span> buffer8: <span class="type">ListBuffer</span>[<span class="type">Int</span>] = buffer1 -= <span class="number">2</span></span><br><span class="line">        println( buffer7 eq buffer1 )</span><br><span class="line">        println( buffer8 eq buffer1 )</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="7-3-3-可变集合和不可变集合转换"><a href="#7-3-3-可变集合和不可变集合转换" class="headerlink" title="7.3.3 可变集合和不可变集合转换"></a>7.3.3 可变集合和不可变集合转换</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ListBuffer</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> buffer = <span class="type">ListBuffer</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">        <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 可变集合转变为不可变集合</span></span><br><span class="line">        <span class="keyword">val</span> list1: <span class="type">List</span>[<span class="type">Int</span>] = buffer.toList</span><br><span class="line">        <span class="comment">// 不可变集合转变为可变集合</span></span><br><span class="line">        <span class="keyword">val</span> buffer1: mutable.<span class="type">Buffer</span>[<span class="type">Int</span>] = list.toBuffer</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="7-4-Set集合"><a href="#7-4-Set集合" class="headerlink" title="7.4 Set集合"></a>7.4 Set集合</h2><h3 id="7-4-1-不可变Set"><a href="#7-4-1-不可变Set" class="headerlink" title="7.4.1 不可变Set"></a>7.4.1 不可变Set</h3><ol>
<li>基本语法 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> set1 = <span class="type">Set</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">        <span class="keyword">val</span> set2 = <span class="type">Set</span>(<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 增加数据</span></span><br><span class="line">        <span class="keyword">val</span> set3: <span class="type">Set</span>[<span class="type">Int</span>] = set1 + <span class="number">5</span> + <span class="number">6</span></span><br><span class="line">        <span class="keyword">val</span> set4: <span class="type">Set</span>[<span class="type">Int</span>] = set1.+(<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>)</span><br><span class="line">        println( set1 eq set3 ) <span class="comment">// false</span></span><br><span class="line">        println( set1 eq set4 ) <span class="comment">// false</span></span><br><span class="line">        set4.foreach(println)</span><br><span class="line">        <span class="comment">// 删除数据</span></span><br><span class="line">        <span class="keyword">val</span> set5: <span class="type">Set</span>[<span class="type">Int</span>] = set1 - <span class="number">2</span> - <span class="number">3</span></span><br><span class="line">        set5.foreach(println)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> set6: <span class="type">Set</span>[<span class="type">Int</span>] = set1 ++ set2</span><br><span class="line">        set6.foreach(println)</span><br><span class="line">        println(<span class="string">&quot;********&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> set7: <span class="type">Set</span>[<span class="type">Int</span>] = set2 ++: set1</span><br><span class="line">        set7.foreach(println)</span><br><span class="line">        println(set6 eq set7)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>基本操作 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> set1 = <span class="type">Set</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">        <span class="keyword">val</span> set2 = <span class="type">Set</span>(<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 增加数据</span></span><br><span class="line">        <span class="keyword">val</span> set3: <span class="type">Set</span>[<span class="type">Int</span>] = set1 + <span class="number">5</span> + <span class="number">6</span></span><br><span class="line">        <span class="keyword">val</span> set4: <span class="type">Set</span>[<span class="type">Int</span>] = set1.+(<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>)</span><br><span class="line">        println( set1 eq set3 ) <span class="comment">// false</span></span><br><span class="line">        println( set1 eq set4 ) <span class="comment">// false</span></span><br><span class="line">        set4.foreach(println)</span><br><span class="line">        <span class="comment">// 删除数据</span></span><br><span class="line">        <span class="keyword">val</span> set5: <span class="type">Set</span>[<span class="type">Int</span>] = set1 - <span class="number">2</span> - <span class="number">3</span></span><br><span class="line">        set5.foreach(println)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> set6: <span class="type">Set</span>[<span class="type">Int</span>] = set1 ++ set2</span><br><span class="line">        set6.foreach(println)</span><br><span class="line">        println(<span class="string">&quot;********&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> set7: <span class="type">Set</span>[<span class="type">Int</span>] = set2 ++: set1</span><br><span class="line">        set7.foreach(println)</span><br><span class="line">        println(set6 eq set7)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="7-4-2-可变Set"><a href="#7-4-2-可变Set" class="headerlink" title="7.4.2 可变Set"></a>7.4.2 可变Set</h3><ol>
<li>基本语法 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> set1 = mutable.<span class="type">Set</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">        <span class="keyword">val</span> set2 = mutable.<span class="type">Set</span>(<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 增加数据</span></span><br><span class="line">        set1.add(<span class="number">5</span>)</span><br><span class="line">        <span class="comment">// 添加数据</span></span><br><span class="line">        set1.update(<span class="number">6</span>,<span class="literal">true</span>)</span><br><span class="line">        println(set1.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">        <span class="comment">// 删除数据</span></span><br><span class="line">        set1.update(<span class="number">3</span>,<span class="literal">false</span>)</span><br><span class="line">        println(set1.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 删除数据</span></span><br><span class="line">        set1.remove(<span class="number">2</span>)</span><br><span class="line">        println(set1.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 遍历数据</span></span><br><span class="line">        set1.foreach(println)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>基本操作 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> set1 = mutable.<span class="type">Set</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">        <span class="keyword">val</span> set2 = mutable.<span class="type">Set</span>(<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 交集</span></span><br><span class="line">        <span class="keyword">val</span> set3: mutable.<span class="type">Set</span>[<span class="type">Int</span>] = set1 &amp; set2</span><br><span class="line">        println(set3.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">        <span class="comment">// 差集</span></span><br><span class="line">        <span class="keyword">val</span> set4: mutable.<span class="type">Set</span>[<span class="type">Int</span>] = set1 &amp;~ set2</span><br><span class="line">        println(set4.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="7-5-Map集合"><a href="#7-5-Map集合" class="headerlink" title="7.5 Map集合"></a>7.5 Map集合</h2><p>Map(映射)是一种可迭代的键值对（key/value）结构。所有的值都可以通过键来获取。Map 中的键都是唯一的。</p>
<h3 id="7-5-1-不可变Map"><a href="#7-5-1-不可变Map" class="headerlink" title="7.5.1 不可变Map"></a>7.5.1 不可变Map</h3><ol>
<li>基本语法 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> map1 = <span class="type">Map</span>( <span class="string">&quot;a&quot;</span> -&gt; <span class="number">1</span>, <span class="string">&quot;b&quot;</span> -&gt; <span class="number">2</span>, <span class="string">&quot;c&quot;</span> -&gt; <span class="number">3</span> )</span><br><span class="line">        <span class="keyword">val</span> map2 = <span class="type">Map</span>( <span class="string">&quot;d&quot;</span> -&gt; <span class="number">4</span>, <span class="string">&quot;e&quot;</span> -&gt; <span class="number">5</span>, <span class="string">&quot;f&quot;</span> -&gt; <span class="number">6</span> )</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 添加数据</span></span><br><span class="line">        <span class="keyword">val</span> map3 = map1 + (<span class="string">&quot;d&quot;</span> -&gt; <span class="number">4</span>)</span><br><span class="line">        println(map1 eq map3) <span class="comment">// false</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 删除数据</span></span><br><span class="line">        <span class="keyword">val</span> map4 = map3 - <span class="string">&quot;d&quot;</span></span><br><span class="line">        println(map4.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> map5: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = map1 ++ map2</span><br><span class="line">        println(map5 eq map1)</span><br><span class="line">        println(map5.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> map6: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = map1 ++: map2</span><br><span class="line">        println(map6 eq map1)</span><br><span class="line">        println(map6.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 修改数据</span></span><br><span class="line">        <span class="keyword">val</span> map7: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = map1.updated(<span class="string">&quot;b&quot;</span>, <span class="number">5</span>)</span><br><span class="line">        println(map7.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 遍历数据</span></span><br><span class="line">        map1.foreach(println)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>基本操作 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> map1 = <span class="type">Map</span>( <span class="string">&quot;a&quot;</span> -&gt; <span class="number">1</span>, <span class="string">&quot;b&quot;</span> -&gt; <span class="number">2</span>, <span class="string">&quot;c&quot;</span> -&gt; <span class="number">3</span> )</span><br><span class="line">        <span class="keyword">val</span> map2 = <span class="type">Map</span>( <span class="string">&quot;d&quot;</span> -&gt; <span class="number">4</span>, <span class="string">&quot;e&quot;</span> -&gt; <span class="number">5</span>, <span class="string">&quot;f&quot;</span> -&gt; <span class="number">6</span> )</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建空集合</span></span><br><span class="line">        <span class="keyword">val</span> empty: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = <span class="type">Map</span>.empty</span><br><span class="line">        println(empty)</span><br><span class="line">        <span class="comment">// 获取指定key的值</span></span><br><span class="line">        <span class="keyword">val</span> i: <span class="type">Int</span> = map1.apply(<span class="string">&quot;c&quot;</span>)</span><br><span class="line">        println(i)</span><br><span class="line">        println(map1(<span class="string">&quot;c&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取可能存在的key值</span></span><br><span class="line">        <span class="keyword">val</span> maybeInt: <span class="type">Option</span>[<span class="type">Int</span>] = map1.get(<span class="string">&quot;c&quot;</span>)</span><br><span class="line">        <span class="comment">// 判断key值是否存在</span></span><br><span class="line">        <span class="keyword">if</span> ( !maybeInt.isEmpty ) &#123;</span><br><span class="line">            <span class="comment">// 获取值</span></span><br><span class="line">            println(maybeInt.get)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 如果不存在，获取默认值</span></span><br><span class="line">            println(maybeInt.getOrElse(<span class="number">0</span>))</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取可能存在的key值, 如果不存在就使用默认值</span></span><br><span class="line">        println(map1.getOrElse(<span class="string">&quot;c&quot;</span>, <span class="number">0</span>))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="7-5-2-可变Map"><a href="#7-5-2-可变Map" class="headerlink" title="7.5.2 可变Map"></a>7.5.2 可变Map</h3><ol>
<li>基本语法 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> map1 = mutable.<span class="type">Map</span>( <span class="string">&quot;a&quot;</span> -&gt; <span class="number">1</span>, <span class="string">&quot;b&quot;</span> -&gt; <span class="number">2</span>, <span class="string">&quot;c&quot;</span> -&gt; <span class="number">3</span> )</span><br><span class="line">        <span class="keyword">val</span> map2 = mutable.<span class="type">Map</span>( <span class="string">&quot;d&quot;</span> -&gt; <span class="number">4</span>, <span class="string">&quot;e&quot;</span> -&gt; <span class="number">5</span>, <span class="string">&quot;f&quot;</span> -&gt; <span class="number">6</span> )</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 添加数据</span></span><br><span class="line">        map1.put(<span class="string">&quot;d&quot;</span>, <span class="number">4</span>)</span><br><span class="line">        <span class="keyword">val</span> map3: mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = map1 + (<span class="string">&quot;e&quot;</span> -&gt; <span class="number">4</span>)</span><br><span class="line">        println(map1 eq map3)</span><br><span class="line">        <span class="keyword">val</span> map4: mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = map1 += (<span class="string">&quot;e&quot;</span> -&gt; <span class="number">5</span>)</span><br><span class="line">        println(map1 eq map4)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 修改数据</span></span><br><span class="line">        map1.update(<span class="string">&quot;e&quot;</span>,<span class="number">8</span>)</span><br><span class="line">        map1(<span class="string">&quot;e&quot;</span>) = <span class="number">8</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 删除数据</span></span><br><span class="line">        map1.remove(<span class="string">&quot;e&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> map5: mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = map1 - <span class="string">&quot;e&quot;</span></span><br><span class="line">        println(map1 eq map5)</span><br><span class="line">        <span class="keyword">val</span> map6: mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = map1 -= <span class="string">&quot;e&quot;</span></span><br><span class="line">        println(map1 eq map6)</span><br><span class="line">        <span class="comment">// 清除集合</span></span><br><span class="line">        map1.clear()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>基本操作 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> map1 = mutable.<span class="type">Map</span>( <span class="string">&quot;a&quot;</span> -&gt; <span class="number">1</span>, <span class="string">&quot;b&quot;</span> -&gt; <span class="number">2</span>, <span class="string">&quot;c&quot;</span> -&gt; <span class="number">3</span> )</span><br><span class="line">        <span class="keyword">val</span> map2 = mutable.<span class="type">Map</span>( <span class="string">&quot;d&quot;</span> -&gt; <span class="number">4</span>, <span class="string">&quot;e&quot;</span> -&gt; <span class="number">5</span>, <span class="string">&quot;f&quot;</span> -&gt; <span class="number">6</span> )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> set: <span class="type">Set</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = map1.toSet</span><br><span class="line">        <span class="keyword">val</span> list: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = map1.toList</span><br><span class="line">        <span class="keyword">val</span> seq: <span class="type">Seq</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = map1.toSeq</span><br><span class="line">        <span class="keyword">val</span> array: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = map1.toArray</span><br><span class="line"></span><br><span class="line">        println(set.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">        println(list.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">        println(seq.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">        println(array.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">        println(map1.get(<span class="string">&quot;a&quot;</span>))</span><br><span class="line">        println(map1.getOrElse(<span class="string">&quot;a&quot;</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        println(map1.keys)</span><br><span class="line">        println(map1.keySet)</span><br><span class="line">        println(map1.keysIterator)</span><br><span class="line">        println(map1.values)</span><br><span class="line">        println(map1.valuesIterator)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="7-6-元组"><a href="#7-6-元组" class="headerlink" title="7.6 元组"></a>7.6 元组</h2><p>在Scala语言中，我们可以将多个无关的数据元素封装为一个整体，这个整体我们称之为：元素组合，简称元组。有时也可将元组看成容纳元素的容器，其中最多只能容纳22个</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建元组，使用小括号</span></span><br><span class="line">        <span class="keyword">val</span> tuple = (<span class="number">1</span>, <span class="string">&quot;zhangsan&quot;</span>, <span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 根据顺序号访问元组的数据</span></span><br><span class="line">        println(tuple._1)</span><br><span class="line">        println(tuple._2)</span><br><span class="line">        println(tuple._3)</span><br><span class="line">        <span class="comment">// 迭代器</span></span><br><span class="line">        <span class="keyword">val</span> iterator: <span class="type">Iterator</span>[<span class="type">Any</span>] = tuple.productIterator</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 根据索引访问元素</span></span><br><span class="line">        tuple.productElement(<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 如果元组的元素只有两个，那么我们称之为对偶元组，也称之为键值对</span></span><br><span class="line">        <span class="keyword">val</span> kv: (<span class="type">String</span>, <span class="type">Int</span>) = (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">val</span> kv1: (<span class="type">String</span>, <span class="type">Int</span>) = <span class="string">&quot;a&quot;</span> -&gt; <span class="number">1</span></span><br><span class="line">        println( kv eq kv1 )</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="7-7-队列"><a href="#7-7-队列" class="headerlink" title="7.7 队列"></a>7.7 队列</h2><p>Scala也提供了队列（Queue）的数据结构，队列的特点就是先进先出。进队和出队的方法分别为enqueue和dequeue。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> que = <span class="keyword">new</span> mutable.<span class="type">Queue</span>[<span class="type">String</span>]()</span><br><span class="line">        <span class="comment">// 添加元素</span></span><br><span class="line">        que.enqueue(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> que1: mutable.<span class="type">Queue</span>[<span class="type">String</span>] = que += <span class="string">&quot;d&quot;</span></span><br><span class="line">        println(que eq que1)</span><br><span class="line">        <span class="comment">// 获取元素</span></span><br><span class="line">        println(que.dequeue())</span><br><span class="line">        println(que.dequeue())</span><br><span class="line">        println(que.dequeue())</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考:<br>kafka中如何保证消费数据的有序？ </p>
<ol>
<li>生产有序: Deque双端队列</li>
<li>存储有序: 存储单个分区</li>
<li>消费有序: 单个消费者，消费指定分区</li>
</ol>
</blockquote>
<h2 id="7-8-并行"><a href="#7-8-并行" class="headerlink" title="7.8 并行"></a>7.8 并行</h2><p>Scala为了充分使用多核CPU，提供了并行集合（有别于前面的串行集合），用于多核环境的并行计算。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> result1 = (<span class="number">0</span> to <span class="number">100</span>).map&#123;x =&gt; <span class="type">Thread</span>.currentThread.getName&#125;</span><br><span class="line">        <span class="keyword">val</span> result2 = (<span class="number">0</span> to <span class="number">100</span>).par.map&#123;x =&gt; <span class="type">Thread</span>.currentThread.getName&#125;</span><br><span class="line"></span><br><span class="line">        println(result1)</span><br><span class="line">        println(result2)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>7.9 常用方法</p>
<ol>
<li>常用方法 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 集合长度</span></span><br><span class="line">        println(<span class="string">&quot;size =&gt;&quot;</span> + list.size)</span><br><span class="line">        println(<span class="string">&quot;length =&gt;&quot;</span> + list.length)</span><br><span class="line">        <span class="comment">// 判断集合是否为空</span></span><br><span class="line">        println(<span class="string">&quot;isEmpty =&gt;&quot;</span> + list.isEmpty)</span><br><span class="line">        <span class="comment">// 集合迭代器</span></span><br><span class="line">        println(<span class="string">&quot;iterator =&gt;&quot;</span> + list.iterator)</span><br><span class="line">        <span class="comment">// 循环遍历集合</span></span><br><span class="line">        list.foreach(println)</span><br><span class="line">        <span class="comment">// 将集合转换为字符串</span></span><br><span class="line">        println(<span class="string">&quot;mkString =&gt;&quot;</span> + list.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">        <span class="comment">// 判断集合中是否包含某个元素</span></span><br><span class="line">        println(<span class="string">&quot;contains =&gt;&quot;</span> + list.contains(<span class="number">2</span>))</span><br><span class="line">        <span class="comment">// 取集合的前几个元素</span></span><br><span class="line">        println(<span class="string">&quot;take =&gt;&quot;</span> + list.take(<span class="number">2</span>))</span><br><span class="line">        <span class="comment">// 取集合的后几个元素</span></span><br><span class="line">        println(<span class="string">&quot;takeRight =&gt;&quot;</span> + list.takeRight(<span class="number">2</span>))</span><br><span class="line">        <span class="comment">// 查找元素</span></span><br><span class="line">        println(<span class="string">&quot;find =&gt;&quot;</span> + list.find(x =&gt; x % <span class="number">2</span>== <span class="number">0</span>))</span><br><span class="line">        <span class="comment">// 丢弃前几个元素</span></span><br><span class="line">        println(<span class="string">&quot;drop =&gt;&quot;</span> + list.drop(<span class="number">2</span>))</span><br><span class="line">        <span class="comment">// 丢弃后几个元素</span></span><br><span class="line">        println(<span class="string">&quot;dropRight =&gt;&quot;</span> + list.dropRight(<span class="number">2</span>))</span><br><span class="line">        <span class="comment">// 反转集合</span></span><br><span class="line">        println(<span class="string">&quot;reverse =&gt;&quot;</span> + list.reverse)</span><br><span class="line">        <span class="comment">// 去重</span></span><br><span class="line">        println(<span class="string">&quot;distinct =&gt;&quot;</span> + list.distinct)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>衍生集合 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">        <span class="keyword">val</span> list1 = <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">        <span class="keyword">val</span> list2 = <span class="type">List</span>(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 集合头</span></span><br><span class="line">        println(<span class="string">&quot;head =&gt; &quot;</span> + list.head)</span><br><span class="line">        <span class="comment">// 集合尾</span></span><br><span class="line">        println(<span class="string">&quot;tail =&gt; &quot;</span> + list.tail)</span><br><span class="line">        <span class="comment">// 集合尾迭代</span></span><br><span class="line">        println(<span class="string">&quot;tails =&gt; &quot;</span> + list.tails)</span><br><span class="line">        <span class="comment">// 集合初始值</span></span><br><span class="line">        println(<span class="string">&quot;init =&gt; &quot;</span> + list.init)</span><br><span class="line">        <span class="comment">// 集合初始值迭代</span></span><br><span class="line">        println(<span class="string">&quot;inits =&gt; &quot;</span> + list.inits)</span><br><span class="line">        <span class="comment">// 集合最后元素</span></span><br><span class="line">        println(<span class="string">&quot;last =&gt; &quot;</span> + list.last)</span><br><span class="line">        <span class="comment">// 集合并集</span></span><br><span class="line">        println(<span class="string">&quot;union =&gt; &quot;</span> + list.union(list1))</span><br><span class="line">        <span class="comment">// 集合交集</span></span><br><span class="line">        println(<span class="string">&quot;intersect =&gt; &quot;</span> + list.intersect(list1))</span><br><span class="line">        <span class="comment">// 集合差集</span></span><br><span class="line">        println(<span class="string">&quot;diff =&gt; &quot;</span> + list.diff(list1))</span><br><span class="line">        <span class="comment">// 切分集合</span></span><br><span class="line">        println(<span class="string">&quot;splitAt =&gt; &quot;</span> + list.splitAt(<span class="number">2</span>))</span><br><span class="line">        <span class="comment">// 滑动（窗口）</span></span><br><span class="line">        println(<span class="string">&quot;sliding =&gt; &quot;</span> + list.sliding(<span class="number">2</span>))</span><br><span class="line">        <span class="comment">// 滚动（没有重复）</span></span><br><span class="line">        println(<span class="string">&quot;sliding =&gt; &quot;</span> + list.sliding(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">        <span class="comment">// 拉链</span></span><br><span class="line">        println(<span class="string">&quot;zip =&gt; &quot;</span> + list.zip(list1))</span><br><span class="line">        <span class="comment">// 数据索引拉链</span></span><br><span class="line">        println(<span class="string">&quot;zipWithIndex =&gt; &quot;</span> + list.zipWithIndex)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>计算函数 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">        <span class="keyword">val</span> list1 = <span class="type">List</span>(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 集合最小值</span></span><br><span class="line">        println(<span class="string">&quot;min =&gt; &quot;</span> + list.min)</span><br><span class="line">        <span class="comment">// 集合最大值</span></span><br><span class="line">        println(<span class="string">&quot;max =&gt; &quot;</span> + list.max)</span><br><span class="line">        <span class="comment">// 集合求和</span></span><br><span class="line">        println(<span class="string">&quot;sum =&gt; &quot;</span> + list.sum)</span><br><span class="line">        <span class="comment">// 集合乘积</span></span><br><span class="line">        println(<span class="string">&quot;product =&gt; &quot;</span> + list.product)</span><br><span class="line">        <span class="comment">// 集合简化规约</span></span><br><span class="line">        println(<span class="string">&quot;reduce =&gt; &quot;</span> + list.reduce((x:<span class="type">Int</span>,y:<span class="type">Int</span>)=&gt;&#123;x+y&#125;))</span><br><span class="line">        println(<span class="string">&quot;reduce =&gt; &quot;</span> + list.reduce((x,y)=&gt;&#123;x+y&#125;))</span><br><span class="line">        println(<span class="string">&quot;reduce =&gt; &quot;</span> + list.reduce((x,y)=&gt;x+y))</span><br><span class="line">        println(<span class="string">&quot;reduce =&gt; &quot;</span> + list.reduce(_+_))</span><br><span class="line">        <span class="comment">// 集合简化规约(左)</span></span><br><span class="line">        println(<span class="string">&quot;reduceLeft =&gt; &quot;</span> + list.reduceLeft(_+_))</span><br><span class="line">        <span class="comment">// 集合简化规约(右)</span></span><br><span class="line">        println(<span class="string">&quot;reduceRight =&gt; &quot;</span> + list.reduceRight(_+_))</span><br><span class="line">        <span class="comment">// 集合折叠</span></span><br><span class="line">        println(<span class="string">&quot;fold =&gt; &quot;</span> + list.fold(<span class="number">0</span>)(_+_))</span><br><span class="line">        <span class="comment">// 集合折叠(左)</span></span><br><span class="line">        println(<span class="string">&quot;foldLeft =&gt; &quot;</span> + list.foldLeft(<span class="number">0</span>)(_+_))</span><br><span class="line">        <span class="comment">// 集合折叠(右)</span></span><br><span class="line">        println(<span class="string">&quot;foldRight =&gt; &quot;</span> + list.foldRight(<span class="number">0</span>)(_+_))</span><br><span class="line">        <span class="comment">// 集合扫描</span></span><br><span class="line">        println(<span class="string">&quot;scan =&gt; &quot;</span> + list.scan(<span class="number">0</span>)(_+_))</span><br><span class="line">        <span class="comment">// 集合扫描(左)</span></span><br><span class="line">        println(<span class="string">&quot;scanLeft =&gt; &quot;</span> + list.scanLeft(<span class="number">0</span>)(_+_))</span><br><span class="line">        <span class="comment">// 集合扫描(右)</span></span><br><span class="line">        println(<span class="string">&quot;scanRight =&gt; &quot;</span> + list.scanRight(<span class="number">0</span>)(_+_))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>功能函数 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCollection</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 集合映射</span></span><br><span class="line">        println(<span class="string">&quot;map =&gt; &quot;</span> + list.map(x=&gt;&#123;x*<span class="number">2</span>&#125;))</span><br><span class="line">        println(<span class="string">&quot;map =&gt; &quot;</span> + list.map(x=&gt;x*<span class="number">2</span>))</span><br><span class="line">        println(<span class="string">&quot;map =&gt; &quot;</span> + list.map(_*<span class="number">2</span>))</span><br><span class="line">        <span class="comment">// 集合扁平化</span></span><br><span class="line">        <span class="keyword">val</span> list1 = <span class="type">List</span>(</span><br><span class="line">            <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            <span class="type">List</span>(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">        )</span><br><span class="line">        println(<span class="string">&quot;flatten =&gt;&quot;</span> + list1.flatten)</span><br><span class="line">        <span class="comment">// 集合扁平映射</span></span><br><span class="line">        println(<span class="string">&quot;flatMap =&gt;&quot;</span> + list1.flatMap(list=&gt;list))</span><br><span class="line">        <span class="comment">// 集合过滤数据</span></span><br><span class="line">        println(<span class="string">&quot;filter =&gt;&quot;</span> + list.filter(_%<span class="number">2</span> == <span class="number">0</span>))</span><br><span class="line">        <span class="comment">// 集合分组数据</span></span><br><span class="line">        println(<span class="string">&quot;groupBy =&gt;&quot;</span> + list.groupBy(_%<span class="number">2</span>))</span><br><span class="line">        <span class="comment">// 集合排序</span></span><br><span class="line">        println(<span class="string">&quot;sortBy =&gt;&quot;</span> + list.sortBy(num=&gt;num)(<span class="type">Ordering</span>.<span class="type">Int</span>.reverse))</span><br><span class="line">        println(<span class="string">&quot;sortWith =&gt;&quot;</span> + list.sortWith((left, right) =&gt; &#123;left &lt; right&#125;))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="7-10-案例实操-WordCount-TopN"><a href="#7-10-案例实操-WordCount-TopN" class="headerlink" title="7.10 案例实操 - WordCount TopN"></a>7.10 案例实操 - WordCount TopN</h2><h3 id="7-10-1-数据准备"><a href="#7-10-1-数据准备" class="headerlink" title="7.10.1 数据准备"></a>7.10.1 数据准备</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Hello Scala</span><br><span class="line">Hello Spark</span><br><span class="line">Hello Hadoop</span><br></pre></td></tr></table></figure>

<h3 id="7-10-2-功能实现"><a href="#7-10-2-功能实现" class="headerlink" title="7.10.2 功能实现"></a>7.10.2 功能实现</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaWordCount</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> list: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;input/word.txt&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> wordList: <span class="type">List</span>[<span class="type">String</span>] = list.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> word2OneList: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordList.map((_,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> word2ListMap: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]] = word2OneList.groupBy(_._1)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> word2CountMap: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = word2ListMap.map(</span><br><span class="line">            kv =&gt; &#123;</span><br><span class="line">                (kv._1, kv._2.size)</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        println(word2CountMap)</span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>

<h1 id="第8章-模式匹配"><a href="#第8章-模式匹配" class="headerlink" title="第8章 模式匹配"></a>第8章 模式匹配</h1><h2 id="8-1-简介"><a href="#8-1-简介" class="headerlink" title="8.1 简介"></a>8.1 简介</h2><p>Scala中的模式匹配类似于Java中的switch语法,但是scala从语法中补充了更多的功能，可以按照指定的规则对数据或对象进行匹配, 所以更加强大。<br>java:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">20</span></span><br><span class="line"><span class="keyword">switch</span> (i) &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="number">10</span> :</span><br><span class="line">        System.out.println(<span class="string">&quot;10&quot;</span>);</span><br><span class="line">        <span class="comment">//break;</span></span><br><span class="line">    <span class="keyword">case</span> <span class="number">20</span> : </span><br><span class="line">        System.out.println(<span class="string">&quot;20&quot;</span>);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span> : </span><br><span class="line">        System.out.println(<span class="string">&quot;other number&quot;</span>);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="8-2-基本语法"><a href="#8-2-基本语法" class="headerlink" title="8.2 基本语法"></a>8.2 基本语法</h2><p>模式匹配语法中，采用match关键字声明，每个分支采用case关键字进行声明，当需要匹配时，会从第一个case分支开始，如果匹配成功，那么执行对应的逻辑代码，如果匹配不成功，继续执行下一个分支进行判断。<font color ='red' >如果所有case都不匹配，那么会执行case _分支，类似于Java中default语句</font>。<font color ='blue' >如果不存在case _分支，那么会发生错误</font>。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaMatch</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">var</span> a: <span class="type">Int</span> = <span class="number">10</span></span><br><span class="line">        <span class="keyword">var</span> b: <span class="type">Int</span> = <span class="number">20</span></span><br><span class="line">        <span class="keyword">var</span> operator: <span class="type">Char</span> = &#x27;d&#x27;</span><br><span class="line">        <span class="keyword">var</span> result = operator <span class="keyword">match</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> &#x27;+&#x27; =&gt; a + b</span><br><span class="line">            <span class="keyword">case</span> &#x27;-&#x27; =&gt; a - b</span><br><span class="line">            <span class="keyword">case</span> &#x27;*&#x27; =&gt; a * b</span><br><span class="line">            <span class="keyword">case</span> &#x27;/&#x27; =&gt; a / b</span><br><span class="line">            <span class="keyword">case</span> _ =&gt; <span class="string">&quot;illegal&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        println(result)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="8-3-匹配规则"><a href="#8-3-匹配规则" class="headerlink" title="8.3 匹配规则"></a>8.3 匹配规则</h2><h3 id="8-3-1-匹配常量"><a href="#8-3-1-匹配常量" class="headerlink" title="8.3.1 匹配常量"></a>8.3.1 匹配常量</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">describe</span></span>(x: <span class="type">Any</span>) = x <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="number">5</span> =&gt; <span class="string">&quot;Int five&quot;</span></span><br><span class="line">    <span class="keyword">case</span> <span class="string">&quot;hello&quot;</span> =&gt; <span class="string">&quot;String hello&quot;</span></span><br><span class="line">    <span class="keyword">case</span> <span class="literal">true</span> =&gt; <span class="string">&quot;Boolean true&quot;</span></span><br><span class="line">    <span class="keyword">case</span> &#x27;+&#x27; =&gt; <span class="string">&quot;Char +&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="8-3-2-匹配类型"><a href="#8-3-2-匹配类型" class="headerlink" title="8.3.2 匹配类型"></a>8.3.2 匹配类型</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">describe</span></span>(x: <span class="type">Any</span>) = x <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> i: <span class="type">Int</span> =&gt; <span class="string">&quot;Int&quot;</span></span><br><span class="line">    <span class="keyword">case</span> s: <span class="type">String</span> =&gt; <span class="string">&quot;String hello&quot;</span></span><br><span class="line">    <span class="keyword">case</span> m: <span class="type">List</span>[_] =&gt; <span class="string">&quot;List&quot;</span></span><br><span class="line">    <span class="keyword">case</span> c: <span class="type">Array</span>[<span class="type">Int</span>] =&gt; <span class="string">&quot;Array[Int]&quot;</span></span><br><span class="line">    <span class="keyword">case</span> someThing =&gt; <span class="string">&quot;something else &quot;</span> + someThing</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="8-3-3-匹配数组"><a href="#8-3-3-匹配数组" class="headerlink" title="8.3.3 匹配数组"></a>8.3.3 匹配数组</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (arr &lt;- <span class="type">Array</span>(</span><br><span class="line">    <span class="type">Array</span>(<span class="number">0</span>),</span><br><span class="line">    <span class="type">Array</span>(<span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">    <span class="type">Array</span>(<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">    <span class="type">Array</span>(<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">    <span class="type">Array</span>(<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>),</span><br><span class="line">    <span class="type">Array</span>(<span class="string">&quot;hello&quot;</span>, <span class="number">90</span>))) &#123;</span><br><span class="line">    <span class="keyword">val</span> result = arr <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="comment">//匹配Array(0) 这个数组</span></span><br><span class="line">        <span class="keyword">case</span> <span class="type">Array</span>(<span class="number">0</span>) =&gt; <span class="string">&quot;0&quot;</span></span><br><span class="line">        <span class="comment">//匹配有两个元素的数组，然后将将元素值赋给对应的x,y</span></span><br><span class="line">        <span class="keyword">case</span> <span class="type">Array</span>(x, y) =&gt; x + <span class="string">&quot;,&quot;</span> + y</span><br><span class="line">        <span class="comment">//匹配以0开头和数组</span></span><br><span class="line">        <span class="keyword">case</span> <span class="type">Array</span>(<span class="number">0</span>, _*) =&gt; <span class="string">&quot;以0开头的数组&quot;</span></span><br><span class="line">        <span class="keyword">case</span> _ =&gt; <span class="string">&quot;something else&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    println(<span class="string">&quot;匹配数组 result = &quot;</span> + result)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="8-3-4-匹配列表"><a href="#8-3-4-匹配列表" class="headerlink" title="8.3.4 匹配列表"></a>8.3.4 匹配列表</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (list &lt;- <span class="type">Array</span>(</span><br><span class="line">    <span class="type">List</span>(<span class="number">0</span>),</span><br><span class="line">    <span class="type">List</span>(<span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">    <span class="type">List</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">    <span class="type">List</span>(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">    <span class="type">List</span>(<span class="number">88</span>))) &#123;</span><br><span class="line">    <span class="keyword">val</span> result = list <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">List</span>(<span class="number">0</span>) =&gt; <span class="string">&quot;0&quot;</span> <span class="comment">//匹配List(0)</span></span><br><span class="line">        <span class="keyword">case</span> <span class="type">List</span>(x, y) =&gt; x + <span class="string">&quot;,&quot;</span> + y <span class="comment">//匹配有两个元素的List</span></span><br><span class="line">        <span class="keyword">case</span> <span class="type">List</span>(<span class="number">0</span>, _*) =&gt; <span class="string">&quot;0 ...&quot;</span></span><br><span class="line">        <span class="keyword">case</span> _ =&gt; <span class="string">&quot;something else&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;匹配列表：&quot;</span> + result)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> list1: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>)</span><br><span class="line"><span class="keyword">val</span> list2: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">val</span> list3: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">list1 <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> first :: second :: rest =&gt; println(<span class="string">&quot;first: &quot;</span> + first + <span class="string">&quot;; &quot;</span> + <span class="string">&quot;second: &quot;</span> + second + <span class="string">&quot;;&quot;</span> + <span class="string">&quot;rest: &quot;</span> + rest)</span><br><span class="line">    <span class="keyword">case</span> _ =&gt; println(<span class="string">&quot;something else&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">list2 <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> first :: second :: rest =&gt; println(<span class="string">&quot;first: &quot;</span> + first + <span class="string">&quot;; &quot;</span> + <span class="string">&quot;second: &quot;</span> + second + <span class="string">&quot;;&quot;</span> + <span class="string">&quot;rest: &quot;</span> + rest)</span><br><span class="line">    <span class="keyword">case</span> _ =&gt; println(<span class="string">&quot;something else&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">list3 <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> first :: second :: rest =&gt; println(<span class="string">&quot;first: &quot;</span> + first + <span class="string">&quot;; &quot;</span> + <span class="string">&quot;second: &quot;</span> + second + <span class="string">&quot;;&quot;</span> + <span class="string">&quot;rest: &quot;</span> + rest)</span><br><span class="line">    <span class="keyword">case</span> _ =&gt; println(<span class="string">&quot;something else&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="8-3-5-匹配元组"><a href="#8-3-5-匹配元组" class="headerlink" title="8.3.5 匹配元组"></a>8.3.5 匹配元组</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//匹配元组</span></span><br><span class="line"><span class="keyword">for</span> (tuple &lt;- <span class="type">Array</span>(</span><br><span class="line">    (<span class="number">0</span>, <span class="number">1</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>))) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> result = tuple <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> (<span class="number">0</span>, _) =&gt; <span class="string">&quot;0 ...&quot;</span> <span class="comment">//是第一个元素是0的元组</span></span><br><span class="line">        <span class="keyword">case</span> (y, <span class="number">0</span>) =&gt; <span class="string">&quot;&quot;</span> + y + <span class="string">&quot;0&quot;</span> <span class="comment">// 匹配后一个元素是0的对偶元组</span></span><br><span class="line">        <span class="keyword">case</span> (a, b) =&gt; <span class="string">&quot;&quot;</span> + a + <span class="string">&quot; &quot;</span> + b</span><br><span class="line">        <span class="keyword">case</span> _ =&gt; <span class="string">&quot;something else&quot;</span> <span class="comment">//默认</span></span><br><span class="line">    &#125;</span><br><span class="line">    println(<span class="string">&quot;匹配元组:&quot;</span> + result)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="8-3-6-匹配对象"><a href="#8-3-6-匹配对象" class="headerlink" title="8.3.6 匹配对象"></a>8.3.6 匹配对象</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">val name: <span class="type">String</span>, val age: <span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">User</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(name: <span class="type">String</span>, age: <span class="type">Int</span>): <span class="type">User</span> = <span class="keyword">new</span> <span class="type">User</span>(name, age)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">unapply</span></span>(user: <span class="type">User</span>): <span class="type">Option</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = &#123;</span><br><span class="line">        <span class="keyword">if</span> (user == <span class="literal">null</span>)</span><br><span class="line">            <span class="type">None</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="type">Some</span>(user.name, user.age)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> user: <span class="type">User</span> = <span class="type">User</span>(<span class="string">&quot;zhangsan&quot;</span>, <span class="number">11</span>)</span><br><span class="line"><span class="keyword">val</span> result = user <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">User</span>(<span class="string">&quot;zhangsan&quot;</span>, <span class="number">11</span>) =&gt; <span class="string">&quot;yes&quot;</span></span><br><span class="line">    <span class="keyword">case</span> _ =&gt; <span class="string">&quot;no&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="8-3-7-样例类"><a href="#8-3-7-样例类" class="headerlink" title="8.3.7 样例类"></a>8.3.7 样例类</h3><ul>
<li>样例类就是使用<code>case</code>关键字声明的类</li>
<li>样例类仍然是类，和普通类相比，只是其自动生成了伴生对象，并且伴生对象中自动提供了一些常用的方法，如apply、<code>unapply</code>、toString、equals、hashCode和copy。</li>
<li>样例类是为<code>模式匹配</code>而优化的类，因为其默认提供了unapply方法，因此，样例类可以直接使用模式匹配，而无需自己实现unapply方法。</li>
<li>构造器中的每一个参数都成为val，除非它被显式地声明为var（不建议这样做）<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">name: <span class="type">String</span>, var age: <span class="type">Int</span></span>)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaCaseClass</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> user: <span class="type">User</span> = <span class="type">User</span>(<span class="string">&quot;zhangsan&quot;</span>, <span class="number">11</span>)</span><br><span class="line">        <span class="keyword">val</span> result = user <span class="keyword">match</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="type">User</span>(<span class="string">&quot;zhangsan&quot;</span>, <span class="number">11</span>) =&gt; <span class="string">&quot;yes&quot;</span></span><br><span class="line">            <span class="keyword">case</span> _ =&gt; <span class="string">&quot;no&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        println(result)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="8-4-应用场景"><a href="#8-4-应用场景" class="headerlink" title="8.4 应用场景"></a>8.4 应用场景</h2><h3 id="8-4-1-变量声明"><a href="#8-4-1-变量声明" class="headerlink" title="8.4.1 变量声明"></a>8.4.1 变量声明</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaMatch</span> </span>&#123; </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> (x, y) = (<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        println(<span class="string">s&quot;x=<span class="subst">$x</span>,y=<span class="subst">$y</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> <span class="type">Array</span>(first, second, _*) = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">7</span>, <span class="number">2</span>, <span class="number">9</span>)</span><br><span class="line">        println(<span class="string">s&quot;first=<span class="subst">$first</span>,second=<span class="subst">$second</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> <span class="type">Person</span>(name, age) = <span class="type">Person</span>(<span class="string">&quot;zhangsan&quot;</span>, <span class="number">16</span>)</span><br><span class="line">        println(<span class="string">s&quot;name=<span class="subst">$name</span>,age=<span class="subst">$age</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Int</span></span>)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="8-4-2-循环匹配"><a href="#8-4-2-循环匹配" class="headerlink" title="8.4.2 循环匹配"></a>8.4.2 循环匹配</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaMatch</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> map = <span class="type">Map</span>(<span class="string">&quot;A&quot;</span> -&gt; <span class="number">1</span>, <span class="string">&quot;B&quot;</span> -&gt; <span class="number">0</span>, <span class="string">&quot;C&quot;</span> -&gt; <span class="number">3</span>)</span><br><span class="line">        <span class="keyword">for</span> ((k, v) &lt;- map) &#123; <span class="comment">//直接将map中的k-v遍历出来</span></span><br><span class="line">            println(k + <span class="string">&quot; -&gt; &quot;</span> + v) <span class="comment">//3个</span></span><br><span class="line">        &#125;</span><br><span class="line">        println(<span class="string">&quot;----------------------&quot;</span>)</span><br><span class="line">        <span class="comment">//遍历value=0的 k-v ,如果v不是0,过滤</span></span><br><span class="line">        <span class="keyword">for</span> ((k, <span class="number">0</span>) &lt;- map) &#123;</span><br><span class="line">            println(k + <span class="string">&quot; --&gt; &quot;</span> + <span class="number">0</span>) <span class="comment">// B-&gt;0</span></span><br><span class="line">        &#125;</span><br><span class="line">        println(<span class="string">&quot;----------------------&quot;</span>)</span><br><span class="line">        <span class="comment">//if v == 0 是一个过滤的条件</span></span><br><span class="line">        <span class="keyword">for</span> ((k, v) &lt;- map <span class="keyword">if</span> v &gt;= <span class="number">1</span>) &#123;</span><br><span class="line">            println(k + <span class="string">&quot; ---&gt; &quot;</span> + v) <span class="comment">// A-&gt;1 和 c-&gt;33</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="8-4-3-函数参数"><a href="#8-4-3-函数参数" class="headerlink" title="8.4.3 函数参数"></a>8.4.3 函数参数</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaMatch</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> list = <span class="type">List</span>(</span><br><span class="line">            (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;c&quot;</span>, <span class="number">3</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">val</span> list1 = list.map &#123;</span><br><span class="line">            <span class="keyword">case</span> ( k, v ) =&gt; &#123;</span><br><span class="line">                (k, v*<span class="number">2</span>)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        println(list1)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="8-5-偏函数"><a href="#8-5-偏函数" class="headerlink" title="8.5 偏函数"></a>8.5 偏函数</h2><p>所谓的偏函数，其实就是对集合中符合条件的数据进行处理的函数<br>偏函数也是函数的一种，通过偏函数我们可以方便的对输入参数做更精确的检查。例如该偏函数的输入类型为Int，但是我们只考虑数值为1的时候，数据该如何处理，其他不考虑。</p>
<h3 id="8-5-1-基本语法"><a href="#8-5-1-基本语法" class="headerlink" title="8.5.1 基本语法"></a>8.5.1 基本语法</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 声明偏函数</span></span><br><span class="line"><span class="keyword">val</span> pf: <span class="type">PartialFunction</span>[<span class="type">Int</span>, <span class="type">String</span>] = &#123; <span class="keyword">case</span> <span class="number">1</span> =&gt; <span class="string">&quot;one&quot;</span> &#125;</span><br><span class="line"></span><br><span class="line">。。。</span><br><span class="line"><span class="comment">// 应用偏函数</span></span><br><span class="line">println(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>).collect(pf))</span><br></pre></td></tr></table></figure>


<h3 id="8-5-2-案例实操"><a href="#8-5-2-案例实操" class="headerlink" title="8.5.2 案例实操"></a>8.5.2 案例实操</h3><p>将该List(1,2,3,4,5,6,”test”)中的Int类型的元素加一，并去掉字符串。</p>
<ul>
<li>不使用偏函数  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="string">&quot;test&quot;</span>)</span><br><span class="line">    .filter(_.isInstanceOf[<span class="type">Int</span>])</span><br><span class="line">    .map(_.asInstanceOf[<span class="type">Int</span>] + <span class="number">1</span>)</span><br><span class="line">    .foreach(println)</span><br></pre></td></tr></table></figure></li>
<li>使用偏函数<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="string">&quot;test&quot;</span>)</span><br><span class="line">    .collect &#123; <span class="keyword">case</span> x: <span class="type">Int</span> =&gt; x + <span class="number">1</span> &#125;</span><br><span class="line">    .foreach(println)</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="第9章-异常"><a href="#第9章-异常" class="headerlink" title="第9章 异常"></a>第9章 异常</h1><h2 id="9-1-简介"><a href="#9-1-简介" class="headerlink" title="9.1 简介"></a>9.1 简介</h2><p>Scala异常语法处理上和Java类似，但是又不尽相同。<br>Java异常：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">int</span> a = <span class="number">10</span>;</span><br><span class="line">    <span class="keyword">int</span> b = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> c = a / b;</span><br><span class="line">&#125; <span class="keyword">catch</span> (ArithmeticException e)&#123;</span><br><span class="line">    <span class="comment">// catch时，需要将范围小的写到前面</span></span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;finally&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="9-2-基本语法"><a href="#9-2-基本语法" class="headerlink" title="9.2 基本语法"></a>9.2 基本语法</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaException</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">var</span> n= <span class="number">10</span> / <span class="number">0</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> ex: <span class="type">ArithmeticException</span>=&gt;&#123;</span><br><span class="line">                <span class="comment">// 发生算术异常</span></span><br><span class="line">                println(<span class="string">&quot;发生算术异常&quot;</span>)</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">case</span> ex: <span class="type">Exception</span>=&gt;&#123;</span><br><span class="line">                <span class="comment">// 对异常处理</span></span><br><span class="line">                println(<span class="string">&quot;发生了异常1&quot;</span>)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            println(<span class="string">&quot;finally&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Scala中的异常不区分所谓的编译时异常和运行时异常，也无需显示抛出方法异常，所以<font color ='red' >Scala中没有throws关键字</font>。</p>
<ul>
<li>如果Java程序调用scala代码，如何明确异常？<ul>
<li>增加注解 @throws[classOf[Exception]]</li>
</ul>
</li>
</ul>
<h1 id="第10章-隐式转换"><a href="#第10章-隐式转换" class="headerlink" title="第10章 隐式转换"></a>第10章 隐式转换</h1><h2 id="10-1-简介"><a href="#10-1-简介" class="headerlink" title="10.1 简介"></a>10.1 简介</h2><p>在之前的类型学习中，我们已经学习了自动类型转换，精度小的类型可以自动转换为精度大的类型，这个转换过程无需开发人员参与，由编译器自动完成，这个转换操作我们称之为隐式转换。<br>在其他的场合，隐式转换也起到了非常重要的作用。如Scala在程序编译错误时，可以通过隐式转换中类型转换机制尝试进行二次编译，将本身错误无法编译通过的代码通过类型转换后编译通过。慢慢地，这也形成了一种扩展功能的转换机制。这个听着很抽象，不好理解，不急，咱慢慢体会。</p>
<h2 id="10-2-隐式函数"><a href="#10-2-隐式函数" class="headerlink" title="10.2 隐式函数"></a>10.2 隐式函数</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaImplicit</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">transform</span></span>( d : <span class="type">Double</span> ): <span class="type">Int</span> = &#123;</span><br><span class="line">            d.toInt</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">var</span> d : <span class="type">Double</span> = <span class="number">2.0</span></span><br><span class="line">        <span class="keyword">val</span> i : <span class="type">Int</span> = d</span><br><span class="line">        println(i)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>思考一个问题:如果有多个相同转换规则怎么办？<ul>
<li>报错</li>
</ul>
</li>
</ul>
<h2 id="10-3-隐式参数-amp-隐式变量"><a href="#10-3-隐式参数-amp-隐式变量" class="headerlink" title="10.3 隐式参数 &amp; 隐式变量"></a>10.3 隐式参数 &amp; 隐式变量</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaImplicit</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">transform</span></span>( <span class="keyword">implicit</span>  d : <span class="type">Double</span> ) = &#123;</span><br><span class="line">            d.toInt</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">implicit</span> <span class="keyword">val</span> dd : <span class="type">Double</span> = <span class="number">2.0</span></span><br><span class="line">        println(transform)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="10-4-隐式类"><a href="#10-4-隐式类" class="headerlink" title="10.4 隐式类"></a>10.4 隐式类</h2><p>在Scala2.10后提供了隐式类，可以使用implicit声明类，隐式类非常强大，同样可以扩展类的功能，在集合的数据处理中，隐式类发挥了重要的作用。</p>
<ul>
<li>其所带的构造参数有且只能有一个</li>
<li>隐式类必须被定义在“类”或“伴生对象”或“包对象”里，即隐式类不能是顶级的。<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaImplicit</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> emp = <span class="keyword">new</span> <span class="type">Emp</span>()</span><br><span class="line">        emp.insertUser()</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Emp</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">implicit</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params"> emp : <span class="type">Emp</span></span>) </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">insertUser</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">            println(<span class="string">&quot;insert user...&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="10-5-隐式机制"><a href="#10-5-隐式机制" class="headerlink" title="10.5 隐式机制"></a>10.5 隐式机制</h2><p>所谓的隐式机制，就是一旦出现编译错误时，编译器会从哪些地方查找对应的隐式转换规则</p>
<ul>
<li>当前代码作用域</li>
<li>当前代码上级作用域</li>
<li>当前类所在的包对象</li>
<li>当前类（对象）的父类（父类）或特质（父特质）<br>其实最直接的方式就是直接导入。</li>
</ul>
<h1 id="第11章-泛型"><a href="#第11章-泛型" class="headerlink" title="第11章 泛型"></a>第11章 泛型</h1><h2 id="11-1-简介"><a href="#11-1-简介" class="headerlink" title="11.1 简介"></a>11.1 简介</h2><p>Scala的泛型和Java中的泛型表达的含义都是一样的，对处理的数据类型进行约束，但是Scala提供了更加强大的功能</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span>[<span class="type">A</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> elements: <span class="type">List</span>[<span class="type">A</span>] = <span class="type">Nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="11-2-泛型转换"><a href="#11-2-泛型转换" class="headerlink" title="11.2 泛型转换"></a>11.2 泛型转换</h2><p>Scala的泛型可以根据功能进行改变</p>
<h3 id="11-2-1-泛型不可变"><a href="#11-2-1-泛型不可变" class="headerlink" title="11.2.1 泛型不可变"></a>11.2.1 泛型不可变</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaGeneric</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> test1 : <span class="type">Test</span>[<span class="type">User</span>] = <span class="keyword">new</span> <span class="type">Test</span>[<span class="type">User</span>] <span class="comment">// OK</span></span><br><span class="line">        <span class="keyword">val</span> test2 : <span class="type">Test</span>[<span class="type">User</span>] = <span class="keyword">new</span> <span class="type">Test</span>[<span class="type">Parent</span>] <span class="comment">// Error</span></span><br><span class="line">        <span class="keyword">val</span> test3 : <span class="type">Test</span>[<span class="type">User</span>] = <span class="keyword">new</span> <span class="type">Test</span>[<span class="type">SubUser</span>]  <span class="comment">// Error</span></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Test</span>[<span class="type">T</span>] </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Parent</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">extends</span> <span class="title">Parent</span></span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">SubUser</span> <span class="keyword">extends</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="11-2-2-泛型协变"><a href="#11-2-2-泛型协变" class="headerlink" title="11.2.2 泛型协变"></a>11.2.2 泛型协变</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaGeneric</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> test1 : <span class="type">Test</span>[<span class="type">User</span>] = <span class="keyword">new</span> <span class="type">Test</span>[<span class="type">User</span>] <span class="comment">// OK</span></span><br><span class="line">        <span class="keyword">val</span> test2 : <span class="type">Test</span>[<span class="type">User</span>] = <span class="keyword">new</span> <span class="type">Test</span>[<span class="type">Parent</span>] <span class="comment">// Error</span></span><br><span class="line">        <span class="keyword">val</span> test3 : <span class="type">Test</span>[<span class="type">User</span>] = <span class="keyword">new</span> <span class="type">Test</span>[<span class="type">SubUser</span>]  <span class="comment">// OK</span></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Test</span>[+<span class="type">T</span>] </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Parent</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">extends</span> <span class="title">Parent</span></span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">SubUser</span> <span class="keyword">extends</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="11-2-3-泛型逆变"><a href="#11-2-3-泛型逆变" class="headerlink" title="11.2.3 泛型逆变"></a>11.2.3 泛型逆变</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaGeneric</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> test1 : <span class="type">Test</span>[<span class="type">User</span>] = <span class="keyword">new</span> <span class="type">Test</span>[<span class="type">User</span>] <span class="comment">// OK</span></span><br><span class="line">        <span class="keyword">val</span> test2 : <span class="type">Test</span>[<span class="type">User</span>] = <span class="keyword">new</span> <span class="type">Test</span>[<span class="type">Parent</span>] <span class="comment">// OK</span></span><br><span class="line">        <span class="keyword">val</span> test3 : <span class="type">Test</span>[<span class="type">User</span>] = <span class="keyword">new</span> <span class="type">Test</span>[<span class="type">SubUser</span>]  <span class="comment">// Error</span></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Test</span>[-<span class="type">T</span>] </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Parent</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">extends</span> <span class="title">Parent</span></span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">SubUser</span> <span class="keyword">extends</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="11-3-泛型边界"><a href="#11-3-泛型边界" class="headerlink" title="11.3 泛型边界"></a>11.3 泛型边界</h2><p>Scala的泛型可以根据功能设定类树的边界</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaGeneric</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> parent : <span class="type">Parent</span> = <span class="keyword">new</span> <span class="type">Parent</span>()</span><br><span class="line">        <span class="keyword">val</span> user : <span class="type">User</span> = <span class="keyword">new</span> <span class="type">User</span>()</span><br><span class="line">        <span class="keyword">val</span> subuser : <span class="type">SubUser</span> = <span class="keyword">new</span> <span class="type">SubUser</span>()</span><br><span class="line">        test[<span class="type">User</span>](parent) <span class="comment">// Error</span></span><br><span class="line">        test[<span class="type">User</span>](user)   <span class="comment">// OK</span></span><br><span class="line">        test[<span class="type">User</span>](subuser) <span class="comment">// OK</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span>  <span class="title">test</span></span>[<span class="type">A</span>]( a : <span class="type">A</span> ): <span class="type">Unit</span> = &#123;</span><br><span class="line">        println(a)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Parent</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">extends</span> <span class="title">Parent</span></span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">SubUser</span> <span class="keyword">extends</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="11-3-1-泛型上限"><a href="#11-3-1-泛型上限" class="headerlink" title="11.3.1 泛型上限"></a>11.3.1 泛型上限</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaGeneric</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> parent : <span class="type">Parent</span> = <span class="keyword">new</span> <span class="type">Parent</span>()</span><br><span class="line">        <span class="keyword">val</span> user : <span class="type">User</span> = <span class="keyword">new</span> <span class="type">User</span>()</span><br><span class="line">        <span class="keyword">val</span> subuser : <span class="type">SubUser</span> = <span class="keyword">new</span> <span class="type">SubUser</span>()</span><br><span class="line">        test[<span class="type">Parent</span>](parent) <span class="comment">// Error</span></span><br><span class="line">        test[<span class="type">User</span>](user)   <span class="comment">// OK</span></span><br><span class="line">        test[<span class="type">SubUser</span>](subuser) <span class="comment">// OK</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span>  <span class="title">test</span></span>[<span class="type">A</span>&lt;:<span class="type">User</span>]( a : <span class="type">A</span> ): <span class="type">Unit</span> = &#123;</span><br><span class="line">        println(a)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Parent</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">extends</span> <span class="title">Parent</span></span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">SubUser</span> <span class="keyword">extends</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="11-3-2-泛型下限"><a href="#11-3-2-泛型下限" class="headerlink" title="11.3.2 泛型下限"></a>11.3.2 泛型下限</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaGeneric</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> parent : <span class="type">Parent</span> = <span class="keyword">new</span> <span class="type">Parent</span>()</span><br><span class="line">        <span class="keyword">val</span> user : <span class="type">User</span> = <span class="keyword">new</span> <span class="type">User</span>()</span><br><span class="line">        <span class="keyword">val</span> subuser : <span class="type">SubUser</span> = <span class="keyword">new</span> <span class="type">SubUser</span>()</span><br><span class="line">        test[<span class="type">Parent</span>](parent) <span class="comment">// OK</span></span><br><span class="line">        test[<span class="type">User</span>](user)   <span class="comment">// OK</span></span><br><span class="line">        test[<span class="type">SubUser</span>](subuser) <span class="comment">// Error</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span>  <span class="title">test</span></span>[<span class="type">A</span>&gt;:<span class="type">User</span>]( a : <span class="type">A</span> ): <span class="type">Unit</span> = &#123;</span><br><span class="line">        println(a)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Parent</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">extends</span> <span class="title">Parent</span></span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">SubUser</span> <span class="keyword">extends</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="11-4-上下文限定"><a href="#11-4-上下文限定" class="headerlink" title="11.4 上下文限定"></a>11.4 上下文限定</h2><p>上下文限定是将泛型和隐式转换的结合产物，以下两者功能相同，使用上下文限定[A : Ordering]之后，方法内无法使用隐式参数名调用隐式参数，需要通过implicitly[Ordering[A]]获取隐式变量，如果此时无法查找到对应类型的隐式变量，会发生出错误。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaGeneric</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">f</span></span>[<span class="type">A</span> : <span class="type">Test</span>](a: <span class="type">A</span>) = println(a)</span><br><span class="line">        <span class="keyword">implicit</span> <span class="keyword">val</span> test : <span class="type">Test</span>[<span class="type">User</span>] = <span class="keyword">new</span> <span class="type">Test</span>[<span class="type">User</span>]</span><br><span class="line">        f( <span class="keyword">new</span> <span class="type">User</span>() )</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Test</span>[<span class="type">T</span>] </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Parent</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">extends</span> <span class="title">Parent</span></span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">SubUser</span> <span class="keyword">extends</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h1 id="第12章-正则表达式"><a href="#第12章-正则表达式" class="headerlink" title="第12章 正则表达式"></a>第12章 正则表达式</h1><h2 id="12-1-简介"><a href="#12-1-简介" class="headerlink" title="12.1 简介"></a>12.1 简介</h2><p>正则表达式(regular expression)描述了一种字符串匹配的模式（pattern），可以用来检查一个串是否含有某种子串、将匹配的子串替换或者从某个串中取出符合某个条件的子串等。</p>
<h2 id="12-2-基本语法"><a href="#12-2-基本语法" class="headerlink" title="12.2 基本语法"></a>12.2 基本语法</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaRegex</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 构建正则表达式</span></span><br><span class="line">        <span class="keyword">val</span> pattern = <span class="string">&quot;Scala&quot;</span>.r</span><br><span class="line">        <span class="keyword">val</span> str = <span class="string">&quot;Scala is Scalable Language&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 匹配字符串 - 第一个</span></span><br><span class="line">        println(pattern findFirstIn str)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 匹配字符串 - 所有</span></span><br><span class="line">        <span class="keyword">val</span> iterator: <span class="type">Regex</span>.<span class="type">MatchIterator</span> = pattern findAllIn str</span><br><span class="line">        <span class="keyword">while</span> ( iterator.hasNext ) &#123;</span><br><span class="line">            println(iterator.next())</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        println(<span class="string">&quot;***************************&quot;</span>)</span><br><span class="line">        <span class="comment">// 匹配规则：大写，小写都可</span></span><br><span class="line">        <span class="keyword">val</span> pattern1 = <span class="keyword">new</span> <span class="type">Regex</span>(<span class="string">&quot;(S|s)cala&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> str1 = <span class="string">&quot;Scala is scalable Language&quot;</span></span><br><span class="line">        println((pattern1 findAllIn str1).mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="12-2-案例实操"><a href="#12-2-案例实操" class="headerlink" title="12.2 案例实操"></a>12.2 案例实操</h2><ul>
<li>手机号正则表达式验证方法  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaRegex</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 构建正则表达式</span></span><br><span class="line">        println(isMobileNumber(<span class="string">&quot;18801234567&quot;</span>))</span><br><span class="line">        println(isMobileNumber(<span class="string">&quot;11111111111&quot;</span>))</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isMobileNumber</span></span>(number: <span class="type">String</span>): <span class="type">Boolean</span> =&#123;</span><br><span class="line">        <span class="keyword">val</span> regex = <span class="string">&quot;^((13[0-9])|(14[5,7,9])|(15[^4])|(18[0-9])|(17[0,1,3,5,6,7,8]))[0-9]&#123;8&#125;$&quot;</span>.r</span><br><span class="line">        <span class="keyword">val</span> length = number.length</span><br><span class="line">        regex.findFirstMatchIn(number.slice(length<span class="number">-11</span>,length)) != <span class="type">None</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>提取邮件地址的域名部分  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScalaRegex</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 构建正则表达式</span></span><br><span class="line">        <span class="keyword">val</span> r = <span class="string">&quot;&quot;&quot;([_A-Za-z0-9-]+(?:\.[_A-Za-z0-9-\+]+)*)(@[A-Za-z0-9-]+(?:\.[A-Za-z0-9-]+)*(?:\.[A-Za-z]&#123;2,&#125;)) ?&quot;&quot;&quot;</span>.r</span><br><span class="line">        println(r.replaceAllIn(<span class="string">&quot;abc.edf+jianli@gmail.com   hello@gmail.com.cn&quot;</span>, (m =&gt; <span class="string">&quot;*****&quot;</span> + m.group(<span class="number">2</span>))))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Scala/" rel="tag">Scala</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Kafka"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/19/Kafka/"
    >Kafka</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/19/Kafka/" class="article-date">
  <time datetime="2021-11-19T13:29:12.000Z" itemprop="datePublished">2021-11-19</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Kafka/">Kafka</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><h1 id="第1章-Kafka概述"><a href="#第1章-Kafka概述" class="headerlink" title="第1章 Kafka概述"></a>第1章 Kafka概述</h1><h2 id="1-1-定义"><a href="#1-1-定义" class="headerlink" title="1.1 定义"></a>1.1 定义</h2><ul>
<li>传统定义：Kafka是一个<font color ='red' >分布式</font>的基于<font color ='red' >发布/订阅模式</font>的<font color ='red' >消息队列（Message Queue）</font>，主要应用于大数据实时处理领域。</li>
<li>最新定义：Kafka是一个开源的分布式事件流平台（Event Streaming Platform），被数千家公司用于高性能数据管道、流分析、数据集成和关键任务应用。<br><img src="https://i.loli.net/2021/11/19/vEKlrIhO9zG5eJX.jpg"></li>
</ul>
<h2 id="1-2-消息队列"><a href="#1-2-消息队列" class="headerlink" title="1.2 消息队列"></a>1.2 消息队列</h2><h3 id="1-2-1-传统消息队列的应用场景"><a href="#1-2-1-传统消息队列的应用场景" class="headerlink" title="1.2.1 传统消息队列的应用场景"></a>1.2.1 传统消息队列的应用场景</h3><ol>
<li><p>缓冲/消峰：有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。<br> <img src="https://i.loli.net/2021/11/19/U5cl9Sw48B3pqGX.jpg"></p>
</li>
<li><p>解耦：允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。<br> <img src="https://i.loli.net/2021/11/19/18xKnaykRSQ2gEX.jpg"></p>
</li>
<li><p>异步通信：很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们<br> <img src="https://i.loli.net/2021/11/19/i5bymXpZ1EINc2J.jpg"></p>
</li>
</ol>
<h3 id="1-2-2-消息队列的两种模式"><a href="#1-2-2-消息队列的两种模式" class="headerlink" title="1.2.2 消息队列的两种模式"></a>1.2.2 消息队列的两种模式</h3><ol>
<li>点对点模式<ul>
<li>消费者主动拉取数据，消息收到后消息清除<br><img src="https://i.loli.net/2021/11/19/etVkIU9p6TOqjoz.jpg"></li>
</ul>
</li>
<li>发布/订阅模式<ul>
<li>可以有多个topic主题 </li>
<li>消费者消费数据之后，不删除数据</li>
<li>每个消费者相互独立，都可以消费到数据<br><img src="https://i.loli.net/2021/11/19/WwGPAJs58LiDMVe.jpg"></li>
</ul>
</li>
</ol>
<h2 id="1-3-Kafka基础架构"><a href="#1-3-Kafka基础架构" class="headerlink" title="1.3 Kafka基础架构"></a>1.3 Kafka基础架构</h2><p><img src="https://i.loli.net/2021/11/19/UQ93WOvw6DN4onj.jpg"></p>
<ol>
<li>设计思路<ul>
<li>为方便扩展，并提高吞吐量，一个topic分为多个partition</li>
<li> 配合分区的设计，提出消费者组的概念，组内每个消费者并行消费</li>
<li> 为提高可用性，为每个partition增加若干副本，类似NameNode HA</li>
<li> ZK中记录谁是leader，Kafka2.8.0以后也可以配置不采用ZK</li>
</ul>
</li>
<li>组件<ul>
<li> Producer：消息生产者，就是向Kafka broker发消息的客户端；</li>
<li> Consumer：消息消费者，向Kafka broker取消息的客户端；</li>
<li> Consumer Group（CG）：消费者组，由多个consumer组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</li>
<li> Broker：一台Kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。</li>
<li> Topic：可以理解为一个队列，生产者和消费者面向的都是一个topic；</li>
<li> Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列；</li>
<li> Replica：副本，为保证集群中的某个节点发生故障时，该节点上的partition数据不丢失，且Kafka仍然能够继续工作，Kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个Leader和若干个Follower。</li>
<li> Leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是Leader。</li>
<li> Follower：每个分区多个副本中的“从”，实时从Leader中同步数据，保持和Leader数据的同步。Leader发生故障时，某个Follower会成为新的Leader。</li>
</ul>
</li>
</ol>
<h1 id="第2章-Kafka快速入门"><a href="#第2章-Kafka快速入门" class="headerlink" title="第2章 Kafka快速入门"></a>第2章 Kafka快速入门</h1><h2 id="2-1-安装部署"><a href="#2-1-安装部署" class="headerlink" title="2.1 安装部署"></a>2.1 安装部署</h2><h3 id="2-1-1-集群规划"><a href="#2-1-1-集群规划" class="headerlink" title="2.1.1 集群规划"></a>2.1.1 集群规划</h3><table>
<thead>
<tr>
<th>hadoop001</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>zk</td>
<td>zk</td>
<td>zk</td>
</tr>
<tr>
<td>kafka</td>
<td>kafka</td>
<td>kafka</td>
</tr>
</tbody></table>
<h3 id="2-1-2-集群部署"><a href="#2-1-2-集群部署" class="headerlink" title="2.1.2 集群部署"></a>2.1.2 集群部署</h3><ol>
<li>官方下载地址：<a target="_blank" rel="noopener" href="http://kafka.apache.org/downloads.html">http://kafka.apache.org/downloads.html</a></li>
<li>解压安装包 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kafka_2.12-3.0.0.tgz -C /opt/module/</span><br></pre></td></tr></table></figure></li>
<li>配置环境变量  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 config]$ sudo vim /etc/profile.d/set_env.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#KAFKA_HOME</span></span><br><span class="line"><span class="built_in">export</span> KAFKA_HOME=/opt/module/kafka_2.12-3.0.0</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$KAFKA_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分发环境变量文件</span></span><br><span class="line"> xsync /etc/profile.d/set_env.sh</span><br></pre></td></tr></table></figure></li>
<li>进入到$KAFKA_HOME/config目录，修改配置文件server.properties输入以下内容 <figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#broker的全局唯一编号，不能重复</span></span><br><span class="line"><span class="meta">broker.id</span>=<span class="string">0</span></span><br><span class="line"><span class="comment">#处理网络请求的线程数量</span></span><br><span class="line"><span class="meta">num.network.threads</span>=<span class="string">3</span></span><br><span class="line"><span class="comment">#用来处理磁盘IO的线程数量</span></span><br><span class="line"><span class="meta">num.io.threads</span>=<span class="string">8</span></span><br><span class="line"><span class="comment">#发送套接字的缓冲区大小</span></span><br><span class="line"><span class="meta">socket.send.buffer.bytes</span>=<span class="string">102400</span></span><br><span class="line"><span class="comment">#接收套接字的缓冲区大小</span></span><br><span class="line"><span class="meta">socket.receive.buffer.bytes</span>=<span class="string">102400</span></span><br><span class="line"><span class="comment">#请求套接字的缓冲区大小</span></span><br><span class="line"><span class="meta">socket.request.max.bytes</span>=<span class="string">104857600</span></span><br><span class="line"><span class="comment">#kafka运行日志(数据)存放的路径，路径不需要提前创建，kafka自动帮你创建</span></span><br><span class="line"><span class="meta">log.dirs</span>=<span class="string">/opt/module/kafka/datas</span></span><br><span class="line"><span class="comment">#topic在当前broker上的分区个数</span></span><br><span class="line"><span class="meta">num.partitions</span>=<span class="string">1</span></span><br><span class="line"><span class="comment">#用来恢复和清理data下数据的线程数量</span></span><br><span class="line"><span class="meta">num.recovery.threads.per.data.dir</span>=<span class="string">1</span></span><br><span class="line"><span class="comment">#segment文件保留的最长时间，超时将被删除</span></span><br><span class="line"><span class="meta">log.retention.hours</span>=<span class="string">168</span></span><br><span class="line"><span class="comment">#配置连接Zookeeper集群地址（在zk根目录下创建/kafka，方便管理）</span></span><br><span class="line"><span class="meta">zookeeper.connect</span>=<span class="string">hadoop001:2181,hadoop002:2181,hadoop003:2181/kafka</span></span><br></pre></td></tr></table></figure></li>
<li>分发安装包 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /opt/module/kafka_2.12-3.0.0/</span><br></pre></td></tr></table></figure></li>
<li>在各个节点上修改配置文件$KAFKA_HOME/config/server.properties中的 <figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># hadoop002</span></span><br><span class="line"><span class="meta">broker.id</span>=<span class="string">1</span></span><br><span class="line"><span class="comment"># hadoop003</span></span><br><span class="line"><span class="meta">broker.id</span>=<span class="string">2</span></span><br><span class="line"><span class="comment"># hadoop004</span></span><br><span class="line"><span class="meta">broker.id</span>=<span class="string">3</span></span><br><span class="line"><span class="comment"># hadoop005</span></span><br><span class="line"><span class="meta">broker.id</span>=<span class="string">4</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：broker.id不得重复</p>
</blockquote>
</li>
<li>启动集群<ul>
<li>先启动Zookeeper集群，然后启动Kafka  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zookeeper_cluster.sh start</span><br></pre></td></tr></table></figure>
<blockquote>
<p>zookeeper_cluster.sh 参考<a href="mweblib://16343691008130">Zookeeper</a>篇《编写启动/停止Zookeeper集群脚本》</p>
</blockquote>
</li>
<li>依次在hadoop002、hadoop003、hadoop004,hadoop005节点上启动Kafka  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ kafka-server-start.sh -daemon <span class="variable">$KAFKA_HOME</span>/config/server.properties</span><br><span class="line">[atguigu@hadoop001 ~]$ ssh hadoop002 kafka-server-start.sh -daemon <span class="variable">$KAFKA_HOME</span>/config/server.properties</span><br><span class="line">[atguigu@hadoop001 ~]$ ssh hadoop003 kafka-server-start.sh -daemon <span class="variable">$KAFKA_HOME</span>/config/server.properties</span><br><span class="line">[atguigu@hadoop001 ~]$ ssh hadoop004 kafka-server-start.sh -daemon <span class="variable">$KAFKA_HOME</span>/config/server.properties</span><br><span class="line">[atguigu@hadoop001 ~]$ ssh hadoop005 kafka-server-start.sh -daemon <span class="variable">$KAFKA_HOME</span>/config/server.properties</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>关闭集群 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ kafka-server-stop.sh -daemon <span class="variable">$KAFKA_HOME</span>/config/server.properties</span><br><span class="line">[atguigu@hadoop001 ~]$ ssh hadoop002 kafka-server-stop.sh -daemon <span class="variable">$KAFKA_HOME</span>/config/server.properties</span><br><span class="line">[atguigu@hadoop001 ~]$ ssh hadoop003 kafka-server-stop.sh -daemon <span class="variable">$KAFKA_HOME</span>/config/server.properties</span><br><span class="line">[atguigu@hadoop001 ~]$ ssh hadoop004 kafka-server-stop.sh -daemon <span class="variable">$KAFKA_HOME</span>/config/server.properties</span><br><span class="line">[atguigu@hadoop001 ~]$ ssh hadoop005 kafka-server-stop.sh -daemon <span class="variable">$KAFKA_HOME</span>/config/server.properties</span><br></pre></td></tr></table></figure></li>
<li>Kafka启动失败的话可以暴力重置一下<ol>
<li>rm -rf /opt/module/kafka_2.12-3.0.0/logs/</li>
<li>删掉zookeeper /kafka</li>
<li>尝试重新启动</li>
</ol>
</li>
</ol>
<h3 id="2-1-3-集群启停脚本"><a href="#2-1-3-集群启停脚本" class="headerlink" title="2.1.3 集群启停脚本"></a>2.1.3 集群启停脚本</h3><ol>
<li>在/home/atguigu/bin目录下创建文件kf.sh脚本文件，脚本如下： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -lt 1 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;No Args Input...&quot;</span></span><br><span class="line">    <span class="built_in">exit</span> ;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)&#123;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> hadoop001 hadoop002 hadoop003 hadoop004 hadoop005</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------启动 <span class="variable">$i</span> Kafka-------&quot;</span></span><br><span class="line">        ssh <span class="variable">$i</span> <span class="string">&quot;kafka-server-start.sh -daemon <span class="variable">$KAFKA_HOME</span>/config/server.properties&quot;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)&#123;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> hadoop001 hadoop002 hadoop003 hadoop004 hadoop005</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------停止 <span class="variable">$i</span> Kafka-------&quot;</span></span><br><span class="line">        ssh <span class="variable">$i</span> <span class="string">&quot;kafka-server-stop.sh &quot;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line">*)</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Input Args Error...&quot;</span></span><br><span class="line">;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure></li>
<li>添加执行权限 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 bin]$ chmod +x kf.sh</span><br></pre></td></tr></table></figure></li>
<li>启动集群命令 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ kf.sh start</span><br></pre></td></tr></table></figure></li>
<li>停止集群命令 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ kf.sh stop</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="2-2-Kafka命令行操作"><a href="#2-2-Kafka命令行操作" class="headerlink" title="2.2 Kafka命令行操作"></a>2.2 Kafka命令行操作</h2><p><img src="https://i.loli.net/2021/11/19/CJ8xFmjYL6tkrMz.jpg"></p>
<h3 id="2-2-1-topic命令行操作"><a href="#2-2-1-topic命令行操作" class="headerlink" title="2.2.1 topic命令行操作"></a>2.2.1 topic命令行操作</h3><ol>
<li><p>查看操作topic命令参数kafka-topics.sh</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>–bootstrap-server<a href="String:servertoconnectto">String:servertoconnectto</a></td>
<td>连接的KafkaBroker主机名称和端口号</td>
</tr>
<tr>
<td>–topic<a href="String:topic">String:topic</a></td>
<td>操作的topic名称</td>
</tr>
<tr>
<td>–create</td>
<td>创建主题</td>
</tr>
<tr>
<td>–delete</td>
<td>删除主题</td>
</tr>
<tr>
<td>–alter</td>
<td>修改主题</td>
</tr>
<tr>
<td>–list</td>
<td>查看所有主题</td>
</tr>
<tr>
<td>–describe</td>
<td>查看主题详细描述</td>
</tr>
<tr>
<td>–partitions<a href="Integer:#ofpartitions">Integer:#ofpartitions</a></td>
<td>设置分区数</td>
</tr>
<tr>
<td>–replication-factor<a href="Integer:replicationfactor">Integer:replicationfactor</a></td>
<td>设置分区副本</td>
</tr>
<tr>
<td>–config<a href="String:name=value">String:name=value</a></td>
<td>更新系统默认的配置</td>
</tr>
</tbody></table>
</li>
<li><p>查看当前服务器中的所有topic</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --bootstrap-server hadoop001:9092 --list</span><br></pre></td></tr></table></figure></li>
<li><p>创建topic</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 bin]$ kafka-topics.sh --bootstrap-server hadoop001:9092 --create --replication-factor 2 --partitions 1 --topic first</span><br><span class="line">Created topic first.</span><br><span class="line">[atguigu@hadoop001 bin]$ kafka-topics.sh --bootstrap-server hadoop001:9092 --list</span><br><span class="line">first</span><br><span class="line">[atguigu@hadoop001 bin]$</span><br></pre></td></tr></table></figure>
<ul>
<li>选项说明：<ul>
<li>–topic 定义topic名</li>
<li>–replication-factor  定义副本数</li>
<li>–partitions  定义分区数</li>
</ul>
</li>
</ul>
</li>
<li><p>查看某个Topic的详情</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">   [atguigu@hadoop001 bin]$ kafka-topics.sh --bootstrap-server hadoop001:9092 --describe --topic first</span><br><span class="line">   Topic: first	TopicId: wF2_VwRXR1q7l6MMamjZyg	PartitionCount: 1	ReplicationFactor: 2	Configs: segment.bytes=1073741824</span><br><span class="line">Topic: first	Partition: 0	Leader: 4	Replicas: 4,2	Isr: 4,2</span><br></pre></td></tr></table></figure></li>
<li><p>修改分区数</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 bin]$ kafka-topics.sh --bootstrap-server hadoop001:9092 --describe --topic first</span><br><span class="line">Topic: first	TopicId: wF2_VwRXR1q7l6MMamjZyg	PartitionCount: 3	ReplicationFactor: 2	Configs: segment.bytes=1073741824</span><br><span class="line">	Topic: first	Partition: 0	Leader: 4	Replicas: 4,2	Isr: 4,2</span><br><span class="line">	Topic: first	Partition: 1	Leader: 0	Replicas: 0,2	Isr: 0,2</span><br><span class="line">	Topic: first	Partition: 2	Leader: 2	Replicas: 2,4	Isr: 2,4</span><br><span class="line">[atguigu@hadoop001 bin]$</span><br></pre></td></tr></table></figure></li>
<li><p>删除topic</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 bin]$ kafka-topics.sh --bootstrap-server hadoop001:9092 --delete --topic first</span><br><span class="line">[atguigu@hadoop001 bin]$ kafka-topics.sh --bootstrap-server hadoop001:9092 --list</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop001 bin]$</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-2-2-生产者命令行操作"><a href="#2-2-2-生产者命令行操作" class="headerlink" title="2.2.2 生产者命令行操作"></a>2.2.2 生产者命令行操作</h3><ol>
<li>查看操作生产者命令参数<code>kafka-console-producer.sh</code><table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>–bootstrap-server &lt;String: server toconnect to&gt;</td>
<td>连接的Kafka Broker主机名称和端口号</td>
</tr>
<tr>
<td>–topic &lt;String: topic&gt;</td>
<td>操作的topic名称</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody></table>
</li>
<li>发送消息 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 bin]$ kafka-console-producer.sh --bootstrap-server hadoop001:9092 --topic first</span><br><span class="line">&gt;hello world</span><br><span class="line">&gt;atguigu atguigu</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-2-3-针对消费者相关命令大全"><a href="#2-2-3-针对消费者相关命令大全" class="headerlink" title="2.2.3 针对消费者相关命令大全"></a>2.2.3 针对消费者相关命令大全</h3><ol>
<li>查看操作消费者命令参数 kafka-console-consumer.sh<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>–bootstrap-server &lt;String: server toconnect to&gt;</td>
<td>连接的Kafka Broker主机名称和端口号</td>
</tr>
<tr>
<td>–topic &lt;String: topic&gt;</td>
<td>操作的topic名称</td>
</tr>
<tr>
<td>–group &lt;String: consumer group id&gt;</td>
<td>指定消费者组名称</td>
</tr>
<tr>
<td>–partition &lt;Integer: partition&gt;</td>
<td>指定消费哪个分区数据</td>
</tr>
<tr>
<td>–offset &lt;String: consume offset&gt;</td>
<td>指定从什么位置消费</td>
</tr>
<tr>
<td>–from-beginning</td>
<td>从头开始消费</td>
</tr>
</tbody></table>
</li>
<li>消费消息 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server hadoop001:9092 --topic first</span><br><span class="line"></span><br><span class="line">kafka-console-consumer.sh --bootstrap-server hadoop001:9092 --from-beginning --topic first</span><br></pre></td></tr></table></figure>
<ul>
<li>–from-beginning：会把主题中现有的所有的数据都读取出来。</li>
</ul>
</li>
</ol>
<h1 id="第3章-Kafka生产者"><a href="#第3章-Kafka生产者" class="headerlink" title="第3章 Kafka生产者"></a>第3章 Kafka生产者</h1><h2 id="3-1-消息发送流程"><a href="#3-1-消息发送流程" class="headerlink" title="3.1 消息发送流程"></a>3.1 消息发送流程</h2><p><img src="https://i.loli.net/2021/11/19/NphlWrxSzD6UsJC.jpg"></p>
<ul>
<li><p>在消息发送过程中，涉及到两个线程，以及一个中间队列-RecordAccumulator.</p>
<ul>
<li>一是主线程，负责将消息进行封装和加工发送给消息中间件（RecordAccumulator）</li>
<li>二是send线程，负责从消息中间件中拉取数据发送到主题（Topic）的对应分区（Partition）</li>
</ul>
</li>
<li><p>流程描述</p>
<ul>
<li>main线程<ol>
<li>生产将要发送的数据封装成ProducerRecord对象，目的是发送到消息中间件</li>
<li>中间要经过拦截器列表、序列化器和分区器将消息发送到消息中间件</li>
<li>RecordAccumulator中有多个队列，与topic的分区相对应。消息发送时直接发送到分区对应的RecordAccumulator队列中</li>
</ol>
</li>
<li>sender线程<ol>
<li>当RecordAccumulator中攒够一批数据后，即达到指定量的数据之后，Sender线程将这一批数据拉取并发送给Topic。<ul>
<li>batch.size：只有数据积累到batch.size之后，sender才会发送数据。默认16k</li>
</ul>
</li>
<li>同时，如果RecordAccumulator中队列迟迟到不到指定量的数据时，会等到一定时长时发送。<ul>
<li>linger.ms：如果数据迟迟未达到batch.size，sender等待linger.time之后就会发送数据。单位ms，默认值是0ms，表示没有延迟。</li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
<li><p>生产者相关调优参数</p>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>batch.size</td>
<td>缓冲区一批数据最大值，默认16k</td>
</tr>
<tr>
<td>linger.ms</td>
<td>如果数据迟迟未达到batch.size，sender等待linger.time之后就会发送数据。单位ms，默认值是0ms，表示没有延迟。</td>
</tr>
<tr>
<td>buffer.memory    RecordAccumulator</td>
<td>缓冲区总大小，默认32m</td>
</tr>
<tr>
<td>retries</td>
<td>当消息发送出现错误的时候，系统会重发消息。retries表示重试次数。</td>
</tr>
<tr>
<td>compression.type</td>
<td>生产者发送的所有数据的压缩方式。默认是none，也就是不压缩。 支持的值：none、gzip、snappy、lz4和zstd。</td>
</tr>
</tbody></table>
</li>
</ul>
<h2 id="3-2-异步发送API"><a href="#3-2-异步发送API" class="headerlink" title="3.2 异步发送API"></a>3.2 异步发送API</h2><h3 id="3-2-1-普通异步发送"><a href="#3-2-1-普通异步发送" class="headerlink" title="3.2.1 普通异步发送"></a>3.2.1 普通异步发送</h3><p><img src="https://i.loli.net/2021/11/19/z6wBqsD5gpbU3rh.jpg"></p>
<ol>
<li>需求：创建Kafka生产者，采用异步的方式发送到Kafka Broker</li>
<li>编码实现<ol>
<li>maven依赖 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>编码 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 给kafka配置对象添加配置信息：bootstrap.servers</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop001:9092,hadoop002:9092,hadoop003:9092,hadoop004:9092,hadoop005:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// key,value序列化（必须）：key.serializer，value.serializer</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 批次大小 默认16K：batch.size</span></span><br><span class="line">        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">16384</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 等待时间：linger.ms</span></span><br><span class="line">        properties.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// RecordAccumulator缓冲区大小 默认32M：buffer.memory</span></span><br><span class="line">        properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG, <span class="number">33554432</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 创建kafka生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 调用send方法,发送消息</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">&quot;first&quot;</span>,<span class="string">&quot;i am producer &quot;</span> + i));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>测试：<ol>
<li>在hadoop001上开启Kafka消费者。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 kafka]$ bin/kafka-console-consumer.sh --bootstrap-server hadoop001:9092 --topic first</span><br></pre></td></tr></table></figure></li>
<li>在IDEA中执行代码，观察hadoop001控制台中是否接收到消息。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 kafka]$  bin/kafka-console-consumer.sh --bootstrap-server hadoop001:9092 --topic first</span><br><span class="line"></span><br><span class="line">atguigu 0</span><br><span class="line">atguigu 1</span><br><span class="line">atguigu 2</span><br><span class="line">atguigu 3</span><br><span class="line">atguigu 4</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="3-2-2-带回调函数的异步发送"><a href="#3-2-2-带回调函数的异步发送" class="headerlink" title="3.2.2 带回调函数的异步发送"></a>3.2.2 带回调函数的异步发送</h3><p>回调函数会在producer收到ack时调用，为异步调用，该方法有两个参数，分别是元数据信息（RecordMetadata）和异常信息（Exception），如果Exception为null，说明消息发送成功，如果Exception不为null，说明消息发送失败。<br><img src="https://i.loli.net/2021/11/19/f7Y9QgpN8LCdiGs.jpg"></p>
<blockquote>
<p>注意：消息发送失败会自动重试，不需要我们在回调函数中手动重试。</p>
</blockquote>
<ol>
<li>编码 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducerCallback</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建kafka生产者的配置对象</span></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 给kafka配置对象添加配置信息：bootstrap.servers</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop001:9092,hadoop002:9092,hadoop003:9092,hadoop004:9092,hadoop005:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// key,value序列化（必须）：key.serializer，value.serializer</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 批次大小 默认16K：batch.size</span></span><br><span class="line">        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">16384</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 等待时间：linger.ms</span></span><br><span class="line">        properties.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// RecordAccumulator缓冲区大小 默认32M：buffer.memory</span></span><br><span class="line">        properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG, <span class="number">33554432</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 创建kafka生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 调用send方法,发送消息</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 添加回调</span></span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;atguigu &quot;</span> + i), <span class="keyword">new</span> Callback() &#123;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 该方法在Producer收到ack时调用，为异步调用</span></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> (exception == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        <span class="comment">// 没有异常,输出信息到控制台</span></span><br><span class="line">                        System.out.println(<span class="string">&quot;onCompletion 主题：&quot;</span> + metadata.topic() + <span class="string">&quot;-&gt;&quot;</span> + <span class="string">&quot;分区：&quot;</span> + metadata.partition());</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">// 出现异常打印</span></span><br><span class="line">                        exception.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 延迟一会会看到数据发往不同分区</span></span><br><span class="line">            Thread.sleep(<span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>测试   <ol>
<li>在hadoop001上开启Kafka消费者。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 kafka]$ bin/kafka-console-consumer.sh --bootstrap-server hadoop001:9092 --topic first</span><br></pre></td></tr></table></figure></li>
<li>在IDEA中执行代码，观察hadoop001控制台中是否接收到消息。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 kafka]$  bin/kafka-console-consumer.sh --bootstrap-server hadoop001:9092 --topic first</span><br><span class="line">atguigu 0</span><br><span class="line">atguigu 1</span><br><span class="line">atguigu 2</span><br><span class="line">atguigu 3</span><br><span class="line">atguigu 4</span><br></pre></td></tr></table></figure></li>
<li>在IDEA控制台观察回调信息 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">onCompletion 主题：first-&gt;分区：2</span><br><span class="line">onCompletion 主题：first-&gt;分区：1</span><br><span class="line">onCompletion 主题：first-&gt;分区：1</span><br><span class="line">onCompletion 主题：first-&gt;分区：0</span><br><span class="line">onCompletion 主题：first-&gt;分区：2</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h2 id="3-3-同步发送API"><a href="#3-3-同步发送API" class="headerlink" title="3.3 同步发送API"></a>3.3 同步发送API</h2><p><img src="https://i.loli.net/2021/11/19/f1SAOroePk75mbG.jpg"><br>由于send方法返回的是一个Future对象，根据Futrue对象的特点，我们也可以实现同步发送的效果，只需在调用Future对象的get方法即可。</p>
<ol>
<li>编码 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducerSync</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException, ExecutionException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建kafka生产者的配置对象</span></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 给kafka配置对象添加配置信息</span></span><br><span class="line">        <span class="comment">// properties.put(&quot;bootstrap.servers&quot;,&quot;hadoop001:9092&quot;);</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop001:9092,hadoop002:9092,hadoop003:9092,hadoop004:9092,hadoop005:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// key,value序列化（必须）：key.serializer，value.serializer</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 批次大小 默认16K：batch.size</span></span><br><span class="line">        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">16384</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 等待时间：linger.ms</span></span><br><span class="line">        properties.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// RecordAccumulator缓冲区大小 默认32M：buffer.memory</span></span><br><span class="line">        properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG, <span class="number">33554432</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置ack</span></span><br><span class="line">        <span class="comment">// properties.put(&quot;acks&quot;, &quot;all&quot;);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 重试次数</span></span><br><span class="line">        <span class="comment">// properties.put(&quot;retries&quot;, 3);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 创建kafka生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 调用send方法,发送消息</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 异步发送 默认</span></span><br><span class="line"><span class="comment">//            kafkaProducer.send(new ProducerRecord&lt;&gt;(&quot;first&quot;,&quot;kafka&quot; + i));</span></span><br><span class="line">            <span class="comment">// 同步发送</span></span><br><span class="line">            <span class="keyword">final</span> Future&lt;RecordMetadata&gt; future = kafkaProducer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;kafka&quot;</span> + i));</span><br><span class="line">            <span class="keyword">final</span> RecordMetadata recordMetadata = future.get();</span><br><span class="line">            System.out.println(<span class="string">&quot;topic:&quot;</span> + recordMetadata.topic() + <span class="string">&quot;--&gt;&quot;</span> + <span class="string">&quot;partition&quot;</span> + recordMetadata.partition());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>测试<ol>
<li>在hadoop001上开启Kafka消费者。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 kafka]$ bin/kafka-console-consumer.sh --bootstrap-server hadoop001:9092 --topic first</span><br></pre></td></tr></table></figure></li>
<li>在IDEA中执行代码，观察hadoop001控制台中是否接收到消息。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 kafka]$  bin/kafka-console-consumer.sh --bootstrap-server hadoop001:9092 --topic first</span><br><span class="line">kafka0</span><br><span class="line">kafka1</span><br><span class="line">kafka2</span><br><span class="line">kafka3</span><br><span class="line">kafka4</span><br><span class="line">kafka5</span><br><span class="line">kafka6</span><br><span class="line">kafka7</span><br><span class="line">kafka8</span><br><span class="line">kafka9</span><br></pre></td></tr></table></figure></li>
<li>在IDEA控制台观察同步返回结果 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">topic:first--&gt;partition0</span><br><span class="line">topic:first--&gt;partition2</span><br><span class="line">topic:first--&gt;partition1</span><br><span class="line">topic:first--&gt;partition0</span><br><span class="line">topic:first--&gt;partition1</span><br><span class="line">topic:first--&gt;partition2</span><br><span class="line">topic:first--&gt;partition0</span><br><span class="line">topic:first--&gt;partition1</span><br><span class="line">topic:first--&gt;partition2</span><br><span class="line">topic:first--&gt;partition0</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h2 id="3-4-生产者分区"><a href="#3-4-生产者分区" class="headerlink" title="3.4 生产者分区"></a>3.4 生产者分区</h2><h3 id="3-4-1-分区的好处"><a href="#3-4-1-分区的好处" class="headerlink" title="3.4.1 分区的好处"></a>3.4.1 分区的好处</h3><p><img src="https://i.loli.net/2021/11/19/e8UvXuCBkH92pN6.jpg"></p>
<ol>
<li><font color ='red' >便于合理使用存储资源</font>，每个Partition在一个Broker上存储一部分数据，如果Broker足够多，那么就可以设置足够多的分区，因此整个集群就可以存储任意大小的数据了；</li>
<li><font color ='red' >提高并发度</font>，消费者可以以分区为单位进行消费。</li>
</ol>
<h3 id="3-4-2-生产者发送消息的分区策略"><a href="#3-4-2-生产者发送消息的分区策略" class="headerlink" title="3.4.2 生产者发送消息的分区策略"></a>3.4.2 生产者发送消息的分区策略</h3><ol>
<li><p>默认的分区器 DefaultPartitioner</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DefaultPartitioner</span> <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line">    ···</span><br><span class="line">    ···</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster,</span></span></span><br><span class="line"><span class="params"><span class="function">                         <span class="keyword">int</span> numPartitions)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (keyBytes == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> stickyPartitionCache.partition(topic, cluster);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// hash the keyBytes to choose a partition</span></span><br><span class="line">        <span class="keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line">    ···</span><br><span class="line">    ···</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>ProducerRecord</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerRecord</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 指明partition的情况下，直接将指明的值作为partiton值。</span></span><br><span class="line"><span class="comment">    * 例如partition=0，所有数据写入分区0</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ProducerRecord</span><span class="params">(String topic, Integer partition, Long timestamp, K key, V value, Iterable&lt;Header&gt; headers)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (topic == <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;Topic cannot be null.&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (timestamp != <span class="keyword">null</span> &amp;&amp; timestamp &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</span><br><span class="line">                    String.format(<span class="string">&quot;Invalid timestamp: %d. Timestamp should always be non-negative or null.&quot;</span>, timestamp));</span><br><span class="line">        <span class="keyword">if</span> (partition != <span class="keyword">null</span> &amp;&amp; partition &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</span><br><span class="line">                    String.format(<span class="string">&quot;Invalid partition: %d. Partition number should always be non-negative or null.&quot;</span>, partition));</span><br><span class="line">        <span class="keyword">this</span>.topic = topic;</span><br><span class="line">        <span class="keyword">this</span>.partition = partition;</span><br><span class="line">        <span class="keyword">this</span>.key = key;</span><br><span class="line">        <span class="keyword">this</span>.value = value;</span><br><span class="line">        <span class="keyword">this</span>.timestamp = timestamp;</span><br><span class="line">        <span class="keyword">this</span>.headers = <span class="keyword">new</span> RecordHeaders(headers);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ProducerRecord</span><span class="params">(String topic, Integer partition, Long timestamp, K key, V value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(topic, partition, timestamp, key, value, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ProducerRecord</span><span class="params">(String topic, Integer partition, K key, V value, Iterable&lt;Header&gt; headers)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(topic, partition, <span class="keyword">null</span>, key, value, headers);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ProducerRecord</span><span class="params">(String topic, Integer partition, K key, V value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(topic, partition, <span class="keyword">null</span>, key, value, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    * 没有指明partition值但有key的情况下，将key的hash值与topic的partition数进行取余得到partition值；</span></span><br><span class="line"><span class="comment">    * 例如：key1的hash值=5， key2的hash值=6 ，topic的partition数=2，那么key1 对应的value1写入1号分区，key2对应的value2写入0号分区。</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ProducerRecord</span><span class="params">(String topic, K key, V value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(topic, <span class="keyword">null</span>, <span class="keyword">null</span>, key, value, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    * 既没有partition值又没有key值的情况下，Kafka采用Sticky Partition（黏性分区器），会随机选择一个分区，并尽可能一直使用该分区，待该分区的batch已满或者已完成，Kafka再随机一个分区进行使用（和上一次的分区不同）。</span></span><br><span class="line"><span class="comment">    * 例如：第一次随机选择0号分区，等0号分区当前批次满了（16k）或者linger.ms设置的时间到， Kafka再随机一个分区进行使用（如果还是0会继续随机）。</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ProducerRecord</span><span class="params">(String topic, V value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(topic, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>, value, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>源码跟踪</p>
<ul>
<li>KafkaProducer#send(ProducerRecord&lt;K,V&gt;)</li>
<li>KafkaProducer#doSend</li>
<li>KafkaProducer#partition  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(ProducerRecord&lt;K, V&gt; record, <span class="keyword">byte</span>[] serializedKey, <span class="keyword">byte</span>[] serializedValue, Cluster cluster)</span> </span>&#123;</span><br><span class="line">    Integer partition = record.partition();</span><br><span class="line">    <span class="keyword">return</span> partition != <span class="keyword">null</span> ?</span><br><span class="line">            partition :</span><br><span class="line">            partitioner.partition(</span><br><span class="line">                    record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>将数据发往指定partition的情况下，例如，将所有数据发往分区1中。</p>
<ol>
<li>编码 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">public class CustomProducerCallbackPartitions &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        // 1. 创建kafka生产者的配置对象</span><br><span class="line">        Properties properties = new Properties();</span><br><span class="line"></span><br><span class="line">        // 2. 给kafka配置对象添加配置信息</span><br><span class="line">        // properties.put(<span class="string">&quot;bootstrap.servers&quot;</span>,<span class="string">&quot;hadoop001:9092&quot;</span>);</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop001:9092,hadoop002:9092,hadoop003:9092,hadoop004:9092,hadoop005:9092&quot;</span>);</span><br><span class="line">        // key,value序列化（必须）：key.serializer，value.serializer</span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = new KafkaProducer&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (int i = 0; i &lt; 5; i++) &#123;</span><br><span class="line">            // 指定数据发送到1号分区，key为空（IDEA中ctrl + p查看参数）</span><br><span class="line">            kafkaProducer.send(new ProducerRecord&lt;&gt;(<span class="string">&quot;first&quot;</span>, 1,<span class="string">&quot;&quot;</span>,<span class="string">&quot;kafka  &quot;</span> + i), new <span class="function"><span class="title">Callback</span></span>() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void onCompletion(RecordMetadata recordMetadata, Exception e) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (e == null)&#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;onCompletion 主题：&quot;</span> + recordMetadata.topic() + <span class="string">&quot;-&gt;&quot;</span> + <span class="string">&quot;分区：&quot;</span> + recordMetadata.partition()</span><br><span class="line">                        );</span><br><span class="line">                    &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>测试<ol>
<li>在hadoop001上开启Kafka消费者。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 kafka]$ bin/kafka-console-consumer.sh --bootstrap-server hadoop001:9092 --topic first</span><br></pre></td></tr></table></figure></li>
<li>在IDEA中执行代码，观察hadoop001控制台中是否接收到消息。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 kafka]$  bin/kafka-console-consumer.sh --bootstrap-server hadoop001:9092 --topic first</span><br><span class="line">atguigu 0</span><br><span class="line">atguigu 1</span><br><span class="line">atguigu 2</span><br><span class="line">atguigu 3</span><br><span class="line">atguigu 4</span><br></pre></td></tr></table></figure></li>
<li>在IDEA控制台观察回调信息 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">onCompletion 主题：first-&gt;分区：1</span><br><span class="line">onCompletion 主题：first-&gt;分区：1</span><br><span class="line">onCompletion 主题：first-&gt;分区：1</span><br><span class="line">onCompletion 主题：first-&gt;分区：1</span><br><span class="line">onCompletion 主题：first-&gt;分区：1</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</li>
<li><p>没有指明partition值但有key的情况下，将key的字节数组hash值与topic的partition数进行取余得到partition值；</p>
<ol>
<li>编码 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducerCallbackWithoutPartition</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">            <span class="comment">// 1. 创建kafka生产者的配置对象</span></span><br><span class="line">            Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">    </span><br><span class="line">            <span class="comment">// 2. 给kafka配置对象添加配置信息</span></span><br><span class="line">            <span class="comment">// properties.put(&quot;bootstrap.servers&quot;,&quot;hadoop001:9092&quot;);</span></span><br><span class="line">            properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop001:9092,hadoop002:9092,hadoop003:9092,hadoop004:9092,hadoop005:9092&quot;</span>);</span><br><span class="line">            <span class="comment">// key,value序列化（必须）：key.serializer，value.serializer</span></span><br><span class="line">            properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">            properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">            KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);</span><br><span class="line">    </span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">                <span class="comment">// 依次指定key值为i ，数据key的hash值与3个分区求余，分别发往1、2、0</span></span><br><span class="line">                <span class="keyword">int</span> finalI = i;</span><br><span class="line">                kafkaProducer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">&quot;first&quot;</span>, i + <span class="string">&quot;&quot;</span>, <span class="string">&quot;atguigu &quot;</span> + i), <span class="keyword">new</span> Callback() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> </span>&#123;</span><br><span class="line">                        <span class="keyword">if</span> (e == <span class="keyword">null</span>) &#123;</span><br><span class="line">                            System.out.println(<span class="string">&quot;key:&quot;</span> + finalI + <span class="string">&quot; 主题：&quot;</span> + recordMetadata.topic() + <span class="string">&quot;-&gt;&quot;</span></span><br><span class="line">                                    + <span class="string">&quot;分区：&quot;</span> + recordMetadata.partition()</span><br><span class="line">                            );</span><br><span class="line">                        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            e.printStackTrace();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;</span><br><span class="line">    </span><br><span class="line">            kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>测试<ol>
<li>在hadoop001上开启Kafka消费者。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 kafka]$ bin/kafka-console-consumer.sh --bootstrap-server hadoop001:9092 --topic first</span><br></pre></td></tr></table></figure></li>
<li>在IDEA中执行代码，观察hadoop001控制台中是否接收到消息。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 kafka]$  bin/kafka-console-consumer.sh --bootstrap-server hadoop001:9092 --topic first</span><br><span class="line">atguigu 0</span><br><span class="line">atguigu 2</span><br><span class="line">atguigu 3</span><br><span class="line">atguigu 9</span><br><span class="line">atguigu 1</span><br><span class="line">atguigu 5</span><br><span class="line">atguigu 7</span><br><span class="line">atguigu 8</span><br><span class="line">atguigu 4</span><br><span class="line">atguigu 6</span><br></pre></td></tr></table></figure></li>
<li>在IDEA控制台观察回调信息 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">key:0 主题：first-&gt;分区：2</span><br><span class="line">key:2 主题：first-&gt;分区：2</span><br><span class="line">key:3 主题：first-&gt;分区：2</span><br><span class="line">key:9 主题：first-&gt;分区：2</span><br><span class="line">key:1 主题：first-&gt;分区：0</span><br><span class="line">key:5 主题：first-&gt;分区：0</span><br><span class="line">key:7 主题：first-&gt;分区：0</span><br><span class="line">key:8 主题：first-&gt;分区：0</span><br><span class="line">key:4 主题：first-&gt;分区：1</span><br><span class="line">key:6 主题：first-&gt;分区：1</span><br></pre></td></tr></table></figure>
<h3 id="3-4-3-自定义分区器"><a href="#3-4-3-自定义分区器" class="headerlink" title="3.4.3 自定义分区器"></a>3.4.3 自定义分区器</h3>研发人员可以根据企业需求，自己重新实现分区器。</li>
</ol>
</li>
</ol>
</li>
<li><p>需求<br> 实现一个分区器，发送过来的数据中如果包含atguigu，就发往0号分区，不包含atguigu，就发往1号分区</p>
</li>
<li><p>实现步骤</p>
<ol>
<li>定义类实现Partitioner接口</li>
<li>重写partition()方法</li>
</ol>
</li>
<li><p>自定义分区器编码</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducerCallbackUsingMyPartition</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop001:9092,hadoop002:9092,hadoop003:9092,hadoop004:9092,hadoop005:9092&quot;</span>);</span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        properties.put(<span class="string">&quot;batch.size&quot;</span>, <span class="number">16384</span>);</span><br><span class="line">        properties.put(<span class="string">&quot;linger.ms&quot;</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        properties.put(<span class="string">&quot;buffer.memory&quot;</span>,<span class="number">33554432</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 添加自定义分区器</span></span><br><span class="line">        properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, MyPartitioner.class.getName());</span><br><span class="line"></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line"></span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">&quot;first&quot;</span>, i % <span class="number">2</span> == <span class="number">0</span> ? <span class="string">&quot;atguigu &quot;</span> + i : i + <span class="string">&quot;&quot;</span>), <span class="keyword">new</span> Callback() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">if</span> (e == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;主题：&quot;</span> + recordMetadata.topic() + <span class="string">&quot;-&gt;&quot;</span></span><br><span class="line">                                + <span class="string">&quot;分区：&quot;</span> + recordMetadata.partition()</span><br><span class="line">                        );</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>使用分区器的方法，在生产者的配置中添加分区器参数</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducerCallbackUsingMyPartition</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop001:9092,hadoop002:9092,hadoop003:9092,hadoop004:9092,hadoop005:9092&quot;</span>);</span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        properties.put(<span class="string">&quot;batch.size&quot;</span>, <span class="number">16384</span>);</span><br><span class="line">        properties.put(<span class="string">&quot;linger.ms&quot;</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        properties.put(<span class="string">&quot;buffer.memory&quot;</span>,<span class="number">33554432</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 添加自定义分区器</span></span><br><span class="line">        properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, MyPartitioner.class.getName());</span><br><span class="line"></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line"></span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">&quot;first&quot;</span>, i % <span class="number">2</span> == <span class="number">0</span> ? <span class="string">&quot;atguigu &quot;</span> + i : i + <span class="string">&quot;&quot;</span>), <span class="keyword">new</span> Callback() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">if</span> (e == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;主题：&quot;</span> + recordMetadata.topic() + <span class="string">&quot;-&gt;&quot;</span></span><br><span class="line">                                + <span class="string">&quot;分区：&quot;</span> + recordMetadata.partition()</span><br><span class="line">                        );</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>测试</p>
<ol>
<li>在hadoop001上开启Kafka消费者。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server hadoop001:9092 --topic first</span><br><span class="line">atguigu 0</span><br><span class="line">atguigu 2</span><br><span class="line">atguigu 4</span><br><span class="line">1</span><br><span class="line">3</span><br></pre></td></tr></table></figure></li>
<li>在IDEA控制台观察回调信息 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">主题：first-&gt;分区：0</span><br><span class="line">主题：first-&gt;分区：0</span><br><span class="line">主题：first-&gt;分区：0</span><br><span class="line">主题：first-&gt;分区：1</span><br><span class="line">主题：first-&gt;分区：1</span><br></pre></td></tr></table></figure>
<h1 id="第4章-Kafka-Broker"><a href="#第4章-Kafka-Broker" class="headerlink" title="第4章 Kafka Broker"></a>第4章 Kafka Broker</h1><h2 id="4-1-Kafka-Broker工作流程"><a href="#4-1-Kafka-Broker工作流程" class="headerlink" title="4.1 Kafka Broker工作流程"></a>4.1 Kafka Broker工作流程</h2><h3 id="4-1-1-Zookeeper中存储的Kafka信息"><a href="#4-1-1-Zookeeper中存储的Kafka信息" class="headerlink" title="4.1.1 Zookeeper中存储的Kafka信息"></a>4.1.1 Zookeeper中存储的Kafka信息</h3><img src="https://i.loli.net/2021/11/19/h7ixP2akuVMmpQT.jpg"></li>
</ol>
</li>
<li><p>在zookeeper的服务端存储的Kafka相关信息：</p>
<ul>
<li><code>/kafka/admin</code>: 存储管理信息。主要为删除主题事件，分区迁移事件，优先副本选举信息 (一般为临时节点)</li>
<li><code>/kafka/brokers</code>: 存储 Broker 相关信息。broker 节点以及节点上的主题相关信息<ul>
<li><code>/kafka/brokers/topics/[topic]</code>: 存储某个topic的partitions所有分配信息  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;removing_replicas&quot;</span>: &#123;&#125;,</span><br><span class="line">  <span class="attr">&quot;partitions&quot;</span>: &#123; </span><br><span class="line">      <span class="attr">&quot;2&quot;</span>: [<span class="number">3</span>, <span class="number">4</span>], # 同步副本组brokerId列表</span><br><span class="line">      <span class="attr">&quot;1&quot;</span>: [<span class="number">2</span>, <span class="number">3</span>], </span><br><span class="line">      <span class="attr">&quot;0&quot;</span>: [<span class="number">1</span>, <span class="number">2</span>] </span><br><span class="line">    &#125;,</span><br><span class="line">  <span class="attr">&quot;topic_id&quot;</span>: <span class="string">&quot;wuuibxosTj2iZnI-8pknXw&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;adding_replicas&quot;</span>: &#123;&#125;,</span><br><span class="line">  <span class="attr">&quot;version&quot;</span>: <span class="number">3</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><code>/kafka/brokers/topics/[topic]/partitions/[broker.id]/state</code>: partition状态信息,记录谁是Leader，有哪些服务器可用  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;controller_epoch&quot;</span>: <span class="number">1</span>, #表示kafka集群中的中央控制器选举次数</span><br><span class="line">  <span class="attr">&quot;leader&quot;</span>: <span class="number">3</span>, #表示该partition选举leader的brokerId,</span><br><span class="line">  <span class="attr">&quot;version&quot;</span>: <span class="number">1</span>,</span><br><span class="line">  <span class="attr">&quot;leader_epoch&quot;</span>: <span class="number">0</span>, #该partition leader选举次数</span><br><span class="line">  <span class="attr">&quot;isr&quot;</span>: [<span class="number">3</span>, <span class="number">4</span>] #[同步副本组brokerId列表]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><code>/kafka/brokers/ids[0...N]</code>: 记录有哪些服务器, 每个broker的配置文件中都需要指定一个数字类型的id(全局不可重复),此节点为临时znode(EPHEMERAL)  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;listener_security_protocol_map&quot;</span>: &#123; <span class="attr">&quot;PLAINTEXT&quot;</span>: <span class="string">&quot;PLAINTEXT&quot;</span> &#125;,</span><br><span class="line">  <span class="attr">&quot;endpoints&quot;</span>: [<span class="string">&quot;PLAINTEXT://hadoop001:9092&quot;</span>],</span><br><span class="line">  <span class="attr">&quot;jmx_port&quot;</span>: <span class="number">-1</span>, # jmx端口号</span><br><span class="line">  <span class="attr">&quot;features&quot;</span>: &#123;&#125;,</span><br><span class="line">  <span class="attr">&quot;host&quot;</span>: <span class="string">&quot;hadoop001&quot;</span>, #主机名或ip地址</span><br><span class="line">  <span class="attr">&quot;timestamp&quot;</span>: <span class="string">&quot;1636338340201&quot;</span>, # kafka broker初始启动时的时间戳</span><br><span class="line">  <span class="attr">&quot;port&quot;</span>: <span class="number">9092</span>, # kafka broker的服务端端口号,由server.properties中参数port确定</span><br><span class="line">  <span class="attr">&quot;version&quot;</span>: <span class="number">5</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><code>/kafka/cluster</code>: 存储 kafka 集群信息</li>
<li><code>/kafka/controller</code>: 存储控制器节点信息,辅助选举Leader  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">     <span class="attr">&quot;version&quot;</span>: <span class="number">1</span>, </span><br><span class="line">     <span class="attr">&quot;brokerid&quot;</span>: <span class="number">1</span>, </span><br><span class="line">     <span class="attr">&quot;timestamp&quot;</span>: <span class="string">&quot;1636338340300&quot;</span> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><code>/kafka/controller_epoch</code><ul>
<li>此值为一个数字,kafka集群中第一个broker第一次启动时为1，以后只要集群中center controller中央控制器所在broker变更或挂掉，就会重新选举新的center controller，每次center controller变更controller_epoch值就会 + 1; <h3 id="4-1-2-Leader选举流程"><a href="#4-1-2-Leader选举流程" class="headerlink" title="4.1.2 Leader选举流程"></a>4.1.2 Leader选举流程</h3>kafka集群中有2个种leader，一种是broker的leader即controller leader，还有一种就是partition的leader<br><img src="https://i.loli.net/2021/11/19/xu9tYf7TRJ1hN2m.jpg"></li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="4-1-2-1-Controller-Leader"><a href="#4-1-2-1-Controller-Leader" class="headerlink" title="4.1.2.1 Controller Leader"></a>4.1.2.1 Controller Leader</h4><p>控制器（Controller），是 Apache Kafka 的核心组件。它的主要作用是在 ZooKeeper 的帮助下管理和协调整个 Kafka 集群。控制器其实就是一个 Broker，只不过它除了具有一般 Broker 的功能以外，还负责 Leader 的选举。</p>
<h5 id="4-1-2-1-1-如何选举控制器"><a href="#4-1-2-1-1-如何选举控制器" class="headerlink" title="4.1.2.1.1 如何选举控制器"></a>4.1.2.1.1 如何选举控制器</h5><p>集群中任意一台 Broker 都能充当控制器的角色，但是，在运行过程中，只能有一个 Broker 成为控制器，行使其管理和协调的职责。实际上，Broker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。Kafka 当前选举控制器的规则是：第一个在 ZooKeeper 成功创建 /controller 临时节点的 Broker 会被指定为控制器。<br><img src="https://i.loli.net/2021/11/19/VD6FaWlZjnR2Ey8.jpg"></p>
<ol>
<li>第一个在 ZooKeeper 中成功创建 /controller 临时节点的 Broker 会被指定为控制器。</li>
<li>其他 Broker 在控制器节点上创建 Zookeeper watch 对象。</li>
<li>如果控制器被关闭或者与 Zookeeper 断开连接，Zookeeper 临时节点就会消失。集群中的其他 Broker 通过 watch 对象得到状态变化的通知，它们会尝试让自己成为新的控制器。</li>
<li>第一个在 Zookeeper 里创建一个临时节点 /controller 的 Broker 成为新控制器。其他 Broker 在新控制器节点上创建 Zookeeper watch 对象。</li>
<li>每个新选出的控制器通过 Zookeeper 的条件递增操作获得一个全新的、数值更大的 controller epoch。其他节点会忽略旧的 epoch 的消息。</li>
<li>当控制器发现一个 Broker 已离开集群，并且这个 Broker 是某些 Partition 的 Leader。此时，控制器会遍历这些 Partition，并用轮询方式确定谁应该成为新 Leader，随后，新 Leader 开始处理生产者和消费者的请求，而 Follower 开始从 Leader 那里复制消息。<blockquote>
<p>总结：<br>Kafka 使用 Zookeeper 的临时节点来选举控制器，并在节点加入集群或退出集群时通知控制器。控制器负责在节点加入或离开集群时进行 Partition Leader 选举。控制器使用 epoch 来避免“脑裂”，“脑裂”是指两个节点同时被认为自己是当前的控制器</p>
</blockquote>
</li>
</ol>
<h4 id="4-1-2-2-Partition-leader"><a href="#4-1-2-2-Partition-leader" class="headerlink" title="4.1.2.2 Partition leader"></a>4.1.2.2 Partition leader</h4><ol>
<li>Controller Leader监听brokers节点变化,并决定分区、副本分配和分区Leader选举</li>
<li>Controller Leader 将节点信息上传到ZK <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/brokers/topics/[topic]/partitions/[broker.id]/state</span><br><span class="line">&#123;&quot;controller_epoch&quot;:1,&quot;leader&quot;:1,&quot;version&quot;:1,&quot;leader_epoch&quot;:0,&quot;isr&quot;:[1,2]&#125;</span><br></pre></td></tr></table></figure></li>
<li>如果当前Partition Leader的Broker挂了</li>
<li>Controller Leader监听到节点变化</li>
<li>Controller Leader获取ISR</li>
<li>选举新的Leader（在ISR中排在前面的优先）</li>
<li>更新Leader及ISR完成Partition Leader 选举</li>
<li>如果 ISR 为空了，就说明 Leader 副本也“挂掉”了，Kafka 需要重新选举一个新的 Leader。<ul>
<li>Kafka 把所有不在 ISR 中的存活副本都称为非同步副本。通常来说，非同步副本落后 Leader 太多，因此，如果选择这些副本作为新 Leader，就可能出现数据的丢失。毕竟，这些副本中保存的消息远远落后于老 Leader 中的消息。在 Kafka 中，选举这种副本的过程称为 Unclean 领导者选举。Broker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举。</li>
<li>开启 Unclean 领导者选举可能会造成数据丢失，但好处是：它使得 Partition Leader 副本一直存在，不至于停止对外提供服务，因此提升了高可用性。反之，禁止 Unclean 领导者选举的好处在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性。</li>
</ul>
</li>
</ol>
<h3 id="4-1-3-Kafka-Broker启动流程"><a href="#4-1-3-Kafka-Broker启动流程" class="headerlink" title="4.1.3 Kafka Broker启动流程"></a>4.1.3 Kafka Broker启动流程</h3><p><img src="https://i.loli.net/2021/11/19/FZSaxJR1PQIpXts.jpg"></p>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>acks</td>
<td>0：生产者发送过来的数据，不需要等数据落盘应答。<br>1：生产者发送过来的数据，Leader收到数据后应答。<br>-1（all）：生产者发送过来的数据，Leader+和isr队列里面的所有节点收齐数据后应答。默认值是-1。</td>
</tr>
<tr>
<td>enable.idempotence</td>
<td>是否开启事务，默认true，开启事务</td>
</tr>
<tr>
<td>max.in.flight.requests.per.connection</td>
<td>允许最多没有返回ack的次数，默认为5，开启幂等性要保证该值是 1-5的数字。</td>
</tr>
<tr>
<td>log.segment.bytes</td>
<td>Kafka中log日志是分成一块块存储的，此配置是指log日志划分 成块的大小，默认值1G。</td>
</tr>
<tr>
<td>log.retention.hours</td>
<td>Kafka中数据保存的时间，默认7天</td>
</tr>
</tbody></table>
<h2 id="4-2-数据可靠性保证"><a href="#4-2-数据可靠性保证" class="headerlink" title="4.2 数据可靠性保证"></a>4.2 数据可靠性保证</h2><h3 id="4-2-1-ack应答级别"><a href="#4-2-1-ack应答级别" class="headerlink" title="4.2.1 ack应答级别"></a>4.2.1 ack应答级别</h3><p>当producer向leader发送数据时，可以通过request.required.acks参数来设置数据可靠性的级别</p>
<ul>
<li>0：生产者发送过来的数据，不需要等数据落盘应答。这种情况下数据传输效率最高，但是数据可靠性确是最低的<br>  <img src="https://i.loli.net/2021/11/19/TVCWoOZ5A3NuR8D.jpg"></li>
<li>1：生产者发送过来的数据，Leader收到数据后应答。<ul>
<li>数据丢失分析：producer发送数据到leader，leader写本地日志成功，返回客户端成功；此时ISR中的副本还没有来得及拉取该消息，leader就宕机了，那么此次发送的消息就会丢失<br><img src="https://i.loli.net/2021/11/19/SEUKrXFvO6ex5Ms.jpg"></li>
</ul>
</li>
<li>-1（all）：生产者发送过来的数据，Leader和ISR队列里面的所有节点收齐数据后应答。<ul>
<li>acks=-1的情况下，数据发送到leader, ISR的follower全部完成数据同步后，leader此时挂掉，那么会选举出新的leader，数据不会丢失<br>  <img src="https://i.loli.net/2021/11/19/yQGx8LTE4cYfXPV.jpg"></li>
<li>思考：Leader收到数据，所有Follower都开始同步数据，但有一个Follower，因为某种故障，迟迟不能与Leader进行同步，那这个问题怎么解决呢？</li>
<li>Leader维护了一个动态的in-sync replica set（ISR），意为和Leader保持同步的Follower集合。当ISR中的Follower完成数据的同步之后，Leader就会给producer发送ack。如果Follower长时间未向Leader同步数据，则该Follower将被踢出ISR，该时间阈值由replica.lag.time.max.ms参数设定，默认30s。Leader发生故障之后，就会从ISR中选举新的Leader。</li>
<li>数据重复分析：acks=-1的情况下，数据发送到leader后 ，部分ISR的副本同步，leader此时挂掉。比如follower1和follower2都有可能变成新的leader, producer端会得到返回异常，producer端会重新发送数据，数据可能会重复<br>  <img src="https://i.loli.net/2021/11/19/5XCGBIZmNsOjQ1F.jpg"><br>  <img src="https://i.loli.net/2021/11/19/mHgn63Gj2yaLs7Z.jpg"></li>
</ul>
</li>
</ul>
<h3 id="4-2-2-Leader和Follower故障处理细节"><a href="#4-2-2-Leader和Follower故障处理细节" class="headerlink" title="4.2.2 Leader和Follower故障处理细节"></a>4.2.2 Leader和Follower故障处理细节</h3><ul>
<li><p>LEO（Log End Offset）：每个副本的最后一个offset</p>
</li>
<li><p>HW（High Watermark）：所有副本中最小的LEO，也是消费者能见到的最大的offset</p>
</li>
<li><p>Leader故障</p>
<ul>
<li>leader 发生故障之后，会从 ISR 中选出一个新的 leader</li>
<li>为保证多个副本之间的数据一致性，其余的 follower 会先将各自的 log 文件高于 HW 的部分截掉，然后从新的 leader同步数据<blockquote>
<p>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Follower故障</p>
<ul>
<li>follower 发生故障后会被临时踢出 ISR</li>
<li>待该 follower 恢复后，follower 会读取本地磁盘记录的上次的 HW，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。</li>
<li>等该 follower 的 LEO 大于等于该 Partition 的 HW，即 follower 追上 leader 之后，就可以重新加入 ISR 了。</li>
</ul>
</li>
</ul>
<h3 id="4-2-3-精确一次（Exactly-Once）"><a href="#4-2-3-精确一次（Exactly-Once）" class="headerlink" title="4.2.3 精确一次（Exactly Once）"></a>4.2.3 精确一次（Exactly Once）</h3><ul>
<li>至少一次（At Least Once）：例如，将服务器的ACK级别设置为-1（ISR完全应答），且min.insync.replicas设置大于等于2.可以保证Producer到Broker之间不会丢失数据。<ul>
<li><code>min.insync.replicas</code>: ack为-1时生效，表示ISR里应答的最小follower数量。默认为1（leader本身也算一个！），所以当ISR里除了leader本身，没有其他的follower，即使ack设为-1，运行过程中也只会保存leader一份数据，相当于1（leader应答）的效果，不能保证不丢数据。</li>
<li>所以需要将min.insync.replicas设置大于等于2，才能保证有其他副本同步到数据</li>
</ul>
</li>
<li>最多一次（At Most Once）：例如，将服务器ACK级别设置为0（无需应答），可以保证生产者每条消息只会被发送一次。<ul>
<li>At Least Once可以保证数据不丢失，但是不能保证数据不重复</li>
<li>At Most Once可以保证数据不重复，但是不能保证数据不丢失。</li>
</ul>
</li>
<li>精确一次（Exactly Once）：对于一些非常重要的信息，比如和钱相关的数据，要求数据既不能重复也不丢失。每条消息肯定会被传输一次且仅传输一次。<ul>
<li>Kafka通过 幂等性（Idempotence）和事务（Transaction）这两种机制实现了 精确一次（exactly once）语义</li>
</ul>
</li>
</ul>
<h3 id="4-2-4-幂等性"><a href="#4-2-4-幂等性" class="headerlink" title="4.2.4 幂等性"></a>4.2.4 幂等性</h3><ol>
<li>幂等性原理<ul>
<li>幂等性就是指Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一条。幂等性结合至少一次（At Least Once），就构成了Kafka的精确一次（Exactly Once）。</li>
<li>即：精确一次（Exactly Once） = 至少一次（At Least Once） + 幂等性 。</li>
<li>开启幂等性的Producer在初始化的时候会被分配一个ProducerID，发往同一Partition的消息会附带Sequence Number。而Broker端会对&lt;ProducerID, Partition, SeqNumber&gt;主键做缓存，当具有相同主键的消息提交时，Broker只会持久化一条。</li>
<li>注意：Producer重启PID就会变化，即&lt;PID, Partition, SeqNumber&gt; 主键变化，所以<font color ='red' >幂等性无法保证跨分区跨会话的Exactly Once</font>。<br>  <img src="https://i.loli.net/2021/11/19/pba75dhHBmuX6TP.jpg"></li>
</ul>
</li>
<li>如何使用幂等性<ul>
<li>开启参数enable.idempotence 默认为true，false关闭</li>
<li>相关参数max.in.flight.requests.per.connection 该参数指定了生产者在收到服务器响应之前可以发送多少个消息。它的值越高，就会占用越多的内存，不过也会提升吞吐量。把它设为 1 可以保证消息是按照发送的顺序写入服务器的，即使发生了重试</li>
<li><font color ='red' >幂等性保证的是单分区单会话exactly once</font></li>
</ul>
</li>
</ol>
<h3 id="4-2-5-生产者事务"><a href="#4-2-5-生产者事务" class="headerlink" title="4.2.5 生产者事务"></a>4.2.5 生产者事务</h3><ul>
<li>保证多次提交到不同主题和不同分区的消息的原子性，即要么全部发送成功，要么全部发送失败</li>
<li>保证conumser-transform-produce 应用模式中，消息能被原子性转换。</li>
</ul>
<ol>
<li><p>Kafka事务原理<br> <img src="https://i.loli.net/2021/11/19/i8TlgIzKCsAGyqH.jpg"></p>
</li>
<li><p>流程描述</p>
<ul>
<li><p>Producer准备TransactionId</p>
<ul>
<li>Kafka事务为了实现Producer的主从功能，提出了TransactionId的概念，同一个TransactionId只能有一个在运行，后面启动的Producer会使得前面的Producer立即抛出异常。</li>
</ul>
</li>
<li><p>初始化事务</p>
<ul>
<li>Producer会首先向任意一个broker发送查找自己对应事务协调器的请求，获取请求后，Producer会向事务协调器请求PID,同时在这个过程中，如果发现对应TransactionId有之前未完成的任务，它还会做以下两件事：<ul>
<li>恢复Producer对应TransactionId之前未完成的事务（Commit/Abort）</li>
<li>对PID对应epoch进行递增，防止脑裂问题。</li>
</ul>
</li>
</ul>
</li>
<li><p>开始事务：</p>
<ul>
<li>本地记录事务状态为开始，但是协调器只有在接受到事务第一条消息后，才会标记为事务真正的开始。</li>
</ul>
</li>
<li><p>进行事务：</p>
<ul>
<li>在kafka事务中，会原子的支持Consumer-Process-Producer过程，因此在这个过程中还提供了一个API</li>
<li>producer.sendOffsetsToTransaction();这个过程会将消费的offset暂存在协调器中，等事务提交时统一提交</li>
</ul>
</li>
<li><p>提交/回滚：</p>
<ul>
<li>当提交或回滚的时候，协调器会进行一个两段提交<ul>
<li>第一阶段，将事务日志，将此事务设置为PREPARE_COMMIT或PREPARE_ABORT</li>
<li>第二阶段，发送Transaction Marker给事务涉及到的Leader发送标记信息，标记此条信息为已提交或已放弃</li>
</ul>
</li>
<li>当完成第二阶段后，协调器最终会将此事务标记为COMPLETE_COMMIT或COMPLETE_ABORT</li>
</ul>
</li>
<li><p>事务故障恢复</p>
<ul>
<li>__transaction_state-分区-Leader存储事务信息的特殊主题，负责传递和持久化事务状态，通过持久化状态，可以使得协调器即使崩溃，也能选举新的Leader继续补全事务</li>
<li>在提交阶段，为了防止其他Leader崩溃而没有收到commit消息，协调器会先保存事务状态，再发送Transaction Marker消息</li>
<li>Producer 在发送 beginTransaction() 时，如果出现 timeout 或者错误：Producer 只需要重试即可；</li>
<li>Producer 在发送数据时出现错误：Producer 应该 abort 这个事务，如果 Produce 没有 abort（比如设置了重试无限次，并且 batch 超时设置得非常大），TransactionCoordinator 将会在这个事务超时之后 abort 这个事务操作；</li>
<li>Producer 发送 commitTransaction() 时出现 timeout 或者错误：Producer 应该重试这个请求（幂等保证）；</li>
<li>Coordinator Failure：如果 Transaction Coordinator 发生切换（事务 topic leader 切换），Coordinator 可以从日志中恢复。如果发送事务有处于 PREPARE_COMMIT 或 PREPARE_ABORT 状态，那么直接执行 commit 或者 abort 操作，如果是一个正在进行的事务，Coordinator 的失败并不需要 abort 事务，producer 只需要向新的 Coordinator 发送请求即可。</li>
</ul>
</li>
</ul>
</li>
<li><p>事务模板</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1初始化事务</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">initTransactions</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2开启事务</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">beginTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3在事务内提交已经消费的偏移量</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sendOffsetsToTransaction</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets,</span></span></span><br><span class="line"><span class="params"><span class="function">                              String consumerGroupId)</span> <span class="keyword">throws</span> ProducerFencedException</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4提交事务</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">commitTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 5放弃事务（类似于回滚事务的操作）</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">abortTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException</span>;</span><br></pre></td></tr></table></figure></li>
<li><p>编码测试</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducerTransaction</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 给kafka配置对象添加配置信息：bootstrap.servers</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop001:9092,hadoop002:9092,hadoop003:9092,hadoop004:9092,hadoop005:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// key,value序列化（必须）：key.serializer，value.serializer</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 批次大小 默认16K：batch.size</span></span><br><span class="line">        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">16384</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 等待时间：linger.ms</span></span><br><span class="line">        properties.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// RecordAccumulator缓冲区大小 默认32M：buffer.memory</span></span><br><span class="line">        properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG, <span class="number">33554432</span>);</span><br><span class="line"></span><br><span class="line">        properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, <span class="string">&quot;transaction_id_0&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 创建kafka生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 1初始化事务</span></span><br><span class="line">        kafkaProducer.initTransactions();</span><br><span class="line">        <span class="comment">// 2开启事务</span></span><br><span class="line">        kafkaProducer.beginTransaction();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 4. 调用send方法,发送消息</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1090000000</span>; i++) &#123;</span><br><span class="line">                kafkaProducer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">&quot;first&quot;</span>,<span class="string">&quot;i am producer &quot;</span> + i));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 4提交事务</span></span><br><span class="line">            kafkaProducer.commitTransaction();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">             <span class="comment">// 5放弃事务（类似于回滚事务的操作）</span></span><br><span class="line">            kafkaProducer.abortTransaction();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">// 5. 关闭资源</span></span><br><span class="line">            kafkaProducer.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="4-3-文件存储"><a href="#4-3-文件存储" class="headerlink" title="4.3 文件存储"></a>4.3 文件存储</h2><h3 id="4-3-1-文件存储机制"><a href="#4-3-1-文件存储机制" class="headerlink" title="4.3.1 文件存储机制"></a>4.3.1 文件存储机制</h3><blockquote>
<p>思考：Topic数据到底是怎么存储的呢？</p>
</blockquote>
<ol>
<li>启动生产者，并发送消息 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ kafka-console-producer.sh --bootstrap-server hadoop001:9092 --topic first</span><br><span class="line">&gt;hello world</span><br></pre></td></tr></table></figure></li>
<li>查看hadoop001（或者其他任意broker）的/opt/module/kafka_2.12-3.0.0/logs/first-0/路径上的文件 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 bin]$ kafka-topics.sh --bootstrap-server hadoop001:9092 --describe -topic first</span><br><span class="line">Topic: first	TopicId: LtoXnmphRHmMEVuj_o5yyw	PartitionCount: 3	ReplicationFactor: 2	Configs: segment.bytes=1073741824</span><br><span class="line">	Topic: first	Partition: 0	Leader: 3	Replicas: 3,5	Isr: 3,5</span><br><span class="line">	Topic: first	Partition: 1	Leader: 5	Replicas: 5,1	Isr: 5,1</span><br><span class="line">	Topic: first	Partition: 2	Leader: 1	Replicas: 1,4	Isr: 1,4</span><br><span class="line">[atguigu@dw-server-001 bin]$</span><br><span class="line">[atguigu@hadoop001 ~]$ ll /opt/module/kafka_2.12-3.0.0/logs/first-0/</span><br><span class="line">总用量 60</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu 10485760 11月  9 21:16 00000000000000000000.index</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu    41536 11月  9 21:16 00000000000000000000.log</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu 10485756 11月  9 21:16 00000000000000000000.timeindex</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu        8 11月  9 11:08 leader-epoch-checkpoint</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu       43 11月  9 10:56 partition.metadata</span><br><span class="line">[atguigu@hadoop001 ~]$</span><br></pre></td></tr></table></figure></li>
<li>查看log日志 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 kafka]$ bin/kafka-console-producer.sh --bootstrap-server hadoop001:9092 --topic first</span><br><span class="line">&gt;hello world</span><br></pre></td></tr></table></figure></li>
<li>通过工具查看index和log信息 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 kafka]$ kafka-run-class.sh kafka.tools.DumpLogSegments --files datas/first-0/00000000000000000000.index </span><br><span class="line"></span><br><span class="line">Dumping datas/first-0/00000000000000000000.index</span><br><span class="line">offset: 3 position: 152</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop001 kafka]$ bin/kafka-run-class.sh kafka.tools.DumpLogSegments --files datas/first-0/00000000000000000000.log</span><br><span class="line"></span><br><span class="line">Dumping datas/first-0/00000000000000000000.log</span><br><span class="line">Starting offset: 0</span><br><span class="line">baseOffset: 0 lastOffset: 1 count: 2 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: <span class="literal">false</span> isControl: <span class="literal">false</span> position: 0 CreateTime: 1636338440962 size: 75 magic: 2 compresscodec: none crc: 2745337109 isvalid: <span class="literal">true</span></span><br><span class="line">baseOffset: 2 lastOffset: 2 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: <span class="literal">false</span> isControl: <span class="literal">false</span> position: 75 CreateTime: 1636351749089 size: 77 magic: 2 compresscodec: none crc: 273943004 isvalid: <span class="literal">true</span></span><br><span class="line">baseOffset: 3 lastOffset: 3 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: <span class="literal">false</span> isControl: <span class="literal">false</span> position: 152 CreateTime: 1636351749119 size: 77 magic: 2 compresscodec: none crc: 106207379 isvalid: <span class="literal">true</span></span><br><span class="line">baseOffset: 4 lastOffset: 8 count: 5 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: <span class="literal">false</span> isControl: <span class="literal">false</span> position: 229 CreateTime: 1636353061435 size: 141 magic: 2 compresscodec: none crc: 157376877 isvalid: <span class="literal">true</span></span><br><span class="line">baseOffset: 9 lastOffset: 13 count: 5 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: <span class="literal">false</span> isControl: <span class="literal">false</span> position: 370 CreateTime: 1636353204051 size: 146 magic: 2 compresscodec: none crc: 4058582827 isvalid: <span class="literal">true</span></span><br></pre></td></tr></table></figure></li>
<li>Topic数据的存储机制<br> topic是逻辑上的概念，而partition是物理上的概念，<font color ='red' >每个partition对应于一个log文件</font>，该log文件中存储的就是Producer生产的数据。<font color ='red' >Producer生产的数据会被不断追加到该log文件末端</font>，为防止log文件过大导致数据定位效率低下，<font color ='red' >Kafka采取了分片和索引机制</font>，将每个partition分为多个segment。<font color ='red' >每个segment对应两个文件：“.index”文件和“.log”文件</font>。这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称+分区序号，例如：first-0。<br> <img src="https://i.loli.net/2021/11/19/Xtf8CTPNYw1bv63.jpg"></li>
<li>index文件和log文件详解<ul>
<li><code>.index</code>文件存储大量的索引信息，索引信息按照数组的逻辑排列。<ul>
<li>Index存储数据采用的是稀疏索引存储</li>
<li>log.index.interval.bytes: 引项字节间隔密度，会影响索引文件中的区间密度和查询效率默认4kb</li>
</ul>
</li>
<li><code>.log</code>文件存储大量的数据，数据直接紧密排列，索引文件中的元数据指向对应数据文件中message的物理偏移地址。<ul>
<li><code>log.segment.bytes</code>：Kafka中log日志是分成一块块存储的，此配置是指log日志划分 成块的大小，默认值1G。</li>
</ul>
</li>
</ul>
</li>
<li>日志切分文件逻辑<ul>
<li>日志文件和索引文件都会存在多个文件，组成多个 SegmentLog</li>
<li>当前日志分段文件的大小超过了 broker 端参数 log.segment.bytes 配置的值。log.segment.bytes 参数的默认值为 1073741824，即 1GB。</li>
<li>当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于 log.roll.ms 或 log.roll.hours 参数配置的值。如果同时配置了 log.roll.ms 和 log.roll.hours 参数，那么 log.roll.ms 的优先级高。默认情况下，只配置了 log.roll.hours 参数，其值为168，即 7 天</li>
<li>偏移量索引文件或时间戳索引文件的大小达到 broker 端参数 log.index.size.max.bytes 配置的值。log.index.size.max.bytes 的默认值为 10485760，即 10MB</li>
<li>追加的消息的偏移量与当前日志分段的偏移量之间的差值大于 Integer.MAX_VALUE，即要追加的消息的偏移量不能转变为相对偏移量<ul>
<li>为什么是 Integer.MAX_VALUE ？<ul>
<li>在偏移量索引文件中，每个索引项共占用 8 个字节，并分为两部分。相对偏移量和物理地址。</li>
<li>相对偏移量：表示消息相对与基准偏移量的偏移量，占 4 个字节</li>
<li>物理地址：消息在日志分段文件中对应的物理位置，也占 4 个字节</li>
<li>4 个字节刚好对应 Integer.MAX_VALUE ，如果大于 Integer.MAX_VALUE ，则不能用 4 个字节进行表示了。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>索引文件切分过程<ul>
<li>索引文件会根据 log.index.size.max.bytes 值进行预先分配空间，即文件创建的时候就是最大值，当真正的进行索引文件切分的时候，才会将其裁剪到实际数据大小的文件。这一点是跟日志文件有所区别的地方。其意义降低了代码逻辑的复杂性。</li>
</ul>
</li>
<li>查找消息<ol>
<li>offset 查询<br> <img src="https://i.loli.net/2021/11/19/MIv3NqtbdhCcRDw.png"><ol>
<li>偏移量索引由相对偏移量和物理地址组成。</li>
<li>可以通过kafka-dump-log.sh命令解析.index 文件 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kafka-dump-log.sh --files ./00000000000000000000.index</span><br><span class="line">offset:0 position:0</span><br><span class="line">offset:20 position:320</span><br><span class="line">offset:43 position:1220</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：offset 与 position 没有直接关系，由于存在数据删除和日志清理。</p>
</blockquote>
</li>
<li>如何查看 偏移量为 23 的消息？<ul>
<li>Kafka 中存在一个 ConcurrentSkipListMap 来保存在每个日志分段，通过跳跃表方式，定位到在 00000000000000000000.index ，通过二分法在偏移量索引文件中找到不大于 23 的最大索引项，即 offset 20 那栏，然后从日志分段文件中的物理位置为320 开始顺序查找偏移量为 23 的消息。</li>
</ul>
</li>
</ol>
</li>
<li>时间戳方式查询<ol>
<li>通过时间戳方式进行查找消息，需要通过查找时间戳索引和偏移量索引两个文件。</li>
<li>时间戳索引索引格式<br> <img src="https://i.loli.net/2021/11/19/XBykJIseCf87pMm.jpg"><br> <img src="https://i.loli.net/2021/11/19/Bh6sgKwkiZFS82d.jpg"></li>
<li>查找时间戳为 1557554753430 开始的消息？<ul>
<li>将 1557554753430 和每个日志分段中最大时间戳 largestTimeStamp 逐一对比，直到找到不小于 1557554753430 所对应的日志分段。日志分段中的 largestTimeStamp 的计算是先查询该日志分段所对应时间戳索引文件，找到最后一条索引项，若最后一条索引项的时间戳字段值大于 0 ，则取该值，否则去该日志分段的最近修改时间。</li>
<li>找到相应日志分段之后，使用二分法进行定位，与偏移量索引方式类似，找到不大于 1557554753430 最大索引项，也就是 [1557554753420 430]。</li>
<li>拿着偏移量为 430 到偏移量索引文件中使用二分法找到不大于 430 最大索引项，即 [20，320] 。</li>
<li>日志文件中从 320 的物理位置开始查找不小于 1557554753430 数据。<blockquote>
<p>注意：timestamp文件中的 offset 与 index 文件中的 relativeOffset 不是一一对应的哦。因为数据的写入是各自追加。</p>
</blockquote>
</li>
</ul>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="4-3-2-文件清理策略"><a href="#4-3-2-文件清理策略" class="headerlink" title="4.3.2 文件清理策略"></a>4.3.2 文件清理策略</h3><ul>
<li>Kafka中默认的日志保存时间为7天，可以通过调整log.retention.hours参数，修改保存时间。</li>
<li>那么日志一旦超过了设置的时间，怎么处理呢？<ul>
<li>Kafka中提供的日志清理策略有delete和compact两种。<ul>
<li>delete日志删除：将过期数据删除。<ul>
<li>log.cleanup.policy = delete    所有数据启用删除策略</li>
<li>cleanup.policy= delete     单个主题数据启用删除策略</li>
<li>思考：如果一个segment中有一部分数据过期，一部分没有过期，怎么处理？<br>  <img src="https://i.loli.net/2021/11/19/4c5bpKFfz3H8R1Q.jpg"></li>
</ul>
</li>
<li>compact日志压缩：对于相同key的不同value值，只保留最后一个版本。<ul>
<li>log.cleanup.policy = compact  所有数据启用压缩策略</li>
<li>cleanup.policy = compact单个主题数据启用删除策略<h2 id="4-4-Kafka-高效读写数据"><a href="#4-4-Kafka-高效读写数据" class="headerlink" title="4.4 Kafka 高效读写数据"></a>4.4 Kafka 高效读写数据</h2></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ol>
<li>Kafka本身是分布式集群，可以采用分区技术，并发度高。</li>
<li>顺序写磁盘 <ul>
<li>Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到600M/s，而随机写只有100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。<br>  <img src="https://i.loli.net/2021/11/19/8lStAREKQoIFXwT.jpg"></li>
</ul>
</li>
<li>零复制技术<ul>
<li>Kafka的数据加工处理操作交由Kafka生产者和Kafka消费者处理。</li>
<li>Kafka Broker应用层不关心存储的数据，所以就不用走应用层，传输效率高。<br>  <img src="https://i.loli.net/2021/11/19/epTbkQq1EvDM3ul.jpg"></li>
</ul>
</li>
</ol>
<h1 id="第5章-Kafka消费者"><a href="#第5章-Kafka消费者" class="headerlink" title="第5章 Kafka消费者"></a>第5章 Kafka消费者</h1><h2 id="5-1-Kafka消费者工作流程"><a href="#5-1-Kafka消费者工作流程" class="headerlink" title="5.1 Kafka消费者工作流程"></a>5.1 Kafka消费者工作流程</h2><p><img src="https://i.loli.net/2021/11/19/OuTZbBEeAcFd7gU.jpg"></p>
<ul>
<li>Kafka中消息是以topic进行分类的，生产者生产消息，消费者消费消息，都是面向topic的。</li>
<li>一个topic下的每一个分区都单独维护一个offset，所以分发到不同分区中的数据是不同的数据。消费者的分区维护是一个消费者组一个主题的一个分区维护一个offset。<br>消费者相关调优参数</li>
<li>消费逻辑<ol>
<li>单个消费者，可以消费Kafka中所有主题、所有分区</li>
<li>单个消费者与消费者之间相互独立。都能同时消费所有主题、所有分区。</li>
<li>消费者组，可以消费Kafka中所有主题、所有分区。只不过在消费的过程中，考虑到并发，每个消费者组中的消费者，只能消费指定分区。</li>
<li>消费者组和消费者组之间一点关系都没有。都能同时消费所有主题、所有分区。</li>
</ol>
</li>
<li>消费者相关调优参数</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>bootstrap.servers</td>
<td>向Kafka集群建立初始连接用到的host/port列表。</td>
</tr>
<tr>
<td>group.id</td>
<td>标记消费者所属的消费者组</td>
</tr>
<tr>
<td>enable.auto.commit</td>
<td>默认值为true，消费者会自动周期性地向服务器提交偏移量。</td>
</tr>
<tr>
<td>auto.commit.interval.ms</td>
<td>如果设置了 enable.auto.commit 的值为true， 则该值定义了消费者偏移量向Kafka提交的频率，默认5s</td>
</tr>
<tr>
<td>auto.offset.reset</td>
<td>当Kafka中没有初始偏移量或当前偏移量在服务器中不存在（如，数据被 删除了），该如何处理？ <br>earliest：自动重置偏移量到最早的偏移量 <br>latest：自动重置偏移量为最新的偏移量 <br>none：如果消费组原来的（previous）偏移量不存在，则向消费者抛异常 <br>anything：向消费者抛异常</td>
</tr>
</tbody></table>
<h2 id="5-2-消费方式"><a href="#5-2-消费方式" class="headerlink" title="5.2 消费方式"></a>5.2 消费方式</h2><p><img src="https://i.loli.net/2021/11/19/q54B7gmylYAhF8i.jpg"></p>
<ul>
<li>pull（拉）模式：consumer采用从broker中主动拉取数据。Kafka采用这种方式。</li>
<li>push（推）模式：Kafka没有采用这种方式，因为由broker决定消息发送速率，很难适应所有消费者的消费速率。例如推送的速度是50m/s，Consumer1、Consumer2就来不及处理消息。</li>
<li>pull模式不足之处是，如果Kafka没有数据，消费者可能会陷入循环中，一直返回空数据。针对这一点，Kafka的消费者在消费数据时会传入一个时长参数timeout，如果当前没有数据可供消费，consumer会等待一段时间之后再返回，这段时长即为timeout。</li>
</ul>
<h3 id="5-2-1-独立消费者"><a href="#5-2-1-独立消费者" class="headerlink" title="5.2.1 独立消费者"></a>5.2.1 独立消费者</h3><blockquote>
<p>注意：在消费者API代码中必须配置消费者组，命令行启动消费者不填写消费者组会被自动填写随机的消费者组。</p>
</blockquote>
<ol>
<li>需求：创建一个独立消费者，消费first主题中数据。</li>
<li>编码 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.kafka.consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomConsumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.创建消费者的配置对象</span></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2.给消费者配置对象添加参数</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置序列化 必须</span></span><br><span class="line">properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置消费者组（组名任意起名） 必须</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 注册要消费的主题（可以消费多个主题）</span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 拉取数据打印</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 设置1s中消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 打印消费到的数据</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>测试<ol>
<li>在IDEA中执行消费者程序</li>
<li>在Kafka集群控制台，创建Kafka生产者，并输入数据 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 kafka]$ kafka-console-producer.sh --bootstrap-server hadoop102:9092 --topic first</span><br><span class="line">&gt;hello</span><br></pre></td></tr></table></figure></li>
<li>在IDEA控制台观察接收到的数据 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 1, leaderEpoch = 3, offset = 0, CreateTime = 1629160841112, serialized key size = -1, serialized value size = 5, headers = RecordHeaders(headers = [], isReadOnly = <span class="literal">false</span>), key = null, value = hello)</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h3 id="5-2-2-消费者组案例"><a href="#5-2-2-消费者组案例" class="headerlink" title="5.2.2 消费者组案例"></a>5.2.2 消费者组案例</h3><ul>
<li>Consumer Group（CG）：消费者组，由多个consumer组成。<ul>
<li>消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；</li>
<li>消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</li>
</ul>
</li>
</ul>
<h2 id="5-3-分区分配策略"><a href="#5-3-分区分配策略" class="headerlink" title="5.3 分区分配策略"></a>5.3 分区分配策略</h2><ul>
<li>一个consumer group中有多个consumer，一个 topic有多个partition，所以必然会涉及到partition的分配问题，即确定哪个partition由哪个consumer来消费。</li>
<li>Kafka有三种主流的分区分配策略： Range、RoundRobin、Sticky。</li>
<li>可以通过配置参数partition.assignment.strategy，修改分区的分配策略。默认策略是Range +  Sticky。Kafka可以同时使用多个分区分配策略。</li>
</ul>
<h3 id="5-3-1-Range"><a href="#5-3-1-Range" class="headerlink" title="5.3.1 Range"></a>5.3.1 Range</h3><p><img src="https://i.loli.net/2021/11/19/s4QuYAL2UBqRfm8.jpg"></p>
<ol>
<li>Range分区策略原理<ul>
<li>按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀地分配给所有的消费者。对于每一个topic，RangeAssignor策略会将消费组内所有订阅这个topic的消费者按照名称的字典序排序，然后为每个消费者划分固定的分区范围，如果不够平均分配，那么字典序靠前的消费者会被多分配一个分区。</li>
<li>假如现在有 7 个分区，3 个消费者，排序后的分区将会是0,1,2,3,4,5,6；消费者排序完之后将会是C0-0,C1-0,C2-0。</li>
<li>通过 partitions数/consumer数 来决定每个消费者应该消费几个分区。如果除不尽，那么前面几个消费者将会多消费 1 个分区。</li>
<li>例如，7/3 = 3 余 1 ，除不尽，那么 消费者 C0-0 便会多消费 1 个分区</li>
</ul>
<blockquote>
<p>注意：如果只是针对 1 个 topic 而言，C0-0消费者多消费1个分区影响不是很大。但是如果有 N 多个 topic，那么针对每个 topic，消费者 C0-0 都将多消费 1 个分区，topic越多，C0-0 消费的分区会比其他消费者明显多消费 N 个分区。<br> 容易产生数据倾斜！</p>
</blockquote>
</li>
<li>Range分区分配策略案例<ul>
<li>修改主题first为7个分区  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 kafka]$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --alter --topic first --partitions 7</span><br></pre></td></tr></table></figure>
<ul>
<li>注意：分区数可以增加，但是不能减少。</li>
</ul>
</li>
<li>创建三个线程启动三个消费者CustomConsumer组成消费者组，组名都为“test”  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> tech.anzhen.kafka.consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomConsumerGroup</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop001:9092,hadoop002:9092,hadoop003:9092,hadoop004:9092,hadoop005:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;123&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; consumerThread(properties)).start();</span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; consumerThread(properties)).start();</span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; consumerThread(properties)).start();</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">consumerThread</span><span class="params">(Properties properties)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> KafkaConsumer&lt;Object, Object&gt; kafkaConsumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> ArrayList&lt;String&gt; topicList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topicList.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topicList);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">final</span> ConsumerRecords&lt;Object, Object&gt; poll = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">if</span> (poll != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">for</span> (ConsumerRecord&lt;Object, Object&gt; consumerRecord : poll) &#123;</span><br><span class="line">                    System.out.println(Thread.currentThread().getName() + <span class="string">&quot; &quot;</span> + consumerRecord);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>启动CustomProducer生产者，发送500条消息，随机发送到不同的分区：<ul>
<li>说明：Kafka默认的分区分配策略就是Range + Sticky，所有不需要修改策略。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> tech.anzhen.kafka.producer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop001:9092,hadoop002:9092,hadoop003:9092,hadoop004:9092,hadoop005:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">500</span>; i++) &#123;</span><br><span class="line"></span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;atguigu &quot;</span> + i));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 避免发送到同一个分区</span></span><br><span class="line">            Thread.sleep(<span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>观察数据分区<br>  <img src="https://i.loli.net/2021/11/19/o3FS1q8waTPmdCe.jpg"></li>
</ul>
</li>
</ol>
<h3 id="5-3-2-RoundRobin"><a href="#5-3-2-RoundRobin" class="headerlink" title="5.3.2 RoundRobin"></a>5.3.2 RoundRobin</h3><p><img src="https://i.loli.net/2021/11/19/IjrJBkqwRslfc1m.jpg"></p>
<ol>
<li>RoundRobin分区策略原理<ul>
<li>RoundRobin 轮询分区策略，是把所有的 partition 和所有的 consumer 都列出来，然后按照 hascode 进行排序，最后通过轮询算法来分配 partition 给到各个消费者。</li>
</ul>
</li>
<li>RoundRobin分区分配策略案例<ol>
<li>修改CustomConsumer消费者代码中分区分配策略为RoundRobin。 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> tech.anzhen.kafka.consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.RoundRobinAssignor;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ConcurrentHashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.CountDownLatch;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.atomic.AtomicInteger;</span><br><span class="line"><span class="keyword">import</span> java.util.function.BiConsumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomConsumerRoundRobin</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> ConcurrentHashMap&lt;String, AtomicInteger&gt; map = <span class="keyword">new</span> ConcurrentHashMap&lt;&gt;();</span><br><span class="line">    <span class="keyword">static</span> CountDownLatch countDownLatch = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;bd-server-001:9092,bd-server-002:9092,bd-server-003:9092,bd-server-004:9092,bd-server-005:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 修改分区分配策略</span></span><br><span class="line">        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, RoundRobinAssignor.class.getName());</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;123&quot;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; consumerThread(properties)).start();</span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; consumerThread(properties)).start();</span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; consumerThread(properties)).start();</span><br><span class="line"></span><br><span class="line">        countDownLatch.await();</span><br><span class="line">        map.forEach((s, atomicInteger) -&gt; &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;线程: &quot;</span> + s.split(<span class="string">&quot;,&quot;</span>)[<span class="number">0</span>] + <span class="string">&quot; 分区: &quot;</span> + s.split(<span class="string">&quot;,&quot;</span>)[<span class="number">1</span>] + <span class="string">&quot; 消费数量：&quot;</span> + atomicInteger.get());</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">consumerThread</span><span class="params">(Properties properties)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> KafkaConsumer&lt;Object, Object&gt; kafkaConsumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> ArrayList&lt;String&gt; topicList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topicList.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topicList);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">final</span> ConsumerRecords&lt;Object, Object&gt; poll = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">if</span> (poll != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">for</span> (ConsumerRecord&lt;Object, Object&gt; consumerRecord : poll) &#123;</span><br><span class="line">                    <span class="keyword">final</span> AtomicInteger atomicInteger = map.putIfAbsent(Thread.currentThread().getName() + <span class="string">&quot;,&quot;</span> + consumerRecord.partition(), <span class="keyword">new</span> AtomicInteger(<span class="number">1</span>));</span><br><span class="line">                    <span class="keyword">if</span> ( atomicInteger != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        atomicInteger.incrementAndGet();</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">if</span> (consumerRecord.value().toString().equals(<span class="string">&quot;over&quot;</span>)) &#123;</span><br><span class="line">                        countDownLatch.countDown();</span><br><span class="line">                        <span class="keyword">return</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li>观察分区分布<br>  <img src="https://i.loli.net/2021/11/19/bB4OuDdJseglSIf.jpg"></li>
</ul>
</li>
</ol>
<h3 id="5-3-3-Sticky"><a href="#5-3-3-Sticky" class="headerlink" title="5.3.3 Sticky"></a>5.3.3 Sticky</h3><p>特殊的分配策略StickyAssignor，Kafka从0.11.x版本开始引入这种分配策略，首先会尽量均衡的放置分区到消费者上面，在出现同一消费者组内消费者出现问题的时候，会尽量保持原有分配的分区不变化。</p>
<ul>
<li>修改分区分配策略为粘性  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> tech.anzhen.kafka.consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.RoundRobinAssignor;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.StickyAssignor;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ConcurrentHashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.CountDownLatch;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.atomic.AtomicInteger;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomConsumerStickyAssignor</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> ConcurrentHashMap&lt;String, AtomicInteger&gt; map = <span class="keyword">new</span> ConcurrentHashMap&lt;&gt;();</span><br><span class="line">    <span class="keyword">static</span> CountDownLatch countDownLatch = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">static</span> AtomicInteger total = <span class="keyword">new</span> AtomicInteger(<span class="number">5001</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;bd-server-001:9092,bd-server-002:9092,bd-server-003:9092,bd-server-004:9092,bd-server-005:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 修改分区分配策略</span></span><br><span class="line">        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, StickyAssignor.class.getName());</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;1234&quot;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; consumerThread(properties,<span class="number">0</span>)).start();</span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; consumerThread(properties,<span class="number">1</span>)).start();</span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; consumerThread(properties,<span class="number">2</span>)).start();</span><br><span class="line"></span><br><span class="line">        countDownLatch.await();</span><br><span class="line">        map.forEach((s, atomicInteger) -&gt; &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;线程: &quot;</span> + s.split(<span class="string">&quot;,&quot;</span>)[<span class="number">0</span>] + <span class="string">&quot; 分区: &quot;</span> + s.split(<span class="string">&quot;,&quot;</span>)[<span class="number">1</span>] + <span class="string">&quot; 消费数量：&quot;</span> + atomicInteger.get());</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">consumerThread</span><span class="params">(Properties properties, <span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> KafkaConsumer&lt;Object, Object&gt; kafkaConsumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> ArrayList&lt;String&gt; topicList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        topicList.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topicList);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">final</span> ConsumerRecords&lt;Object, Object&gt; poll = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">if</span> (poll != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">for</span> (ConsumerRecord&lt;Object, Object&gt; consumerRecord : poll) &#123;</span><br><span class="line">                    <span class="keyword">final</span> AtomicInteger atomicInteger = map.putIfAbsent(Thread.currentThread().getName() + <span class="string">&quot;,&quot;</span> + consumerRecord.partition(), <span class="keyword">new</span> AtomicInteger(<span class="number">1</span>));</span><br><span class="line">                    <span class="keyword">if</span> ( atomicInteger != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        atomicInteger.incrementAndGet();</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">if</span> (total.decrementAndGet() == <span class="number">0</span>) &#123;</span><br><span class="line">                        countDownLatch.countDown();</span><br><span class="line">                        <span class="keyword">return</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">if</span> (index == <span class="number">2</span> &amp;&amp; total.get() &lt; <span class="number">4900</span>) &#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;线程2挂掉了&quot;</span>);</span><br><span class="line">                        <span class="keyword">return</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>观察消息分布<br>  <img src="https://i.loli.net/2021/11/19/FY1Hnhak7oQjPuq.jpg"></li>
</ul>
<h2 id="5-4-offset相关"><a href="#5-4-offset相关" class="headerlink" title="5.4 offset相关"></a>5.4 offset相关</h2><h3 id="5-4-1-offset的维护"><a href="#5-4-1-offset的维护" class="headerlink" title="5.4.1 offset的维护"></a>5.4.1 offset的维护</h3><ul>
<li>由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。</li>
<li>Kafka0.9版本之前，consumer默认将offset保存在Zookeeper中，</li>
<li>从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为<code>__consumer_offsets</code>。</li>
</ul>
<ol>
<li>消费offset案例<ul>
<li>思想：__consumer_offsets为Kafka中的topic，那就可以通过消费者进行消费。</li>
<li>采用命令行方式，创建一个新的topic  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@bd-server-001 ~]<span class="comment"># kafka-topics.sh --bootstrap-server bd-server-001:9092 --create --topic test-consumer-offset --partitions 2 --replication-factor 2</span></span><br><span class="line">Created topic test-consumer-offset.</span><br><span class="line">[root@bd-server-001 ~]<span class="comment"># kafka-topics.sh --bootstrap-server bd-server-001:9092 --list</span></span><br><span class="line">__consumer_offsets</span><br><span class="line">first</span><br><span class="line">test-consumer-offset</span><br></pre></td></tr></table></figure></li>
<li>在配置文件$KAFKA_HOME/config/consumer.properties中添加配置exclude.internal.topics=false，默认是true，表示不能消费系统主题。为了查看该系统主题数据，所以该参数修改为false。</li>
<li>启动生产者往atguigu生产数据  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@bd-server-001 ~]<span class="comment"># kafka-console-producer.sh --topic test-consumer-offset --bootstrap-server  bd-server-001:9092</span></span><br><span class="line">&gt;123</span><br><span class="line">&gt;321</span><br><span class="line">&gt;1234567</span><br></pre></td></tr></table></figure></li>
<li>启动消费者消费atguigu数据  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@bd-server-001 ~]<span class="comment"># kafka-console-consumer.sh --bootstrap-server bd-server-001:9092 --topic test-consumer-offset --group test</span></span><br><span class="line">123</span><br><span class="line">321</span><br><span class="line">1234567</span><br></pre></td></tr></table></figure>
<ul>
<li>注意：必须指定消费者组。</li>
</ul>
</li>
<li>查看消费者消费主题__consumer_offsets  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@bd-server-001 ~]<span class="comment"># kafka-console-consumer.sh --topic __consumer_offsets --bootstrap-server  bd-server-001:9092 --consumer.config $KAFKA_HOME/config/consumer.properties  --formatter &quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter&quot; --from-beginning</span></span><br><span class="line">···</span><br><span class="line">[test-consumer-group,__consumer_offsets,26]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1637325778217, expireTimestamp=None)</span><br><span class="line">[test-consumer-group,__consumer_offsets,29]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1637325778217, expireTimestamp=None)</span><br><span class="line">[test-consumer-group,__consumer_offsets,34]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1637325778217, expireTimestamp=None)</span><br><span class="line">[test-consumer-group,__consumer_offsets,10]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1637325778217, expireTimestamp=None)</span><br><span class="line">[test-consumer-group,__consumer_offsets,32]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1637325778217, expireTimestamp=None)</span><br><span class="line">[test-consumer-group,__consumer_offsets,40]::OffsetAndMetadata(offset=8792, leaderEpoch=Optional[3], metadata=, commitTimestamp=1637325778217, expireTimestamp=None)</span><br><span class="line">···</span><br></pre></td></tr></table></figure>
<h3 id="5-4-2-自动提交offset"><a href="#5-4-2-自动提交offset" class="headerlink" title="5.4.2 自动提交offset"></a>5.4.2 自动提交offset</h3>为了使我们能够专注于自己的业务逻辑，Kafka提供了自动提交offset的功能。<br>自动提交offset的相关参数：</li>
</ul>
</li>
</ol>
<ul>
<li>enable.auto.commit：是否开启自动提交offset功能，默认是true</li>
<li>auto.commit.interval.ms：自动提交offset的时间间隔，默认是5s  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> tech.anzhen.kafka.producer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 给kafka配置对象添加配置信息：bootstrap.servers</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;bd-server-001:9092,bd-server-002:9092,bd-server-003:9092,bd-server-004:9092,bd-server-005:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// key,value序列化（必须）：key.serializer，value.serializer</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 批次大小 默认16K：batch.size</span></span><br><span class="line">        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">16384</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 等待时间：linger.ms</span></span><br><span class="line">        properties.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// RecordAccumulator缓冲区大小 默认32M：buffer.memory</span></span><br><span class="line">        properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG, <span class="number">33554432</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 创建kafka生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 调用send方法,发送消息</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5000</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">&quot;first&quot;</span>, i + <span class="string">&quot;&quot;</span>, <span class="string">&quot;i am producer &quot;</span> + i));</span><br><span class="line">        &#125;</span><br><span class="line">        TimeUnit.SECONDS.sleep(<span class="number">10</span>);</span><br><span class="line">        kafkaProducer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;over&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="5-4-3-自动重置Offset"><a href="#5-4-3-自动重置Offset" class="headerlink" title="5.4.3 自动重置Offset"></a>5.4.3 自动重置Offset</h3><ul>
<li><code>auto.offset.reset = earliest | latest | none</code>, 默认是latest</li>
<li>当Kafka中没有初始偏移量（消费者组第一次消费）或服务器上不再存在当前偏移量时（例如该数据已被删除），该怎么办：<ul>
<li>earliest：自动将偏移量重置为最早的偏移量</li>
<li>latest（默认值）：自动将偏移量重置为最新偏移量</li>
<li>none：如果未找到消费者组的先前偏移量，则向消费者抛出异常<br><img src="https://i.loli.net/2021/11/19/koWfR193XKUJgMe.jpg"></li>
</ul>
</li>
</ul>
<h3 id="5-4-4-手动提交offset"><a href="#5-4-4-手动提交offset" class="headerlink" title="5.4.4 手动提交offset"></a>5.4.4 手动提交offset</h3><ul>
<li>虽然自动提交offset十分简单便利，但由于其是基于时间提交的，开发人员难以把握offset提交的时机。因此Kafka还提供了手动提交offset的API。</li>
<li>手动提交offset的方法有两种：分别是commitSync（同步提交）和commitAsync（异步提交）。<ul>
<li>两者的相同点是，都会将本次poll的一批数据最高的偏移量提交；</li>
<li>不同点是，同步提交阻塞当前线程，一直到提交成功，并且会自动失败重试（由不可控因素导致，也会出现提交失败）；而异步提交则没有失败重试机制，故有可能提交失败。</li>
</ul>
</li>
<li>同步提交offset<ul>
<li>由于同步提交offset有失败重试机制，故更加可靠，以下为同步提交offset的示例。  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> tech.anzhen.kafka.consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: Anzhen</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span>:</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@PROJECT</span>_NAME: sgg-big-data</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@create</span>: 2021-11-19 20:49</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomConsumerByHand</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 1. 创建kafka消费者配置类</span></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">// 2. 添加配置参数</span></span><br><span class="line">        <span class="comment">// 添加连接</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;bd-server-001:9092,bd-server-002:9092,bd-server-003:9092,bd-server-004:9092,bd-server-005:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置序列化 必须</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置消费者组</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 是否自动提交offset</span></span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string">&quot;false&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 创建kafka消费者</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 设置消费主题  形参是列表</span></span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">&quot;first&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5. 消费数据</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>)&#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 读取消息</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 输出消息</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord.value());</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 同步提交offset</span></span><br><span class="line">            consumer.commitSync();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>异步提交offset<ul>
<li>虽然同步提交offset更可靠一些，但是由于其会阻塞当前线程，直到提交成功。因此吞吐量会受到很大的影响。因此更多的情况下，会选用异步提交offset的方式。</li>
<li>以下为异步提交offset的示例：  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建kafka消费者配置类</span></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 添加配置参数</span></span><br><span class="line">        <span class="comment">// 添加连接</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置序列化 必须</span></span><br><span class="line">properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置消费者组</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 是否自动提交offset</span></span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string">&quot;false&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 创建Kafka消费者</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 设置消费主题  形参是列表</span></span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">&quot;first&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5. 消费数据</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>)&#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 读取消息</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 输出消息</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord.value());</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 异步提交offset</span></span><br><span class="line">            consumer.commitAsync(<span class="keyword">new</span> OffsetCommitCallback() &#123;</span><br><span class="line">                <span class="comment">/**</span></span><br><span class="line"><span class="comment">                 * 回调函数输出</span></span><br><span class="line"><span class="comment">                 * <span class="doctag">@param</span> offsets   offset信息</span></span><br><span class="line"><span class="comment">                 * <span class="doctag">@param</span> exception 异常</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception)</span> </span>&#123;</span><br><span class="line">                    <span class="comment">// 如果出现异常打印</span></span><br><span class="line">                    <span class="keyword">if</span> (exception != <span class="keyword">null</span> )&#123;</span><br><span class="line">                        System.err.println(<span class="string">&quot;Commit failed for &quot;</span> + offsets);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h3 id="5-4-5-数据漏消费和重复消费分析"><a href="#5-4-5-数据漏消费和重复消费分析" class="headerlink" title="5.4.5 数据漏消费和重复消费分析"></a>5.4.5 数据漏消费和重复消费分析</h3><p>无论是同步提交还是异步提交offset，都有可能会造成数据的漏消费或者重复消费。先提交offset后消费，有可能造成数据的漏消费；而先消费后提交offset，有可能会造成数据的重复消费。所以需要Consumer事务保证<font color ='red' >精准一次性消费</font></p>
<h2 id="5-5-Consumer事务（精准一次性消费）"><a href="#5-5-Consumer事务（精准一次性消费）" class="headerlink" title="5.5 Consumer事务（精准一次性消费）"></a>5.5 Consumer事务（精准一次性消费）</h2><p><img src="https://i.loli.net/2021/11/19/mlHzxE5U2XwLYyd.jpg"><br>如果想完成Consumer端的精准一次性消费，那么需要Kafka消费端将消费过程和提交offset过程做原子绑定。此时我们需要将Kafka的offset保存到支持事务的自定义介质（比如MySQL）</p>
<h1 id="第6章-Kafka-Eagle监控"><a href="#第6章-Kafka-Eagle监控" class="headerlink" title="第6章 Kafka-Eagle监控"></a>第6章 Kafka-Eagle监控</h1><ul>
<li>官网：<a target="_blank" rel="noopener" href="https://www.kafka-eagle.org/">https://www.kafka-eagle.org/</a></li>
</ul>
<ol>
<li>关闭Kafka集群 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 kafka]$ kf.sh stop</span><br></pre></td></tr></table></figure></li>
<li>修改$KAFAK_HOME/bin/kafka-server-start.sh命令修改如下参数值： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;x<span class="variable">$KAFKA_HEAP_OPTS</span>&quot;</span> = <span class="string">&quot;x&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">export</span> KAFKA_HEAP_OPTS=<span class="string">&quot;-server -Xms2G -Xmx2G -XX:PermSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:ParallelGCThreads=8 -XX:ConcGCThreads=5 -XX:InitiatingHeapOccupancyPercent=70&quot;</span></span><br><span class="line">    <span class="built_in">export</span> JMX_PORT=<span class="string">&quot;9999&quot;</span></span><br><span class="line">    <span class="comment">#export KAFKA_HEAP_OPTS=&quot;-Xmx1G -Xms1G&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：修改之后在启动Kafka之前要分发之其他节点<br>xsync kafka-server-start.sh</p>
</blockquote>
</li>
<li>上传压缩包kafka-eagle-bin-2.0.8.tar.gz到集群/opt/software目录</li>
<li>解压到本地 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 software]$ tar -zxvf kafka-eagle-bin-2.0.8.tar.gz </span><br></pre></td></tr></table></figure></li>
<li>将efak-web-2.0.8-bin.tar.gz解压至/opt/module <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 kafka-eagle-bin-2.0.8]$ tar -zxvf efak-web-2.0.8-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure></li>
<li>修改配置文件 /opt/module/efak-web-2.0.8/conf/system-config.properties <figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># multi zookeeper &amp; kafka cluster list</span></span><br><span class="line"><span class="comment"># Settings prefixed with &#x27;kafka.eagle.&#x27; will be deprecated, use &#x27;efak.&#x27; instead</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="meta">efak.zk.cluster.alias</span>=<span class="string">cluster1</span></span><br><span class="line"><span class="meta">cluster1.zk.list</span>=<span class="string">hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># zookeeper enable acl</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="meta">cluster1.zk.acl.enable</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">cluster1.zk.acl.schema</span>=<span class="string">digest</span></span><br><span class="line"><span class="meta">cluster1.zk.acl.username</span>=<span class="string">test</span></span><br><span class="line"><span class="meta">cluster1.zk.acl.password</span>=<span class="string">test123</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># broker size online list</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="meta">cluster1.efak.broker.size</span>=<span class="string">20</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># zk client thread limit</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="meta">kafka.zk.limit.size</span>=<span class="string">32</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># EFAK webui port</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="meta">efak.webui.port</span>=<span class="string">8048</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># kafka jmx acl and ssl authenticate</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="meta">cluster1.efak.jmx.acl</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">cluster1.efak.jmx.user</span>=<span class="string">keadmin</span></span><br><span class="line"><span class="meta">cluster1.efak.jmx.password</span>=<span class="string">keadmin123</span></span><br><span class="line"><span class="meta">cluster1.efak.jmx.ssl</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">cluster1.efak.jmx.truststore.location</span>=<span class="string">/data/ssl/certificates/kafka.truststore</span></span><br><span class="line"><span class="meta">cluster1.efak.jmx.truststore.password</span>=<span class="string">ke123456</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># kafka offset storage</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># offset保存在kafka</span></span><br><span class="line"><span class="meta">cluster1.efak.offset.storage</span>=<span class="string">kafka</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># kafka jmx uri</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="meta">cluster1.efak.jmx.uri</span>=<span class="string">service:jmx:rmi:///jndi/rmi://%s/jmxrmi</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># kafka metrics, 15 days by default</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="meta">efak.metrics.charts</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">efak.metrics.retain</span>=<span class="string">15</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># kafka sql topic records max</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="meta">efak.sql.topic.records.max</span>=<span class="string">5000</span></span><br><span class="line"><span class="meta">efak.sql.topic.preview.records.max</span>=<span class="string">10</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># delete kafka topic token</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="meta">efak.topic.token</span>=<span class="string">keadmin</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># kafka sasl authenticate</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="meta">cluster1.efak.sasl.enable</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">cluster1.efak.sasl.protocol</span>=<span class="string">SASL_PLAINTEXT</span></span><br><span class="line"><span class="meta">cluster1.efak.sasl.mechanism</span>=<span class="string">SCRAM-SHA-256</span></span><br><span class="line"><span class="meta">cluster1.efak.sasl.jaas.config</span>=<span class="string">org.apache.kafka.common.security.scram.ScramLoginModule required username=&quot;kafka&quot; password=&quot;kafka-eagle&quot;;</span></span><br><span class="line"><span class="meta">cluster1.efak.sasl.client.id</span>=<span class="string"></span></span><br><span class="line"><span class="meta">cluster1.efak.blacklist.topics</span>=<span class="string"></span></span><br><span class="line"><span class="meta">cluster1.efak.sasl.cgroup.enable</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">cluster1.efak.sasl.cgroup.topics</span>=<span class="string"></span></span><br><span class="line"><span class="meta">cluster2.efak.sasl.enable</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">cluster2.efak.sasl.protocol</span>=<span class="string">SASL_PLAINTEXT</span></span><br><span class="line"><span class="meta">cluster2.efak.sasl.mechanism</span>=<span class="string">PLAIN</span></span><br><span class="line"><span class="meta">cluster2.efak.sasl.jaas.config</span>=<span class="string">org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;kafka&quot; password=&quot;kafka-eagle&quot;;</span></span><br><span class="line"><span class="meta">cluster2.efak.sasl.client.id</span>=<span class="string"></span></span><br><span class="line"><span class="meta">cluster2.efak.blacklist.topics</span>=<span class="string"></span></span><br><span class="line"><span class="meta">cluster2.efak.sasl.cgroup.enable</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">cluster2.efak.sasl.cgroup.topics</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># kafka ssl authenticate</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="meta">cluster3.efak.ssl.enable</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">cluster3.efak.ssl.protocol</span>=<span class="string">SSL</span></span><br><span class="line"><span class="meta">cluster3.efak.ssl.truststore.location</span>=<span class="string"></span></span><br><span class="line"><span class="meta">cluster3.efak.ssl.truststore.password</span>=<span class="string"></span></span><br><span class="line"><span class="meta">cluster3.efak.ssl.keystore.location</span>=<span class="string"></span></span><br><span class="line"><span class="meta">cluster3.efak.ssl.keystore.password</span>=<span class="string"></span></span><br><span class="line"><span class="meta">cluster3.efak.ssl.key.password</span>=<span class="string"></span></span><br><span class="line"><span class="meta">cluster3.efak.ssl.endpoint.identification.algorithm</span>=<span class="string">https</span></span><br><span class="line"><span class="meta">cluster3.efak.blacklist.topics</span>=<span class="string"></span></span><br><span class="line"><span class="meta">cluster3.efak.ssl.cgroup.enable</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">cluster3.efak.ssl.cgroup.topics</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># kafka sqlite jdbc driver address</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># 配置mysql连接</span></span><br><span class="line"><span class="meta">efak.driver</span>=<span class="string">com.mysql.jdbc.Driver</span></span><br><span class="line"><span class="meta">efak.url</span>=<span class="string">jdbc:mysql://hadoop102:3306/ke?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull</span></span><br><span class="line"><span class="meta">efak.username</span>=<span class="string">root</span></span><br><span class="line"><span class="meta">efak.password</span>=<span class="string">000000</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># kafka mysql jdbc driver address</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment">#efak.driver=com.mysql.cj.jdbc.Driver</span></span><br><span class="line"><span class="comment">#efak.url=jdbc:mysql://127.0.0.1:3306/ke?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull</span></span><br><span class="line"><span class="comment">#efak.username=root</span></span><br><span class="line"><span class="comment">#efak.password=123456</span></span><br></pre></td></tr></table></figure></li>
<li>添加环境变量 /etc/profile.d/my_env.sh <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kafkaEFAK</span></span><br><span class="line"><span class="built_in">export</span> KE_HOME=/opt/module/efak</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$KE_HOME</span>/bin</span><br></pre></td></tr></table></figure></li>
<li>启动<ol>
<li>启动ZK以及KAFKA</li>
<li>启动efak <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 efak]$ bin/ke.sh start</span><br><span class="line">Version 2.0.8 -- Copyright 2016-2021</span><br><span class="line">*****************************************************************</span><br><span class="line">* EFAK Service has started success.</span><br><span class="line">* Welcome, Now you can visit <span class="string">&#x27;http://192.168.10.102:8048&#x27;</span></span><br><span class="line">* Account:admin ,Password:123456</span><br><span class="line">*****************************************************************</span><br><span class="line">* &lt;Usage&gt; ke.sh [start|status|stop|restart|stats] &lt;/Usage&gt;</span><br><span class="line">* &lt;Usage&gt; https://www.kafka-eagle.org/ &lt;/Usage&gt;</span><br><span class="line">*****************************************************************</span><br></pre></td></tr></table></figure>
<blockquote>
<p>说明：如果停止efak，执行命令 ke.sh stop</p>
</blockquote>
</li>
</ol>
</li>
<li>登录页面查看监控数据<br> <a target="_blank" rel="noopener" href="http://192.168.10.102:8048/">http://192.168.10.102:8048/</a></li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/interview/" rel="tag">interview</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Java并发与多线程"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/Java%E5%B9%B6%E5%8F%91%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B/"
    >Java并发与多线程</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/Java%E5%B9%B6%E5%8F%91%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B/" class="article-date">
  <time datetime="2021-11-07T02:56:22.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Java/">Java</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="并发与多线程"><a href="#并发与多线程" class="headerlink" title="并发与多线程"></a>并发与多线程</h1><h2 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h2><ol>
<li>volatile 有什么用？<ul>
<li>volatile 保证内存可见性和禁止指令重排。volatile 可以提供部分原子性。</li>
<li>volatile 用于多线程环境下的单次操作(单次读或者单次写)。</li>
</ul>
</li>
<li>volatile 变量和 atomic 变量有什么不同？<ul>
<li>volatile 变量，可以确保先行关系，即写操作会发生在后续的读操作之前，但它并不能保证原子性。例如用 volatile 修饰 count 变量，那么 count++ 操作就不是原子性的。</li>
<li>AtomicInteger 类提供的 atomic 方法，可以让这种操作具有原子性。例如 #getAndIncrement() 方法，会原子性的进行增量操作把当前值加一，其它数据类型和引用变量也可以进行相似操作。</li>
</ul>
</li>
<li>Java 中能创建 volatile 数组吗?<ul>
<li>能创建但指向引用,不保证内部元素;</li>
</ul>
</li>
<li>volatile 能使得一个非原子操作变成原子操作吗？<ul>
<li>对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种读写复合操作不具有原子性。</li>
</ul>
</li>
<li>volatile 修饰符的有过什么实践？<ul>
<li>用 volatile 修饰 long 和 double 变量,使其读写支持原子性;</li>
<li>状态标志 Boolean 值;</li>
<li>独立观察,单独监测某个多个线程共享的变量</li>
<li>轻量级锁</li>
</ul>
</li>
<li>volatile 类型变量提供什么保证？<ul>
<li>volatile 变量提供顺序性和可见性保证</li>
<li>避免指令重排</li>
<li>可见性保证</li>
</ul>
</li>
<li>volatile 和 synchronized 的区别？<ul>
<li>volatile 本质是在告诉 JVM 当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取。synchronized 则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。</li>
<li>volatile 仅能使用在变量级别。synchronized 则可以使用在变量、方法、和类级别的。</li>
<li>volatile 仅能实现变量的修改可见性，不能保证原子性。而synchronized 则可以保证变量的修改可见性和原子性。</li>
<li>volatile 不会造成线程的阻塞。synchronized 可能会造成线程的阻塞。</li>
<li>volatile 标记的变量不会被编译器优化。synchronized标记的变量可以被编译器优化。</li>
</ul>
</li>
<li>什么场景下可以使用 volatile 替换 synchronized ？<ul>
<li>只需要保证共享资源的可见性的时候可以使用 volatile 替代，synchronized 保证可操作的原子性一致性和可见性。</li>
<li>volatile 适用于新值不依赖于旧值的情形。</li>
<li>1 写 N 读。</li>
<li>不与其他变量构成不变性条件时候使用 volatile 。<h2 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h2></li>
</ul>
</li>
<li>synchronized 的原理是什么?<ul>
<li>synchronized是 Java 内置的关键字，它提供了一种独占的加锁方式。</li>
<li>synchronized的获取和释放锁由JVM实现，用户不需要显示的释放锁，非常方便。</li>
<li>synchronized 也有一定的局限性。<ul>
<li>当线程尝试获取锁的时候，如果获取不到锁会一直阻塞。</li>
<li>如果获取锁的线程进入休眠或者阻塞，除非当前线程异常，否则其他线程尝试获取锁必须一直等待。</li>
</ul>
</li>
</ul>
</li>
<li>同步方法和同步块，哪个是更好的选择？<ul>
<li>同步块是更好的选择，因为它不会锁住整个对象（当然你也可以让它锁住整个对象）。同步方法会锁住整个对象，哪怕这个类中有多个不相关联的同步块，这通常会导致他们停止执行并需要等待获得这个对象上的锁。</li>
<li>同步块更要符合开放调用的原则，只在需要锁住的代码块锁住相应的对象，这样从侧面来说也可以避免死锁。</li>
</ul>
</li>
<li>当一个线程进入某个对象的一个 synchronized 的实例方法后，其它线程是否可进入此对象的其它方法？<ul>
<li>如果其他方法没有 synchronized 的话，其他线程是可以进入的。</li>
<li>所以要开放一个线程安全的对象时，得保证每个方法都是线程安全的。、</li>
</ul>
</li>
<li>在监视器(Monitor)内部，是如何做线程同步的？<ul>
<li>监视器和锁在 Java 虚拟机中是一块使用的。监视器监视一块同步代码块，确保一次只有一个线程执行同步代码块。每一个监视器都和一个对象引用相关联。线程在获取锁之前不允许执行同步代码。</li>
</ul>
</li>
<li>Java 如何实现“自旋”（spin） <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpinLock</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> AtomicReference&lt;Thread&gt; sign =<span class="keyword">new</span> AtomicReference&lt;&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">lock</span><span class="params">()</span> </span>&#123; <span class="comment">// &lt;1&gt;</span></span><br><span class="line">        Thread current = Thread.currentThread();</span><br><span class="line">        <span class="keyword">while</span>(!sign .compareAndSet(<span class="keyword">null</span>, current)) &#123;</span><br><span class="line">            <span class="comment">// &lt;1.1&gt;</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">unlock</span> <span class="params">()</span> </span>&#123; <span class="comment">// &lt;2&gt;</span></span><br><span class="line">        Thread current = Thread.currentThread();</span><br><span class="line">        sign .compareAndSet(current, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>&lt;1&gt; 处，#lock() 方法，如果获得不到锁，就会“死循环”，直到或得到锁为止。考虑到“死循环”会持续占用 CPU ，可能导致其它线程无法获得到 CPU 执行，可以在 &lt;1.1&gt; 处增加 Thread.yiead() 代码段，出让下 CPU 。</li>
<li>&lt;2&gt; 处，#unlock() 方法，释放锁。</li>
</ul>
</li>
</ol>
<p>#Java Lock 接口<br>    - <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15852735326621.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>什么是 Java Lock 接口？<ul>
<li>java.util.concurrent.locks.Lock 接口，比 synchronized 提供更具拓展性的锁操作。它允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。它的优势有：<ul>
<li>可以使锁更公平。</li>
<li>可以使线程在等待锁的时候响应中断。</li>
<li>可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间。</li>
<li>可以在不同的范围，以不同的顺序获取和释放锁。</li>
</ul>
</li>
</ul>
</li>
<li>什么是可重入锁（ReentrantLock）？<ul>
<li>举例来说明锁的可重入性。代码如下：  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UnReentrant</span></span>&#123;</span><br><span class="line">    Lock lock = <span class="keyword">new</span> Lock();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">outer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        lock.lock();</span><br><span class="line">        inner();</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">inner</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        lock.lock();</span><br><span class="line">        <span class="comment">//do something</span></span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>outer() 方法中调用了 #inner() 方法，#outer() 方法先锁住了 lock ，这样 #inner() 就不能再获取 lock 。</li>
<li>其实调用 #outer() 方法的线程已经获取了 lock 锁，但是不能在 #inner() 方法中重复利用已经获取的锁资源，这种锁即称之为不可重入。</li>
<li>可重入就意味着：线程可以进入任何一个它已经拥有的锁所同步着的代码块。</li>
<li>synchronized、ReentrantLock 都是可重入的锁，可重入锁相对来说简化了并发编程的开发。</li>
<li>ReenTrantLock 的实现是一种自旋锁，通过循环调用 CAS 操作来实现加锁。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。</li>
</ul>
</li>
<li>synchronized 和 ReentrantLock 异同？<ul>
<li>相同点<ul>
<li>都实现了多线程同步和内存可见性语义。</li>
<li>都是可重入锁。</li>
</ul>
</li>
<li>不同点<ul>
<li>同步实现机制不同<ul>
<li>synchronized 通过 Java 对象头锁标记和 Monitor 对象实现同步。</li>
<li>ReentrantLock 通过CAS、AQS（AbstractQueuedSynchronizer）和 LockSupport（用于阻塞和解除阻塞）实现同步。</li>
</ul>
</li>
<li>可见性实现机制不同<ul>
<li>synchronized 依赖 JVM 内存模型保证包含共享变量的多线程内存可见性。</li>
<li>ReentrantLock 通过 ASQ 的 volatile state 保证包含共享变量的多线程内存可见性。</li>
</ul>
</li>
<li>使用方式不同<ul>
<li>synchronized 可以修饰实例方法（锁住实例对象）、静态方法（锁住类对象）、代码块（显示指定锁对象）。</li>
<li>ReentrantLock 显示调用 tryLock 和 lock 方法，需要在 finally 块中释放锁。</li>
</ul>
</li>
<li>功能丰富程度不同<ul>
<li>synchronized 不可设置等待时间、不可被中断（interrupted）。</li>
<li>ReentrantLock 提供有限时间等候锁（设置过期时间）、可中断锁（lockInterruptibly）、condition（提供 await、condition（提供 await、signal 等方法）等丰富功能</li>
</ul>
</li>
<li>锁类型不同<ul>
<li>synchronized 只支持非公平锁。</li>
<li>ReentrantLock 提供公平锁和非公平锁实现。当然，在大部分情况下，非公平锁是高效的选择。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>ReadWriteLock 是什么？<ul>
<li>ReadWriteLock ，读写锁是，用来提升并发程序性能的锁分离技术的 Lock 实现类。可以用于 “多读少写” 的场景，读写锁支持多个读操作并发执行，写操作只能由一个线程来操作。</li>
<li>ReadWriteLock 对向数据结构相对不频繁地写入，但是有多个任务要经常读取这个数据结构的这类情况进行了优化。ReadWriteLock 使得你可以同时有多个读取者，只要它们都不试图写入即可。如果写锁已经被其他任务持有，那么任何读取者都不能访问，直至这个写锁被释放为止。</li>
<li>ReadWriteLock 对程序性能的提高主要受制于如下几个因素：<ul>
<li>数据被读取的频率与被修改的频率相比较的结果。</li>
<li>读取和写入的时间</li>
<li>有多少线程竞争</li>
<li>是否在多处理机器上运行</li>
</ul>
</li>
</ul>
</li>
<li>Condition 是什么？<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15852741845639.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10" alt="-w762"><h2 id="Java-内存模型"><a href="#Java-内存模型" class="headerlink" title="Java 内存模型"></a>Java 内存模型</h2></li>
</ul>
</li>
<li>两个线程之间是如何通信的呢？<ul>
<li>线程之间的通信方式，目前有共享内存和消息传递两种。<ul>
<li>在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信。典型的共享内存通信方式，就是通过共享对象进行通信。<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15852745337896.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ul>
</li>
<li>在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。在 Java 中典型的消息传递方式，就是 #wait() 和 #notify() ，或者 BlockingQueue 。<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15852745812427.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>为什么代码会重排序？<ul>
<li>在执行程序时，为了提供性能，处理器和编译器常常会对指令进行重排序，但是不能随意重排序，不是你想怎么排序就怎么排序，它需要满足以下两个条件：<ul>
<li>在单线程环境下不能改变程序运行的结果。</li>
<li>存在数据依赖关系的不允许重排序</li>
</ul>
<blockquote>
<p>重排序不会影响单线程环境的执行结果，但是会破坏多线程的执行语义。</p>
</blockquote>
</li>
</ul>
</li>
</ol>
<h2 id="Java-并发容器"><a href="#Java-并发容器" class="headerlink" title="Java 并发容器"></a>Java 并发容器</h2><ol>
<li>Java 中 ConcurrentHashMap 的并发度是什么？<ul>
<li>锁单个Node节点</li>
</ul>
</li>
<li>ConcurrentHashMap 为何读不用加锁？<ul>
<li>Node 的 val 和 next 均为 volatile 型。</li>
<li>tabAt(..,) 和 casTabAt(…) 对应的 Unsafe 操作实现了 volatile 语义。</li>
</ul>
</li>
<li>CopyOnWriteArrayList 可以用于什么应用场景？<ul>
<li>CopyOnWriteArrayList(免锁容器)的好处之一是当多个迭代器同时遍历和修改这个列表时，不会抛出ConcurrentModificationException 异常。在 CopyOnWriteArrayList 中，写入将导致创建整个底层数组的副本，而源数组将保留在原地，使得复制的数组在被修改时，读取操作可以安全地执行。<ul>
<li>由于写操作的时候，需要拷贝数组，会消耗内存，如果原数组的内容比较多的情况下，可能导致 ygc 或者 fgc 。</li>
<li>不能用于实时读的场景，像拷贝数组、新增元素都需要时间，所以调用一个 set 操作后，读取到数据可能还是旧的,虽然 CopyOnWriteArrayList 能做到最终一致性,但是还是没法满足实时性要求。</li>
</ul>
</li>
<li>CopyOnWriteArrayList 透露的思想：</li>
<li>读写分离，读和写分开</li>
<li>最终一致性</li>
<li>使用另外开辟空间的思路，来解决并发冲突<h2 id="Java-阻塞队列"><a href="#Java-阻塞队列" class="headerlink" title="Java 阻塞队列"></a>Java 阻塞队列</h2></li>
</ul>
</li>
<li>什么是阻塞队列？有什么适用场景？<ul>
<li>阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作是：<ul>
<li>在队列为空时，获取元素的线程会等待队列变为非空。</li>
<li>当队列满时，存储元素的线程会等待队列可用。</li>
</ul>
</li>
<li>阻塞队列常用于生产者和消费者的场景：<ul>
<li>生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程</li>
<li>阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。</li>
</ul>
</li>
<li>BlockingQueue 接口，是 Queue 的子接口，它的主要用途并不是作为容器，而是作为线程同步的的工具，因此他具有一个很明显的特性：<ul>
<li>当生产者线程试图向 BlockingQueue 放入元素时，如果队列已满，则线程被阻塞。</li>
<li>当消费者线程试图从中取出一个元素时，如果队列为空，则该线程会被阻塞。</li>
<li>正是因为它所具有这个特性，所以在程序中多个线程交替向BlockingQueue中 放入元素，取出元素，它可以很好的控制线程之间的通信。</li>
<li>阻塞队列使用最经典的场景，就是 Socket 客户端数据的读取和解析：<ul>
<li>读取数据的线程不断将数据放入队列。</li>
<li>然后，解析线程不断从队列取数据解析。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Java 提供了哪些阻塞队列的实现？<ul>
<li>ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。</li>
<li>LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。</li>
<li>PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。</li>
<li>DelayQueue：支持延时获取元素的无界阻塞队列，即可以指定多久才能从队列中获取当前元素。</li>
<li>SynchronousQueue：一个不存储元素的阻塞队列。</li>
</ul>
</li>
<li>简述 ConcurrentLinkedQueue 和 LinkedBlockingQueue 的用处和不同之处？<ul>
<li>阻塞队列，典型例子是 LinkedBlockingQueue 。使用阻塞队列的好处：多线程操作共同的队列时不需要额外的同步，另外就是队列会自动平衡负载，即那边（生产与消费两边）处理快了就会被阻塞掉，从而减少两边的处理速度差距。</li>
<li>非阻塞队列，典型例子是 ConcurrentLinkedQueue 。当许多线程共享访问一个公共集合时，ConcurrentLinkedQueue 是一个恰当的选择。</li>
<li>具体的选择，如下：<ul>
<li>LinkedBlockingQueue 多用于任务队列。<ul>
<li>单生产者，单消费者</li>
<li>多生产者，单消费者</li>
</ul>
</li>
<li>ConcurrentLinkedQueue 多用于消息队列。<ul>
<li>单生产者，多消费者</li>
<li>多生产者，多消费者</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="Java-原子操作类"><a href="#Java-原子操作类" class="headerlink" title="Java 原子操作类"></a>Java 原子操作类</h2><ol>
<li>什么是原子操作？<ul>
<li>原子操作（Atomic Operation），意为”不可被中断的一个或一系列操作”。</li>
<li>处理器使用基于对缓存加锁或总线加锁的方式，来实现多处理器之间的原子操作。</li>
<li>在 Java 中，可以通过锁和循环 CAS 的方式来实现原子操作。CAS操作 —— Compare &amp; Set ，或是 Compare &amp; Swap ，现在几乎所有的 CPU 指令都支持 CAS 的原子操作。</li>
</ul>
</li>
<li>CAS 操作有什么缺点？<ul>
<li>ABA 问题<ul>
<li>比如说一个线程 one 从内存位置 V 中取出 A ，这时候另一个线程 two 也从内存中取出 A ，并且 two 进行了一些操作变成了 B ，然后 two 又将 V 位置的数据变成 A ，这时候线程 one 进行 CAS 操作发现内存中仍然是 A ，然后 one 操作成功。尽管线程 one 的 CAS 操作成功，但可能存在潜藏的问题。</li>
</ul>
</li>
<li>循环时间长开销大<ul>
<li>对于资源竞争严重（线程冲突严重）的情况，CAS 自旋的概率会比较大，从而浪费更多的 CPU 资源，效率低于</li>
</ul>
</li>
<li>只能保证一个共享变量的原子操作<ul>
<li>当对一个共享变量执行操作时，我们可以使用循环 CAS 的方式来保证原子操作，但是对多个共享变量操作时，循环 CAS 就无法保证操作的原子性，这个时候就可以用锁。<h2 id="Java-并发工具类"><a href="#Java-并发工具类" class="headerlink" title="Java 并发工具类"></a>Java 并发工具类</h2></li>
</ul>
</li>
</ul>
</li>
<li>Semaphore 是什么？<ul>
<li>Semaphore ，是一种新的同步类，它是一个计数信号。从概念上讲，从概念上讲，信号量维护了一个许可集合。<ul>
<li>如有必要，在许可可用前会阻塞每一个 #acquire() 方法，然后再获取该许可。</li>
<li>每个 #release() 方法，添加一个许可，从而可能释放一个正在阻塞的获取者。</li>
<li>但是，不使用实际的许可对象，Semaphore 只对可用许可的数量进行计数，并采取相应的行动。</li>
</ul>
</li>
</ul>
</li>
<li>说说 CountDownLatch 原理<ul>
<li>CountDownLatch ，字面意思是减小计数（CountDown）的门闩（Latch）。它要做的事情是，等待指定数量的计数被减少，意味着门闩被打开，然后进行执行。</li>
<li>CountDownLatch 默认的构造方法是 CountDownLatch(int count) ，其参数表需要减少的计数，主线程调用 #await() 方法告诉 CountDownLatch 阻塞等待指定数量的计数被减少，然后其它线程调用 CountDownLatch 的 #countDown() 方法，减小计数(不会阻塞)。等待计数被减少到零，主线程结束阻塞等待，继续往下执行。</li>
</ul>
</li>
<li>说说 CyclicBarrier 原理<ul>
<li>CyclicBarrier ，字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。</li>
<li>CyclicBarrier 默认的构造方法是 CyclicBarrier(int parties) ，其参数表示屏障拦截的线程数量，每个线程调用 #await() 方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞，直到 parties 个线程到达，结束阻塞。</li>
</ul>
</li>
<li>CyclicBarrier 和 CountdownLatch 有什么区别？<ul>
<li>CyclicBarrier 可以重复使用，而 CountdownLatch 不能重复使用。</li>
<li>CountDownLatch 其实可以把它看作一个计数器，只不过这个计数器的操作是原子操作。</li>
<li>CyclicBarrier 一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)</li>
</ul>
<table>
<thead>
<tr>
<th>CountDownLatch</th>
<th>CyclicBarrier</th>
</tr>
</thead>
<tbody><tr>
<td>减计数方式</td>
<td>加计数方式</td>
</tr>
<tr>
<td>计算为 0 时释放所有等待的线程</td>
<td>计数达到指定值时释放所有等待线程</td>
</tr>
<tr>
<td>计数为 0 时，无法重置</td>
<td>计数达到指定值时，计数置为 0 重新开始</td>
</tr>
<tr>
<td>调用 #countDown() 方法计数减一，调用 #await() 方法只进行阻塞，对计数没任何影响</td>
<td>调用 #await() 方法计数加 1 ，若加 1 后的值不等于构造方法的值，则线程阻塞</td>
</tr>
<tr>
<td>不可重复利用</td>
<td>可重复利用</td>
</tr>
</tbody></table>
</li>
</ol>
<h2 id="Java-线程池"><a href="#Java-线程池" class="headerlink" title="Java 线程池"></a>Java 线程池</h2><ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15852766289037.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ul>
<ol>
<li>什么是 Executor 框架？<ul>
<li>Executor 框架，是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架。</li>
<li>无限制的创建线程，会引起应用程序内存溢出。所以创建一个线程池是个更好的的解决方案，因为可以限制线程的数量并且可以回收再利用这些线程。利用 Executor 框架，可以非常方便的创建一个线程池。</li>
</ul>
</li>
<li>为什么使用 Executor 框架？<ul>
<li>每次执行任务创建线程 new Thread() 比较消耗性能，创建一个线程是比较耗时、耗资源的。</li>
<li>调用 new Thread() 创建的线程缺乏管理，被称为野线程，而且可以无限制的创建，线程之间的相互竞争会导致过多占用系统资源而导致系统瘫痪，还有线程之间的频繁交替也会消耗很多系统资源。</li>
<li>接使用 new Thread() 启动的线程不利于扩展，比如定时执行、定期执行、定时定期执行、线程中断等都不便实现。</li>
</ul>
</li>
<li>在 Java 中 Executor 和 Executors 的区别？<ul>
<li>Executors 是 Executor 的工具类，不同方法按照我们的需求创建了不同的线程池，来满足业务的需求。</li>
<li>Executor 是接口对象，能执行我们的线程任务。<ul>
<li>ExecutorService 接口，继承了 Executor 接口，并进行了扩展，提供了更多的方法我们能获得任务执行的状态并且可以获取任务的返回值。</li>
<li>使用 ThreadPoolExecutor ，可以创建自定义线程池。</li>
<li>Future 表示异步计算的结果，他提供了检查计算是否完成的方法，以等待计算的完成，并可以使用 #get() 方法，获取计算的结果。</li>
</ul>
</li>
</ul>
</li>
<li>创建线程池的几种方式？<ul>
<li>Executors 创建的线程池，分成普通任务线程池，和定时任务线程池。<ul>
<li>普通任务线程池<ul>
<li>1、#newFixedThreadPool(int nThreads) 方法，创建一个固定长度的线程池。每当提交一个任务就创建一个线程，直到达到线程池的最大数量，这时线程规模将不再变化。当线程发生未预期的错误而结束时，线程池会补充一个新的线程。</li>
<li>2、#newCachedThreadPool() 方法，创建一个可缓存的线程池。如果线程池的规模超过了处理需求，将自动回收空闲线程。当需求增加时，则可以自动添加新线程。线程池的规模不存在任何限制。</li>
<li>3、#newSingleThreadExecutor() 方法，创建一个单线程的线程池。它创建单个工作线程来执行任务，如果这个线程异常结束，会创建一个新的来替代它。它的特点是，能确保依照任务在队列中的顺序来串行执行。</li>
</ul>
</li>
<li>定时任务线程池<ul>
<li>4、#newScheduledThreadPool(int corePoolSize) 方法，创建了一个固定长度的线程池，而且以延迟或定时的方式来执行任务，类似 Timer 。</li>
<li>5、#newSingleThreadExecutor() 方法，创建了一个固定长度为 1 的线程池，而且以延迟或定时的方式来执行任务，类似 Timer 。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>如何使用 ThreadPoolExecutor 创建线程池？ <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutor</span><span class="params">(<span class="keyword">int</span> corePoolSize,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="keyword">int</span> maximumPoolSize,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="keyword">long</span> keepAliveTime,</span></span></span><br><span class="line"><span class="params"><span class="function">                      TimeUnit unit,</span></span></span><br><span class="line"><span class="params"><span class="function">                      BlockingQueue&lt;Runnable&gt; workQueue,</span></span></span><br><span class="line"><span class="params"><span class="function">                      ThreadFactory threadFactory,</span></span></span><br><span class="line"><span class="params"><span class="function">                      RejectedExecutionHandler handler)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (corePoolSize &lt; <span class="number">0</span> ||</span><br><span class="line">        maximumPoolSize &lt;= <span class="number">0</span> ||</span><br><span class="line">        maximumPoolSize &lt; corePoolSize ||</span><br><span class="line">        keepAliveTime &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();</span><br><span class="line">    <span class="keyword">if</span> (workQueue == <span class="keyword">null</span> || threadFactory == <span class="keyword">null</span> || handler == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    <span class="keyword">this</span>.corePoolSize = corePoolSize;</span><br><span class="line">    <span class="keyword">this</span>.maximumPoolSize = maximumPoolSize;</span><br><span class="line">    <span class="keyword">this</span>.workQueue = workQueue;</span><br><span class="line">    <span class="keyword">this</span>.keepAliveTime = unit.toNanos(keepAliveTime);</span><br><span class="line">    <span class="keyword">this</span>.threadFactory = threadFactory;</span><br><span class="line">    <span class="keyword">this</span>.handler = handler;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>corePoolSize 参数，核心线程数大小，当线程数 &lt; corePoolSize ，会创建线程执行任务。</li>
<li>maximumPoolSize 参数，最大线程数， 当线程数 &gt;= corePoolSize 的时候，会把任务放入 workQueue 队列中。</li>
<li>keepAliveTime 参数，保持存活时间，当线程数大于 corePoolSize 的空闲线程能保持的最大时间。</li>
<li>unit 参数，时间单位。</li>
<li>workQueue 参数，保存任务的阻塞队列。</li>
<li>handler 参数，超过阻塞队列的大小时，使用的拒绝策略。</li>
<li>threadFactory 参数，创建线程的工厂。</li>
</ul>
</li>
<li>ThreadPoolExecutor 有哪些拒绝策略？<ul>
<li>ThreadPoolExecutor 默认有四个拒绝策略：<ul>
<li>ThreadPoolExecutor.AbortPolicy() ，直接抛出异常 RejectedExecutionException 。</li>
<li>ThreadPoolExecutor.CallerRunsPolicy() ，直接调用 run 方法并且阻塞执行。</li>
<li>ThreadPoolExecutor.DiscardPolicy() ，直接丢弃后来的任务。</li>
<li>ThreadPoolExecutor.DiscardOldestPolicy() ，丢弃在队列中队首的任务。</li>
<li>如果有需要，可以自己实现 RejectedExecutionHandler 接口，实现自定义的拒绝逻辑</li>
</ul>
</li>
</ul>
</li>
<li>线程池的关闭方式有几种？<ul>
<li>ThreadPoolExecutor 提供了两个方法，用于线程池的关闭，分别是：<ul>
<li>shutdown() 方法，不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务。</li>
<li>shutdownNow() 方法，立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务。</li>
</ul>
</li>
</ul>
</li>
<li>Java 线程池大小为何会大多被设置成 CPU 核心数 +1 ？<ul>
<li>如果是 CPU 密集型应用，则线程池大小设置为 N+1<ul>
<li>因为 CPU 密集型任务使得 CPU 使用率很高，若开过多的线程数，只能增加上下文切换的次数，因此会带来额外的开销。</li>
</ul>
</li>
<li>如果是 IO 密集型应用，则线程池大小设置为 2N+1<ul>
<li>IO密 集型任务 CPU 使用率并不高，因此可以让 CPU 在等待 IO 的时候去处理别的任务，充分利用 CPU 时间。</li>
</ul>
</li>
<li>如果是混合型应用，那么分别创建线程池<ul>
<li>可以将任务分成 IO 密集型和 CPU 密集型任务，然后分别用不同的线程池去处理。 只要分完之后两个任务的执行时间相差不大，那么就会比串行执行来的高效。</li>
<li>因为如果划分之后两个任务执行时间相差甚远，那么先执行完的任务就要等后执行完的任务，最终的时间仍然取决于后执行完的任务，而且还要加上任务拆分与合并的开销，得不偿失。</li>
</ul>
</li>
</ul>
</li>
<li>线程池容量的动态调整？<ul>
<li>ThreadPoolExecutor 提供了动态调整线程池容量大小的方法：<ul>
<li>setCorePoolSize：设置核心池大小。</li>
<li>setMaximumPoolSize：设置线程池最大能创建的线程数目大小。</li>
</ul>
</li>
<li>当上述参数从小变大时，ThreadPoolExecutor 进行线程赋值，还可能立即创建新的线程来执行任务。</li>
</ul>
</li>
<li>什么是 Callable、Future、FutureTask ？ <ul>
<li>Callable: 可以认为是带有回调的 Runnable 。</li>
<li>Future: 表示异步任务，是还没有完成的任务给出的未来结果。所以说 Callable 用于产生结果，Future 用于获取结果。</li>
<li>FutureTask; 表示一个可以取消的异步运算。<ul>
<li>它有启动和取消运算、查询运算是否完成和取回运算结果等方法。只有当运算完成的时候结果才能取回，如果运算尚未完成 get 方法将会阻塞。</li>
<li>一个 FutureTask 对象，可以对调用了 Callable 和 Runnable 的对象进行包装，由于 FutureTask 也是继承了 Runnable 接口，所以它可以提交给 Executor 来执行。</li>
</ul>
</li>
</ul>
</li>
<li>线程池执行任务的过程？<ul>
<li>刚创建时，里面没有线程调用 execute() 方法，添加任务时：<ul>
<li>如果正在运行的线程数量小于核心参数 corePoolSize ，继续创建线程运行这个任务<ul>
<li>否则，如果正在运行的线程数量大于或等于 corePoolSize ，将任务加入到阻塞队列中。<ul>
<li>否则，如果队列已满，同时正在运行的线程数量小于核心参数 maximumPoolSize ，继续创建线程运行这个任务。<ul>
<li>否则，如果队列已满，同时正在运行的线程数量大于或等于 maximumPoolSize ，根据设置的拒绝策略处理。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>完成一个任务，继续取下一个任务处理。<ul>
<li>没有任务继续处理，线程被中断或者线程池被关闭时，线程退出执行，如果线程池被关闭，线程结束。</li>
<li>否则，判断线程池正在运行的线程数量是否大于核心线程数，如果是，线程结束，否则线程阻塞。因此线程池任务全部执行完成后，继续留存的线程池大小为 corePoolSize 。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>线程池中 submit 和 execute 方法有什么区别？<ul>
<li>两个方法都可以向线程池提交任务。<ul>
<li>execute(…) 方法，返回类型是 void ，它定义在 Executor 接口中。</li>
<li>submit(…) 方法，可以返回持有计算结果的 Future 对象，它定义在 ExecutorService 接口中，它扩展了 Executor 接口，其它线程池类像 ThreadPoolExecutor 和 ScheduledThreadPoolExecutor 都有这些方法。</li>
</ul>
</li>
</ul>
</li>
<li>如果你提交任务时，线程池队列已满，这时会发生什么？<ul>
<li>重点在于线程池的队列是有界还是无界的。</li>
</ul>
</li>
<li>Fork/Join 框架是什么？<ul>
<li>Fork/Join 框架是一个实现了 ExecutorService接口 的多线程处理器。它可以把一个大的任务划分为若干个小的任务并发执行，充分利用可用的资源，进而提高应用的执行效率。</li>
<li>Fork 就是把一个大任务切分为若干子任务并行的执行</li>
<li>Join 就是合并这些子任务的执行结果，最后得到这个大任务的结果。</li>
<li>比如计算 1+2+…＋10000 ，可以分割成 10 个子任务，每个子任务分别对 1000 个数进行求和，最终汇总这 10 个子任务的结果。</li>
</ul>
</li>
<li>如何让一段程序并发的执行，并最终汇总结果？<ul>
<li>1、CountDownLatch：允许一个或者多个线程等待前面的一个或多个线程完成，构造一个 CountDownLatch 时指定需要 countDown 的点的数量，每完成一点就 countDown 一下。当所有点都完成，CountDownLatch 的 #await() 就解除阻塞。</li>
<li>2、CyclicBarrier：可循环使用的 Barrier ，它的作用是让一组线程到达一个 Barrier 后阻塞，直到所有线程都到达 Barrier 后才能继续执行。</li>
<li>3、Fork/Join 框架，fork 把大任务分解成多个小任务，然后汇总多个小任务的结果得到最终结果。使用一个双端队列，当线程空闲时从双端队列的另一端领取任务。</li>
</ul>
</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Java/" rel="tag">Java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/interview/" rel="tag">interview</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-RocketMQ"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/RocketMQ/"
    >RocketMQ</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/RocketMQ/" class="article-date">
  <time datetime="2021-11-07T02:54:34.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Java/">Java</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="RocketMQ"><a href="#RocketMQ" class="headerlink" title="RocketMQ"></a>RocketMQ</h1><ol>
<li>RocketMQ 由哪些角色组成？<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15850381816926.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>生产者（Producer）：负责产生消息，生产者向消息服务器发送由业务应用程序系统生成的消息。</li>
<li>消费者（Consumer）：负责消费消息，消费者从消息服务器拉取信息并将其输入用户应用程序。</li>
<li>消息服务器（Broker）：是消息存储中心，主要作用是接收来自 Producer 的消息并存储， Consumer 从这里取得消息。</li>
<li>名称服务器（NameServer）：用来保存 Broker 相关 Topic 等元信息并给 Producer ，提供 Consumer 查找 Broker 信息。</li>
</ul>
</li>
<li>请描述下 RocketMQ 的整体流程？<pre><code> - ![](https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15850382480500.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10)
</code></pre>
<ul>
<li>启动 Namesrv，Namesrv起 来后监听端口，等待 Broker、Producer、Consumer 连上来，相当于一个路由控制中心。</li>
<li>Broker 启动，<strong>跟所有的 Namesrv 保持长连接</strong>，定时发送心跳包。心跳包中，包含当前 Broker 信息(IP+端口等)以及存储所有 Topic 信息。注册成功后，Namesrv 集群中就有 Topic 跟 Broker 的映射关系。</li>
<li>收发消息前，先创建 Topic 。创建 Topic 时，需要指定该 Topic 要存储在 哪些 Broker上。也可以在发送消息时自动创建Topic。</li>
<li>Producer 发送消息。启动时，先跟 Namesrv 集群中的其中一台建立长连接，并从Namesrv 中获取当前发送的 Topic 存在哪些 Broker 上，然后跟对应的 Broker 建立长连接，直接向 Broker 发消息</li>
<li>Consumer 消费消息。Consumer 跟 Producer 类似。跟其中一台 Namesrv 建立长连接，获取当前订阅 Topic 存在哪些 Broker 上，然后直接跟 Broker 建立连接通道，开始消费消息。</li>
</ul>
</li>
<li>请说说你对 Namesrv 的了解？<ul>
<li>Namesrv 用于存储 Topic、Broker 关系信息，功能简单，稳定性高。<ul>
<li>多个 Namesrv 之间相互没有通信，单台 Namesrv 宕机不影响其它 Namesrv 与集群。多个 Namesrv 之间的信息共享，通过 Broker 主动向多个 Namesrv 都发起心跳。正如上文所说，Broker 需要跟所有 Namesrv 连接。</li>
<li>即使整个 Namesrv 集群宕机，已经正常工作的 Producer、Consumer、Broker 仍然能正常工作，但新起的 Producer、Consumer、Broker 就无法工作。(这点和 Dubbo 有些不同，不会缓存 Topic 等元信息到本地文件。)</li>
</ul>
</li>
<li> Namesrv 压力不会太大，平时主要开销是在维持心跳和提供 Topic-Broker 的关系数据。但有一点需要注意，Broker 向 Namesr 发心跳时，会带上当前自己所负责的所有 Topic 信息，如果 Topic 个数太多（万级别），会导致一次心跳中，就 Topic 的数据就几十 M，网络情况差的话，网络传输失败，心跳失败，导致 Namesrv 误认为 Broker 心跳失败。</li>
</ul>
</li>
<li>如何配置 Namesrv 地址到生产者和消费者？<ul>
<li><strong>编程方式</strong>，就像 producer.setNamesrvAddr(“ip:port”) 。</li>
<li>Java 启动参数设置，使用 rocketmq.namesrv.addr 。</li>
<li>环境变量，使用 NAMESRV_ADDR 。</li>
<li>HTTP 端点，例如说：<a target="_blank" rel="noopener" href="http://namesrv.rocketmq.xxx.com/">http://namesrv.rocketmq.xxx.com</a> 地址，通过 DNS 解析获得 Namesrv 真正的地址。</li>
</ul>
</li>
<li>请说说你对 Broker 的了解？<ul>
<li>高并发读写服务。Broker的高并发读写主要是依靠以下两点:<ul>
<li>消息顺序写，所有 Topic 数据同时只会写一个文件，一个文件满1G ，再写新文件，真正的顺序写盘，使得发消息 TPS 大幅提高。</li>
<li>消息随机读，RocketMQ 尽可能让读命中系统 Pagecache ，因为操作系统访问 Pagecache 时，即使只访问 1K 的消息，系统也会提前预读出更多的数据，在下次读时就可能命中 Pagecache ，减少 IO 操作。</li>
</ul>
</li>
<li>负载均衡与动态伸缩。<ul>
<li>负载均衡：Broker 上存 Topic 信息，Topic 由多个队列组成，队列会平均分散在多个 Broker 上，而 Producer 的发送机制保证消息尽量平均分布到所有队列中，最终效果就是所有消息都平均落在每个 Broker 上。</li>
<li>动态伸缩能力（非顺序消息）：Broker 的伸缩性体现在两个维度：Topic、Broker。<ul>
<li>Topic 维度：假如一个 Topic 的消息量特别大，但集群水位压力还是很低，就可以扩大该 Topic 的队列数， Topic 的队列数跟发送、消费速度成正比。<ul>
<li>Topic 的队列数一旦扩大，就无法很方便的缩小。因为，生产者和消费者都是基于相同的队列数来处理。如果真的想要缩小，只能新建一个 Topic ，然后使用它。</li>
</ul>
</li>
<li>Broker 维度：如果集群水位很高了，需要扩容，直接加机器部署 Broker 就可以。Broker 启动后向 Namesrv 注册，Producer、Consumer 通过 Namesrv 发现新Broker，立即跟该 Broker 直连，收发消息。<ul>
<li>新增的 Broker 想要下线，想要下线也比较麻烦，暂时没特别好的方案。大体的前提是，消费者消费完该 Broker 的消息，生产者不往这个 Broker 发送消息。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>高可用 &amp; 高可靠。<ul>
<li>高可用：集群部署时一般都为主备，备机实时从主机同步消息，如果其中一个主机宕机，备机提供消费服务，但不提供写服务。</li>
<li>高可靠：所有发往 Broker 的消息，有同步刷盘和异步刷盘机制。<ul>
<li>同步刷盘时，消息写入物理文件才会返回成功。</li>
<li>异步刷盘时，只有机器宕机，才会产生消息丢失，Broker 挂掉可能会发生，但是机器宕机崩溃是很少发生的，除非突然断电。如果 Broker 挂掉，未同步到硬盘的消息，还在 Pagecache 中呆着。</li>
</ul>
</li>
</ul>
</li>
<li>Broker 与 Namesrv 的心跳机制。<ul>
<li>单个 Broker 跟所有 Namesrv 保持心跳请求，心跳间隔为30秒，心跳请求中包括当前 Broker 所有的 Topic 信息。</li>
<li>Namesrv 会反查 Broker 的心跳信息，如果某个 Broker 在 2 分钟之内都没有心跳，则认为该 Broker 下线，调整 Topic 跟 Broker 的对应关系。但此时 Namesrv 不会主动通知Producer、Consumer 有 Broker 宕机。也就说，只能等 Producer、Consumer 下次定时拉取 Topic 信息的时候，才会发现有 Broker 宕机。</li>
</ul>
</li>
</ul>
</li>
<li>Broker 如何实现消息的存储？<ul>
<li>?????????????????????????</li>
</ul>
</li>
<li>请说说你对 Producer 的了解？<ul>
<li>获得 Topic-Broker 的映射关系。<ul>
<li>Producer 启动时，也需要指定 Namesrv 的地址，从 Namesrv 集群中选一台建立长连接。如果该 Namesrv 宕机，会自动连其他 Namesrv ，直到有可用的 Namesrv 为止。</li>
<li>生产者每 30 秒从 Namesrv 获取 Topic 跟 Broker 的映射关系，更新到本地内存中。然后再跟 Topic 涉及的所有 Broker 建立长连接，每隔 30 秒发一次心跳。</li>
<li>在 Broker 端也会每 10 秒扫描一次当前注册的 Producer ，如果发现某个 Producer 超过 2 分钟都没有发心跳，则断开连接。</li>
</ul>
</li>
<li>生产者端的负载均衡。<ul>
<li>生产者发送时，会自动轮询当前所有可发送的broker，一条消息发送成功，下次换另外一个broker发送，以达到消息平均落到所有的broker上。</li>
<li>假如某个 Broker 宕机，意味生产者最长需要 30 秒才能感知到。在这期间会向宕机的 Broker 发送消息。当一条消息发送到某个 Broker 失败后，会自动再重发 2 次，假如还是发送失败，则抛出发送失败异常。客户端里会自动轮询另外一个 Broker 重新发送，这个对于用户是透明的。</li>
</ul>
</li>
</ul>
</li>
<li>Producer 发送消息有几种方式？<ul>
<li>Producer 发送消息，有三种方式：<ul>
<li>同步方式</li>
<li>异步方式</li>
<li>Oneway 方式</li>
</ul>
</li>
</ul>
</li>
<li>请说说你对 Consumer 的了解？<ul>
<li>获得 Topic-Broker 的映射关系。<ul>
<li>Consumer 启动时需要指定 Namesrv 地址，与其中一个 Namesrv 建立长连接。消费者每隔 30 秒从 Namesrv 获取所有Topic 的最新队列情况，这意味着某个 Broker 如果宕机，客户端最多要 30 秒才能感知。连接建立后，从 Namesrv 中获取当前消费 Topic 所涉及的 Broker，直连 Broker 。</li>
<li>Consumer 跟 Broker 是长连接，会每隔 30 秒发心跳信息到Broker 。Broker 端每 10 秒检查一次当前存活的 Consumer ，若发现某个 Consumer 2 分钟内没有心跳，就断开与该 Consumer 的连接，并且向该消费组的其他实例发送通知，触发该消费者集群的负载均衡。</li>
</ul>
</li>
<li>消费者端的负载均衡。根据消费者的消费模式不同，负载均衡方式也不同。<ul>
<li>集群消费：一个 Topic 可以由同一个消费这分组( Consumer Group )下所有消费者分担消费。<ul>
<li>具体例子：假如 TopicA 有 6 个队列，，每个消费者分组起了 2 个消费者实例，那么每个消费者负责消费 3 个队列。如果再增加一个消费者分组相同消费者实例，即当前共有 3 个消费者同时消费 6 个队列，那每个消费者负责 2 个队列的消费。</li>
</ul>
</li>
<li>广播消费：每个消费者消费 Topic 下的所有队列。</li>
</ul>
</li>
</ul>
</li>
<li>消费者消费模式有几种？<ul>
<li>集群消费：一个 Consumer Group 中的各个 Consumer 实例分摊去消费消息，即一条消息只会投递到一个 Consumer Group 下面的一个实例。<ul>
<li>实际上，每个 Consumer 是平均分摊 Message Queue 的去做拉取消费。例如某个 Topic 有 3 个队列，其中一个 Consumer Group 有 3 个实例（可能是 3 个进程，或者 3 台机器），那么每个实例只消费其中的 1 个队列。</li>
<li>而由 Producer 发送消息的时候是轮询所有的队列，所以消息会平均散落在不同的队列上，可以认为队列上的消息是平均的。那么实例也就平均地消费消息了。</li>
<li>这种模式下，消费进度的存储会持久化到 Broker 。</li>
<li>当新建一个 Consumer Group 时，默认情况下，该分组的消费者会从 min offset 开始重新消费消息。</li>
</ul>
</li>
<li>广播消费：消息将对一 个Consumer Group 下的各个 Consumer 实例都投递一遍。即即使这些 Consumer 属于同一个Consumer Group ，消息也会被 Consumer Group 中的每个 Consumer 都消费一次。<ul>
<li>实际上，是一个消费组下的每个消费者实例都获取到了 Topic 下面的每个 Message Queue 去拉取消费。所以消息会投递到每个消费者实例。</li>
<li>这种模式下，消费进度会存储持久化到实例本地。</li>
</ul>
</li>
</ul>
</li>
<li>消费者获取消息有几种模式？<ul>
<li>PushConsumer推送模式（虽然 RocketMQ 使用的是长轮询）的消费者。消息的能及时被消费。使用非常简单，内部已处理如线程池消费、流控、负载均衡、异常处理等等的各种场景。</li>
<li>PullConsumer拉取模式的消费者。应用主动控制拉取的时机，怎么拉取，怎么消费等。主动权更高。但要自己处理各种场景。</li>
<li>决绝绝大多数场景下，我们只会使用 PushConsumer 推送模式。</li>
</ul>
</li>
<li>如何对消息进行重放？<ul>
<li>消费位点就是一个数字，把 Consumer Offset 改一下，就可以达到重放的目的了。</li>
</ul>
</li>
<li>什么是顺序消息？如何实现？<ul>
<li>消费消息的顺序要同发送消息的顺序一致。由于 Consumer 消费消息的时候是针对 Message Queue 顺序拉取并开始消费，且一条 Message Queue 只会给一个消费者（集群模式下），所以能够保证同一个消费者实例对于 Queue 上消息的消费是顺序地开始消费（不一定顺序消费完成，因为消费可能并行）。</li>
<li>RocketMQ 提供了两种顺序级别：<ul>
<li>顺序消息包括两块：Producer 的顺序发送，和 Consumer 的顺序消费。</li>
<li>普通顺序消息 ：Producer 将相关联的消息发送到相同的消息队列。</li>
<li>严格顺序消息 ：在【普通顺序消息】的基础上，Consumer 严格顺序消费。</li>
</ul>
</li>
</ul>
</li>
<li>顺序消息扩容的过程中，如何在不停写的情况下保证消息顺序？<ul>
<li>成倍扩容，实现扩容前后，同样的 key，hash 到原队列，或者 hash 到新扩容的队列。</li>
<li>扩容前，记录旧队列中的最大位点。</li>
<li>对于每个 Consumer Group ，保证旧队列中的数据消费完，再消费新队列，也即：先对新队列进行禁读即可。</li>
</ul>
</li>
<li>什么是定时消息？如何实现？<ul>
<li>定时消息，是指消息发到 Broker 后，不能立刻被 Consumer 消费，要到特定的时间点或者等待特定的时间后才能被消费。</li>
<li>可通过配置文件，自定义每个延迟级别对应的延迟时间。当然，这是全局的。</li>
<li>如果想要实现任一时刻的延迟消息，比较简单的方式是插入延迟消息到数据库中，然后通过定时任务轮询，到达指定时间，发送到 RocketMQ 中。</li>
<li>实现原理：<ul>
<li>定时消息发送到 Broker 后，会被存储 Topic 为 SCHEDULE_TOPIC_XXXX 中，并且所在 Queue 编号为延迟级别 - 1 。（需要 -1 的原因是，延迟级别是从 1 开始的。如果延迟级别为 0 ，意味着无需延迟。）</li>
<li>Broker 针对每个 SCHEDULE_TOPIC_XXXX 的队列，都创建一个定时任务，顺序扫描到达时间的延迟消息，重新存储到延迟消息原始的 Topic 的原始 Queue 中，这样它就可以被 Consumer 消费到。<ul>
<li>为什么是“顺序扫描到达时间的延迟消息”？因为先进 SCHEDULE_TOPIC_XXXX 的延迟消息，在其所在的队列，意味着先到达延迟时间。</li>
<li>会不会存在重复扫描的情况？每个 SCHEDULE_TOPIC_XXXX 的扫描进度，会每 10s 存储到 config/delayOffset.json 文件中，所以正常情况下，不会存在重复扫描。如果异常关闭，则可能导致重复扫描。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>什么是消息重试？如何实现？<ul>
<li>消息重试，Consumer 消费消息失败后，要提供一种重试机制，令消息再消费一次。</li>
<li>Consumer 会将消费失败的消息发回 Broker，进入延迟消息队列。即，消费失败的消息，不会立即消费。也就是说，消息重试是构建在定时消息之上的功能。</li>
<li>消息重试的主要流程：<ul>
<li>Consumer 消费失败，将消息发送回 Broker 。</li>
<li>Broker 收到重试消息之后置换 Topic ，存储消息。</li>
<li>Consumer 会拉取该 Topic 对应的 retryTopic 的消息。</li>
<li>Consumer 拉取到 retryTopic 消息之后，置换到原始的 Topic ，把消息交给 Listener 消费。<ul>
<li>Consumer 消息失败后，会将消息的 Topic 修改为 %RETRY% + Topic 进行，添加 “RETRY_TOPIC” 属性为原始 Topic ，然后再返回给 Broker 中。</li>
<li>Broker 收到重试消息之后，会有两次修改消息的 Topic 。<ul>
<li>首先，会将消息的 Topic 修改为 %RETRY% + ConsumerGroup ，因为这个消息是当前消费这分组消费失败，只能被这个消费组所重新消费。注意，消费者会默认订阅 Topic 为 %RETRY% + ConsumerGroup 的消息。</li>
<li>然后，会将消息的 Topic 修改为 SCHEDULE_TOPIC_XXXX ，添加 “REAL_TOPIC” 属性为 %RETRY% + ConsumerGroup ，因为重试消息需要延迟消费。</li>
<li>Consumer 会拉取该 Topic 对应的 retryTopic 的消息，此处的 retryTopic 为 %RETRY% + ConsumerGroup 。<br>Consumer 拉取到 retryTopic 消息之后，置换到原始的 Topic ，因为有消息的 “RETRY_TOPIC” 属性是原始 Topic ，然后把消息交给 Listener 消费。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>基于RocketMQ的分布式事务解决方案<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15850377370094.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>1、在扣款之前，先发送预备消息</li>
<li>2、发送预备消息成功后，执行本地扣款事务</li>
<li>3、扣款成功后，再发送确认消息</li>
<li>4、消息端（加钱业务）可以看到确认消息，消费此消息，进行加钱<blockquote>
<p>注意：上面的确认消息可以为commit消息，可以被订阅者消费；也可以是Rollback消息，即执行本地扣款事务失败后，提交rollback消息，即删除那个预备消息，订阅者无法消费</p>
</blockquote>
</li>
<li>异常1：如果发送预备消息失败，下面的流程不会走下去；这个是正常的</li>
<li>异常2：如果发送预备消息成功，但执行本地事务失败；这个也没有问题，因为此预备消息不会被消费端订阅到，消费端不会执行业务。</li>
<li>异常3：如果发送预备消息成功，执行本地事务成功，但发送确认消息失败；这个就有问题了，因为用户A扣款成功了，但加钱业务没有订阅到确认消息，无法加钱。这里出现了数据不一致。</li>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15850378513462.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>RocketMq解决上面的问题，核心思路就是【状态回查】，也就是RocketMq会定时遍历commitlog中的预备消息。<blockquote>
<p>因为预备消息最终肯定会变为commit消息或Rollback消息，所以遍历预备消息去回查本地业务的执行状态，如果发现本地业务没有执行成功就rollBack，如果执行成功就发送commit消息。</p>
</blockquote>
</li>
</ul>
</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Java/" rel="tag">Java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/interview/" rel="tag">interview</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" rel="tag">消息队列</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-SpringMVC"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/SpringMVC/"
    >SpringMVC</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/SpringMVC/" class="article-date">
  <time datetime="2021-11-07T02:53:39.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Java/">Java</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Spring-MVC"><a href="#Spring-MVC" class="headerlink" title="Spring-MVC"></a>Spring-MVC</h1><ol>
<li>Spring MVC 框架有什么用？<ul>
<li>Spring Web MVC 框架提供”模型-视图-控制器”( Model-View-Controller )架构和随时可用的组件，用于开发灵活且松散耦合的 Web 应用程序。</li>
<li>MVC 模式有助于分离应用程序的不同方面，如输入逻辑，业务逻辑和 UI 逻辑，同时在所有这些元素之间提供松散耦合。</li>
</ul>
</li>
<li>介绍下 Spring MVC 的核心组件？<ul>
<li>Spring MVC 一共有九大核心组件，分别是：<ul>
<li>MultipartResolver</li>
<li>LocaleResolver</li>
<li>ThemeResolver</li>
<li>HandlerMapping</li>
<li>HandlerAdapter</li>
<li>HandlerExceptionResolver</li>
<li>RequestToViewNameTranslator</li>
<li>ViewResolver</li>
<li>FlashMapManager</li>
</ul>
</li>
</ul>
</li>
<li>描述一下 DispatcherServlet 的工作流程？<br> <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15850164969118.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10" alt="-w803"><ul>
<li><ol>
<li>发送请求:用户向服务器发送 HTTP 请求，请求被 Spring MVC 的调度控制器 DispatcherServlet 捕获。</li>
</ol>
</li>
<li><ol start="2">
<li>映射处理器:DispatcherServlet 根据请求 URL ，调用 HandlerMapping 获得该 Handler 配置的所有相关的对象（包括 Handler 对象以及 Handler 对象对应的拦截器），最后以 HandlerExecutionChain 对象的形式返回。</li>
</ol>
</li>
<li><ol start="3">
<li>处理器适配:</li>
<li>DispatcherServlet 根据获得的 Handler，选择一个合适的HandlerAdapter 。（附注：如果成功获得 HandlerAdapter 后，此时将开始执行拦截器的 #preHandler(…) 方法）。</li>
<li>提取请求 Request 中的模型数据，填充 Handler 入参，开始执行Handler（Controller)。 在填充Handler的入参过程中，根据你的配置，Spring 将帮你做一些额外的工作：<ol>
<li>HttpMessageConverter ：会将请求消息（如 JSON、XML 等数据）转换成一个对象。</li>
<li>数据转换：对请求消息进行数据转换。如 String 转换成 Integer、Double 等。</li>
<li>数据格式化：对请求消息进行数据格式化。如将字符串转换成格式化数字或格式化日期等。</li>
<li>数据验证： 验证数据的有效性（长度、格式等），验证结果存储到 BindingResult 或 Error 中。</li>
</ol>
</li>
</ol>
</li>
<li><ol start="4">
<li>Handler(Controller) 执行完成后，向 DispatcherServlet 返回一个 ModelAndView 对象。</li>
</ol>
</li>
<li><ol start="5">
<li>解析视图:根据返回的 ModelAndView ，选择一个适合的 ViewResolver</li>
</ol>
</li>
<li>6 7 渲染视图 + 响应请求</li>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15850167871281.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ul>
</li>
<li>@Controller 注解有什么用？<ul>
<li>@Controller 注解，它将一个类标记为 Spring Web MVC 控制器 Controller 。</li>
</ul>
</li>
<li>@RestController 和 @Controller 有什么区别？<ul>
<li>@RestController 注解，在 @Controller 基础上，增加了 @ResponseBody 注解，更加适合目前前后端分离的架构下，提供 Restful API ，返回例如 JSON 数据格式。当然，返回什么样的数据格式，根据客户端的 “ACCEPT” 请求头来决定。</li>
</ul>
</li>
<li>@RequestMapping 注解有什么用？<ul>
<li>@RequestMapping 注解，用于将特定 HTTP 请求方法映射到将处理相应请求的控制器中的特定类/方法。此注释可应用于两个级别：<ul>
<li>类级别：映射请求的 URL。</li>
<li>方法级别：映射 URL 以及 HTTP 请求方法。</li>
</ul>
</li>
</ul>
</li>
<li>@RequestMapping 和 @GetMapping 注解的不同之处在哪里？<ul>
<li>@RequestMapping 可注解在类和方法上；@GetMapping 仅可注册在方法上。</li>
<li>@RequestMapping 可进行 GET、POST、PUT、DELETE 等请求方法</li>
<li>@GetMapping 是 @RequestMapping 的 GET 请求方法的特例，目的是为了提高清晰度。</li>
</ul>
</li>
<li>返回 JSON 格式使用什么注解？<ul>
<li>可以使用 @ResponseBody 注解，或者使用包含 @ResponseBody 注解的 @RestController 注解。</li>
<li>当然，还是需要配合相应的支持 JSON 格式化的 HttpMessageConverter 实现类。例如，Spring MVC 默认使用 MappingJackson2HttpMessageConverter 。</li>
</ul>
</li>
<li>介绍一下 WebApplicationContext ？<ul>
<li>WebApplicationContext 是实现ApplicationContext接口的子类，专门为 WEB 应用准备的。</li>
<li>它允许从相对于 Web 根目录的路径中加载配置文件，完成初始化 Spring MVC 组件的工作。</li>
<li>从 WebApplicationContext 中，可以获取 ServletContext 引用，整个 Web 应用上下文对象将作为属性放置在 ServletContext 中，以便 Web 应用环境可以访问 Spring 上下文。</li>
</ul>
</li>
<li>Spring MVC 的异常处理？<ul>
<li>Spring MVC 提供了异常解析器 HandlerExceptionResolver 接口，将处理器( handler )执行时发生的异常，解析( 转换 )成对应的 ModelAndView 结果。代码如下：</li>
<li>一般情况下，我们使用 @ExceptionHandler 注解来实现过异常的处理</li>
</ul>
</li>
<li>Spring MVC 有什么优点？<ul>
<li>使用真的真的真的非常方便，无论是添加 HTTP 请求方法映射的方法，还是不同数据格式的响应。</li>
<li>提供拦截器机制，可以方便的对请求进行拦截处理。</li>
<li>提供异常机制，可以方便的对异常做统一处理。</li>
<li>可以任意使用各种视图技术，而不仅仅局限于 JSP ，例如 Freemarker、Thymeleaf 等等。</li>
<li>不依赖于 Servlet API (目标虽是如此，但是在实现的时候确实是依赖于 Servlet 的，当然仅仅依赖 Servlet ，而不依赖 Filter、Listener )。</li>
</ul>
</li>
<li>Spring MVC 怎样设定重定向和转发 ？<ul>
<li>结果转发：在返回值的前面加 “forward:/“ 。</li>
<li>重定向：在返回值的前面加上 “redirect:/“ 。</li>
</ul>
</li>
<li>Spring MVC 的 Controller 是不是单例？<ul>
<li>绝绝绝大多数情况下，Controller 是单例。</li>
<li>那么，Controller 里一般不建议存在共享的变量。</li>
</ul>
</li>
<li>Spring MVC 和 Struts2 的异同？<ul>
<li>入口不同<ul>
<li>Spring MVC 的入门是一个 Servlet 控制器。</li>
<li>Struts2 入门是一个 Filter 过滤器。</li>
</ul>
</li>
<li>配置映射不同，<ul>
<li>Spring MVC 是基于方法开发，传递参数是通过方法形参，一般设置为单例。</li>
<li>Struts2 是基于类开发，传递参数是通过类的属性，只能设计为多例。</li>
</ul>
</li>
</ul>
</li>
<li>详细介绍下 Spring MVC 拦截器？<ul>
<li><code>org.springframework.web.servlet.HandlerInterceptor</code> ，拦截器接口。代码如下：  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">        <span class="comment">// HandlerInterceptor.java</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 拦截处理器，在 &#123;<span class="doctag">@link</span> HandlerAdapter#handle(HttpServletRequest, HttpServletResponse, Object)&#125; 执行之前</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="function"><span class="keyword">default</span> <span class="keyword">boolean</span> <span class="title">preHandle</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler)</span></span></span><br><span class="line"><span class="function">        		<span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        	<span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 拦截处理器，在 &#123;<span class="doctag">@link</span> HandlerAdapter#handle(HttpServletRequest, HttpServletResponse, Object)&#125; 执行成功之后</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">postHandle</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler,</span></span></span><br><span class="line"><span class="params"><span class="function">        		<span class="meta">@Nullable</span> ModelAndView modelAndView)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 拦截处理器，在 &#123;<span class="doctag">@link</span> HandlerAdapter#handle(HttpServletRequest, HttpServletResponse, Object)&#125; 执行完之后，无论成功还是失败</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * 并且，只有该处理器 &#123;<span class="doctag">@link</span> #preHandle(HttpServletRequest, HttpServletResponse, Object)&#125; 执行成功之后，才会被执行</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">afterCompletion</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler,</span></span></span><br><span class="line"><span class="params"><span class="function">        		<span class="meta">@Nullable</span> Exception ex)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>preHandle(…) 方法，调用 Controller 方法之前执行。<ul>
<li>preHandle(…) 方法，按拦截器定义顺序调用。若任一拦截器返回 false ，则 Controller 方法不再调用。    </li>
</ul>
</li>
<li>postHandle(…) 方法，调用 Controller 方法之后执行。<ul>
<li>postHandle(…) 和 #afterCompletion(…) 方法，按拦截器定义逆序调用。</li>
<li>postHandler(…) 方法，在调用 Controller 方法之后执行。</li>
</ul>
</li>
<li>afterCompletion(…) 方法，处理完 Controller 方法返回结果之后执行,无论调用 Controller 方法是否成功，都会执行。<ul>
<li>afterCompletion(…) 方法，只有该拦截器在 #preHandle(…) 方法返回 true 时，才能够被调用，且一定会被调用。为什么“且一定会被调用”呢？即使 #afterCompletion(…) 方法，按拦截器定义逆序调用时，前面的拦截器发生异常，后面的拦截器还能够调用，即无视异常。</li>
</ul>
</li>
</ul>
</li>
<li>Spring MVC 的拦截器可以做哪些事情？<ul>
<li>记录访问日志。</li>
<li>记录异常日志。</li>
<li>需要登陆的请求操作，拦截未登陆的用户。</li>
<li>参数替换</li>
</ul>
</li>
<li>Spring MVC 的拦截器和 Filter 过滤器有什么差别？<ul>
<li>功能相同：拦截器和 Filter都能实现相应的功能，谁也不比谁强。</li>
<li>容器不同：拦截器构建在 Spring MVC 体系中；Filter 构建在 Servlet 容器之上。</li>
<li>使用便利性不同：拦截器提供了三个方法，分别在不同的时机执行；过滤器仅提供一个方法，当然也能实现拦截器的执行时机的效果，就是麻烦一些。</li>
</ul>
</li>
</ol>
<h2 id="REST"><a href="#REST" class="headerlink" title="REST"></a>REST</h2><ol>
<li>REST 代表着什么?<ul>
<li>REST 代表着抽象状态转移，它是根据 HTTP 协议从客户端发送数据到服务端，例如：服务端的一本书可以以 XML 或 JSON 格式传递到客户端。</li>
</ul>
</li>
<li>资源是什么?<ul>
<li>资源是指数据在 REST 架构中如何显示的。将实体作为资源公开 ，它允许客户端通过 HTTP 方法如：GET, POST,PUT, DELETE 等读，写，修改和创建资源。</li>
</ul>
</li>
<li>什么是安全的 REST 操作?<ul>
<li>REST 接口是通过 HTTP 方法完成操作。<ul>
<li>一些HTTP操作是安全的，如 GET 和 HEAD ，它不能在服务端修改资源换句话说，PUT,POST 和 DELETE 是不安全的，因为他们能修改服务端的资源。</li>
</ul>
</li>
<li>是否安全的界限，在于是否修改服务端的资源。</li>
</ul>
</li>
<li>什么是幂等操作? 为什么幂等操作如此重要?<ul>
<li>有一些HTTP方法，如：GET，不管你使用多少次它都能产生相同的结果，在没有任何一边影响的情况下，发送多个 GET 请求到相同的URI 将会产生相同的响应结果。因此，这就是所谓幂等操作。</li>
<li>换句话说，POST方法不是幂等操作 ，因为如果发送多个 POST 请求，它将在服务端创建不同的资源。但是，假如你用PUT更新资源，它将是幂等操作。</li>
</ul>
</li>
<li>REST 是可扩展的或说是协同的吗?<ul>
<li>是的，REST 是可扩展的和可协作的。它既不托管一种特定的技术选择，也不定在客户端或者服务端。你可以用 Java, C++, Python, 或 JavaScript 来创建 RESTful Web 服务，也可以在客户端使用它们。</li>
<li>这里的“可拓展”、“协同”对应到我们平时常说的，“跨语言”、“语言无关”。</li>
</ul>
</li>
<li>REST 用哪种 HTTP 方法呢?<ul>
<li>REST 能用任何的 HTTP 方法，但是，最受欢迎的是：<ul>
<li>用 GET 来检索服务端资源</li>
<li>用 POST 来创建服务端资源</li>
<li>用 PUT 来更新服务端资源</li>
<li>用 DELETE 来删除服务端资源。</li>
</ul>
</li>
</ul>
</li>
<li>删除的 HTTP 状态返回码是什么 ?<ul>
<li>在删除成功之后，您的 REST API 应该返回什么状态代码，并没有严格的规则。它可以返回 200 或 204 没有内容。<ul>
<li>一般来说，如果删除操作成功，响应主体为空，返回 204 。</li>
<li>如果删除请求成功且响应体不是空的，则返回 200 。</li>
</ul>
</li>
</ul>
</li>
<li>REST API 是无状态的吗?<ul>
<li>是的，REST API 应该是无状态的，因为它是基于 HTTP 的，它也是无状态的。</li>
<li>REST API 中的请求应该包含处理它所需的所有细节。它不应该依赖于以前或下一个请求或服务器端维护的一些数据，例如会话。</li>
</ul>
</li>
<li>REST安全吗? 你能做什么来保护它?<ul>
<li>REST 通常不是安全的，但是您可以通过使用 Spring Security 来保护它。</li>
<li>至少，你可以通过在 Spring Security 配置文件中使用 HTTP 来启用 HTTP Basic Auth 基本认证。</li>
<li>类似地，如果底层服务器支持 HTTPS ，你可以使用 HTTPS 公开 REST API 。</li>
</ul>
</li>
<li>RestTemplate 的优势是什么?<ul>
<li>在 Spring Framework 中，RestTemplate 类是 模板方法模式 的实现。跟其他主流的模板类相似，如 JdbcTemplate 或 JmsTempalte ，它将在客户端简化跟 RESTful Web 服务的集成。正如在 RestTemplate 例子中显示的一样，你能非常容易地用它来调用 RESTful Web 服务。</li>
<li>实际场景我还是更喜欢使用 OkHttp 作为 HTTP 库，因为更好的性能，使用也便捷，并且无需依赖 Spring 库。</li>
</ul>
</li>
<li>HttpMessageConverter 在 Spring REST 中代表什么?<ul>
<li>HttpMessageConverter 是一种策略接口 ，它指定了一个转换器，它可以转换 HTTP 请求和响应。Spring REST 用这个接口转换 HTTP 响应到多种格式，例如：JSON 或 XML 。</li>
<li>每个 HttpMessageConverter 实现都有一种或几种相关联的MIME协议。Spring 使用 “Accept” 的标头来确定客户端所期待的内容类型。</li>
<li>然后，它将尝试找到一个注册的 HTTPMessageConverter ，它能够处理特定的内容类型，并使用它将响应转换成这种格式，然后再将其发送给客户端。</li>
</ul>
</li>
<li>@PathVariable 注解，在 Spring MVC 做了什么? 为什么 REST 在 Spring 中如此有用<ul>
<li>@PathVariable 注解，是 Spring MVC 中有用的注解之一，它允许您从 URI 读取值，比如查询参数。它在使用 Spring 创建 RESTful Web 服务时特别有用，因为在 REST 中，资源标识符是 URI 的一部分。</li>
</ul>
</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Java/" rel="tag">Java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spring/" rel="tag">Spring</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/interview/" rel="tag">interview</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-MyBatis"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/MyBatis/"
    >MyBatis</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/MyBatis/" class="article-date">
  <time datetime="2021-11-07T02:52:28.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Java/">Java</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="MyBatis"><a href="#MyBatis" class="headerlink" title="MyBatis"></a>MyBatis</h1><ol>
<li><p>MyBatis 编程步骤</p>
<ul>
<li>创建 SqlSessionFactory 对象。</li>
<li>通过 SqlSessionFactory 获取 SqlSession 对象。</li>
<li>通过 SqlSession 获得 Mapper 代理对象。</li>
<li>通过 Mapper 代理对象，执行数据库操作。</li>
<li>执行成功，则使用 SqlSession 提交事务。</li>
<li>执行失败，则使用 SqlSession 回滚事务。</li>
<li>最终，关闭会话。</li>
</ul>
</li>
<li><p>#{} 和 ${} 的区别是什么？</p>
<ul>
<li>${} 是 Properties 文件中的变量占位符，它可以用于 XML 标签属性值和 SQL 内部，属于字符串替换,#{} 是预编译处理，可以有效防止 SQL 注入，提高系统安全性</li>
<li>${} 也可以对传递进来的参数原样拼接在 SQL 中,可能有 SQL 注入的风险。</li>
</ul>
</li>
<li><p>当实体类中的属性名和表中的字段名不一样 ，怎么办？</p>
<ul>
<li>在查询的 SQL 语句中定义字段名的别名</li>
<li>配置自动的下划线转驼峰的功能</li>
<li>通过 <resultMap> 来映射字段名和实体类属性名的一一对应的关系</li>
</ul>
</li>
<li><p>Mybatis 动态 SQL 是做什么的？都有哪些动态 SQL ？能简述一下动态 SQL 的执行原理吗？</p>
<ul>
<li>Mybatis 动态 SQL ，可以让我们在 XML 映射文件内，以 XML 标签的形式编写动态 SQL ，完成逻辑判断和动态拼接 SQL 的功能。</li>
<li>Mybatis 提供了 9 种动态 SQL 标签：<code>&lt;if /&gt;、&lt;choose /&gt;、&lt;when /&gt;、&lt;otherwise /&gt;、&lt;trim /&gt;、&lt;where /&gt;、&lt;set /&gt;、&lt;foreach /&gt;、&lt;bind /&gt; </code>。</li>
<li>其执行原理为，使用 OGNL 的表达式，从 SQL 参数对象中计算表达式的值，根据表达式的值动态拼接 SQL ，以此来完成动态 SQL 的功能。</li>
</ul>
</li>
<li><p>最佳实践中，通常一个 XML 映射文件，都会写一个 Mapper 接口与之对应。请问，这个 Mapper 接口的工作原理是什么？Mapper 接口里的方法，参数不同时，方法能重载吗？</p>
<ul>
<li>接口的全限名，就是映射文件中的 “namespace” 的值。</li>
<li>接口的方法名，就是映射文件中 MappedStatement 的 “id” 值。</li>
<li>接口方法内的参数，就是传递给 SQL 的参数。</li>
<li>另外，Mapper 接口的实现类，通过 MyBatis 使用 JDK Proxy 自动生成其代理对象 Proxy ，而代理对象 Proxy 会拦截接口方法，从而“调用”对应的 MappedStatement 方法，最终执行 SQL ，返回执行结果。整体流程如下图：<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15850110187997.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ul>
</li>
<li>其中，SqlSession 在调用 Executor 之前，会获得对应的 MappedStatement 方法。例如：DefaultSqlSession#select(String statement, Object parameter, RowBounds rowBounds, ResultHandler handler) 方法，代码如下：  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DefaultSqlSession.java</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">select</span><span class="params">(String statement, Object parameter, RowBounds rowBounds, ResultHandler handler)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 获得 MappedStatement 对象</span></span><br><span class="line">        MappedStatement ms = configuration.getMappedStatement(statement);</span><br><span class="line">        <span class="comment">// 执行查询</span></span><br><span class="line">        executor.query(ms, wrapCollection(parameter), rowBounds, handler);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> ExceptionFactory.wrapException(<span class="string">&quot;Error querying database.  Cause: &quot;</span> + e, e);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        ErrorContext.instance().reset();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Mapper 接口绑定有几种实现方式,分别是怎么实现的?</p>
<ul>
<li>通过 XML Mapper 里面写 SQL 来绑定。在这种情况下，要指定 XML 映射文件里面的 “namespace” 必须为接口的全路径名。</li>
<li>通过注解绑定，就是在接口的方法上面加上 @Select、@Update、@Insert、@Delete 注解，里面包含 SQL 语句来绑定。</li>
<li>是第二种的特例，也是通过注解绑定，在接口的方法上面加上 @SelectProvider、@UpdateProvider、@InsertProvider、@DeleteProvider 注解，通过 Java 代码，生成对应的动态 SQL </li>
</ul>
</li>
<li><p>Mybatis 的 XML Mapper文件中，不同的 XML 映射文件，id 是否可以重复？</p>
<ul>
<li>不同的 XML Mapper 文件，如果配置了 “namespace” ，那么 id 可以重复；如果没有配置 “namespace” ，那么 id 不能重复。毕竟”namespace” 不是必须的，只是最佳实践而已。</li>
<li>原因就是，namespace + id 是作为 Map&lt;String, MappedStatement&gt; 的 key 使用的。如果没有 “namespace”，就剩下 id ，那么 id 重复会导致数据互相覆盖。如果有了 “namespace”，自然 id 就可以重复，”namespace”不同，namespace + id 自然也就不同。</li>
</ul>
</li>
<li><p>如何获取自动生成的(主)键值?</p>
<ul>
<li>Mysql 自增主键<ul>
<li>使用 useGeneratedKeys + keyProperty 属性  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">    <span class="tag">&lt;<span class="name">insert</span> <span class="attr">id</span>=<span class="string">&quot;insert&quot;</span> <span class="attr">parameterType</span>=<span class="string">&quot;Person&quot;</span> <span class="attr">useGeneratedKeys</span>=<span class="string">&quot;true&quot;</span> <span class="attr">keyProperty</span>=<span class="string">&quot;id&quot;</span>&gt;</span></span><br><span class="line">        INSERT INTO person(name, pswd)</span><br><span class="line">        VALUE (#&#123;name&#125;, #&#123;pswd&#125;)</span><br><span class="line">    <span class="tag">&lt;/<span class="name">insert</span>&gt;</span></span><br><span class="line">    ```    </span><br><span class="line">- 使用 `<span class="tag">&lt;<span class="name">selectKey</span> /&gt;</span>` 标签</span><br><span class="line"></span><br><span class="line">    ```xml</span><br><span class="line">        <span class="tag">&lt;<span class="name">insert</span> <span class="attr">id</span>=<span class="string">&quot;insert&quot;</span> <span class="attr">parameterType</span>=<span class="string">&quot;Person&quot;</span> <span class="attr">useGeneratedKeys</span>=<span class="string">&quot;true&quot;</span> <span class="attr">keyProperty</span>=<span class="string">&quot;id&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">selectKey</span> <span class="attr">keyProperty</span>=<span class="string">&quot;id&quot;</span> <span class="attr">resultType</span>=<span class="string">&quot;long&quot;</span> <span class="attr">order</span>=<span class="string">&quot;AFTER&quot;</span>&gt;</span></span><br><span class="line">            SELECT LAST_INSERT_ID()</span><br><span class="line">        <span class="tag">&lt;/<span class="name">selectKey</span>&gt;</span> </span><br><span class="line">            INSERT INTO person(name, pswd)</span><br><span class="line">            VALUE (#&#123;name&#125;, #&#123;pswd&#125;)</span><br><span class="line">        <span class="tag">&lt;/<span class="name">insert</span>&gt;</span>            </span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>Oracle序列自增  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">insert</span> <span class="attr">id</span>=<span class="string">&quot;add&quot;</span> <span class="attr">parameterType</span>=<span class="string">&quot;Student&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">selectKey</span> <span class="attr">keyProperty</span>=<span class="string">&quot;student_id&quot;</span> <span class="attr">resultType</span>=<span class="string">&quot;int&quot;</span> <span class="attr">order</span>=<span class="string">&quot;BEFORE&quot;</span>&gt;</span></span><br><span class="line">        select student_sequence.nextval FROM dual</span><br><span class="line">    <span class="tag">&lt;/<span class="name">selectKey</span>&gt;</span></span><br><span class="line">    INSERT INTO student(student_id, student_name, student_age)</span><br><span class="line">    VALUES (#&#123;student_id&#125;,#&#123;student_name&#125;,#&#123;student_age&#125;)</span><br><span class="line"><span class="tag">&lt;/<span class="name">insert</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Mybatis 执行批量插入，能返回数据库主键列表吗？</p>
<ul>
<li>能，JDBC 都能做，Mybatis 当然也能做。</li>
</ul>
</li>
<li><p>MyBatis 如何执行批量插入?</p>
<ul>
<li>单条插傻循环</li>
<li>拼接insert into values (),(),();</li>
<li>使用BatchExecutor批处理</li>
</ul>
</li>
<li><p>在 Mapper 中如何传递多个参数?</p>
<ul>
<li>使用 Map 集合，装载多个参数进行传递</li>
<li>保持传递多个参数，使用 @Param 注解</li>
<li>保持传递多个参数，不使用 @Param 注解，#{param2}</li>
<li>使用对象定义VO，装载多个参数进行传递</li>
</ul>
</li>
<li><p>Mybatis 是否可以映射 Enum 枚举类？</p>
<ul>
<li>Mybatis 可以映射枚举类，对应的实现类为 EnumTypeHandler 或 EnumOrdinalTypeHandler 。<ul>
<li>EnumTypeHandler ，基于 Enum.name 属性( String )。默认。</li>
<li>EnumOrdinalTypeHandler ，基于 Enum.ordinal 属性( int )。可通过 <setting name="defaultEnumTypeHandler" value="EnumOrdinalTypeHandler" /> 来设置。</li>
</ul>
</li>
</ul>
</li>
<li><p>Mybatis 都有哪些 Executor 执行器？它们之间的区别是什么？</p>
<ul>
<li>Mybatis 有四种 Executor 执行器，分别是 SimpleExecutor、ReuseExecutor、BatchExecutor、CachingExecutor 。<ul>
<li>SimpleExecutor ：每执行一次 update 或 select 操作，就创建一个 Statement 对象，用完立刻关闭 Statement 对象。</li>
<li>ReuseExecutor ：执行 update 或 select 操作，以 SQL 作为key 查找缓存的 Statement 对象，存在就使用，不存在就创建；用完后，不关闭 Statement 对象，而是放置于缓存 Map&lt;String, Statement&gt; 内，供下一次使用。简言之，就是重复使用 Statement 对象。</li>
<li>BatchExecutor ：执行 update 操作（没有 select 操作，因为 JDBC 批处理不支持 select 操作），将所有 SQL 都添加到批处理中（通过 addBatch 方法），等待统一执行（使用 executeBatch 方法）。它缓存了多个 Statement 对象，每个 Statement 对象都是调用 addBatch 方法完毕后，等待一次执行 executeBatch 批处理。实际上，整个过程与 JDBC 批处理是相同。</li>
<li>CachingExecutor ：在上述的三个执行器之上，增加二级缓存的功能。</li>
</ul>
</li>
</ul>
</li>
<li><p>介绍 MyBatis 的一级缓存和二级缓存的概念和实现原理？</p>
<ul>
<li><p>一级缓存：</p>
<ul>
<li><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15850119544106.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
</li>
<li><p>每个SqlSession中持有了Executor，每个Executor中有一个LocalCache。当用户发起查询时，MyBatis根据当前执行的语句生成MappedStatement，在Local Cache进行查询，如果缓存命中的话，直接返回结果给用户，如果缓存没有命中的话，查询数据库，结果写入Local Cache，最后返回结果给用户</p>
</li>
</ul>
</li>
<li><p>二级缓存</p>
<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15850120537632.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>二级缓存开启后，同一个namespace下的所有操作语句，都影响着同一个Cache，即二级缓存被多个SqlSession共享，是一个全局的变量。</li>
<li>当开启缓存后，数据的查询执行的流程就是 二级缓存 -&gt; 一级缓存 -&gt; 数据库。</li>
</ul>
</li>
</ul>
</li>
<li><p>Mybatis 是否支持延迟加载？如果支持，它的实现原理是什么？</p>
<ul>
<li>Mybatis 仅支持 association 关联对象和 collection 关联集合对象的延迟加载。其中，association 指的就是一对一，collection 指的就是一对多查询。</li>
<li>在 Mybatis 配置文件中，可以配置 <setting name="lazyLoadingEnabled" value="true" /> 来启用延迟加载的功能。默认情况下，延迟加载的功能是关闭的。</li>
<li>它的原理是，使用 CGLIB 或 Javassist( 默认 ) 创建目标对象的代理对象。当调用代理对象的延迟加载属性的 getting 方法时，进入拦截器方法。比如调用 a.getB().getName() 方法，进入拦截器的 invoke(…) 方法，发现 a.getB() 需要延迟加载时，那么就会单独发送事先保存好的查询关联 B 对象的 SQL ，把 B 查询上来，然后调用a.setB(b) 方法，于是 a 对象 b 属性就有值了，接着完成a.getB().getName() 方法的调用。这就是延迟加载的基本原理。</li>
</ul>
</li>
<li><p>简述 Mybatis 的插件运行原理？以及如何编写一个插件？</p>
<ul>
<li>Mybatis 仅可以编写针对 ParameterHandler、ResultSetHandler、StatementHandler、Executor 这 4 种接口的插件。</li>
<li>Mybatis 使用 JDK 的动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这 4 种接口对象的方法时，就会进入拦截方法，具体就是 InvocationHandler 的 #invoke(…)方法。当然，只会拦截那些你指定需要拦截的方法。</li>
</ul>
</li>
<li><p>Mybatis 是如何进行分页的？分页插件的原理是什么？</p>
<ul>
<li>Mybatis 使用 RowBounds 对象进行分页，它是针对 ResultSet 结果集执行的内存分页，而非数据库分页</li>
<li>分页插件的基本原理是使用 Mybatis 提供的插件接口，实现自定义分页插件。在插件的拦截方法内，拦截待执行的 SQL ，然后重写 SQL ，根据dialect 方言，添加对应的物理分页语句和物理分页参数。</li>
<li>目前使用比较广泛的 MyBatis 分页插件有：Mybatis-PageHelper、MyBatis-Plus</li>
</ul>
</li>
<li><p>MyBatis 与 Hibernate 有哪些不同？</p>
<ul>
<li>Mybatis 学习门槛低，简单易学，程序员直接编写原生态 SQL ，可严格控制 SQL 执行性能，灵活度高。但是灵活的前提是 MyBatis 无法做到数据库无关性，如果需要实现支持多种数据库的软件则需要自定义多套 SQL 映射文件，工作量大</li>
<li>Hibernate 对象/关系映射能力强，数据库无关性好。如果用 Hibernate 开发可以节省很多代码，提高效率。但是 Hibernate 的缺点是学习门槛高，要精通门槛更高，而且怎么设计 O/R 映射，在性能和对象模型之间如何权衡，以及怎样用好 Hibernate 需要具有很强的经验和能力才行</li>
</ul>
</li>
<li><p>JDBC 编程有哪些不足之处，MyBatis是如何解决这些问题的？</p>
<ul>
<li>问题一：SQL 语句写在代码中造成代码不易维护，且代码会比较混乱。<ul>
<li>解决方式：将 SQL 语句配置在 Mapper XML 文件中，与 Java 代码分离。</li>
</ul>
</li>
<li>问题二：根据参数不同，拼接不同的 SQL 语句非常麻烦。例如 SQL 语句的 WHERE 条件不一定，可能多也可能少，占位符需要和参数一一对应。<ul>
<li>解决方式：MyBatis 提供 <where />、<if /> 等等动态语句所需要的标签，并支持 OGNL 表达式，简化了动态 SQL 拼接的代码，提升了开发效率。</li>
</ul>
</li>
<li>问题三，对结果集解析麻烦，SQL 变化可能导致解析代码变化，且解析前需要遍历。<ul>
<li>解决方式：Mybatis 自动将 SQL 执行结果映射成 Java 对象。</li>
</ul>
</li>
</ul>
</li>
<li><p>Mybatis 映射文件中，如果 A 标签通过 include 引用了B标签的内容，请问，B 标签能否定义在 A 标签的后面，还是说必须定义在A标签的前面？</p>
<ul>
<li>虽然 Mybatis 解析 XML 映射文件是按照顺序解析的。但是，被引用的 B 标签依然可以定义在任何地方，Mybatis 都可以正确识别。也就是说，无需按照顺序，进行定义。</li>
<li>原理是，Mybatis 解析 A 标签，发现 A 标签引用了 B 标签，但是 B 标签尚未解析到，尚不存在，此时，Mybatis 会将 A 标签标记为未解析状态。然后，继续解析余下的标签，包含 B 标签，待所有标签解析完毕，Mybatis 会重新解析那些被标记为未解析的标签，此时再解析A标签时，B 标签已经存在，A 标签也就可以正常解析完成了。</li>
</ul>
</li>
<li><p>简述 Mybatis 的 XML 映射文件和 Mybatis 内部数据结构之间的映射关系？</p>
<ul>
<li>Mybatis 将所有 XML 配置信息都封装到 All-In-One 重量级对象Configuration内部。</li>
<li>在 XML Mapper 文件中：<ul>
<li><parameterMap> 标签，会被解析为 ParameterMap 对象，其每个子元素会被解析为 ParameterMapping 对象。</li>
<li><resultMap> 标签，会被解析为 ResultMap 对象，其每个子元素会被解析为 ResultMapping 对象。</li>
<li>每一个 <code>&lt;select&gt;、&lt;insert&gt;、&lt;update&gt;、&lt;delete&gt;</code> 标签，均会被解析为一个 MappedStatement 对象，标签内的 SQL 会被解析为一个 BoundSql 对象。</li>
</ul>
</li>
</ul>
</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Java/" rel="tag">Java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ORM/" rel="tag">ORM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/interview/" rel="tag">interview</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
  </article>
  

  
  <nav class="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/">下一页</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2019-2022
        <i class="ri-heart-fill heart_icon"></i> Anzhen
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src=''></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="anzhen.tech"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/HDFS">HDFS</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Yarn">Yarn</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/MR">MR</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Hive">Hive</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86">数据采集</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/HBase">HBase</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Kafka">Kafka</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Spark">Spark</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Flink">Flink</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/MySQL">MySQL</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Java">Java</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/interview">面试宝典</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2019/11/07/about-me">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.png">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.png">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->
 <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true,
  };
</script>

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    <div id="music">
    
    
    
    <iframe frameborder="no" border="1" marginwidth="0" marginheight="0" width="200" height="52"
        src="//music.163.com/outchain/player?type=2&id=318916815&auto=1&height=32"></iframe>
</div>

<style>
    #music {
        position: fixed;
        right: 15px;
        bottom: 0;
        z-index: 998;
    }
</style>
    
    

  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>