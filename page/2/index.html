<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title> anzhen.tech</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css"
      />
      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
       
 
<script>
var _hmt = _hmt || [];
(function() {
	var hm = document.createElement("script");
	hm.src = "https://hm.baidu.com/hm.js?20878462c8c8a6915b11b2d93a956d26";
	var s = document.getElementsByTagName("script")[0]; 
	s.parentNode.insertBefore(hm, s);
})();
</script>


      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
      <meta name="baidu-site-verification" content="code-mBRwXRLQqk" />
      <meta name="google-site-verification" content="bqavzWFaou2XjWPiLJI2ZoQwSGDVv_wZFPMkWKjEAz0" />
      
    <link rel="alternate" href="/atom.xml" title="anzhen.tech" type="application/atom+xml">
</head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      
<section class="cover">
    
      
      <a class="forkMe" href="https://gitee.com/anzhen-tech"
        target="_blank"><img width="149" height="149" src="/images/forkme.png"
          class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="/images/cover1.jpg" alt="image frame" />
    </div>
    <div class="cover-inner text-center text-white">
      <h1><a href="/">anzhen.tech</a></h1>
      <div id="subtitle-box">
        
        <span id="subtitle"></span>
        
      </div>
      <div>
        
        <img
          src="/images/ayer.svg"
          class="cover-logo"
          alt="anzhen.tech"
        />
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>



<script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js"></script>


<!-- Subtitle -->

  <script>
    try {
      var typed = new Typed("#subtitle", {
        strings: ['越努力，越美好', '愿你一生努力，一生被爱', '想要的都拥有，得不到的都释怀'],
        startDelay: 0,
        typeSpeed: 200,
        loop: true,
        backSpeed: 100,
        showCursor: true
      });
    } catch (err) {
      console.log(err)
    }
  </script>
  
<div id="main">
  <section class="outer">
  
  <ul class="ads">
    
        <li>
            <a target="_blank" rel="noopener" href="https://www.aliyun.com/minisite/goods?userCode=e6rdw2zn&amp;share_source=copy_link">
                <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/WX20211107-102324@2x.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10" width="300" alt="阿里云服务器">
            </a>
        </li>
    
</ul>
  
  
  

<div class="notice" style="margin-top:50px">
    <i class="ri-heart-fill"></i>
    <div class="notice-content" id="broad"></div>
</div>
<script type="text/javascript">
    fetch('https://v1.hitokoto.cn')
        .then(response => response.json())
        .then(data => {
            document.getElementById("broad").innerHTML = data.hitokoto;
        })
        .catch(console.error)
</script>

<style>
    .notice {
        padding: 20px;
        border: 1px dashed #e6e6e6;
        color: #969696;
        position: relative;
        display: inline-block;
        width: 100%;
        background: #fbfbfb50;
        border-radius: 10px;
    }

    .notice i {
        float: left;
        color: #999;
        font-size: 16px;
        padding-right: 10px;
        vertical-align: middle;
        margin-top: -2px;
    }

    .notice-content {
        display: initial;
        vertical-align: middle;
    }
</style>
  
  <article class="articles">
    
    
    
    
    <article
  id="post-Nginx"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/Nginx/"
    >Nginx</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/Nginx/" class="article-date">
  <time datetime="2021-11-07T02:51:33.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Linux/">Linux</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h1><ol>
<li><p>请解释一下什么是 Nginx ？</p>
<ul>
<li>Nginx ，是一个 Web 服务器和反向代理服务器，用于 HTTP、HTTPS、SMTP、POP3 和 IMAP 协议。</li>
<li>作为 http server</li>
<li>反向代理服务器</li>
<li>正向代理</li>
<li>实现负载均衡</li>
</ul>
</li>
<li><p>Nginx 常用命令？</p>
<ul>
<li>启动 nginx 。</li>
<li>停止 nginx -s stop 或 nginx -s quit 。</li>
<li>重载配置 ./sbin/nginx -s reload(平滑重启) 或 service nginx reload 。</li>
<li>重载指定配置文件 .nginx -c /usr/local/nginx/conf/nginx.conf 。</li>
<li>查看 nginx 版本 nginx -v 。</li>
<li>检查配置文件是否正确 nginx -t 。</li>
<li>显示帮助信息 nginx -h 。</li>
</ul>
</li>
<li><p>Nginx 常用配置？</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">worker_processes  8; # 工作进程个数</span><br><span class="line">worker_connections  65535; # 每个工作进程能并发处理（发起）的最大连接数（包含所有连接数）</span><br><span class="line"># 错误日志打印地址</span><br><span class="line">error_log         /data/logs/nginx/error.log;</span><br><span class="line"># 访问日志打印地址 </span><br><span class="line">access_log      /data/logs/nginx/access.log; </span><br><span class="line"># 日志格式</span><br><span class="line">log_format  main  &#x27;$remote_addr&quot;$request&quot; &#x27;&#x27;$status $upstream_addr &quot;$request_time&quot;&#x27;; </span><br><span class="line">listen       80; # 监听端口</span><br><span class="line"># 允许域名</span><br><span class="line">server_name  rrc.test.jiedaibao.com; </span><br><span class="line"># 项目根目录</span><br><span class="line">root  /data/release/rrc/web; </span><br><span class="line"># 访问根文件</span><br><span class="line">index  index.php index.html index.htm; </span><br></pre></td></tr></table></figure></li>
<li><p>Nginx 日志格式中的<code>$time_local</code>表示的是什么时间？请求开始的时间？请求结束的时间？其次，当我们从前到后观察日志中的 $time_local 时间时，有时候会发现时间顺序前后错乱的现象，请说明原因？</p>
<ul>
<li><code>$time_local</code> ：在服务器里请求开始写入本地的时间。</li>
<li>因为请求发生时间有前有后，所以会时间顺序前后错乱。</li>
</ul>
</li>
<li><p>Nginx 有哪些优点？</p>
<ul>
<li>跨平台、配置简单。</li>
<li>非阻塞、高并发连接</li>
<li>内存消耗小</li>
<li>成本低廉，且开源。</li>
<li>稳定性高，宕机的概率非常小。</li>
</ul>
</li>
<li><p>使用“反向代理服务器”的优点是什么？</p>
<ul>
<li>反向代理服务器可以隐藏源服务器的存在和特征。它充当互联网云和 Web 服务器之间的中间层。这对于安全方面来说是很好的，特别是当我们使用 Web 托管服务时。</li>
</ul>
</li>
<li><p>什么是正向代理？</p>
<ul>
<li>一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。</li>
<li>客户端才能使用正向代理。</li>
<li>正向代理总结就一句话：代理端代理的是客户端</li>
</ul>
</li>
<li><p>什么是反向代理？</p>
<ul>
<li>反向代理（Reverse Proxy）方式，是指以代理服务器来接受 Internet上的连接请求，然后将请求，发给内部网络上的服务器并将从服务器上得到的结果返回给 Internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。</li>
<li>反向代理总结就一句话：代理端代理的是服务端。</li>
</ul>
</li>
<li><p>LVS、Nginx、HAproxy 有什么区别？</p>
<ul>
<li>LVS ：是基于四层的转发。</li>
<li>HAproxy ： 是基于四层和七层的转发，是专业的代理服务器。</li>
<li>Nginx ：是 WEB 服务器，缓存服务器，又是反向代理服务器，可以做七层的转发。 <ul>
<li>Nginx 引入 TCP 插件之后，也可以支持四层的转发。</li>
</ul>
</li>
</ul>
</li>
<li><p>请解释 Nginx 如何处理 HTTP 请求？</p>
<ul>
<li>首先，Nginx 在启动时，会解析配置文件，得到需要监听的端口与 IP 地址，然后在 Nginx 的 Master 进程里面先初始化好这个监控的Socket(创建 S ocket，设置 addr、reuse 等选项，绑定到指定的 ip 地址端口，再 listen 监听)。</li>
<li>然后，再 fork(一个现有进程可以调用 fork 函数创建一个新进程。由 fork 创建的新进程被称为子进程 )出多个子进程出来。</li>
<li>之后，子进程会竞争 accept 新的连接。此时，客户端就可以向 nginx 发起连接了。当客户端与nginx进行三次握手，与 nginx 建立好一个连接后。此时，某一个子进程会 accept 成功，得到这个建立好的连接的 Socket ，然后创建 nginx 对连接的封装，即 ngx_connection_t 结构体。</li>
<li>接着，设置读写事件处理函数，并添加读写事件来与客户端进行数据的交换。</li>
<li>Nginx 或客户端来主动关掉连接，到此，一个连接就寿终正寝了。</li>
</ul>
</li>
<li><p>什么是动态资源、静态资源分离？</p>
<ul>
<li>动态资源、静态资源分离，是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路。</li>
<li>动态资源、静态资源分离简单的概括是：动态文件与静态文件的分离。</li>
</ul>
</li>
<li><p>为什么要做动、静分离？</p>
<ul>
<li>在我们的软件开发中，有些请求是需要后台处理的（如：.jsp,.do 等等），有些请求是不需要经过后台处理的（如：css、html、jpg、js 等等文件），这些不需要经过后台处理的文件称为静态文件，否则动态文件</li>
<li>因此我们后台处理忽略静态文件。这会有人又说那我后台忽略静态文件不就完了吗？当然这是可以的，但是这样后台的请求次数就明显增多了。在我们对资源的响应速度有要求的时候，我们应该使用这种动静分离的策略去解决动、静分离将网站静态资源（HTML，JavaScript，CSS，img等文件）与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问</li>
<li>这里我们将静态资源放到 Nginx 中，动态资源转发到 Tomcat 服务器中去。 </li>
<li>因为现在七牛、阿里云等 CDN 服务已经很成熟，主流的做法，是把静态资源缓存到 CDN 服务中，从而提升访问速度。<ul>
<li>相比本地的 Nginx 来说，CDN 服务器由于在国内有更多的节点，可以实现用户的就近访问。</li>
<li>并且，CDN 服务可以提供更大的带宽，不像我们自己的应用服务，提供的带宽是有限的。</li>
</ul>
</li>
</ul>
</li>
<li><p>什么叫 CDN 服务？</p>
<ul>
<li>CDN ，即内容分发网络。</li>
<li>其目的是，通过在现有的 Internet中 增加一层新的网络架构，将网站的内容发布到最接近用户的网络边缘，使用户可就近取得所需的内容，提高用户访问网站的速度。</li>
<li>一般来说，因为现在 CDN 服务比较大众，所以基本所有公司都会使用 CDN 服务。</li>
</ul>
</li>
<li><p>Nginx 有哪些负载均衡策略？</p>
<ul>
<li><p>轮询（默认）round_robin：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。</p>
</li>
<li><p>IP 哈希 ip_hash：每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 共享的问题。当然，实际场景下，一般不考虑使用 ip_hash 解决 session 共享。</p>
</li>
<li><p>最少连接 least_conn：下一个请求将被分派到活动连接数量最少的服务器</p>
</li>
<li><p>权重</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">weight=1; # (weight 默认为1.weight越大，负载的权重就越大)</span><br><span class="line">down; # (down 表示单前的server暂时不参与负载)</span><br><span class="line">backup; # (其它所有的非backup机器down或者忙的时候，请求backup机器)</span><br><span class="line">max_fails=1; # 允许请求失败的次数默认为 1 。当超过最大次数时，返回</span><br><span class="line">proxy_next_upstream 模块定义的错误</span><br><span class="line">fail_timeout=30; # max_fails 次失败后，暂停的时间</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Nginx 如何实现后端服务的健康检查？</p>
<ul>
<li>利用 nginx 自带模块 ngx_http_proxy_module 和 ngx_http_upstream_module 对后端节点做健康检查。</li>
<li>利用 nginx_upstream_check_module 模块对后端节点做健康检查。</li>
</ul>
</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/interview/" rel="tag">interview</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/" rel="tag">负载均衡</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Java基础"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/Java%E5%9F%BA%E7%A1%80/"
    >Java基础</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/Java%E5%9F%BA%E7%A1%80/" class="article-date">
  <time datetime="2021-11-07T02:50:47.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Java/">Java</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Java核心基础"><a href="#Java核心基础" class="headerlink" title="Java核心基础"></a>Java核心基础</h1><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><ol>
<li><p>JAVA基本数据类型所占长度、</p>
<table>
<thead>
<tr>
<th>基本类型</th>
<th>大小</th>
<th>最小值</th>
<th>最大值</th>
</tr>
</thead>
<tbody><tr>
<td>int</td>
<td>32bit</td>
<td>-2^31</td>
<td>+2^32 -1</td>
</tr>
<tr>
<td>short</td>
<td>16bit</td>
<td>-2^15</td>
<td>+2^15 -1</td>
</tr>
<tr>
<td>byte</td>
<td>8bit</td>
<td>-128</td>
<td>+127</td>
</tr>
<tr>
<td>long</td>
<td>64bit</td>
<td>-2^63</td>
<td>+2^63 -1</td>
</tr>
<tr>
<td>float</td>
<td>32bit</td>
<td>IEEE754</td>
<td>IEEE754</td>
</tr>
<tr>
<td>double</td>
<td>64bit</td>
<td>IEEE754</td>
<td>IEEE754</td>
</tr>
<tr>
<td>char</td>
<td>16bit</td>
<td>Unicode 0</td>
<td>Unicode 2^16 -1</td>
</tr>
<tr>
<td>boolean</td>
<td>1bit</td>
<td>—-</td>
<td>—-</td>
</tr>
</tbody></table>
<ul>
<li>JAVA基本数据类型的长度是平台无关的，32位系统和64位系统一样，因为JAVA是运行在JVM上的。</li>
</ul>
</li>
<li><p>Java String 占用内存大小分析</p>
<ul>
<li>Java 对象在虚拟机的结构如下：<ul>
<li>对象头（object header）：8 个字节（保存对象的 class 信息、ID、在虚拟机中的状态）</li>
<li>Java 原始类型数据：如 int, float, char 等类型的数据</li>
<li>引用（reference）：4 个字节</li>
<li>填充符（padding）</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="线程基础"><a href="#线程基础" class="headerlink" title="线程基础"></a>线程基础</h2><ol>
<li>什么是线程？<ul>
<li>线程是操作系统能够进行运算调度的最小单位，它被包含在进程之中，是进程中的实际运作单位</li>
</ul>
</li>
<li>线程和进程有什么区别？<ul>
<li>线程是进程的子集，一个进程可以有很多线程，每条线程并行执行不同的任务。不同的进程使用不同的内存空间，而所有的线程共享一片相同的内存空间。别把它和栈内存搞混，每个线程都拥有单独的栈内存用来存储本地数据</li>
</ul>
</li>
<li>如何在Java中实现线程？<ul>
<li>继承java.lang.Thread 类或者直接调用Runnable接口来重写run()方法实现线程</li>
</ul>
</li>
<li>用Runnable还是Thread？<ul>
<li>Runnable可以继承其他类</li>
</ul>
</li>
<li>Thread 类中的start() 和 run() 方法有什么区别？<ul>
<li>start()方法被用来启动新创建的线程，而且start()内部调用了run()方法，这和直接调用run()方法的效果不一样。当<strong>调用run()方法的时候，只会是在原来的线程中调用，没有新的线程启动，start()方法才会启动新线程</strong></li>
</ul>
</li>
<li>Java中Runnable和Callable有什么不同？<ul>
<li>Callable的 call() 方法有返回值和抛出异常，而Runnable的run()方法没有这些功能。</li>
<li>Callable可以返回装载有计算结果的Future对象。</li>
</ul>
</li>
<li>什么是线程安全？Vector是一个线程安全类吗？<ul>
<li>多线程操作下数据一致性</li>
</ul>
</li>
</ol>
<h2 id="ThreadLocal-相关"><a href="#ThreadLocal-相关" class="headerlink" title="ThreadLocal 相关"></a>ThreadLocal 相关</h2><ol>
<li>作为线程局部变量使用</li>
<li><code>set(T value)</code>:获取<code>ThreadLocalMap</code>(静态内部类)并保存value,为空则调用<code>createMap(Thread t, T firstValue)</code>;</li>
<li><code>getMap(Thread t)</code>:获取<code>ThreadLocalMap</code>,不为空则获取对应值;为空调用<code>setInitialValue()</code> 初始化value;内部调用<code>initialValue()</code>;</li>
<li>需要初始化值,要重写<code>initialValue</code></li>
<li><a target="_blank" rel="noopener" href="http://blog.csdn.net/sonny543/article/details/51336457">threadlocal原理及常用应用场景</a></li>
</ol>
<h2 id="java-集合框架-队列相关"><a href="#java-集合框架-队列相关" class="headerlink" title="java 集合框架 队列相关"></a>java 集合框架 队列相关</h2><ol>
<li>HashMap <ul>
<li>基于Hash表的非同步实现,允许K-V 为null;</li>
<li>底层基于数组实现(HashMap.Entry[]),单项为一个链表</li>
<li>HashMap.Entry 包含K,V,next Entry&lt;K,V&gt;,hash</li>
<li>put(K,V) 通过hash(key.hashCode())计算出hash值决定其在数组中的存储位置，如果此位置上有对象的话，再去使用 equals方法进行比较，如果对此链上的每个对象的 equals 方法比较都为 false，则将该对象放到数组当中，然后将数组中该位置以前存在的那个对象链接到此对象的后面</li>
<li>get(K) 首先计算key的hashCode，找到数组中对应位置的某一元素，然后通过key的equals方法在对应位置的链表中找到需要的元素。</li>
<li>当hash冲突很多时，HashMap退化成链表。</li>
<li>key为null时，都放到table[0]</li>
<li>扩容默认负载因子0.75,重新计算位置单个Entry在新数组中的位置 (resize)</li>
<li>fast-fail volatile modCount</li>
<li>java 8 HashMap 改为 数组+链表/红黑树,同一hash位下链表元素&gt;=8时,链表转换为红黑树</li>
</ul>
</li>
<li>ConcurrentHashMap<ul>
<li>ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术。</li>
<li><font color="red" >待补充源码及具体实现</font></li>
</ul>
</li>
<li>LinkedHashMap<ul>
<li>LinkedHashMap继承于HashMap，底层使用哈希表和双向链表来保存所有元素，并且它是非同步，允许使用null值和null键</li>
<li>重新定义了数组中保存的元素Entry，来实现自己的链接列表特性。该Entry除了保存当前对象的引用外，还保存了其上一个元素before和下一个元素after的引用，从而构成了双向链接列表</li>
</ul>
</li>
<li>HashSet<ul>
<li>HashSet由哈希表支持,基于HashMap实现，不保证set的迭代顺序，并允许使用null元素。</li>
</ul>
</li>
<li>LinkedHashSet<ul>
<li>对于LinkedHashSet而言，它继承与HashSet、又基于LinkedHashMap来实现的。LinkedHashSet底层使用LinkedHashMap来保存所有元素，它继承与HashSet，其所有的方法操作上又与HashSet相同。</li>
</ul>
</li>
<li>ArrayList<ul>
<li>ArrayList是List接口的可变数组非同步实现，并允许包括null在内的所有元素。底层使用数组实现</li>
<li>该集合是可变长度数组，数组扩容时，会将老数组中的元素重新拷贝一份到新的数组中，每次数组容量增长大约是其容量的<font color="red">1.5倍</font>，这种操作的代价很高。</li>
<li>采用了Fail-Fast机制，面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险</li>
</ul>
</li>
<li>LinkedList<ul>
<li>LinkedList是List接口的双向链表非同步实现，并允许包括null在内的所有元素。</li>
<li>底层的数据结构是基于双向链表的，该数据结构我们称为节点(Node)</li>
<li>双向链表节点对应的静态内部类Node<E>的实例，Node中包含成员变量：next，prev，item。</li>
</ul>
</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Java/" rel="tag">Java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/interview/" rel="tag">interview</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spring"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
     
    <div class="article-meta">
      <a href="/2021/11/07/Spring/" class="article-date">
  <time datetime="2021-11-07T02:49:27.000Z" itemprop="datePublished">2021-11-07</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h1><h2 id="Spring-整体相关的面试"><a href="#Spring-整体相关的面试" class="headerlink" title="Spring 整体相关的面试"></a>Spring 整体相关的面试</h2><ol>
<li>什么是 Spring Framework？<ul>
<li>Spring 是一个开源应用框架，旨在降低应用程序开发的复杂度。</li>
<li>它是轻量级、松散耦合的。随着 Spring 的体系越来越庞大，大家被 Spring 的配置搞懵逼了，所以后来出了 Spring Boot 。</li>
<li>它具有分层体系结构，允许用户选择组件，同时还为 J2EE 应用程序开发提供了一个有凝聚力的框架。</li>
<li>它可以集成其他框架，如 Spring MVC、Hibernate、MyBatis 等，所以又称为框架的框架( 粘合剂、脚手架 )。</li>
</ul>
</li>
<li>Spring Framework 中有多少个模块，它们分别是什么？<ul>
<li><img src="https://s2.loli.net/2022/03/08/Gfdneam1stSNTYu.jpg"></li>
<li>Spring 核心容器:核心容器提供 Spring 框架的基本功能。核心容器的主要组件是 BeanFactory，它是工厂模式的实现。BeanFactory 使用控制反转 （IOC）模式将应用程序的配置和依赖性规范与实际的应用程序代码分开。<ul>
<li>Spring Core</li>
<li>Spring Bean</li>
<li>Spring Context:Spring 上下文是一个配置文件，向 Spring 框架提供上下文信息。Spring 上下文包括企业服务，例如 JNDI、EJB、电子邮件、国际化、事件机制、校验和调度功能。</li>
<li>SpEL (Spring Expression Language):Spring 表达式语言全称为 “Spring Expression Language”，缩写为 “SpEL” ，类似于 Struts2 中使用的 OGNL 表达式语言，能在运行时构建复杂表达式、存取对象图属性、对象方法调用等等，并且能与 Spring 功能完美整合，如能用来配置 Bean 定义。</li>
</ul>
</li>
<li>数据访问:Data Access 。<ul>
<li>JDBC: Spring 对 JDBC 的封装模块，提供了对关系数据库的访问。</li>
<li>ORM: Spring ORM 模块，提供了对 hibernate5 和 JPA 的集成。<ul>
<li>hibernate5 是一个 ORM 框架。</li>
<li>JPA 是一个 Java 持久化 API 。</li>
</ul>
</li>
<li>Transaction:Spring 简单而强大的事务管理功能，包括声明式事务和编程式事务。</li>
</ul>
</li>
<li>Web: 提供了创建 Web 应用程序的支持。它包含以下模块：<ul>
<li>WebMVC 框架是一个全功能的构建 Web 应用程序的 MVC 实现。通过策略接口，MVC 框架变成为高度可配置的，MVC 容纳了大量视图技术，其中包括 JSP、Velocity、Tiles、iText 和 POI。</li>
<li>WebFlux:基于 Reactive 库的响应式的 Web 开发框架</li>
<li>WebSocket:Websocket 提供了一个在 Web 应用中实现高效、双向通讯，需考虑客户端(浏览器)和服务端之间高频和低延时消息交换的机制。</li>
<li>一般的应用场景有：在线交易、网页聊天、游戏、协作、数据可视化等。</li>
</ul>
</li>
<li>AOP:支持面向切面编程。它包含以下模块：<ul>
<li>AOP通过配置管理特性，Spring AOP 模块直接将面向方面的编程功能集成到了 Spring 框架中。所以，可以很容易地使 Spring 框架管理的任何对象支持 AOP。</li>
<li>Spring AOP 模块为基于 Spring 的应用程序中的对象提供了事务管理服务。通过使用 Spring AOP，不用依赖 EJB 组件，就可以将声明性事务管理集成到应用程序中。</li>
</ul>
</li>
<li>JMS</li>
<li>Test</li>
<li>Messaging</li>
</ul>
</li>
<li>使用 Spring 框架能带来哪些好处？<ul>
<li>DI ：依赖注入，使得构造器和 JavaBean、properties 文件中的依赖关系一目了然。</li>
<li>轻量级：与 EJB 容器相比较，IoC 容器更加趋向于轻量级。这样一来 IoC 容器在有限的内存和 CPU 资源的情况下，进行应用程序的开发和发布就变得十分有利。</li>
<li>面向切面编程(AOP)： Spring 支持面向切面编程，同时把应用的业务逻辑与系统的服务分离开来。</li>
<li>集成主流框架：Spring 并没有闭门造车，Spring 集成了已有的技术栈，比如 ORM 框架、Logging 日期框架、J2EE、Quartz 和 JDK Timer ，以及其他视图技术。</li>
<li>模块化：Spring 框架是按照模块的形式来组织的。由包和类的命名，就可以看出其所属的模块，开发者仅仅需要选用他们需要的模块即可。</li>
<li>便捷的测试：要 测试一项用Spring开发的应用程序 十分简单，因为测试相关的环境代码都已经囊括在框架中了。更加简单的是，利用 JavaBean 形式的 POJO 类，可以很方便的利用依赖注入来写入测试数据。</li>
<li>Web 框架：Spring 的 Web 框架亦是一个精心设计的 Web MVC 框架，为开发者们在 Web 框架的选择上提供了一个除了主流框架比如 Struts 、过度设计的、不流行 Web 框架的以外的有力选项。</li>
<li>事务管理：Spring 提供了一个便捷的事务管理接口，适用于小型的本地事物处理（比如在单 DB 的环境下）和复杂的共同事物处理（比如利用 JTA 的复杂 DB 环境）。</li>
</ul>
</li>
<li>Spring 框架中都用到了哪些设计模式？<ul>
<li>代理模式 — 在 AOP 和 remoting 中被用的比较多。</li>
<li>单例模式 — 在 Spring 配置文件中定义的 Bean 默认为单例模式。</li>
<li>模板方法 — 用来解决代码重复的问题。比如 RestTemplate、JmsTemplate、JdbcTemplate 。</li>
<li>前端控制器 — Spring提供了 DispatcherServlet 来对请求进行分发。</li>
<li>依赖注入 — 贯穿于 BeanFactory / ApplicationContext 接口的核心理念。</li>
<li>工厂模式 — BeanFactory 用来创建对象的实例。</li>
</ul>
</li>
</ol>
<h2 id="Spring-IoC-相关的面试题"><a href="#Spring-IoC-相关的面试题" class="headerlink" title="Spring IoC 相关的面试题"></a>Spring IoC 相关的面试题</h2><ol>
<li>什么是 Spring IoC 容器？<ul>
<li><img src="https://s2.loli.net/2022/03/08/ChtRG5upeASvPwr.jpg"></li>
<li>Spring 框架的核心是 Spring IoC 容器。容器创建 Bean 对象，将它们装配在一起，配置它们并管理它们的完整生命周期。<ul>
<li>Spring 容器使用依赖注入来管理组成应用程序的 Bean 对象。</li>
<li>容器通过读取提供的配置元数据 Bean Definition 来接收对象进行实例化，配置和组装的指令。</li>
<li>该配置元数据 Bean Definition 可以通过 XML，Java 注解或 Java Config 代码提供。</li>
</ul>
</li>
</ul>
</li>
<li>什么是依赖注入？<ul>
<li>在依赖注入中，你不必主动、手动创建对象，但必须描述如何创建它们。你不是直接在代码中将组件和服务连接在一起，而是描述配置文件中哪些组件需要哪些服务。</li>
<li>然后，再由 IoC 容器将它们装配在一起。</li>
</ul>
</li>
<li>IoC 和 DI 有什么区别？<ul>
<li> IOC就是由 Spring IOC 容器来负责对象的生命周期和对象之间的关系；容器控制应用程序，由容器反向的向应用程序注入应用程序所需要的外部资源。</li>
<li> DI应用程序依赖容器创建并注入它所需要的外部资源；</li>
</ul>
</li>
<li>可以通过多少种方式完成依赖注入？<ul>
<li>可以通过多少种方式完成依赖注入？<ul>
<li>接口注入</li>
<li>构造函数注入</li>
<li>setter 注入</li>
</ul>
</li>
<li>实际场景下，setting 注入使用的更多。</li>
</ul>
</li>
<li>Spring 中有多少种 IoC 容器？<ul>
<li>Spring 提供了两种( 不是“个” ) IoC 容器，分别是 BeanFactory、ApplicationContext <ul>
<li>BeanFactory：spring-beans 项目提供，就像一个包含 Bean 集合的工厂类。它会在客户端要求时实例化 Bean 对象。</li>
<li>ApplicationContext：接口扩展了 BeanFactory 接口，它在 BeanFactory 基础上提供了一些额外的功能。内置如下功能：<ul>
<li>MessageSource ：管理 message ，实现国际化等功能。</li>
<li>ApplicationEventPublisher ：事件发布。</li>
<li>ResourcePatternResolver ：多资源加载。</li>
<li>EnvironmentCapable ：系统 Environment（profile + Properties）相关。</li>
<li>Lifecycle ：管理生命周期。</li>
<li>Closable ：关闭，释放资源</li>
<li>InitializingBean：自定义初始化。</li>
<li>BeanNameAware：设置 beanName 的 Aware 接口。</li>
<li>常用WebApplicationContext ClassPathXmlApplicationContext</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>请介绍下常用的 BeanFactory 容器？<ul>
<li>BeanFactory 最常用的是 XmlBeanFactory 。它可以根据 XML 文件中定义的内容，创建相应的 Bean。</li>
<li>ListableBeanFactory:实现了枚举方法可以列举出当前 BeanFactory 中所有的 bean 对象而不必根据 name 一个一个的获取。</li>
</ul>
</li>
<li>请介绍下常用的 ApplicationContext 容器？<ul>
<li>ClassPathXmlApplicationContext ：从 ClassPath 的 XML 配置文件中读取上下文，并生成上下文定义。应用程序上下文从程序环境变量中取得。示例代码如下：  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ApplicationContext context = <span class="keyword">new</span> ClassPathXmlApplicationContext(“bean.xml”);</span><br></pre></td></tr></table></figure></li>
<li>FileSystemXmlApplicationContext ：由文件系统中的XML配置文件读取上下文。示例代码如下：  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ApplicationContext context = <span class="keyword">new</span> FileSystemXmlApplicationContext(“bean.xml”); </span><br></pre></td></tr></table></figure></li>
<li>Spring Boot 使用的是ConfigServletWebServerApplicationContext ApplicationContext 容器，。</li>
</ul>
</li>
<li>列举一些 IoC 的一些好处？<ul>
<li>它将最小化应用程序中的代码量。</li>
<li>它以最小的影响和最少的侵入机制促进松耦合。</li>
<li>它支持即时的实例化和延迟加载 Bean 对象。</li>
<li>它将使应用程序易于测试，因为它不需要单元测试用例中的任何单例或 JNDI 查找机制。</li>
</ul>
</li>
<li>简述 Spring IoC 的实现机制？<ul>
<li>Spring 中的 IoC 的实现原理，就是工厂模式加反射机制</li>
</ul>
</li>
</ol>
<h2 id="Spring-Bean"><a href="#Spring-Bean" class="headerlink" title="Spring Bean"></a>Spring Bean</h2><ol>
<li><p>什么是 Spring Bean ？</p>
<ul>
<li>Bean 由 Spring IoC 容器实例化，配置，装配和管理。</li>
<li>Bean 是基于用户提供给 IoC 容器的配置元数据 Bean Definition 创建。</li>
</ul>
</li>
<li><p>Spring 有哪些配置Bean的方式</p>
<ul>
<li>XML 配置文件。</li>
<li>注解配置。</li>
<li>Java Config 配置，使用 @Bean 和 @Configuration 来实现。</li>
<li>具体举例<ul>
<li>Dubbo 服务的配置，使用 XML 。</li>
<li>Spring MVC 请求的配置，艿艿喜欢使用 @RequestMapping 注解。</li>
<li>Spring MVC 拦截器的配置，艿艿喜欢 Java Config 配置。</li>
<li>Spring Boot 以Java Config 配置为主。</li>
</ul>
</li>
</ul>
</li>
<li><p>Spring 支持几种 Bean Scope ？</p>
<ul>
<li>Singleton - 每个 Spring IoC 容器仅有一个单 Bean 实例。默认</li>
<li>Prototype - 每次请求都会产生一个新的实例。</li>
<li>Request - 每一次 HTTP 请求都会产生一个新的 Bean 实例，并且该 Bean 仅在当前 HTTP 请求内有效。</li>
<li>Session - 每一个的 Session 都会产生一个新的 Bean 实例，同时该 Bean 仅在当前 HTTP Session 内有效。</li>
<li>Application - 每一个 Web Application 都会产生一个新的 Bean ，同时该 Bean 仅在当前 Web Application 内有效。</li>
</ul>
</li>
<li><p>Spring Bean 在容器的生命周期是什么样的？</p>
<ul>
<li>Spring Bean 的初始化流程如下：<ul>
<li>实例化 Bean 对象<ul>
<li>Spring 容器根据配置中的 Bean Definition(定义)中实例化 Bean 对象。(Bean Definition 可以通过 XML，Java 注解或 Java Config 代码提供)。</li>
<li>Spring 使用依赖注入填充所有属性，如 Bean 中所定义的配置。</li>
</ul>
</li>
<li>Aware 相关的属性，注入到 Bean 对象<ul>
<li>如果 Bean 实现 BeanNameAware 接口，则工厂通过传递 Bean 的 beanName 来调用 #setBeanName(String name) 方法。</li>
<li>如果 Bean 实现 BeanFactoryAware 接口，工厂通过传递自身的实例来调用 #setBeanFactory(BeanFactory beanFactory) 方法。</li>
</ul>
</li>
<li>调用相应的方法，进一步初始化 Bean 对象<ul>
<li>如果存在与 Bean 关联的任何 BeanPostProcessor 们，则调用 #preProcessBeforeInitialization(Object bean, String beanName) 方法。</li>
<li>如果 Bean 实现 InitializingBean 接口，则会调用 #afterPropertiesSet() 方法。</li>
<li>如果为 Bean 指定了 init 方法（例如 <bean /> 的 init-method 属性），那么将调用该方法。</li>
<li>如果存在与 Bean 关联的任何 BeanPostProcessor 们，则将调用 #postProcessAfterInitialization(Object bean, String beanName) 方法。</li>
</ul>
</li>
</ul>
</li>
<li>Spring Bean 的销毁流程如下：<ul>
<li>如果 Bean 实现 DisposableBean 接口，当 spring 容器关闭时，会调用 #destroy() 方法。</li>
<li>如果为 bean 指定了 destroy 方法（例如 <bean /> 的 destroy-method 属性），那么将调用该方法。<ul>
<li><img src="https://s2.loli.net/2022/03/08/kG3rdih45nALEFO.jpg"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>什么是 Spring 装配？</p>
<ul>
<li>装配，和上文提到的 DI 依赖注入，实际是一个东西。</li>
</ul>
</li>
<li><p>自动装配有哪些方式？</p>
<ul>
<li>Spring 容器能够自动装配 Bean 。也就是说，可以通过检查 BeanFactory 的内容让 Spring 自动解析 Bean 的协作者。</li>
<li>自动装配的不同模式：<ul>
<li>no - 这是默认设置，表示没有自动装配。应使用显式 Bean 引用进行装配。</li>
<li>byName - 它根据 Bean 的名称注入对象依赖项。它匹配并装配其属性与 XML 文件中由相同名称定义的 Bean 。</li>
<li>【最常用】byType - 它根据类型注入对象依赖项。如果属性的类型与 XML 文件中的一个 Bean 类型匹配，则匹配并装配属性。</li>
<li>构造函数 - 它通过调用类的构造函数来注入依赖项。它有大量的参数。</li>
<li>autodetect - 首先容器尝试通过构造函数使用 autowire 装配，如果不能，则尝试通过 byType 自动装配。</li>
</ul>
</li>
</ul>
</li>
<li><p>解释什么叫延迟加载？</p>
<ul>
<li>默认情况下，容器启动之后会将所有作用域为单例的 Bean 都创建好，但是有的业务场景我们并不需要它提前都创建好。此时，我们可以在Bean 中设置 lzay-init = “true” 。</li>
<li>这样，当容器启动之后，作用域为单例的 Bean ，就不在创建。而是在获得该 Bean 时，才真正在创建加载。</li>
</ul>
</li>
<li><p>Spring 框架中的单例 Bean 是线程安全的么？</p>
<ul>
<li>Spring 框架并没有对单例 Bean 进行任何多线程的封装处理。</li>
</ul>
</li>
<li><p>Spring Bean 怎么解决循环依赖的问题？</p>
<ul>
<li><p><img src="https://s2.loli.net/2022/03/08/KHAGPVekZOWIa6r.jpg"></p>
</li>
<li><p>Spring 在创建 bean 的时候并不是等它完全完成，而是在创建过程中将创建中的 bean 的 ObjectFactory 提前曝光（即加入到 singletonFactories 缓存中）。</p>
</li>
<li><p>这样，一旦下一个 bean 创建的时候需要依赖 bean ，则直接使用 ObjectFactory 的 #getObject() 方法来获取了。</p>
</li>
<li><p>实例如 A 依赖 B，B 依赖 C，C 依赖 A：</p>
<ul>
<li>首先 A 完成初始化第一步并将自己提前曝光出来（通过 ObjectFactory 将自己提前曝光），在初始化的时候，发现自己依赖对象 B，此时就会去尝试 get(B)，这个时候发现 B 还没有被创建出来</li>
<li>然后 B 就走创建流程，在 B 初始化的时候，同样发现自己依赖 C，C 也没有被创建出来</li>
<li>这个时候 C 又开始初始化进程，但是在初始化的过程中发现自己依赖 A，于是尝试 get(A)，这个时候由于 A 已经添加至缓存中（一般都是添加至三级缓存 singletonFactories ），通过 ObjectFactory 提前曝光，所以可以通过 ObjectFactory#getObject() 方法来拿到 A 对象，C 拿到 A 对象后顺利完成初始化，然后将自己添加到一级缓存中</li>
<li>回到 B ，B 也可以拿到 C 对象，完成初始化，A 可以顺利拿到 B 完成初始化。到这里整个链路就已经完成了初始化过程了</li>
</ul>
</li>
</ul>
</li>
<li><p>BeanFactory和FactoryBean的区别</p>
<ul>
<li>BeanFactory是个Factory，也就是IOC容器或对象工厂</li>
<li>FactoryBean是个Bean。</li>
<li>Spring中所有的Bean都是由BeanFactory(也就是IOC容器)来进行管理的。但对FactoryBean而言，这个Bean不是简单的Bean，而是一个能生产或者修饰对象生成的工厂Bean,它的实现与设计模式中的工厂模式和修饰器模式类似 <h2 id="Spring-注解"><a href="#Spring-注解" class="headerlink" title="Spring 注解"></a>Spring 注解</h2></li>
</ul>
</li>
<li><p>什么是基于注解的容器配置？</p>
<ul>
<li>不使用 XML 来描述 Bean 装配，开发人员通过在相关的类，方法或字段声明上使用注解将配置移动到组件类本身。它可以作为 XML 设置的替代方案</li>
<li>以Java Config 配置Bean的方式。</li>
</ul>
</li>
<li><p>如何在 Spring 中启动注解装配？</p>
<ul>
<li><code>&lt;context：annotation-config /&gt;</code></li>
<li>Spring Boot默认情况下已经开启。</li>
</ul>
</li>
<li><p>@Component, @Controller, @Repository, @Service 有何区别？</p>
<ul>
<li>@Component ：它将 Java 类标记为 Bean 。它是任何 Spring 管理组件的通用构造型。</li>
<li>@Controller ：它将一个类标记为 Spring Web MVC 控制器。</li>
<li>@Service ：此注解是组件注解的特化。它不会对 @Component 注解提供任何其他行为。您可以在服务层类中使用 @Service 而不是 @Component ，因为它以更好的方式指定了意图。</li>
<li>@Repository ：这个注解是具有类似用途和功能的 @Component 注解的特化。它为 DAO 提供了额外的好处。它将 DAO 导入 IoC 容器，并使未经检查的异常有资格转换为 Spring DataAccessException 。</li>
</ul>
</li>
<li><p>@Required 注解有什么用？</p>
<ul>
<li>此注解仅指示必须在配置时使用 Bean 定义中的显式属性值或使用自动装配填充受影响的 Bean 属性。</li>
<li>如果尚未填充受影响的 Bean 属性，则容器将抛出 BeanInitializationException 异常。</li>
</ul>
</li>
<li><p>@Autowired 注解有什么用？</p>
<ul>
<li>@Autowired 注解，可以更准确地控制应该在何处以及如何进行自动装配。<ul>
<li>此注解用于在 setter 方法，构造函数，具有任意名称或多个参数的属性或方法上自动装配 Bean。</li>
<li>默认情况下，它是类型驱动的注入。</li>
</ul>
</li>
</ul>
</li>
<li><p>@Qualifier 注解有什么用？</p>
<ul>
<li>当你创建多个相同类型的 Bean ，并希望仅使用属性装配其中一个 Bean 时，您可以使用 @Qualifier 注解和 @Autowired 通过指定 ID 应该装配哪个确切的 Bean 来消除歧义。</li>
</ul>
</li>
<li><p>@Autowired注解与@Resource注解的区别</p>
<ul>
<li>@Autowired为Spring提供的注解，需要导入包org.springframework.beans.factory.annotation.Autowired;只按照byType注入。</li>
<li>@Autowired注解是按照类型（byType）装配依赖对象，默认情况下它要求依赖对象必须存在，如果允许null值，可以设置它的required属性为false。如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用。(通过类型匹配找到多个candidate,在没有@Qualifier、@Primary注解的情况下，会使用对象名作为最后的fallback匹配)</li>
<li>@Resource默认按照ByName自动注入，由J2EE提供，需要导入包javax.annotation.Resource。@Resource有两个重要的属性：name和type，而Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。</li>
<li>@Resource装配顺序：<ul>
<li>①如果同时指定了name和type，则从Spring上下文中找到唯一匹配的bean进行装配，找不到则抛出异常。</li>
<li>②如果指定了name，则从上下文中查找名称（id）匹配的bean进行装配，找不到则抛出异常。</li>
<li>③如果指定了type，则从上下文中找到类似匹配的唯一bean进行装配，找不到或是找到多个，都会抛出异常。</li>
<li>④如果既没有指定name，又没有指定type，则自动按照byName方式进行装配；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="Spring-AOP"><a href="#Spring-AOP" class="headerlink" title="Spring AOP"></a>Spring AOP</h2><ol>
<li>什么是 AOP ？<ul>
<li>AOP(Aspect-Oriented Programming)，即面向切面编程, 它与 OOP( Object-Oriented Programming, 面向对象编程) 相辅相成， 提供了与 OOP 不同的抽象软件结构的视角。</li>
<li>在 OOP 中，以类( Class )作为基本单元</li>
<li>在 AOP 中，以切面( Aspect )作为基本单元。</li>
</ul>
</li>
<li>什么是 Aspect ？<ul>
<li>Aspect 由 PointCut 和 Advice 组成,@Aspect 注解的类就是切面。<ul>
<li>它既包含了横切逻辑的定义，也包括了连接点的定义。</li>
<li>Spring AOP 就是负责实施切面的框架，它将切面所定义的横切逻辑编织到切面所指定的连接点中。</li>
<li>AOP 的工作重心在于如何将增强编织目标对象的连接点上, 这里包含两个工作:<ul>
<li>如何通过 PointCut 和 Advice 定位到特定的 JoinPoint 上。</li>
<li>如何在 Advice 中编写切面代码。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>什么是 JoinPoint ?<ul>
<li>JoinPoint ，切点，程序运行中的一些时间点, 例如：<ul>
<li> 一个方法的执行。</li>
<li> 或者是一个异常的处理。</li>
</ul>
</li>
<li> 在 Spring AOP 中，JoinPoint 总是方法的执行点。</li>
</ul>
</li>
<li>什么是 PointCut ？<ul>
<li>PointCut 是匹配 JoinPoint 的条件。</li>
<li>Advice 是和特定的 PointCut 关联的，并且在 PointCut 相匹配的 JoinPoint 中执行。即 Advice =&gt; PointCut =&gt; JoinPoint 。</li>
<li>在 Spring 中, 所有的方法都可以认为是 JoinPoint ，但是我们并不希望在所有的方法上都添加 Advice 。而 PointCut 的作用，就是提供一组规则(使用 AspectJ PointCut expression language 来描述) 来匹配 JoinPoint ，给满足规则的 JoinPoint 添加 Advice 。</li>
</ul>
</li>
<li>关于 JoinPoint 和 PointCut 的区别<ul>
<li>首先，Advice 通过 PointCut 查询需要被织入的 JoinPoint 。</li>
<li>然后，Advice 在查询到 JoinPoint 上执行逻辑。</li>
</ul>
</li>
<li>什么是 Advice ？<ul>
<li>特定 JoinPoint 处的 Aspect 所采取的动作称为 Advice 。</li>
<li>Spring AOP 使用一个 Advice 作为拦截器，在 JoinPoint “周围”维护一系列的拦截器。</li>
</ul>
</li>
<li>有哪些类型的 Advice？<ul>
<li>1.@Before前置通知在切入点运行前执行，不会影响切入点的逻辑</li>
<li>2.@After后置通知在切入点正常运行结束后执行，如果切入点抛出异常，则在抛出异常前执行</li>
<li>3.@AfterThrowing异常通知:在切入点抛出异常前执行，如果切入点正常运行（未抛出异常），则不执行</li>
<li>4.@AfterReturning返回通知:在切入点正常运行结束后执行，如果切入点抛出异常，则不执行</li>
<li>5.@Around环绕通知是功能最强大的通知，可以在切入点执行前后自定义一些操作。环绕通知需要负责决定是继续处理join point(调用ProceedingJoinPoint的proceed方法)还是中断执行</li>
</ul>
</li>
<li>什么是 Target ？<ul>
<li>Target ，织入 Advice 的目标对象。目标对象也被称为 Advised Object 。<ul>
<li>因为 Spring AOP 使用运行时代理的方式来实现 Aspect ，因此 Advised Object 总是一个代理对象(Proxied Object) 。</li>
<li>注意, Advised Object 指的不是原来的对象，而是织入 Advice 后所产生的代理对象。</li>
<li>Advice + Target Object = Advised Object = Proxy 。</li>
</ul>
</li>
</ul>
</li>
<li>AOP 有哪些实现方式？<ul>
<li>静态代理 - 指使用 AOP 框架提供的命令进行编译，从而在编译阶段就可生成 AOP 代理类，因此也称为编译时增强。<ul>
<li>例如，SkyWalking 基于 Java Agent 机制，配置上 ByteBuddy 库，实现类加载时编织时增强，从而实现链路追踪的透明埋点。</li>
</ul>
</li>
<li>动态代理 - 在运行时在内存中“临时”生成 AOP 动态代理类，因此也被称为运行时增强。目前 Spring 中使用了两种动态代理库：<ul>
<li>JDK 动态代理</li>
<li>CGLIB</li>
</ul>
</li>
</ul>
</li>
<li>Spring 如何使用 AOP 切面？<ul>
<li>基于 XML 方式的切面实现。</li>
<li>基于 注解 方式的切面实现。</li>
</ul>
</li>
</ol>
<h2 id="Spring-Transaction-相关的面试题"><a href="#Spring-Transaction-相关的面试题" class="headerlink" title="Spring Transaction 相关的面试题"></a>Spring Transaction 相关的面试题</h2><ol>
<li>列举 Spring 支持的事务管理类型？<ul>
<li>声明式事务：通过使用注解或基于 XML 的配置事务，从而事务管理与业务代码分离。</li>
<li>编程式事务：通过编码的方式实现事务管理，需要在代码中显式的调用事务的获得、提交、回滚。它为您提供极大的灵活性，但维护起来非常困难。</li>
</ul>
</li>
<li>Spring 事务如何和不同的数据持久层框架做集成？<ul>
<li>Spring 事务的管理，是通过org.springframework.transaction.PlatformTransactionManager 进行管理<ul>
<li>PlatformTransactionManager 是负责事务管理的接口，一共有三个接口方法，分别负责事务的获得、提交、回滚。<ul>
<li><code>getTransaction(TransactionDefinition definition)</code> 方法，根据事务定义 TransactionDefinition ，获得 TransactionStatus 。<ul>
<li>为什么不是创建事务？因为如果当前如果已经有事务，则不会进行创建，一般来说会跟当前线程进行绑定。如果不存在事务，则进行创建。</li>
<li>为什么返回的是 TransactionStatus 对象？在 TransactionStatus 中，不仅仅包含事务属性，还包含事务的其它信息，例如是否只读、是否为新创建的事务等等。</li>
</ul>
</li>
<li><code>commit(TransactionStatus status)</code> 方法，根据 TransactionStatus 情况，提交事务。<ul>
<li>为什么根据 TransactionStatus 情况，进行提交？<ul>
<li>例如，带@Transactional 注解的的 A 方法，会调用 @Transactional 注解的的 B 方法。</li>
<li>在 B 方法结束调用后，会执行 PlatformTransactionManager#commit(TransactionStatus status) 方法，此处事务是不能、也不会提交的。</li>
<li>而是在 A 方法结束调用后，执行 PlatformTransactionManager#commit(TransactionStatus status) 方法，提交事务。</li>
</ul>
</li>
</ul>
</li>
<li><code>rollback(TransactionStatus status)</code> 方法，根据 TransactionStatus 情况，回滚事务。<ul>
<li>为什么根据 TransactionStatus 情况，进行回滚？原因同 #commit(TransactionStatus status) 方法。</li>
</ul>
</li>
</ul>
</li>
<li>PlatformTransactionManager 有抽象子类 <code>org.springframework.transaction.support.AbstractPlatformTransactionManager</code> ，基于 模板方法模式 ，实现事务整体逻辑的骨架，而抽象 <code>doCommit(DefaultTransactionStatus status)</code>、<code>doRollback(DefaultTransactionStatus status)</code> 等等方法，交由子类类来实现</li>
<li>不同的数据持久层框架，会有其对应的 PlatformTransactionManager 实现类<ul>
<li><img src="https://s2.loli.net/2022/03/08/j3u5gsL6BdCkIaU.jpg"></li>
<li>所有的实现类，都基于 AbstractPlatformTransactionManager 这个骨架类。</li>
<li>HibernateTransactionManager ，和 Hibernate5 的事务管理做集成。</li>
<li>DataSourceTransactionManager ，和 JDBC 的事务管理做集成。所以，它也适用于 MyBatis、Spring JDBC 等等。</li>
<li>JpaTransactionManager ，和 JPA 的事务管理做集成。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>为什么在 Spring 事务中不能切换数据源？<ul>
<li>在 Spring 的事务管理中，所使用的数据库连接会和当前线程所绑定，即使我们设置了另外一个数据源，使用的还是当前的数据源连接。</li>
<li>多个数据源且需要事务的场景，本身会带来多事务一致性的问题，暂时没有特别好的解决方案。</li>
<li>所以一般一个应用，推荐除非了读写分离所带来的多数据源，其它情况下，建议只有一个数据源。并且，随着微服务日益身形，一个服务对应一个 DB 是比较常见的架构选择。</li>
</ul>
</li>
<li>@Transactional 注解有哪些属性？如何使用？<ul>
<li>@Transactional 注解的属性如下：<table>
<thead>
<tr>
<th>属性</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>value</td>
<td>String</td>
<td>可选的限定描述符，指定使用的事务管理器</td>
</tr>
<tr>
<td>propagation</td>
<td>enum: Propagation</td>
<td>可选的事务传播行为设置</td>
</tr>
<tr>
<td>isolation</td>
<td>enum: Isolation</td>
<td>可选的事务隔离级别设置</td>
</tr>
<tr>
<td>readOnly</td>
<td>boolean</td>
<td>读写或只读事务，默认读写</td>
</tr>
<tr>
<td>timeout</td>
<td>int (in seconds granularity)</td>
<td>事务超时时间设置</td>
</tr>
<tr>
<td>rollbackFor</td>
<td>Class对象数组，必须继承自Throwable</td>
<td>导致事务回滚的异常类数组</td>
</tr>
<tr>
<td>rollbackForClassName</td>
<td>类名数组，必须继承自Throwable</td>
<td>导致事务回滚的异常类名字数组</td>
</tr>
<tr>
<td>noRollbackFor</td>
<td>Class对象数组，必须继承自Throwable</td>
<td>不会导致事务回滚的异常类数组</td>
</tr>
<tr>
<td>noRollbackForClassName</td>
<td>类名数组，必须继承自Throwable</td>
<td>不会导致事务回滚的异常类名字数组</td>
</tr>
</tbody></table>
<ul>
<li>具体用法如下：<ul>
<li>@Transactional 可以作用于接口、接口方法、类以及类方法上。当作用于类上时，该类的所有 public 方法将都具有该类型的事务属性，同时，我们也可以在方法级别使用该标注来覆盖类级别的定义。</li>
<li>虽然 @Transactional 注解可以作用于接口、接口方法、类以及类方法上，但是 Spring 建议不要在接口或者接口方法上使用该注解，因为这只有在使用基于接口的代理时它才会生效。另外， @Transactional 注解应该只被应用到 public 方法上，这是由 Spring AOP 的本质决定的。如果你在 protected、private 或者默认可见性的方法上使用 @Transactional 注解，这将被忽略，也不会抛出任何异常。这一点，非常需要注意。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>什么是事务的传播级别？分成哪些传播级别？<ul>
<li>事务的传播行为，指的是当前带有事务配置的方法，需要怎么处理事务。  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ========== 支持当前事务的情况 ========== </span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 如果当前存在事务，则使用该事务。</span></span><br><span class="line"><span class="comment"> * 如果当前没有事务，则创建一个新的事务。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int</span> PROPAGATION_REQUIRED = <span class="number">0</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 如果当前存在事务，则使用该事务。</span></span><br><span class="line"><span class="comment"> * 如果当前没有事务，则以非事务的方式继续运行。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int</span> PROPAGATION_SUPPORTS = <span class="number">1</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 如果当前存在事务，则使用该事务。</span></span><br><span class="line"><span class="comment"> * 如果当前没有事务，则抛出异常。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int</span> PROPAGATION_MANDATORY = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ========== 不支持当前事务的情况 ========== </span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 创建一个新的事务。</span></span><br><span class="line"><span class="comment"> * 如果当前存在事务，则把当前事务挂起。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int</span> PROPAGATION_REQUIRES_NEW = <span class="number">3</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 以非事务方式运行。</span></span><br><span class="line"><span class="comment"> * 如果当前存在事务，则把当前事务挂起。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int</span> PROPAGATION_NOT_SUPPORTED = <span class="number">4</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 以非事务方式运行。</span></span><br><span class="line"><span class="comment"> * 如果当前存在事务，则抛出异常。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int</span> PROPAGATION_NEVER = <span class="number">5</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ========== 其他情况 ========== </span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行。</span></span><br><span class="line"><span class="comment"> * 如果当前没有事务，则等价于 &#123;<span class="doctag">@link</span> TransactionDefinition#PROPAGATION_REQUIRED&#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int</span> PROPAGATION_NESTED = <span class="number">6</span>;</span><br><span class="line">        </span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>什么是事务的超时属性？<ul>
<li>所谓事务超时，就是指一个事务所允许执行的最长时间，如果超过该时间限制但事务还没有完成，则自动回滚事务。</li>
<li>在 TransactionDefinition 中以 int 的值来表示超时时间，其单位是秒。</li>
</ul>
</li>
<li>什么是事务的只读属性？<ul>
<li>事务的只读属性是指，对事务性资源进行只读操作或者是读写操作。</li>
<li>所谓事务性资源就是指那些被事务管理的资源，比如数据源、JMS 资源，以及自定义的事务性资源等等。</li>
<li>如果确定只对事务性资源进行只读操作，那么我们可以将事务标志为只读的，以提高事务处理的性能。</li>
</ul>
</li>
<li>什么是事务的回滚规则？<ul>
<li>回滚规则，定义了哪些异常会导致事务回滚而哪些不会。</li>
<li>默认情况下，事务只有遇到运行期异常时才会回滚，而在遇到检查型异常时不会回滚（这一行为与EJB的回滚行为是一致的）。</li>
<li>但是你可以声明事务在遇到特定的检查型异常时像遇到运行期异常那样回滚。同样，你还可以声明事务遇到特定的异常不回滚，即使这些异常是运行期异常。</li>
<li>注意，事务的回滚规则，并不是数据库事务规范中的名词，而是 Spring 自身所定义的。</li>
</ul>
</li>
<li>简单介绍 TransactionStatus ？ <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TransactionStatus.java</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">TransactionStatus</span> <span class="keyword">extends</span> <span class="title">SavepointManager</span>, <span class="title">Flushable</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 是否是新创建的事务</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isNewTransaction</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 是否有 Savepoint</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 在 &#123;<span class="doctag">@link</span> TransactionDefinition#PROPAGATION_NESTED&#125; 传播级别使用。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">hasSavepoint</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 设置为只回滚</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">setRollbackOnly</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 是否为只回滚</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isRollbackOnly</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 执行 flush 操作</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">flush</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 是否事务已经完成</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isCompleted</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>为什么没有事务对象呢？在 TransactionStatus 的实现类 DefaultTransactionStatus 中，有个 Object transaction 属性，表示事务对象。</li>
<li>isNewTransaction() 方法，表示是否是新创建的事务。有什么用呢？答案结合 「Spring 事务如何和不同的数据持久层框架做集成？」 问题，我们对 commit(TransactionStatus status) 方法的解释。通过该方法，我们可以判断，当前事务是否当前方法所创建的，只有创建事务的方法，才能且应该真正的提交事务。</li>
</ul>
</li>
<li>使用 Spring 事务有什么优点？<ul>
<li>通过 PlatformTransactionManager ，为不同的数据层持久框架提供统一的 API ，无需关心到底是原生 JDBC、Spring JDBC、JPA、Hibernate 还是 MyBatis 。</li>
<li>通过使用声明式事务，使业务代码和事务管理的逻辑分离，更加清晰。</li>
</ul>
</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-JVM"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/JVM/"
    >JVM</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/JVM/" class="article-date">
  <time datetime="2021-11-07T02:47:01.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Java/">Java</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h1><ol>
<li><p>JVM 由哪些部分组成？</p>
<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15847504847911.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15847532504574.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>类加载器：在JVM启动时或者类运行时将需要的class加载到JVM。</li>
<li>运行时数据区：将内存划分为若干个区以模拟实际机器上的存储，记录，调度功能模块。</li>
<li>执行引擎：执行引擎的任务是负责执行 class 文件中包含的字节码指令，相当于实际机器上的 CPU。</li>
<li>本地方法调用：调用 C 或 C++ 实现的本地方法的代码返回结果。</li>
</ul>
</li>
<li><p>JVM 运行内存（运行时数据区）的分类？</p>
<ul>
<li>程序计数器（线程私有）：记录正在执行的Java方法的字节码指令地址，唯一没有OutOfMemoryError情况的区域</li>
<li>栈内存（线程私有）：描述Java方法执行时的内存模型 <ul>
<li>每个方法在执行的时候，都会创建一个栈帧用于存储局部变量，操作数，动态链接，方法出口等信息</li>
<li>每个方法调用都意味着一个栈帧再虚拟机栈中入栈到出栈的过程</li>
<li>局部变量表：基本数据类型（boolean,byte,short,int,long,float,double,char），对象引用（reference类型，不等同与对象，是指针或者资源地址），returnAddress类型（指向一条字节码指令的位置）</li>
<li>线程执行栈深度超出限制，跑出StackOverFlowError</li>
</ul>
</li>
<li>本地方法栈：<ul>
<li>和 Java 虚拟机栈的作用类似，区别是该区域为 JVM 提供使用 Native 方法的服务</li>
</ul>
</li>
<li>堆内存（线程共享）：所有线程共享的一块区域，存放对象实例，垃圾收集器管理的主要区域。<ul>
<li>目前主要的垃圾回收算法都是分代收集算法，所以 Java 堆中还可以细分为：新生代和老年代；再细致一点的有 Eden 空间、From Survivor 空间、To Survivor 空间等，默认情况下新生代按照 8:1:1 的比例来分配。</li>
<li>Java 堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘一样。</li>
<li>可固定，可拓展通过-Xms -Xmx控制</li>
<li>堆内存无法分配内存，且无法拓展，抛出OutOfMemory</li>
</ul>
</li>
<li>方法区（线程共享）：主要用于已被虚拟机加载的类信息、静态变量、常量、JIT编译后的代码<ul>
<li>JDK 1.8 的对 JVM 架构的改造将类元数据放到本地内存中，另外，将常量池和静态变量放到 Java 堆里</li>
<li>JDK 1.7 <code>java.lang.OutOfMemoryError: PermGen space</code> -XX:MaxPermSize -XX:PermSize</li>
<li>JDK 1.8 -XX:MetaspaceSize，初始空间大小;-XX:MaxMetaspaceSize，最大空间，默认是没有限制的</li>
<li>运行时常量池</li>
</ul>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/paddix/p/5309550.html">Java8内存模型—永久代(PermGen)和元空间(Metaspace)</a></p>
</blockquote>
</li>
</ul>
</li>
<li><p>直接内存是不是虚拟机运行时数据区的一部分？</p>
<ul>
<li>直接内存(Direct Memory)不是虚拟机运行时数据区的一部分</li>
<li>使用 native 函数库直接分配堆外内存，使用Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作，避免了在 Java 堆和 Native 堆中来回复制数据显著提高性能</li>
<li>本机直接内存的分配不会受到 Java 堆大小的限制，受到本机总内存大小限制。</li>
<li>配置虚拟机参数时，不要忽略直接内存，防止出现 OutOfMemoryError 异常。</li>
</ul>
</li>
<li><p>Java内存模型?</p>
<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15848403457744.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>定义程序中各个变量的访问规则</li>
<li>所有的变量都存储在主内存</li>
<li>线程有自己的工作内存，工作内存保存了该线程使用到的变量的主内存副本拷贝</li>
<li>线程间变量值的传递均需要通过主内存来实现</li>
<li>原子性: synchronized保证了原子性，提供了两个高级的字节码指令monitorenter和monitorexit</li>
<li>可见性：Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值的这种依赖主内存作为传递媒介的方式来实现的。可以使用synchronized，volatile， final实现</li>
<li>有序性：在Java中，可以使用synchronized和volatile来保证多线程之间操作的有序性；volatile关键字会禁止指令重排。synchronized关键字保证同一时刻只允许一条线程操作。</li>
</ul>
</li>
<li><p>直接内存（堆外内存）与堆内存比较？</p>
<ul>
<li>直接内存申请空间耗费更高的性能，当频繁申请到一定量时尤为明显。</li>
<li>直接内存 IO 读写的性能要优于普通的堆内存，在多次读写操作的情况下差异明显。</li>
</ul>
</li>
<li><p>为什么要废弃永久代？</p>
<ul>
<li>由于永久代内存经常不够用或发生内存泄露，爆出异常 java.lang.OutOfMemoryError: PermGen</li>
<li>字符串存在永久代中，容易出现性能问题和内存溢出。</li>
<li>类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出。</li>
<li>永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。</li>
</ul>
</li>
<li><p>Java 内存堆和栈区别？</p>
<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15847579303911.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>栈内存存储基本类型的变量和对象的引用变量；堆内存用来存储Java中的对象，无论是成员变量，局部变量，还是类变量，它们指向的对象都存储在堆内存中。</li>
<li>栈内存归属于单个线程，每个线程都会有一个栈内存，其存储的变量只能在其所属线程中可见，即栈内存可以理解成线程的私有内存；堆内存中的对象对所有线程可见。堆内存中的对象可以被所有线程访问。</li>
<li>栈溢出 java.lang.StackOverFlowError；堆溢出java.lang.OutOfMemoryError</li>
<li>栈的内存要远远小于堆内存，如果你使用递归的话，那么你的栈很快就会充满。-Xss 选项设置栈内存的大小，-Xms 选项可以设置堆的开始时的大小。</li>
</ul>
<blockquote>
<p>JVM 中堆和栈属于不同的内存区域，使用目的也不同。栈常用于保存方法帧和局部变量，而对象总是在堆上分配。栈通常都比堆小，也不会在多个线程之间共享，而堆被整个 JVM 的所有线程共享。</p>
</blockquote>
</li>
<li><p>JAVA 对象创建的过程？</p>
<pre><code> - ![](https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15847585045516.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10)                                                    
 - ![](https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15847593821321.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10)        
</code></pre>
<ol>
<li>检测类是否被加载:当虚拟机遇到 new 指令时，首先先去检查这个指令的参数是否能在常量池(方法区-运行时常量池)中定位到一<strong>个类的符号引用</strong>，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，就执行类加载过程</li>
<li>为对象分配内存：<ul>
<li>内存空间绝对规整：虚拟机只需要在被占用的内存和可用空间之间移动指针即可，这种方式被称为“<strong>指针碰撞</strong>”。</li>
<li>内存不规整：虚拟机需要维护一个列表，来记录哪些内存是可用的。分配内存的时候需要找到一个可用的内存空间，然后在列表上记录下已被分配，这种方式成为“<strong>空闲列表</strong>”。</li>
</ul>
</li>
<li>为分配的内存空间初始化零值：对象的内存分配完成后，还需要将对象的内存空间都初始化为零值，这样能保证对象的实例字段即使没有赋初值，也可以直接使用。</li>
<li>对对象进行其他设置：在对象头中设置对象所属的类，类的元数据信息，对象的 hashcode ，GC 分代年龄等信息。</li>
<li>执行 init 方法：Java 在编译之后会在字节码文件中生成 init 方法，称之为实例构造器，该实例构造器会将语句块，变量初始化，调用父类的构造器等操作收敛到 init 方法中，收敛顺序为：<ol>
<li>父类变量初始化</li>
<li>父类语句块</li>
<li>父类构造函数</li>
<li>子类变量初始化</li>
<li>子类语句块</li>
<li>子类构造函数</li>
</ol>
</li>
</ol>
</li>
<li><p>A a = new A() 经历过什么过程?</p>
<blockquote>
<p>同上</p>
</blockquote>
</li>
<li><p>对象的内存布局是怎样的？JAVA对象模型？</p>
<ul>
<li>对象头：对象头包括两部分信息。<ul>
<li>第一部分，是存储对象自身的运行时数据，如哈希码，GC 分代年龄，锁状态标志，线程持有的锁等等。</li>
<li>第二部分，是类型指针，即对象指向类元数据的指针。</li>
</ul>
</li>
<li>实例数据：对象真正存储的有效信息</li>
<li>对齐填充：不是必然的存在，就是为了对齐。</li>
</ul>
</li>
<li><p>对象是如何定位访问的？</p>
<ul>
<li>对象的访问定位有两种：<ol>
<li>句柄定位：Java 堆会画出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15847606523598.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ul>
</li>
<li>直接指针访问：Java 堆对象的不居中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象地址。<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15847606809648.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ul>
</li>
</ol>
</li>
<li>对比两种方式？<ul>
<li>使用句柄来访问的最大好处，就是 reference 中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。</li>
<li>使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销。</li>
</ul>
</li>
</ul>
</li>
<li><p>有哪些 OutOfMemoryError 异常？</p>
<ul>
<li>除了程序计数器外，虚拟机内存的其它几个运行时区域都有发生的 OutOfMemoryError(简称为“OOM”) 异常的可能。</li>
<li>Java 堆溢出:不停new对象，保证GCRoot可达性</li>
<li>虚拟机栈和本地方法栈溢出：栈容量由 -Xss参数设定 递归</li>
<li>方法区和运行时常量池溢出 大量类<blockquote>
<p>从 JDK8 开始，就变成元数据区的内存溢出。</p>
</blockquote>
</li>
<li>元数据区的内存溢出:-XX:MaxMetaspaceSize=10m</li>
<li>本机直接内存溢出 申请对外内存</li>
</ul>
</li>
<li><p>当出现了内存溢出，怎么排错？</p>
<ol>
<li>首先，控制台查看错误日志。</li>
<li>使用 JDK 自带的 jvisualvm 工具查看系统的堆栈日志。<code>jstat</code> <code>jmap</code></li>
<li>定位出内存溢出的空间：堆，栈还是永久代（JDK8 以后不会出现永久代的内存溢出）。<ol>
<li>如果是堆内存溢出，看是否创建了超大的对象。</li>
<li>如果是栈内存溢出，看是否创建了超大的对象，或者产生了死循环。</li>
</ol>
</li>
</ol>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/2fdee831ed03">Java内存溢出(OOM)异常完全指南</a></p>
</blockquote>
</li>
<li><p>Java 中会存在内存泄漏吗？</p>
<ul>
<li>Hibernate 的 Session（一级缓存）中的对象属于持久态，垃圾回收器是不会回收这些对象的，然而这些对象中可能存在无用的垃圾对象。</li>
<li>使用 Netty 的堆外的 ByteBuf 对象，在使用完后，并未归还，导致使用的一点一点在泄露。</li>
</ul>
</li>
</ol>
<h2 id="垃圾收集器与内存分配策略"><a href="#垃圾收集器与内存分配策略" class="headerlink" title="垃圾收集器与内存分配策略"></a>垃圾收集器与内存分配策略</h2><ol>
<li><p>什么是垃圾回收机制？</p>
<ul>
<li>Java 中对象是采用 new 或者反射的方法创建的，这些对象的创建都是在堆(Heap)中分配的，所有对象的回收都是由 Java 虚拟机通过垃圾回收机制完成的。GC 为了能够正确释放对象，会监控每个对象的运行状况，对他们的申请、引用、被引用、赋值等状况进行监控。</li>
<li>Java 程序员不用担心内存管理，因为垃圾收集器会自动进行管理。</li>
<li>可以调用下面的方法之一：<code>System.gc()</code> 或 <code>Runtime.getRuntime().gc()</code> ，但 JVM 也可以屏蔽掉显示的垃圾回收调用。</li>
</ul>
</li>
<li><p>为什么不建议在程序中显式的声明 System.gc() ？</p>
<ul>
<li>因为显式声明是做堆内存全扫描，也就是 Full GC ，是需要停止所有的活动的(Stop The World Collection)，对应用很大可能存在影响。</li>
<li>调用 System.gc() 方法后，不会立即执行 Full GC ，而是虚拟机自己决定的。</li>
</ul>
</li>
<li><p>如果一个对象的引用被设置为 null , GC 会立即释放该对象的内存么?</p>
<ul>
<li>不会, 这个对象将会在下一次 GC 循环中被回收。</li>
</ul>
</li>
<li><p><code>finalize()</code> 方法什么时候被调用？它的目的是什么？</p>
<ul>
<li><code>finallize()</code>方法，是在释放该对象内存前由 GC (垃圾回收器)调用。</li>
<li><del>通常建议在这个方法中释放该对象持有的资源，例如持有的堆外内存、和远程服务的长连接。</del></li>
<li>对于一个对象，该方法有且仅会被调用一次。</li>
</ul>
</li>
<li><p>如何判断一个对象是否已经死去？</p>
<ul>
<li>引用计数<ul>
<li>每个对象有一个引用计数属性，新增一个引用时计数加 1 ，引用释放时计数减 1 ，计数为 0 时可以回收。此方法简单，无法解决对象相互循环引用的问题。目前在用的有 Python、ActionScript3 等语言。</li>
</ul>
</li>
<li>可达性分析<ul>
<li>从 GC Roots 开始向下搜索，搜索所走过的路径称为引用链。当一个对象到 GC Roots 没有任何引用链相连时，则证明此对象是不可用的。不可达对象。目前在用的有 Java、C# 等语言。</li>
</ul>
</li>
</ul>
</li>
<li><p>如果 A 和 B 对象循环引用，是否可以被 GC？</p>
<ul>
<li>可以，因为 Java 采用可达性分析的判断方式。</li>
</ul>
</li>
<li><p>在 Java 语言里，可作为 GC Roots 的对象包括以下几种？</p>
<ul>
<li>虚拟机栈（栈帧中的本地变量表）中引用的对象。(参数)</li>
<li>方法区中的类静态属性引用的对象。</li>
<li>方法区中常量引用的对象。</li>
<li>本地方法栈中 JNI(即一般说的 Native 方法)中引用的对象。</li>
</ul>
</li>
<li><p>方法区是否能被回收？</p>
<ul>
<li>方法区可以被回收，但是价值很低，主要回收废弃的常量和无用的类。</li>
<li>如何判断无用的类，需要完全满足如下三个条件：<ul>
<li>该类所有实例都被回收（Java 堆中没有该类的对象）。</li>
<li>加载该类的 ClassLoader 已经被回收。</li>
<li>该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方利用反射访问该类。</li>
</ul>
</li>
</ul>
</li>
<li><p>Java 对象有哪些引用类型?</p>
<ul>
<li>强引用<ul>
<li>以前我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用。如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。</li>
</ul>
</li>
<li>软引用（SoftReference）<ul>
<li>如果一个对象只具有软引用，那就类似于可有可物的生活用品。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。</li>
<li>软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA 虚拟机就会把这个软引用加入到与之关联的引用队列中。</li>
<li><code>Mybatis SoftCache</code></li>
</ul>
</li>
<li>弱引用（WeakReference）<ul>
<li>如果一个对象只具有弱引用，那就类似于可有可物的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。</li>
<li>弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。</li>
<li><code>Mybatis WeakCache</code></li>
</ul>
</li>
<li>虚引用（PhantomReference）<ul>
<li>“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。</li>
<li>虚引用主要用来跟踪对象被垃圾回收的活动。虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列（ReferenceQueue）联合使用。当垃 圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。</li>
</ul>
</li>
</ul>
</li>
<li><p>WeakReference 与 SoftReference的区别？</p>
<ul>
<li>虽然 WeakReference 与 SoftReference 都有利于提高 GC 和 内存的效率。但是 WeakReference 一旦失去最后一个强引用，就会被 GC 回收而 SoftReference 虽然不能阻止被回收，但是可以延迟到 JVM 内存不足的时候。</li>
</ul>
</li>
<li><p>为什么要有不同的引用类型？</p>
<ul>
<li>不像 C 语言，我们可以控制内存的申请和释放，在 Java 中有时候我们需要适当的控制对象被回收的时机，因此就诞生了不同的引用类型，可以说不同的引用类型实则是对 GC 回收时机不可控的妥协。有以下几个使用场景可以充分的说明：</li>
<li>利用软引用和弱引用解决 OOM 问题。用一个 HashMap 来保存图片的路径和相应图片对象关联的软引用之间的映射关系，在内存不足时，JVM 会自动回收这些缓存图片对象所占用的空间，从而有效地避免了 OOM 的问题.</li>
<li>通过软引用实现 Java 对象的高速缓存。比如我们创建了一 Person 的类，如果每次需要查询一个人的信息，哪怕是几秒中之前刚刚查询过的，都要重新构建一个实例，这将引起大量 Person 对象的消耗，并且由于这些对象的生命周期相对较短，会引起多次 GC 影响性能。此时，通过软引用和 HashMap 的结合可以构建高速缓存，提供性能。</li>
</ul>
</li>
<li><p>JVM 垃圾回收算法？</p>
<ul>
<li><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15847757529717.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
</li>
<li><p>标记-清除算法</p>
<ul>
<li>标记-清除算法将垃圾回收分为两个阶段：标记阶段和清除阶段。</li>
<li>一种可行的实现是，在标记阶段，首先通过根节点，标记所有从根节点开始的可达对象。因此，未被标记的对象就是未被引用的垃圾对象（好多资料说标记出要回收的对象，其实明白大概意思就可以了）。然后，在清除阶段，清除所有未被标记的对象。</li>
<li>缺点：<ol>
<li>效率问题，标记和清除两个过程的效率都不高。</li>
<li>空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大的对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。</li>
</ol>
</li>
</ul>
</li>
<li><p>标记-整理算法</p>
<ul>
<li><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15847758515877.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
</li>
<li><p>标记整理算法，类似与标记清除算法，不过它标记完对象后，不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉边界以外的内存。</p>
</li>
<li><p>优点：</p>
<ol>
<li>相对标记清除算法，解决了内存碎片问题。</li>
<li>没有内存碎片后，对象创建内存分配也更快速了（可以使用TLAB进行分配）。</li>
</ol>
</li>
<li><p>缺点：</p>
<ol start="3">
<li>效率问题，（同标记清除算法）标记和整理两个过程的效率都不高。</li>
</ol>
</li>
</ul>
</li>
<li><p>复制算法</p>
<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15847759518607.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>复制算法，可以解决效率问题，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块，当这一块内存用完了，就将还存活着的对象复制到另一块上面，然后再把已经使用过的内存空间一次清理掉，这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可（还可使用TLAB进行高效分配内存）。</li>
<li>图的上半部分是未回收前的内存区域，图的下半部分是回收后的内存区域。通过图，可以发现不管回收前还是回收后都有一半的空间未被利用。</li>
<li>优点：<ol start="4">
<li>效率高，没有内存碎片。</li>
</ol>
</li>
<li>缺点：<ol start="5">
<li>浪费一半的内存空间。</li>
<li>复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。</li>
</ol>
</li>
</ul>
</li>
<li><p>分代收集算法</p>
<ul>
<li><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15847762126339.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
</li>
<li><p>当前商业虚拟机都是采用分代收集算法，它根据对象存活周期的不同将内存划分为几块，一般是把 Java 堆分为新生代和老年代，然后根据各个年代的特点采用最适当的收集算法。</p>
</li>
<li><p>在新生代中，每次垃圾收集都发现有大批对象死去，只有少量存活，就选用复制算法。</p>
</li>
<li><p>而老年代中，因为对象存活率高，没有额外空间对它进行分配担保，就必须使用“标记清理”或者“标记整理”算法来进行回收。</p>
</li>
<li><p>对象分配策略：</p>
<ul>
<li>对象优先在 Eden 区域分配，如果对象过大直接分配到 Old 区域。</li>
<li>长时间存活的对象进入到 Old 区域。</li>
</ul>
</li>
<li><p>改进自复制算法</p>
<ul>
<li>现在的商业虚拟机都采用这种收集算法来回收新生代，IBM 公司的专门研究表明，新生代中的对象 98% 是“朝生夕死”的，所以并不需要按照 1:1 的比例来划分内存空间，而是将内存分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 和其中一块 Survivor 。当回收时，将 Eden 和 Survivor 中还存活着的对象一次性地复制到另外一块 Survivor 空间上，最后清理掉 Eden 和刚才用过的 Survivor 空间。</li>
<li>HotSpot 虚拟机默认 Eden 和 2 块 Survivor 的大小比例是 8:1:1，也就是每次新生代中可用内存空间为整个新生代容量的 90%（80%+10%），只有 10% 的内存会被“浪费”。当然，98% 的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于 10% 的对象存活，当 Survivor 空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保（Handle Promotion）。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>什么是安全点？</p>
<ul>
<li>SafePoint 安全点，顾名思义是指一些特定的位置，当线程运行到这些位置时，线程的一些状态可以被确定(the thread’s representation of it’s Java machine state is well described)，比如记录OopMap 的状态，从而确定 GC Root 的信息，使 JVM 可以安全的进行一些操作，比如开始 GC 。</li>
</ul>
</li>
<li><p>那些位置可以作为安全点</p>
<ul>
<li>循环的末尾 (防止大循环的时候一直不进入 Safepoint ，而其他线程在等待它进入 Safepoint )。</li>
<li>方法返回前。</li>
<li>调用方法的 Call 之后。</li>
<li>抛出异常的位置。</li>
</ul>
</li>
<li><p>GC发生时停止到安全点的方式</p>
<ul>
<li>主动式<ul>
<li> JVM 设置一个全局变量，线程去按照某种策略检查这个变量一旦发现是 SafePoint 就主动挂起。轮询点==安全点</li>
<li> HostSpot 虚拟机采用的是主动式使线程中断。</li>
</ul>
</li>
<li>抢先式<ul>
<li>JVM发出信号，所有线程全部停止，检查非安全点的线程，让其恢复跑到安全点</li>
</ul>
</li>
<li>安全区域<ul>
<li>如果程序长时间不执行，比如线程调用的 sleep 方法，这时候程序无法响应 JVM 中断请求这时候线程无法到达安全点，显然 JVM 也不可能等待程序唤醒，这时候就需要安全区域了。</li>
<li>安全区域是指一段代码片中，引用关系不会发生变化，在这个区域任何地方 GC 都是安全的，安全区域可以看做是安全点的一个扩展。</li>
<li>线程执行到安全区域的代码时，首先标识自己进入了安全区域，这样 GC 时就不用管进入安全区域的线程了.</li>
<li>线程要离开安全区域时就检查 JVM 是否完成了 GC Roots 枚举（或者整个 GC 过程），如果完成就继续执行，如果没有完成就等待直到收到可以安全离开的信号。</li>
</ul>
</li>
</ul>
</li>
<li><p>JVM 垃圾收集器有哪些？</p>
<ul>
<li>新生代收集器<ul>
<li>Serial 收集器</li>
<li>ParNew 收集器<blockquote>
<p>ParNew 收集器，是 Serial 收集器的多线程版。</p>
</blockquote>
</li>
<li>Parallel Scavenge 收集器</li>
</ul>
</li>
<li>老年代收集器<ul>
<li>Serial Old 收集器<blockquote>
<p>Serial Old 收集器，是 Serial 收集器的老年代版本。</p>
</blockquote>
</li>
<li>Parallel Old 收集器<blockquote>
<p>Parallel Old 收集器，是 Parallel Scavenge 收集器的老年代版本。</p>
</blockquote>
</li>
<li>CMS 收集器</li>
</ul>
</li>
<li>新生代 + 老年代收集器<ul>
<li>G1 收集器</li>
<li>ZGC 收集器</li>
</ul>
</li>
<li>对比<table>
<thead>
<tr>
<th>收集器</th>
<th>串行/并行/并发</th>
<th>新生代/老年代</th>
<th>算法</th>
<th>目标</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>Serial</td>
<td>串行</td>
<td>新生代</td>
<td>复制算法</td>
<td>响应速度</td>
<td>单CPU环境下的Client模式</td>
</tr>
<tr>
<td>Serial Old</td>
<td>串行</td>
<td>老年代</td>
<td>标记-整理</td>
<td>响应速度</td>
<td>单CPU环境下的Client模式、CMS的后备预案</td>
</tr>
<tr>
<td>ParNew</td>
<td>并行</td>
<td>新生代</td>
<td>复制算法</td>
<td>响应速度</td>
<td>多CPU环境时在Server模式下与CMS配合</td>
</tr>
<tr>
<td>Parallel Scavenge</td>
<td>并行</td>
<td>新生代</td>
<td>复制算法</td>
<td>吞吐量</td>
<td>在后台运算而不需要太多交互的任务</td>
</tr>
<tr>
<td>Parallel Old</td>
<td>并行</td>
<td>老年代</td>
<td>标记-整理</td>
<td>吞吐量</td>
<td>在后台运算而不需要太多交互的任务</td>
</tr>
<tr>
<td>CMS</td>
<td>并发</td>
<td>老年代</td>
<td>标记-清除</td>
<td>响应速度</td>
<td>集中在互联网站或B/S系统服务端上的Java应用</td>
</tr>
<tr>
<td>G1</td>
<td>并发</td>
<td>both</td>
<td>标记-整理+复制算法</td>
<td>响应速度</td>
<td>面向服务端应用，将来替换CMS</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
<li><p>JDK默认的垃圾回收器?</p>
<ul>
<li>JDK1.7: Parallel Scavenge（新生代）+Parallel Old（老年代）</li>
<li>JDK1.8: Parallel Scavenge（新生代）+Parallel Old（老年代）</li>
<li>JDK1.9: G1</li>
<li>-XX:+PrintCommandLineFlagsjvm 看默认设置收集器类型</li>
<li>-XX:+PrintGCDetails 通过打印的GC日志的新生代、老年代名称判断</li>
</ul>
</li>
<li><p>G1 和 CMS 的区别？</p>
<ul>
<li>CMS ：并发标记清除。他的主要步骤有：初始收集，并发标记，重新标记，并发清除（删除）、重置。</li>
<li>G1：主要步骤：初始标记，并发标记，重新标记，复制清除（整理）</li>
<li>CMS 的缺点是对 CPU 的要求比较高。G1是将内存化成了多块，所有对内存的大小有很大的要求。</li>
<li>CMS是清除，所以会存在很多的内存碎片。G1是整理，所以碎片空间较小。</li>
<li>G1 和 CMS 都是响应优先，他们的目的都是尽量控制 STW 时间。</li>
<li>G1 和 CMS 的 Full GC 都是单线程 mark sweep compact 算法，直到 JDK10 才优化为并行的。</li>
</ul>
</li>
<li><p>CMS 算法回收过程中 JVM 是否需要暂停？</p>
<ul>
<li>会有短暂的停顿</li>
</ul>
</li>
<li><p>如何使用指定的垃圾收集器</p>
<table>
<thead>
<tr>
<th>配置</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>-XX:+UserSerialGC</td>
<td>串行垃圾收集器</td>
</tr>
<tr>
<td>-XX:+UserParrallelGC</td>
<td>并行垃圾收集器</td>
</tr>
<tr>
<td>-XX:+UseConcMarkSweepGC</td>
<td>并发标记扫描垃圾回收器</td>
</tr>
<tr>
<td>-XX:ParallelCMSThreads</td>
<td>并发标记扫描垃圾回收器 =为使用的线程数量</td>
</tr>
<tr>
<td>-XX:+UseG1GC</td>
<td>G1垃圾回收器</td>
</tr>
</tbody></table>
</li>
<li><p>对象分配规则是什么？</p>
<ul>
<li><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15847831931490.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10" alt="-w655"></p>
</li>
<li><p>对象优先分配在 Eden 区。</p>
<ul>
<li>如果 Eden 区无法分配，那么尝试把活着的对象放到 Survivor0 中去（Minor GC）<ul>
<li>如果 Survivor0 可以放入，那么放入之后清除 Eden 区。</li>
<li>如果 Survivor0 不可以放入，那么尝试把 Eden 和 Survivor0 的存活对象放到 Survivor1 中。<ul>
<li>如果 Survivor1 可以放入，那么放入 Survivor1 之后清除 Eden 和 Survivor0 ，之后再把 Survivor1 中的对象复制到 Survivor0 中，保持 Survivor1 一直为空。</li>
<li>如果 Survivor1 不可以放入，那么直接把它们放入到老年代中，并清除 Eden 和 Survivor0 ，这个过程也称为分配担保。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。</p>
<ul>
<li>这样做的目的是，避免在 Eden 区和两个 Survivor 区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。</li>
</ul>
</li>
<li><p>长期存活的对象进入老年代。</p>
<ul>
<li>虚拟机为每个对象定义了一个年龄计数器，如果对象经过了 1 次 Minor GC 那么对象会进入 Survivor 区，之后每经过一次 Minor GC 那么对象的年龄加 1 ，知道达到阀值对象进入老年区。</li>
</ul>
</li>
<li><p>动态判断对象的年龄。</p>
<ul>
<li>为了更好的适用不同程序的内存情况，虚拟机并不是永远要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代。</li>
<li>如果 Survivor 区中相同年龄的所有对象大小的总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代。</li>
</ul>
</li>
<li><p>空间分配担保。</p>
<ul>
<li>每次进行 Minor GC 时，JVM 会计算 Survivor 区移至老年区的对象的平均大小，如果这个值大于老年区的剩余值大小则进行一次 Full GC ，如果小于检查 HandlePromotionFailure 设置，如果 true 则只进行 or GC ，如果 false 则进行 Full GC 。</li>
</ul>
</li>
</ul>
</li>
<li><p>为什么新生代内存需要有两个 Survivor 区？</p>
<ul>
<li>解决了碎片化</li>
<li>减少被送到老年代的对象，进而减少Full GC的发生，Survivor的预筛选保证，只有经历16次Minor GC还能在新生代中存活的对象，才会被送到老年代。</li>
</ul>
</li>
<li><p>什么是新生代 GC 和老年代 GC？</p>
<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15847835594680.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10" alt="-w435"></li>
<li>默认新生代(Young)与老年代(Old)的比例的值为 1:2 (该值可以通过参数 –XX:NewRatio 来指定)。</li>
<li>默认的 Eden:from:to=8:1:1 (可以通过参数 –XX:SurvivorRatio 来设定)。</li>
<li>新生代GC（MinorGC/YoungGC）：指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生夕灭的特性，所以 MinorGC 非常频繁，一般回收速度也比较快。</li>
<li>老年代GC（MajorGC/FullGC）：指发生在老年代的 GC，出现了 MajorGC，经常会伴随至少一次的 MinorGC（但非绝对的，在 Parallel Scavenge 收集器的收集策略里就有直接进行 MajorGC 的策略选择过程）。MajorGC 的速度一般会比 MinorGC 慢 10 倍以上。</li>
</ul>
</li>
<li><p>什么情况下会出现 Young GC？</p>
<ul>
<li>对象优先在新生代 Eden 区中分配，如果 Eden 区没有足够的空间时，就会触发一次 Young GC 。</li>
</ul>
</li>
<li><p>什么情况下回出现 Full GC？</p>
<ul>
<li>Full GC 的触发条件有多个，FULL GC 的时候会 STOP THE WORD 。<ul>
<li>在执行 Young GC 之前，JVM 会进行空间分配担保——如果老年代的连续空间小于新生代对象的总大小（或历次晋升的平均大小），则触发一次 Full GC 。</li>
<li>大对象直接进入老年代，从年轻代晋升上来的老对象，尝试在老年代分配内存时，但是老年代内存空间不够。</li>
<li>显式调用 <code>System.gc()</code> 方法时。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="虚拟机性能监控与故障处理工具"><a href="#虚拟机性能监控与故障处理工具" class="headerlink" title="虚拟机性能监控与故障处理工具"></a>虚拟机性能监控与故障处理工具</h2><ol>
<li><p>JDK 的命令行工具有哪些可以监控虚拟机？</p>
<ul>
<li>jps ：虚拟机进程状况工具<ul>
<li>JVM Process Status Tool ，显示系统内所有的HotSpot虚拟机进程。</li>
</ul>
</li>
<li>jstat ：虚拟机统计信息监控工具<ul>
<li>JVM statistics Monitoring ，是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。</li>
<li><code>jstat -gccause PID 1000</code></li>
</ul>
</li>
<li>jinfo ：Java 配置信息工具<ul>
<li>JVM Configuration info ，这个命令作用是实时查看和调整虚拟机运行参数。</li>
</ul>
</li>
</ul>
</li>
<li><p>JDK 的可视化工具有哪些可以监控虚拟机？</p>
<ul>
<li>JConsole对 JVM 中内存，线程和类等的监控。</li>
<li>VisualVM 可以分析内存快照、线程快照、监控内存变化、GC变化等。</li>
<li>JProfile</li>
<li>GC日志分析工具</li>
</ul>
</li>
<li><p>怎么获取 Java 程序使用的内存？</p>
<ul>
<li>可以通过 java.lang.Runtime 类中与内存相关方法来获取剩余的内存，总内存及最大堆内存。通过这些方法你也可以获取到堆使用的百分比及堆内存的剩余空间。<ul>
<li>Runtime.freeMemory() 方法，返回剩余空间的字节数。</li>
<li>Runtime.totalMemory() 方法，总内存的字节数。</li>
<li>Runtime.maxMemory() 方法，返回最大内存的字节数。</li>
</ul>
</li>
</ul>
</li>
<li><p>常见 GC 的优化配置？</p>
<table>
<thead>
<tr>
<th>配置</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>-Xms</td>
<td>初始化堆内存大小</td>
</tr>
<tr>
<td>-Xmx</td>
<td>堆内存最大值</td>
</tr>
<tr>
<td>-Xmn</td>
<td>新生代大小</td>
</tr>
<tr>
<td>-XX:PermSize</td>
<td>初始化永久代大小</td>
</tr>
<tr>
<td>-XX:MaxPermSize</td>
<td>永久代最大容量</td>
</tr>
<tr>
<td>-XX:SurvivorRatio</td>
<td>设置年轻代中 Eden 区与 Survivor 区的比值</td>
</tr>
<tr>
<td>-XX:Xmn</td>
<td>设置年轻代大小</td>
</tr>
</tbody></table>
</li>
<li><p>如何排查线程 Full GC 频繁的问题</p>
<ul>
<li>System.gc()方法的调用</li>
<li>老年代代空间不足</li>
<li>永生区空间不足</li>
<li>统计得到的Minor GC晋升到旧生代的平均大小大于老年代的剩余空间</li>
<li>堆中分配很大的对象</li>
</ul>
</li>
<li><p>类加载器是有了解吗？</p>
<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15847900544255.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ul>
</li>
<li><p>什么是双亲委派模型（Parent Delegation Model）？</p>
<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15847901946443.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>类加载器 ClassLoader 是具有层次结构的，也就是父子关系</li>
<li>Bootstrap ClassLoader ：根类加载器，负责加载 Java 的核心类，它不是 java.lang.ClassLoader 的子类，而是由 JVM 自身实现。</li>
<li>Extension ClassLoader ：扩展类加载器</li>
<li>Application ClassLoader ：系统(应用)类加载器</li>
<li>该模型要求除了顶层的 Bootstrap 启动类加载器外，其余的类加载器都应当有自己的父类加载器。子类加载器和父类加载器不是以继承（Inheritance）的关系来实现，而是通过组合（Composition）关系来复用父加载器的代码</li>
</ul>
</li>
<li><p>Java 虚拟机是如何判定两个 Java 类是相同的？</p>
<ul>
<li>Java 虚拟机不仅要看类的全名是否相同，还要看加载此类的类加载器是否一样。只有两者都相同的情况，才认为两个类是相同的。即便是同样的字节代码，被不同的类加载器加载之后所得到的类，也是不同的。</li>
</ul>
</li>
<li><p>双亲委派模型的工作过程？</p>
<ul>
<li>当前 ClassLoader 首先从自己已经加载的类中，查询是否此类已经加载，如果已经加载则直接返回原来已经加载的类。</li>
<li>当前 ClassLoader 的缓存中没有找到被加载的类的时候<ul>
<li>委托父类加载器去加载，父类加载器采用同样的策略，首先查看自己的缓存，然后委托父类的父类去加载，一直到 bootstrap ClassLoader。</li>
<li>当所有的父类加载器都没有加载的时候，再由当前的类加载器加载，并将其放入它自己的缓存中，以便下次有加载请求的时候直接返回。</li>
</ul>
</li>
</ul>
</li>
<li><p>为什么优先使用父 ClassLoader 加载类？</p>
<ul>
<li>共享功能：可以避免重复加载，当父亲已经加载了该类的时候，子类不需要再次加载，一些 Framework 层级的类一旦被顶层的 ClassLoader 加载过就缓存在内存里面，以后任何地方用到都不需要重新加载。</li>
<li>隔离功能：主要是为了安全性，避免用户自己编写的类动态替换 Java 的一些核心类，比如 String ，同时也避免了重复加载，因为 JVM 中区分不同类，不仅仅是根据类名，相同的 class 文件被不同的 ClassLoader 加载就是不同的两个类，如果相互转型的话会抛 java.lang.ClassCaseException 。  </li>
</ul>
</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Java/" rel="tag">Java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/interview/" rel="tag">interview</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-设计模式"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"
    >设计模式</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" class="article-date">
  <time datetime="2021-11-07T02:45:29.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Java/">Java</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="设计模式-TODO"><a href="#设计模式-TODO" class="headerlink" title="设计模式(TODO)"></a>设计模式(TODO)</h1><h3 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h3><ol>
<li>饿汉 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton_Hunger</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton_Hunger SINGLETON_HUNGER = <span class="keyword">new</span> Singleton_Hunger();</span><br><span class="line">    <span class="comment">//限制产生多个对象</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton_Hunger</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//通过该方法获得实例对象</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton_Hunger <span class="title">getSingletonHunger</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> SINGLETON_HUNGER;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//类中其他方法，尽量是static</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">doSomething</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>懒汉 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton_Lazy</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 静态实例变量加上volatile</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> Singleton_Lazy instance;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 私有化构造函数</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton_Lazy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 双重检查锁</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton_Lazy <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">synchronized</span>(Singleton_Lazy.class)&#123;</span><br><span class="line">                <span class="keyword">if</span>(instance == <span class="keyword">null</span>)&#123;</span><br><span class="line">                    instance = <span class="keyword">new</span> Singleton_Lazy();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>静态内部类(懒汉) <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 利用静态内部类特性实现外部类的单例</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SingleTon</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 利用静态内部类特性实现外部类的单例</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SingleTonBuilder</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> SingleTon singleTon = <span class="keyword">new</span> SingleTon();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 私有化构造函数</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">SingleTon</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SingleTon <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> SingleTonBuilder.singleTon;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SingleTon instance = getInstance();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>枚举实现 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 利用静态内部类特性实现外部类的单例</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">SingleTon</span> </span>&#123;</span><br><span class="line">    ONE , TWO</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="工厂模式"><a href="#工厂模式" class="headerlink" title="工厂模式"></a>工厂模式</h2><ul>
<li><p>定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行。</p>
</li>
<li><p>主要解决：主要解决接口选择的问题。</p>
</li>
<li><p>实现</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义接口</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Shape</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">draw</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 实现接口</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Rectangle</span> <span class="keyword">implements</span> <span class="title">Shape</span> </span>&#123;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">draw</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;Inside Rectangle::draw() method.&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Square</span> <span class="keyword">implements</span> <span class="title">Shape</span> </span>&#123;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">draw</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;Inside Square::draw() method.&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Circle</span> <span class="keyword">implements</span> <span class="title">Shape</span> </span>&#123;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">draw</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;Inside Circle::draw() method.&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 定义工厂</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShapeFactory</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> Shape <span class="title">getShape</span><span class="params">(String shapeType)</span></span>&#123;</span><br><span class="line">      <span class="keyword">if</span>(shapeType == <span class="keyword">null</span>)&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">      &#125;        </span><br><span class="line">      <span class="keyword">if</span>(shapeType.equalsIgnoreCase(<span class="string">&quot;CIRCLE&quot;</span>))&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">new</span> Circle();</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span>(shapeType.equalsIgnoreCase(<span class="string">&quot;RECTANGLE&quot;</span>))&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">new</span> Rectangle();</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span>(shapeType.equalsIgnoreCase(<span class="string">&quot;SQUARE&quot;</span>))&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">new</span> Square();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="抽象工厂模式"><a href="#抽象工厂模式" class="headerlink" title="抽象工厂模式"></a>抽象工厂模式</h2><h2 id="建造者模式"><a href="#建造者模式" class="headerlink" title="建造者模式"></a>建造者模式</h2><h2 id="原型模式"><a href="#原型模式" class="headerlink" title="原型模式"></a>原型模式</h2><h2 id="适配器模式"><a href="#适配器模式" class="headerlink" title="适配器模式"></a>适配器模式</h2><h2 id="桥接模式"><a href="#桥接模式" class="headerlink" title="桥接模式"></a>桥接模式</h2><h2 id="过滤器模式"><a href="#过滤器模式" class="headerlink" title="过滤器模式"></a>过滤器模式</h2><h2 id="组合模式"><a href="#组合模式" class="headerlink" title="组合模式"></a>组合模式</h2><h2 id="装饰器模式"><a href="#装饰器模式" class="headerlink" title="装饰器模式"></a>装饰器模式</h2><h2 id="外观模式"><a href="#外观模式" class="headerlink" title="外观模式"></a>外观模式</h2><h2 id="享元模式"><a href="#享元模式" class="headerlink" title="享元模式"></a>享元模式</h2><h2 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h2><h2 id="责任链模式"><a href="#责任链模式" class="headerlink" title="责任链模式"></a>责任链模式</h2><h2 id="命令模式"><a href="#命令模式" class="headerlink" title="命令模式"></a>命令模式</h2><h2 id="解释器模式"><a href="#解释器模式" class="headerlink" title="解释器模式"></a>解释器模式</h2><h2 id="迭代器模式"><a href="#迭代器模式" class="headerlink" title="迭代器模式"></a>迭代器模式</h2><h2 id="中介者模式"><a href="#中介者模式" class="headerlink" title="中介者模式"></a>中介者模式</h2><h2 id="备忘录模式"><a href="#备忘录模式" class="headerlink" title="备忘录模式"></a>备忘录模式</h2><h2 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a>观察者模式</h2><h2 id="状态模式"><a href="#状态模式" class="headerlink" title="状态模式"></a>状态模式</h2><h2 id="空对象模式"><a href="#空对象模式" class="headerlink" title="空对象模式"></a>空对象模式</h2><h2 id="策略模式"><a href="#策略模式" class="headerlink" title="策略模式"></a>策略模式</h2><h2 id="模板模式"><a href="#模板模式" class="headerlink" title="模板模式"></a>模板模式</h2><h2 id="访问者模式"><a href="#访问者模式" class="headerlink" title="访问者模式"></a>访问者模式</h2><h2 id="MVC-模式"><a href="#MVC-模式" class="headerlink" title="MVC 模式"></a>MVC 模式</h2><h2 id="业务代表模式"><a href="#业务代表模式" class="headerlink" title="业务代表模式"></a>业务代表模式</h2><h2 id="组合实体模式"><a href="#组合实体模式" class="headerlink" title="组合实体模式"></a>组合实体模式</h2><h2 id="数据访问对象模式"><a href="#数据访问对象模式" class="headerlink" title="数据访问对象模式"></a>数据访问对象模式</h2><h2 id="前端控制器模式"><a href="#前端控制器模式" class="headerlink" title="前端控制器模式"></a>前端控制器模式</h2><h2 id="拦截过滤器模式"><a href="#拦截过滤器模式" class="headerlink" title="拦截过滤器模式"></a>拦截过滤器模式</h2><h2 id="服务定位器模式"><a href="#服务定位器模式" class="headerlink" title="服务定位器模式"></a>服务定位器模式</h2><h2 id="传输对象模式"><a href="#传输对象模式" class="headerlink" title="传输对象模式"></a>传输对象模式</h2> 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Java/" rel="tag">Java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/interview/" rel="tag">interview</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Redis面试题"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/Redis%E9%9D%A2%E8%AF%95%E9%A2%98/"
    >Redis面试题</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/Redis%E9%9D%A2%E8%AF%95%E9%A2%98/" class="article-date">
  <time datetime="2021-11-07T02:44:00.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Redis/">Redis</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><ol>
<li>什么是 Redis ？<ul>
<li>Redis是一个基于内存的高性能 Key-Value 数据库</li>
</ul>
</li>
<li>Redis 有什么优点？<ul>
<li>速度快:数据存在内存中，类似于 HashMap ，HashMap 的优势就是查找和操作的时间复杂度都是O (1) 每秒可以处理超过 10 万次读写操作，是已知性能最快的 Key-Value 数据库。</li>
<li>支持丰富数据类型:String ，List，Set，Sorted Set，Hash 五种基础的数据结构。</li>
<li>丰富的特性: 订阅发布 Pub / Sub 功能,Key 过期策略,事务,支持多个 DB,计数</li>
<li>持久化存储: Redis 提供 RDB 和 AOF 两种数据的持久化存储方案，解决内存数据库最担心的万一 Redis 挂掉，数据会消失掉。</li>
<li>高可用:内置 Redis Sentinel ，提供高可用方案，实现主从故障自动转移;内置 Redis Cluster ，提供集群方案，实现基于槽的分片方案，从而支持更大的 Redis 规模。</li>
</ul>
</li>
<li>Redis 有什么缺点？<ul>
<li>由于 Redis 是内存数据库，所以，单台机器，存储的数据量，跟机器本身的内存大小。虽然 Redis 本身有 Key 过期策略，但是还是需要提前预估和节约内存。如果内存增长过快，需要定期删除数据。(可使用 Redis Cluster、Codis 等方案，对 Redis 进行分区，从单机 Redis 变成集群 Redis 。)</li>
<li>如果进行完整重同步，由于需要生成 RDB 文件，并进行传输，会占用主机的 CPU ，并会消耗现网的带宽。不过 Redis2.8 版本，已经有部分重同步的功能，但是还是有可能有完整重同步的。比如，新上线的备机。</li>
<li>修改配置文件，进行重启，将硬盘中的数据加载进内存，时间比较久。在这个过程中，Redis 不能提供服务。</li>
</ul>
</li>
<li>请说说 Redis 的线程模型？<ul>
<li>Redis 是非阻塞 IO ，多路复用。</li>
</ul>
</li>
<li>为什么 Redis 单线程模型也能效率这么高？<ul>
<li> C 语言实现。</li>
<li> 纯内存操作。</li>
<li> 基于非阻塞的 IO 多路复用机制。</li>
<li> 单线程，避免了多线程的频繁上下文切换问题。</li>
</ul>
</li>
<li>Redis 是单线程的，如何提高多核 CPU 的利用率？<ul>
<li>可以在同一个服务器部署多个 Redis 的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个 CPU ，你可以考虑一下分区。</li>
</ul>
</li>
<li>Redis 有几种持久化方式？<ul>
<li>【全量】RDB 持久化<ul>
<li>在指定的时间间隔内将内存中的数据集快照写入磁盘。实际操作过程是，fork 一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储</li>
<li>RDB 优点：<ul>
<li>灵活设置备份频率和周期。你可能打算每个小时归档一次最近 24 小时的数据，同时还要每天归档一次最近 30 天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复</li>
<li>非常适合冷备份，对于灾难恢复而言，RDB 是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。推荐，可以将这种完整的数据文件发送到一些远程的安全存储上去，</li>
<li>性能最大化。对于 Redis 的服务进程而言，在开始持久化时，它唯一需要做的只是 fork 出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行 IO 操作了。也就是说，RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis 保持高性能。</li>
<li>恢复更快。相比于 AOF 机制，RDB 的恢复速度更更快，更适合恢复数据，特别是在数据集非常大的情况</li>
</ul>
</li>
<li>RDB 缺点：<ul>
<li>如果想保证数据的高可用性，即最大限度的避免数据丢失，那么 RDB 将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。</li>
<li>由于 RDB 是通过 fork 子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是 1 秒钟。</li>
</ul>
</li>
</ul>
</li>
<li>【增量】AOF持久化<ul>
<li>以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。</li>
<li>AOF 优点<ul>
<li>该机制可以带来更高的数据安全性，即数据持久性。Redis 中提供了 3 种同步策略，即每秒同步、每修改(执行一个命令)同步和不同步。</li>
<li>由于该机制对日志文件的写入操作采用的是 append 模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。（redis-check-aof）</li>
<li>如果 AOF 日志过大，Redis 可以自动启用 rewrite 机制。即使出现后台重写操作，也不会影响客户端的读写。因为在 rewrite log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。</li>
</ul>
</li>
<li>AOF 缺点<ul>
<li>对于相同数量的数据集而言，AOF 文件通常要大于 RDB 文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</li>
<li>根据同步策略的不同，AOF 在运行效率上往往会慢于 RDB 。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和 RDB 一样高效。</li>
<li>以前 AOF 发生过 bug ，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志/merge/回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug 。不过 AOF 就是为了避免 rewrite 过程导致的 bug ，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。</li>
</ul>
</li>
</ul>
</li>
<li>如何选择：<ul>
<li>不要仅仅使用 RDB，因为那样会导致你丢失很多数据。</li>
<li>也不要仅仅使用 AOF，因为那样有两个问题，第一，你通过 AOF 做冷备，没有 RDB 做冷备，来的恢复速度更快; 第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug 。</li>
<li>Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。</li>
</ul>
</li>
<li>AOF rewrite 机制，和 RDB 一样，也需要 fork 出一次子进程，如果 Redis 内存比较大，可能会因为 fork 阻塞下主进程。</li>
</ul>
</li>
<li>Redis 有哪几种数据“淘汰”策略？<ul>
<li>Redis 内存数据集大小上升到一定大小的时候，就会进行数据淘汰策略。Redis 提供了 6 种数据淘汰策略：<ul>
<li>volatile-lru</li>
<li>volatile-ttl</li>
<li>volatile-random</li>
<li>allkeys-lru</li>
<li>allkeys-random</li>
<li>【默认策略】no-enviction</li>
</ul>
</li>
</ul>
</li>
<li>Redis LRU 算法<ul>
<li> Redis 的 LRU 算法，并不是一个严格的 LRU 实现。这意味着 Redis 不能选择最佳候选键来回收，也就是最久未被访问的那些键。相反，Redis 会尝试执行一个近似的 LRU 算法，通过采样一小部分键，然后在采样键中回收最适合(拥有最久未被访问时间)的那个。</li>
<li> Redis 没有使用真正实现严格的 LRU 算是的原因是，因为消耗更多的内存。然而对于使用 Redis 的应用来说，使用近似的 LRU 算法，事实上是等价的。</li>
</ul>
</li>
<li>MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据？<ul>
<li>选择 volatile-lru 或 allkeys-lru 这两个基于 LRU 算法的淘汰策略。</li>
</ul>
</li>
<li>Redis 回收进程如何工作的？<ul>
<li>一个客户端运行了新的写命令，添加了新的数据。</li>
<li>Redis 检查内存使用情况，如果大于 maxmemory 的限制, 则根据设定好的策略进行回收。</li>
<li>Redis 执行新命令。</li>
<li>不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下（跌宕起伏）。</li>
</ul>
</li>
<li>如果有大量的 key 需要设置同一时间过期，一般需要注意什么？<ul>
<li>如果大量的 key 过期时间设置的过于集中，到过期的那个时间点，Redis可能会出现短暂的卡顿现象。</li>
<li>调大 hz 参数，每次过期的 key 更多，从而最终达到避免一次过期过多。<ul>
<li> hz 参数代表了一秒钟内，后台任务期望被调用的次数,hz 调大将会提高 Redis 主动淘汰的频率</li>
</ul>
</li>
<li>一般需要在时间上加一个随机值，使得过期时间分散一些。</li>
</ul>
</li>
<li>Redis 有哪些数据结构？<ul>
<li>初级<ul>
<li>字符串 String</li>
<li>字典Hash</li>
<li>列表List</li>
<li>集合Set</li>
<li>有序集合 SortedSet</li>
</ul>
</li>
<li>中级<ul>
<li>HyperLogLog</li>
<li>Geo</li>
<li>Bitmap</li>
</ul>
</li>
<li>高级<ul>
<li>BloomFilter</li>
<li>RedisSearch</li>
<li>Redis-ML</li>
<li>JSON</li>
</ul>
</li>
</ul>
</li>
<li>聊聊 Redis 使用场景/为什么使用redis<ul>
<li>数据缓存</li>
<li>会话缓存</li>
<li>时效性数据</li>
<li>访问频率</li>
<li>计数器</li>
<li>社交列表</li>
<li>记录用户判定信息</li>
<li>交集、并集和差集</li>
<li>热门列表与排行榜</li>
<li>最新动态</li>
<li>消息队列</li>
<li>分布式锁</li>
</ul>
</li>
<li>Redis 支持的 Java 客户端都有哪些？<ol>
<li>Redisson：封装好</li>
<li>Jedis：命令全</li>
<li>Lettuce：是一个可伸缩线程安全的 Redis 客户端。多个线程可以共享同一个 RedisConnection 。它利用优秀 Netty NIO 框架来高效地管理多个连接。</li>
</ol>
</li>
<li>如何使用 Redis 实现分布式锁？<ul>
<li>正确的获得锁：set 指令附带 nx 参数，保证有且只有一个进程获得到。</li>
<li>正确的释放锁：使用 Lua 脚本，比对锁持有的是不是自己。如果是，则进行删除来释放。</li>
<li>超时的自动释放锁：set 指令附带 expire 参数，通过过期机制来实现超时释放。</li>
<li>未获得到锁的等待机制：sleep 或者基于 Redis 的订阅 Pub/Sub 机制。一些业务场景，可能需要支持获得不到锁，直接返回 false ，不等待。</li>
<li>锁超时的处理：告警 + 后台线程自动续锁的超时时间。通过这样的机制，保证有且仅有一个线程，正在持有锁。</li>
<li>set 指令：<code>SET key value [EX seconds] [PX milliseconds] [NX|XX]</code></li>
<li>Redlock: Redisson 实现，所有master超过半数</li>
</ul>
</li>
<li>Redis 分布式锁 对比 Zookeeper 分布式锁<ul>
<li>从可靠性上来说，Zookeeper 分布式锁好于 Redis 分布式锁。</li>
<li>从性能上来说，Redis 分布式锁好于 Zookeeper 分布式锁。</li>
</ul>
</li>
<li>如何使用 Redis 实现消息队列？<ul>
<li>使用 list 结构作为队列，rpush 生产消息，lpop 消费消息。当 lpop 没有消息的时候，要适当 sleep 一会再重试。</li>
<li>如果对方追问可不可以不用 sleep 呢？list 还有个指令叫 blpop ，在没有消息的时候，它会阻塞住直到消息到来。</li>
<li>如果对方追问能不能生产一次消费多次呢？使用 pub / sub 主题订阅者模式，可以实现 1:N 的消息队列。</li>
<li>如果对方追问 pub / sub 有什么缺点？在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如 rabbitmq 等。</li>
<li>果对方追问 redis 如何实现延时队列？使用 sortedset ，拿时间戳作为 score ，消息内容作为 key 调用 zadd 来生产消息，消费者用 zrangebyscore 指令获取 N 秒之前的数据轮询进行处理。</li>
</ul>
</li>
<li>Redis 如何做大量数据插入？<ul>
<li>Redis-cli 支持一种新的被称之为 pipe mode 的新模式用于执行大量数据插入工作。</li>
</ul>
</li>
<li>什么是 Redis 事务？<ul>
<li>MULTI / EXEC / DISCARD / WATCH 这四个命令是我们实现事务的基石<ul>
<li>在事务中的所有命令都将会被串行化的顺序执行，事务执行期间，Redis 不会再为其它客户端的请求提供任何服务，从而保证了事物中的所有命令被原子的执行。</li>
<li>和关系型数据库中的事务相比，在 Redis 事务中如果有某一条命令执行失败，其后的命令仍然会被继续执行。</li>
<li>我们可以通过 MULTI 命令开启一个事务，有关系型数据库开发经验的人可以将其理解为 “BEGIN TRANSACTION” 语句。在该语句之后执行的命令，都将被视为事务之内的操作，最后我们可以通过执行 EXEC / DISCARD 命令来提交 / 回滚该事务内的所有操作。这两个 Redis 命令，可被视为等同于关系型数据库中的 COMMIT / ROLLBACK 语句。(开启事务后，所有语句，发送给 Redis Server ，都会暂存在 Server 中。)</li>
<li>在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。然而如果网络中断事件是发生在客户端执行 EXEC 命令之后，那么该事务中的所有命令都会被服务器执行。</li>
</ul>
</li>
</ul>
</li>
<li>如何实现 Redis CAS 操作？<ul>
<li>在 Redis 的事务中，WATCH 命令可用于提供 CAS(check-and-set) 功能。</li>
<li>假设我们通过 WATCH 命令在事务执行之前监控了多个 keys ，倘若在 WATCH 之后有任何 Key 的值发生了变化，EXEC 命令执行的事务都将被放弃，同时返回 nil 应答以通知调用者事务执行失败</li>
</ul>
</li>
<li>Redis 集群都有哪些方案？<ul>
<li>Redis Sentinel<ul>
<li>体量较小时，选择 Redis Sentinel ，单主 Redis 足以支撑业务。</li>
</ul>
</li>
<li>Redis Cluster<ul>
<li>体量较大时，选择 Redis Cluster ，通过分片，使用更多内存。</li>
</ul>
</li>
<li>多大体量需要使用 Redis Cluster 呢<ol>
<li>一次 RDB 时间随着内存越大，会变大越来越久。同时，一次 fork 的时间也会变久。还有，重启通过 RDB 文件，或者 AOF 日志，恢复时间都会变长。</li>
<li>体量大之后，读写的 QPS 势必比体量小的时候打的多，那么使用 Redis Cluster 相比 Redis Sentinel ，可以分散读写压力到不同的集群中。</li>
</ol>
</li>
</ul>
</li>
<li>什么是 Redis 主从同步？<ul>
<li>Redis 的主从同步(replication)机制，允许 Slave 从 Master 那里，通过网络传输拷贝到完整的数据备份，从而达到主从机制。</li>
<li>主数据库可以进行读写操作，当发生写操作的时候自动将数据同步到从数据库，而从数据库一般是只读的，并接收主数据库同步过来的数据。</li>
<li>一个主数据库可以有多个从数据库，而一个从数据库只能有一个主数据库。</li>
<li>第一次同步时，主节点做一次 bgsave 操作，并同时将后续修改操作记录到内存 buffer ，待完成后将 RDB 文件全量同步到复制节点，复制节点接受完成后将 RDB 镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。</li>
</ul>
</li>
<li>Redis Cluster 的主从复制模型是怎样的？<ul>
<li>为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型，每个节点都会有 N-1 个复制节点。</li>
<li>所以，Redis Cluster 可以说是 Redis Sentinel 带分片的加强版。也可以说：<ul>
<li>Redis Sentinel 着眼于高可用，在 master 宕机时会自动将 slave 提升为 master ，继续提供服务。</li>
<li>Redis Cluster 着眼于扩展性，在单个 Redis 内存不足时，使用 Cluster 进行分片存储。</li>
</ul>
</li>
</ul>
</li>
<li>Redis Cluster 方案什么情况下会导致整个集群不可用？<ul>
<li>有 A，B，C 三个节点的集群，在没有复制模型的情况下，如果节点 B 宕机了，那么整个集群就会以为缺少 5501-11000 这个范围的槽而不可用。当然，这种情况也可以配置 cluster-require-full-coverage=no ，整个集群无需所有槽位覆盖。</li>
</ul>
</li>
<li>Redis Cluster 会有写操作丢失吗？为什么？<ul>
<li>Redis 并不能保证数据的强一致性，而是【异步复制】，这意味这在实际中集群在特定的条件下可能会丢失写操作。</li>
<li>无论对于 Redis Sentinel 还是 Redis Cluster 方案，都是通过主从复制，所以在数据的复制方面，都存在相同的情况。</li>
</ul>
</li>
<li>Redis 集群如何选择数据库？<ul>
<li>Redis 集群目前无法做数据库选择，默认在 0 数据库。</li>
</ul>
</li>
<li>请说说生产环境中的 Redis 是怎么部署的？<ul>
<li>Redis Cluster ，10 台机器，5 台机器部署了 Redis 主实例，另外 5 台机器部署了 Redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰 qps 可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求每秒。</li>
<li>机器是什么配置？32G 内存 + 8 核 CPU + 1T 磁盘，但是分配给 Redis 进程的是 10G 内存，一般线上生产环境，Redis 的内存尽量不要超过 10G，超过 10G 可能会有问题。那么，5 台机器对外提供读写，一共有 50G 内存。</li>
<li>因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，Redis 从实例会自动变成主实例继续提供读写服务。</li>
<li>你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb 。100 条数据是 1mb ，10 万条数据是 1G 。常驻内存的是 200 万条商品数据，占用内存是 20G ，仅仅不到总内存的 50% 。目前高峰期每秒就是 3500 左右的请求量。</li>
<li>公司体量大了之后，建议是一个业务线独占一个或多个 Redis Cluster 集群，实现好业务线与业务线之间的隔离。</li>
</ul>
</li>
<li>什么是 Redis 分区？<ul>
<li>分区是分割数据到多个Redis实例的处理过程，因此每个实例只保存key的一个子集。</li>
<li>分区的优势:通过利用多台计算机内存的和值，允许我们构造更大的数据库。通过多核和多台计算机，允许我们扩展计算能力；通过多台计算机和网络适配器，允许我们扩展网络带宽。</li>
<li>分区的不足:不支持涉及多个key的操作通</li>
<li>分区类型:范围分区 &amp;&amp; 哈希分区</li>
</ul>
</li>
<li>Redis 有哪些重要的健康指标？<ul>
<li>存活情况</li>
<li>连接数</li>
<li>阻塞客户端数量</li>
<li>使用内存峰值</li>
<li>内存碎片率</li>
<li>缓存命中率</li>
<li>OPS</li>
<li>持久化</li>
<li>失效KEY</li>
<li>慢日志</li>
</ul>
</li>
<li>一个 Redis 实例最多能存放多少的 keys？List、Set、Sorted Set 他们最多能存放多少元素？<ul>
<li>Redis 可以处理多达 2^32 的 keys ，并且在实际中进行了测试，每个实例至少存放了 2 亿 5 千万的 keys。</li>
<li>任何 list、set、和 sorted set 都可以放 2^32 </li>
</ul>
</li>
<li>假如 Redis 里面有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？<ul>
<li>keys 指令可以扫出指定模式的 key 列表。</li>
<li>对方接着追问：如果这个 Redis 正在给线上的业务提供服务，那使用 keys 指令会有什么问题？</li>
<li>这个时候你要回答 Redis 关键的一个特性：Redis 的单线程的。keys 指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 scan 指令，scan 指令可以无阻塞的提取出指定模式的 key 列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 keys 指令长。</li>
</ul>
</li>
<li>Redis 常见的性能问题都有哪些？如何解决？<ul>
<li>Master 最好不要做任何持久化工作，如 RDB 内存快照和 AOF 日志文件。</li>
<li></li>
</ul>
</li>
<li>Redis雪崩<ul>
<li><ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15849210200503.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ul>
</li>
<li>同一时间大量缓存失效，请求直接落到数据库，造成数据库崩溃</li>
<li>解决方式：<ul>
<li>失效期设置永不过期</li>
<li>失效期添加随机数</li>
<li>设置多层缓存，redis失效的情况下，使用内部缓存</li>
</ul>
</li>
</ul>
</li>
</ol>
<ul>
<li>缓存穿透，缓存击穿,雪崩的区别<ul>
<li>缓存穿透是指缓存和数据库中都没有的数据，比如id=-1导致数据库压力过大<ul>
<li>参数校验保证数据合法性</li>
<li>缓存假结果，添加失效期</li>
<li><ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15849213541298.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ul>
</li>
</ul>
</li>
<li>缓存击穿是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库<ul>
<li>设置热点数据永远不过期</li>
</ul>
</li>
</ul>
</li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Redis/" rel="tag">Redis</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/interview/" rel="tag">interview</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Dubbo面试题"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/Dubbo%E9%9D%A2%E8%AF%95%E9%A2%98/"
    >Dubbo面试题</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/Dubbo%E9%9D%A2%E8%AF%95%E9%A2%98/" class="article-date">
  <time datetime="2021-11-07T02:41:33.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Dubbo/">Dubbo</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Dubbo"><a href="#Dubbo" class="headerlink" title="Dubbo"></a>Dubbo</h1><ol>
<li><p>Dubbo 有几种配置方式？</p>
<ul>
<li>XML 配置</li>
<li>注解配置</li>
<li>Java API 配置</li>
<li>属性配置</li>
</ul>
</li>
<li><p>Dubbo 如何和 Spring Boot 进行集成？</p>
<ul>
<li>官方提供提供了集成库 dubbo-spring-boot</li>
</ul>
</li>
<li><p>Dubbo 框架的分层设计</p>
<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15850280657994.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>总体分成 Business、RPC、Remoting 三大层<ul>
<li>Service 业务层：业务代码的接口与实现。我们实际使用 Dubbo 的业务层级。接口层，给服务提供者和消费者来实现的。</li>
<li>RPC层：<ul>
<li>config 配置层：主要是对 Dubbo 进行各种配置的。</li>
<li>proxy 服务代理层：服务代理层，无论是 consumer 还是 provider，Dubbo 都会给你生成代理，代理之间进行网络通信。（ 对比Spring Cloud 体系，可以类比成 Feign 对于 consumer ，Spring MVC 对于 provider 。）</li>
<li>registry 注册中心层：服务注册层，负责服务的注册与发现。（对比 Spring Cloud 体系，可以类比成 Eureka Client ）</li>
<li>cluster 路由层：封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务。（对比Spring Cloud 体系，可以类比成 Ribbon ）</li>
<li>monitor 监控层：对 rpc 接口的调用次数和调用时间进行监控。</li>
</ul>
</li>
<li>Remoting：<ul>
<li>protocol 远程调用层：远程调用层，封装 rpc 调用。</li>
<li>exchange 信息交换层：信息交换层，封装请求响应模式，同步转异步。</li>
<li>transport 网络传输层：抽象 mina 和 netty 为统一接口。</li>
<li>serialize 数据序列化层：可复用的一些工具，扩展接口为 Serialization, ObjectInput, ObjectOutput</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Dubbo 调用流程</p>
<ul>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15850284072280.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15850285070885.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>Provider<ul>
<li>第 0 步，start 启动服务。</li>
<li>第 1 步，register 注册服务到注册中心。</li>
</ul>
</li>
<li>Consumer<ul>
<li>第 2 步，subscribe 向注册中心订阅服务。<ul>
<li>注意，只订阅使用到的服务。</li>
<li>再注意，首次会拉取订阅的服务列表，缓存在本地。</li>
<li>【异步】第 3 步，notify 当服务发生变化时，获取最新的服务列表，更新本地缓存。</li>
</ul>
</li>
</ul>
</li>
<li>invoke 调用<ul>
<li>Consumer 直接发起对 Provider 的调用，无需经过注册中心。而对多个 Provider 的负载均衡，Consumer 通过 cluster 组件实现。</li>
</ul>
</li>
<li>count 监控<ul>
<li>【异步】Consumer 和 Provider 都异步通知监控中心。</li>
</ul>
</li>
</ul>
</li>
<li><p>Dubbo 调用是同步的吗？</p>
<ul>
<li>默认情况下，调用是同步的方式。</li>
</ul>
</li>
<li><p>谈谈对 Dubbo 的异常处理机制？</p>
<ul>
<li>dubbo的异常处理类是com.alibaba.dubbo.rpc.filter.ExceptionFilter 类,源码这里就不贴了.归纳下对异常的处理分为下面几类:<ul>
<li>1)如果provider实现了GenericService接口,直接抛出</li>
<li>2)如果是checked异常，直接抛出</li>
<li>3)在方法签名上有声明，直接抛出</li>
<li>4)异常类和接口类在同一jar包里，直接抛出</li>
<li>5)是JDK自带的异常，直接抛出</li>
<li>6)是Dubbo本身的异常，直接抛出</li>
<li>7)否则，包装成RuntimeException抛给客户端（防止客户端反序列化失败.前面几种情况都能保证反序列化正常.）</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq315737546/article/details/53915067">dubbo异常处理</a></li>
</ul>
</li>
<li><p>Dubbo 如何做参数校验？</p>
<ul>
<li>参数校验功能，通过参数校验过滤器 ValidationFilter 来实现。</li>
<li>ValidationFilter 在 Dubbo Provider 和 Consumer 都可生效。<ul>
<li>如果我们将校验注解写在 Service 接口的方法上，那么 Consumer 在本地就会校验。如果校验不通过，直接抛出校验失败的异常，不会发起 Dubbo 调用。</li>
<li>如果我们将校验注解写在 Service 实现的方法上，那么 Consumer 在本地不会校验，而是由 Provider 校验。</li>
</ul>
</li>
</ul>
</li>
<li><p>Dubbo 可以对调用结果进行缓存吗?</p>
<ul>
<li>Dubbo 通过 CacheFilter 过滤器，提供结果缓存的功能，且既可以适用于 Consumer 也可以适用于 Provider 。</li>
<li>通过结果缓存，用于加速热门数据的访问速度，Dubbo 提供声明式缓存，以减少用户加缓存的工作量。</li>
<li>Dubbo 目前提供三种实现：<ul>
<li>lru ：基于最近最少使用原则删除多余缓存，保持最热的数据被缓存。</li>
<li>threadlocal ：当前线程缓存，比如一个页面渲染，用到很多 portal，每个 portal 都要去查用户信息，通过线程缓存，可以减少这种多余访问。</li>
<li>jcache ：与 JSR107 集成，可以桥接各种缓存实现。</li>
</ul>
</li>
</ul>
</li>
<li><p>注册中心挂了还可以通信吗？</p>
<ul>
<li>可以。对于正在运行的 Consumer 调用 Provider 是不需要经过注册中心，所以不受影响。并且，Consumer 进程中，内存已经缓存了 Provider 列表。</li>
<li>此时 Provider 如果下线呢？<ul>
<li>如果 Provider 是正常关闭，它会主动且直接对和其处于连接中的 Consumer 们，发送一条“我要关闭”了的消息。那么，Consumer 们就不会调用该 Provider ，而调用其它的 Provider 。</li>
<li>因为 Consumer 也会持久化 Provider 列表到本地文件。所以，此处如果 Consumer 重启，依然能够通过本地缓存的文件，获得到 Provider 列表。</li>
<li>一般情况下，注册中心是一个集群，如果一个节点挂了，Dubbo Consumer 和 Provider 将自动切换到集群的另外一个节点上。</li>
</ul>
</li>
</ul>
</li>
<li><p>Dubbo 在 Zookeeper 存储了哪些信息？</p>
<pre><code> - ![](https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15850292909765.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10)
</code></pre>
<ul>
<li>服务提供者启动时: 向 /dubbo/com.foo.BarService/providers 目录下写入自己的 URL 地址</li>
<li>服务消费者启动时: 订阅 /dubbo/com.foo.BarService/providers 目录下的提供者 URL 地址。并向 /dubbo/com.foo.BarService/consumers 目录下写入自己的 URL 地址（服务消费者启动后，不仅仅订阅了 “providers” 分类，也订阅了 “routes” “configurations” 分类。）</li>
<li>监控中心启动时: 订阅 /dubbo/com.foo.BarService 目录下的所有提供者和消费者 URL 地址。</li>
<li>Zookeeper 的节点层级，自上而下是：<ul>
<li> Root 层：根目录，可通过 &lt;dubbo:registry group=”dubbo” /&gt; 的 “group” 设置 Zookeeper 的根节点，缺省使用 “dubbo” 。</li>
<li> Service 层：服务接口全名。</li>
<li> Type 层：分类。目前除了我们在图中看到的 “providers”( 服务提供者列表 ) “consumers”( 服务消费者列表 ) 外，还有 “routes”( 路由规则列表 ) 和 “configurations”( 配置规则列表 )。</li>
<li> URL 层：URL ，根据不同 Type 目录，下面可以是服务提供者 URL 、服务消费者 URL 、路由规则 URL 、配置规则 URL 。</li>
<li> 实际上 URL 上带有 “category” 参数，已经能判断每个 URL 的分类，但是 Zookeeper 是基于节点目录订阅的，所以增加了 Type 层。</li>
</ul>
</li>
</ul>
</li>
<li><p>Dubbo Provider 如何实现优雅停机？</p>
<ul>
<li>Dubbo 是通过 JDK 的 ShutdownHook 来完成优雅停机的，所以如果用户使用 kill -9 PID 等强制关闭指令，是不会执行优雅停机的，只有通过 kill PID 时，才会执行。</li>
<li>因为大多数情况下，Dubbo 的声明周期是交给 Spring 进行管理，所以在最新的 Dubbo 版本中，增加了对 Spring 关闭事件的监听，从而关闭 Dubbo 服务</li>
<li>服务提供方的优雅停机过程<ul>
<li>首先，从注册中心中取消注册自己，从而使消费者不要再拉取到它。</li>
<li>然后，sleep 10 秒( 可配 )，等到服务消费，接收到注册中心通知到该服务提供者已经下线，加大了在不重试情况下优雅停机的成功率。</li>
<li>之后，广播 READONLY 事件给所有 Consumer 们，告诉它们不要在调用我了！！！如果此处注册中心挂掉的情况，依然能达到告诉 Consumer ，我要下线了的功能。</li>
<li>再之后，sleep 10 毫秒，保证 Consumer 们，尽可能接收到该消息。</li>
<li>再再之后，先标记为不接收新请求，新请求过来时直接报错，让客户端重试其它机器。</li>
<li>再再再之后，关闭心跳线程。</li>
<li>最后，检测线程池中的线程是否正在运行，如果有，等待所有线程执行完成，除非超时，则强制关闭。</li>
<li>最最后，关闭服务器。</li>
</ul>
</li>
<li>服务消费方的优雅停机过程<ul>
<li>停止时，不再发起新的调用请求，所有新的调用在客户端即报错。</li>
<li>然后，检测有没有请求的响应还没有返回，等待响应返回，除非超时，则强制关闭。</li>
</ul>
</li>
</ul>
</li>
<li><p>Dubbo Provider 异步关闭时，如何从注册中心下线？</p>
<ul>
<li>服务提供者，注册到 Zookeeper 上时，创建的是 EPHEMERAL 临时节点。所以在服务提供者异常关闭时，等待 Zookeeper 会话超时，那么该临时节点就会自动删除。</li>
</ul>
</li>
<li><p>Dubbo Consumer 只能调用从注册中心获取的 Provider 么？</p>
<ul>
<li>不是，Consumer 可以强制直连 Provider 。</li>
<li>在开发及测试环境下，经常需要绕过注册中心，只测试指定服务提供者，这时候可能需要点对点直连，点对点直连方式，将以服务接口为单位，忽略注册中心的提供者列表，A 接口配置点对点，不影响 B 接口从注册中心获取列表。</li>
<li>另外，直连 Dubbo Provider 时，如果要 Debug 调试 Dubbo Provider ，可以通过配置，禁用该 Provider 注册到注册中心。否则，会被其它 Consumer 调用到</li>
</ul>
</li>
<li><p>Dubbo 支持哪些通信协议？对应【protocol 远程调用层】。</p>
<ul>
<li>dubbo://</li>
<li>rest://</li>
<li>rmi://</li>
<li>webservice://</li>
<li>hessian://</li>
<li>thrift://</li>
<li>memcached://</li>
<li>redis://</li>
<li>http://</li>
</ul>
</li>
<li><p>什么是本地暴露和远程暴露，他们的区别？</p>
<ul>
<li>远程暴露:每次 Consumer 调用 Provider 都是跨进程，需要进行网络通信。</li>
<li>本地暴露:使用了 injvm:// 协议，是一个伪协议，它不开启端口，不发起远程调用，只在 JVM 内直接关联，但执行 Dubbo 的 Filter 链。</li>
</ul>
</li>
<li><p>Dubbo 使用什么通信框架？对应【transport 网络传输层】。</p>
<ul>
<li>Netty3</li>
<li>Netty4</li>
<li>Mina</li>
<li>Grizzly</li>
<li>在 Dubbo 的最新版本，默认使用 Netty4 的版本</li>
</ul>
</li>
<li><p>Dubbo 支持哪些序列化方式？对应【serialize 数据序列化层】。</p>
<ul>
<li>Dubbo 目前支付如下 7 种序列化方式：<ul>
<li>【重要】Hessian2 ：基于 Hessian 实现的序列化拓展。dubbo:// 协议的默认序列化方案。<ul>
<li>Hessian 除了是 Web 服务，也提供了其序列化实现，因此 Dubbo 基于它实现了序列化拓展。</li>
<li>另外，Dubbo 维护了自己的 hessian-lite ，对 Hessian 2 的 序列化 部分的精简、改进、BugFix 。</li>
</ul>
</li>
<li>Dubbo ：Dubbo 自己实现的序列化拓展。</li>
<li>Kryo ：基于 Kryo 实现的序列化拓展。</li>
<li>FST ：基于 FST 实现的序列化拓展。</li>
<li>JSON ：基于 Fastjson 实现的序列化拓展。</li>
<li>NativeJava ：基于 Java 原生的序列化拓展。</li>
<li>CompactedJava ：在 NativeJava 的基础上，实现了对 ClassDescriptor 的处理。</li>
</ul>
</li>
</ul>
</li>
<li><p>Dubbo 有哪些负载均衡策略？对应【cluster 路由层】的 LoadBalance 组件。</p>
<ul>
<li>Random LoadBalance <ul>
<li>随机，按权重设置随机概率。</li>
<li>在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。</li>
</ul>
</li>
<li>RoundRobin LoadBalance<ul>
<li>轮询，按公约后的权重设置轮询比率。</li>
<li>存在慢的提供者累积请求的问题，比如</li>
</ul>
</li>
<li>LeastActive LoadBalance<ul>
<li>最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。</li>
<li>使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。</li>
</ul>
</li>
<li>ConsistentHash LoadBalance<ul>
<li>一致性 Hash，相同参数的请求总是发到同一提供者。</li>
<li>当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。</li>
</ul>
</li>
</ul>
</li>
<li><p>Dubbo 有哪些集群容错策略？对应【cluster 路由层】的 Cluster 组件。</p>
<ul>
<li><p>Consumer 仅仅引用服务 ***-api.jar 包，那么可以获得到需要服务的 XXXService 接口。那么，通过动态创建对应调用 Dubbo 服务的实现类。简化代码如下：</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ProxyFactory.java</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * create proxy.</span></span><br><span class="line"><span class="comment"> * 创建 Proxy ，在引用服务调用。</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> invoker Invoker 对象</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> proxy</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Adaptive(&#123;Constants.PROXY_KEY&#125;)</span></span><br><span class="line">&lt;T&gt; <span class="function">T <span class="title">getProxy</span><span class="params">(Invoker&lt;T&gt; invoker)</span> <span class="keyword">throws</span> RpcException</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>方法参数 invoker ，实现了调用 Dubbo 服务的逻辑。</li>
<li>返回的 <T> 结果，就是 XXXService 的实现类，而这个实现类，就是通过动态代理的工具类进行生成。</li>
</ul>
</li>
</ul>
</li>
<li><p>Dubbo SPI 的设计思想是什么？</p>
<ul>
<li>？？？？？？？？？？？？？？？？？</li>
</ul>
</li>
<li><p>Dubbo 服务如何监控和管理？</p>
<ul>
<li>Dubbo 管理平台 + 监控平台<ul>
<li>dubbo-monitor 监控平台，基于 Dubbo 的【monitor 监控层】，实现相应的监控数据的收集到监控平台。</li>
<li>dubbo-admin 管理平台，基于注册中心，可以获取到服务相关的信息。</li>
</ul>
</li>
<li>链路追踪<ul>
<li>目前能够实现链路追踪的组件还是比较多的，如下：<ul>
<li>Apache SkyWalking 【推荐】</li>
<li>Zipkin</li>
<li>Cat</li>
<li>PinPoint</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Dubbo 服务如何做降级？比如说服务 A 调用服务 B，结果服务 B 挂掉了。服务 A 再重试几次调用服务 B，还是不行，那么直接降级，走一个备用的逻辑，给用户返回响应。</p>
<ul>
<li>Dubbo 原生自带的服务降级功能：不能实现现代微服务的熔断器的功能</li>
<li>引入支持服务降级的组件<ul>
<li>目前开源社区常用的有两种组件支持服务降级的功能，分别是：<ul>
<li>Alibaba Sentinel</li>
<li>Netflix Hystrix</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Dubbo 如何做限流？</p>
<ul>
<li>Dubbo 原生自带的限流功能：通过 TpsLimitFilter 实现，仅适用于服务提供者</li>
<li>引入支持限流的组件：推荐集成 Sentinel 组件。</li>
</ul>
</li>
<li><p>Dubbo 的失败重试是什么？</p>
<ul>
<li>所谓失败重试，就是 consumer 调用 provider 要是失败了，比如抛异常了，此时应该是可以重试的，或者调用超时了也可以重试。</li>
<li>实际场景下，我们一般会禁用掉重试。因为，因为超时后重试会有问题，超时你不知道是成功还是失败。例如，可能会导致两次扣款的问题。</li>
<li>所以，我们一般使用 failfast 集群容错策略，而不是 failover 策略。配置如下：  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dubbo:service</span> <span class="attr">cluster</span>=<span class="string">&quot;failfast&quot;</span> <span class="attr">timeout</span>=<span class="string">&quot;2000&quot;</span> /&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>一定一定一定要配置适合自己业务的超时时间。</li>
<li>当然，可以将操作分成读和写两种，前者支持重试，后者不支持重试。因为，读操作天然具有幂等性。</li>
</ul>
</li>
<li><p>Dubbo 支持哪些注册中心？</p>
<ul>
<li>【默认】Zookeeper </li>
<li>Redis </li>
<li>Multicast</li>
<li>Simple 注册中心</li>
<li>Nacos </li>
</ul>
</li>
<li><p>Dubbo 如何升级接口？</p>
<ul>
<li>当一个接口实现，出现不兼容升级时，可以用版本号过渡，版本号不同的服务相互间不引用。</li>
<li>可以按照以下的步骤进行版本迁移：<ul>
<li>在低压力时间段，先升级一半提供者为新版本。</li>
<li>再将所有消费者升级为新版本。</li>
<li>然后将剩下的一半提供者升级为新版本。</li>
</ul>
</li>
</ul>
</li>
<li><p>Dubbo 在安全机制方面是如何解决的？</p>
<pre><code> - ![](https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/15850320360538.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10)
</code></pre>
<ul>
<li>通过令牌验证在注册中心控制权限，以决定要不要下发令牌给消费者，可以防止消费者绕过注册中心访问提供者。</li>
<li>另外通过注册中心可灵活改变授权方式，而不需修改或升级提供者。</li>
</ul>
</li>
<li><p>Dubbo 需要 Web 容器吗？Dubbo 服务启动是否需要启动类似 Tomcat、Jetty 等服务器。</p>
<ul>
<li>这个答案可以是，也可以是不是。为什么呢？根据协议的不同，Provider 会启动不同的服务器。<ul>
<li>在使用 dubbo:// 协议时，答案是否，因为 Provider 启动 Netty、Mina 等 NIO Server 。</li>
<li>在使用 rest:// 协议时，答案是是，Provider 启动 Tomcat、Jetty 等 HTTP 服务器，或者也可以使用 Netty 封装的 HTTP 服务器。</li>
<li>在使用 hessian:// 协议时，答案是是，Provider 启动 Jetty、Tomcat 等 HTTP 服务器。</li>
</ul>
</li>
</ul>
</li>
<li><p>为什么要将系统进行拆分？SOA?微服务?</p>
<ul>
<li>维护成本</li>
<li>分布式挑战</li>
</ul>
</li>
<li><p>Dubbo 如何集成配置中心？</p>
<ul>
<li>对于使用了 Dubbo 的系统，配置分成两类：<ul>
<li>① Dubbo 自身配置。如：Dubbo 请求超时，Dubbo 重试次数等等。</li>
<li>② 非 Dubbo 自身配置<ul>
<li>基建配置，例如：数据库、Redis 等配置。</li>
<li>业务配置，例如：订单超时时间，下单频率等等配置。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Dubbo 如何实现分布式事务？</p>
<ul>
<li>？？？？？？？？？？？？？？？？？？</li>
</ul>
</li>
<li><p>Spring Cloud 与 Dubbo 怎么选择？</p>
<ul>
<li>？？？？？？？？？？？？</li>
</ul>
</li>
<li><p>如何自己设计一个类似 Dubbo 的 RPC 框架？</p>
<ul>
<li>服务提供者在注册中心服务发布</li>
<li>消费者去注册中心拿对应的服务信息</li>
<li>基于动态代理发起请求</li>
<li>负载均衡算法</li>
<li>通信方式，序列化方式</li>
<li>服务提供者生成一个动态代理，监听某个网络端口，然后代理本地的服务代码。接收到请求的时候，就调用对应的服务代码</li>
</ul>
</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Dubbo/" rel="tag">Dubbo</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/RPC/" rel="tag">RPC</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8/" rel="tag">面试宝典</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Hive进阶"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/Hive%E8%BF%9B%E9%98%B6/"
    >Hive进阶</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/Hive%E8%BF%9B%E9%98%B6/" class="article-date">
  <time datetime="2021-11-07T00:11:52.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hive/">Hive</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Hive进阶"><a href="#Hive进阶" class="headerlink" title="Hive进阶"></a>Hive进阶</h1><h1 id="第1章-Explain-查看执行计划"><a href="#第1章-Explain-查看执行计划" class="headerlink" title="第1章 Explain 查看执行计划"></a>第1章 Explain 查看执行计划</h1><h2 id="1-1-创建测试用表"><a href="#1-1-创建测试用表" class="headerlink" title="1.1 创建测试用表"></a>1.1 创建测试用表</h2><ol>
<li><p>建大表、小表和 JOIN 后表的语句</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建大表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> bigtable (</span><br><span class="line">    id        <span class="type">bigint</span>,</span><br><span class="line">    t         <span class="type">bigint</span>,</span><br><span class="line">    uid       string,</span><br><span class="line">    keyword   string,</span><br><span class="line">    url_rank  <span class="type">int</span>,</span><br><span class="line">    click_num <span class="type">int</span>,</span><br><span class="line">    click_url string</span><br><span class="line">) <span class="type">row</span> format delimited</span><br><span class="line">    fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建小表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> smalltable</span><br><span class="line">(</span><br><span class="line">    id        <span class="type">bigint</span>,</span><br><span class="line">    t         <span class="type">bigint</span>,</span><br><span class="line">    uid       string,</span><br><span class="line">    keyword   string,</span><br><span class="line">    url_rank  <span class="type">int</span>,</span><br><span class="line">    click_num <span class="type">int</span>,</span><br><span class="line">    click_url string</span><br><span class="line">) <span class="type">row</span> format delimited</span><br><span class="line">    fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建 JOIN 后表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> jointable</span><br><span class="line">(</span><br><span class="line">    id        <span class="type">bigint</span>,</span><br><span class="line">    t         <span class="type">bigint</span>,</span><br><span class="line">    uid       string,</span><br><span class="line">    keyword   string,</span><br><span class="line">    url_rank  <span class="type">int</span>,</span><br><span class="line">    click_num <span class="type">int</span>,</span><br><span class="line">    click_url string</span><br><span class="line">) <span class="type">row</span> format delimited</span><br><span class="line">    fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>分别向大表和小表中导入数据</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/data/bigtable&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> bigtable;</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/data/smalltable&#x27;</span> <span class="keyword">into</span>  <span class="keyword">table</span> smalltable;</span><br></pre></td></tr></table></figure>
<h2 id="1-2-基本语法"><a href="#1-2-基本语法" class="headerlink" title="1.2 基本语法"></a>1.2 基本语法</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN [EXTENDED <span class="operator">|</span> DEPENDENCY <span class="operator">|</span> <span class="keyword">AUTHORIZATION</span>] query<span class="operator">-</span><span class="keyword">sql</span></span><br></pre></td></tr></table></figure>
<h2 id="1-3-案例实操"><a href="#1-3-案例实操" class="headerlink" title="1.3 案例实操"></a>1.3 案例实操</h2></li>
<li><p>查看下面这条语句的执行计划</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> bigtable;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                      Explain                       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> STAGE DEPENDENCIES:                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>   Stage<span class="number">-0</span> <span class="keyword">is</span> a root stage                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                                                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> STAGE PLANS:                                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>   Stage: Stage<span class="number">-0</span>                                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>     <span class="keyword">Fetch</span> Operator                                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       limit: <span class="number">-1</span>                                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       Processor Tree:                              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>         TableScan                                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           alias: bigtable                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">1291573248</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           <span class="keyword">Select</span> Operator                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             expressions: id (type: <span class="type">bigint</span>), t (type: <span class="type">bigint</span>), uid (type: string), keyword (type: string), url_rank (type: <span class="type">int</span>), click_num (type: <span class="type">int</span>), click_url (type: string) <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">1291573248</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             ListSink                               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                                                    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">17</span> <span class="keyword">rows</span> selected (<span class="number">0.112</span> seconds)</span><br><span class="line"></span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span>  explain <span class="keyword">select</span> click_url, <span class="built_in">count</span>(<span class="operator">*</span>) ct <span class="keyword">from</span> bigtable <span class="keyword">group</span> <span class="keyword">by</span> click_url;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                      Explain                       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> STAGE DEPENDENCIES:                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>   Stage<span class="number">-1</span> <span class="keyword">is</span> a root stage                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>   Stage<span class="number">-0</span> depends <span class="keyword">on</span> stages: Stage<span class="number">-1</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                                                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> STAGE PLANS:                                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>   Stage: Stage<span class="number">-1</span>                                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>     Map Reduce                                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       Map Operator Tree:                           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           TableScan                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             alias: bigtable                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">1291573248</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             <span class="keyword">Select</span> Operator                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>               expressions: click_url (type: string) <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>               outputColumnNames: click_url         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>               Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">1291573248</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>               <span class="keyword">Group</span> <span class="keyword">By</span> Operator                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                 aggregations: <span class="built_in">count</span>()              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                 keys: click_url (type: string)     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                 mode: hash                         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                 outputColumnNames: _col0, _col1    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                 Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">1291573248</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                 Reduce Output Operator             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                   key expressions: _col0 (type: string) <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                   sort <span class="keyword">order</span>: <span class="operator">+</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                   Map<span class="operator">-</span>reduce <span class="keyword">partition</span> columns: _col0 (type: string) <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                   Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">1291573248</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                   <span class="keyword">value</span> expressions: _col1 (type: <span class="type">bigint</span>) <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       Execution mode: vectorized                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       Reduce Operator Tree:                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>         <span class="keyword">Group</span> <span class="keyword">By</span> Operator                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           aggregations: <span class="built_in">count</span>(VALUE._col0)         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           keys: KEY._col0 (type: string)           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           mode: mergepartial                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           outputColumnNames: _col0, _col1          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">1291573248</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           File Output Operator                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             compressed: <span class="literal">false</span>                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">1291573248</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             <span class="keyword">table</span>:                                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                 output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                                                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>   Stage: Stage<span class="number">-0</span>                                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>     <span class="keyword">Fetch</span> Operator                                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       limit: <span class="number">-1</span>                                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       Processor Tree:                              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>         ListSink                                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                                                    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">49</span> <span class="keyword">rows</span> selected (<span class="number">0.072</span> seconds)</span><br></pre></td></tr></table></figure>
<ul>
<li>STAGE DEPENDENCIES: 各个stage之间的依赖性</li>
<li>STAGE PLANS: 各个stage的执行计划</li>
<li>Map Operator Tree: MAP端的执行计划树</li>
<li>Reduce Operator Tree: Reduce端的执行计划树</li>
<li>TableScan: 表扫描操作，常见的属性：<ul>
<li>alias： 表名称</li>
<li>Statistics： 表统计信息，包含表中数据条数，数据大小等</li>
<li>Select Operator： 选取操作，常见的属性 ：</li>
<li>expressions：需要的字段名称及字段类型</li>
<li>outputColumnNames：输出的列名称</li>
</ul>
</li>
<li>Group By Operator：分组聚合操作，常见的属性：<ul>
<li>aggregations：显示聚合函数信息</li>
<li>mode：聚合模式，值有 hash：随机聚合，就是hash partition；partial：局部聚合；final：最终聚合</li>
<li>keys：分组的字段，如果没有分组，则没有此字段</li>
<li>outputColumnNames：聚合之后输出列名</li>
<li>Statistics： 表统计信息，包含分组聚合之后的数据条数，数据大小等</li>
</ul>
</li>
<li>Reduce Output Operator：输出到reduce操作，常见属性：<ul>
<li>sort order：值为空 不排序；值为 + 正序排序，值为 - 倒序排序；值为 +- 排序的列为两列，第一列为正序，第二列为倒序</li>
</ul>
</li>
<li>Filter Operator：过滤操作，常见的属性：<ul>
<li>predicate：过滤条件，如sql语句中的where id&gt;=1，则此处显示(id &gt;= 1)</li>
</ul>
</li>
<li>Map Join Operator：join 操作，常见的属性：<ul>
<li>condition map：join方式 ，如Inner Join 0 to 1 Left Outer Join0 to 2</li>
<li>keys: join 的条件字段</li>
<li>outputColumnNames： join 完成之后输出的字段</li>
<li>Statistics： join 完成之后生成的数据条数，大小等</li>
</ul>
</li>
<li>File Output Operator：文件输出操作，常见的属性<ul>
<li>compressed：是否压缩</li>
<li>table：表的信息，包含输入输出文件格式化方式，序列化方式等</li>
</ul>
</li>
<li>Fetch Operator 客户端获取数据操作，常见的属性：<ul>
<li>limit，值为 -1 表示不限制条数，其他值为限制的条数</li>
</ul>
</li>
</ul>
</li>
<li><p>查看详细执行计划</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> explain extended <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> bigtable;</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> explain extended <span class="keyword">select</span> click_url, <span class="built_in">count</span>(<span class="operator">*</span>) ct <span class="keyword">from</span> bigtable <span class="keyword">group</span> <span class="keyword">by</span> click_url;</span><br></pre></td></tr></table></figure>
<h1 id="第2章-Hive-建表优化"><a href="#第2章-Hive-建表优化" class="headerlink" title="第2章 Hive 建表优化"></a>第2章 Hive 建表优化</h1><h2 id="2-1-分区表"><a href="#2-1-分区表" class="headerlink" title="2.1 分区表"></a>2.1 分区表</h2><h2 id="2-2-分桶表"><a href="#2-2-分桶表" class="headerlink" title="2.2 分桶表"></a>2.2 分桶表</h2><h2 id="2-3-合适的文件格式"><a href="#2-3-合适的文件格式" class="headerlink" title="2.3 合适的文件格式"></a>2.3 合适的文件格式</h2><h2 id="2-4-合适的压缩格式"><a href="#2-4-合适的压缩格式" class="headerlink" title="2.4 合适的压缩格式"></a>2.4 合适的压缩格式</h2></li>
</ol>
<h1 id="第3章-HQL-语法优化"><a href="#第3章-HQL-语法优化" class="headerlink" title="第3章 HQL 语法优化"></a>第3章 HQL 语法优化</h1><h2 id="3-1-列裁剪与分区裁剪"><a href="#3-1-列裁剪与分区裁剪" class="headerlink" title="3.1 列裁剪与分区裁剪"></a>3.1 列裁剪与分区裁剪</h2><ul>
<li>列裁剪就是在查询时只读取需要的列，分区裁剪就是只读取需要的分区。当列很多或者<br>数据量很大时，如果 select * 或者不指定分区，全列扫描和全表扫描效率都很低。</li>
<li>Hive 在读数据的时候，可以只读取查询中所需要用到的列，而忽略其他的列。这样做<br>可以节省读取开销：中间表存储开销和数据整合开销。</li>
</ul>
<h2 id="3-2-Group-By"><a href="#3-2-Group-By" class="headerlink" title="3.2 Group By"></a>3.2 Group By</h2><ol>
<li>开启 Map 端聚合参数设置<ol>
<li>是否在 Map 端进行聚合，默认为 True<br> <code>set hive.map.aggr = true; </code></li>
<li>在 Map 端进行聚合操作的条目数目<br> <code>set hive.groupby.mapaggr.checkinterval = 100000;</code></li>
<li>有数据倾斜的时候进行负载均衡（默认是 false）<br> <code>set hive.groupby.skewindata = true;</code><br> 当选项设定为 true，生成的查询计划会有两个 MR Job。<ul>
<li>第一个 MR Job 中，Map 的输出结果会随机分布到 Reduce 中，每个 Reduce 做部分聚合操作，并输出结果，这样处理的结果是相同的 Group By Key 有可能被分发到不同的 Reduce中，从而达到负载均衡的目的；</li>
<li>第二个 MR Job 再根据预处理的数据结果按照 Group By Key 分布到 Reduce 中（这个过程可以保证相同的 Group By Key 被分布到同一个 Reduce 中），最后完成最终的聚合操作（虽然能解决数据倾斜，但是不能让运行速度的更快）。<h2 id="3-3-Vectorization"><a href="#3-3-Vectorization" class="headerlink" title="3.3 Vectorization"></a>3.3 Vectorization</h2>vectorization : 矢量计算的技术，在计算类似scan, filter, aggregation的时候，vectorization技术以设置批处理的增量大小为 1024 行单次来达到比单条记录单次获得更高的效率。<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.vectorized.execution.enabled <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.vectorized.execution.reduce.enabled <span class="operator">=</span> <span class="literal">true</span>;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
</li>
</ol>
<h2 id="3-4-多重模式"><a href="#3-4-多重模式" class="headerlink" title="3.4 多重模式"></a>3.4 多重模式</h2><ul>
<li>如果碰到一堆 SQL，并且这一堆 SQL 的模式还一样。都是从同一个表进行扫描，做不<br>同的逻辑。</li>
<li>可优化的地方：如果有 n 条 SQL，每个 SQL 执行都会扫描一次这张表。  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> .... <span class="keyword">select</span> id,name,sex, age <span class="keyword">from</span> student <span class="keyword">where</span> age <span class="operator">&gt;</span> <span class="number">17</span>;</span><br><span class="line"><span class="keyword">insert</span> .... <span class="keyword">select</span> id,name,sex, age <span class="keyword">from</span> student <span class="keyword">where</span> age <span class="operator">&gt;</span> <span class="number">18</span>;</span><br><span class="line"><span class="keyword">insert</span> .... <span class="keyword">select</span> id,name,sex, age <span class="keyword">from</span> student <span class="keyword">where</span> age <span class="operator">&gt;</span> <span class="number">19</span>;</span><br></pre></td></tr></table></figure></li>
<li>隐藏了一个问题：这种类型的 SQL 有多少个，那么最终。这张表就被全表扫描了多少次  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="type">int</span> t_ptn <span class="keyword">partition</span>(city<span class="operator">=</span>A). <span class="keyword">select</span> id,name,sex, age <span class="keyword">from</span> student <span class="keyword">where</span> city<span class="operator">=</span> A;</span><br><span class="line"><span class="keyword">insert</span> <span class="type">int</span> t_ptn <span class="keyword">partition</span>(city<span class="operator">=</span>B). <span class="keyword">select</span> id,name,sex, age <span class="keyword">from</span> student <span class="keyword">where</span> city<span class="operator">=</span> B;</span><br><span class="line"><span class="keyword">insert</span> <span class="type">int</span> t_ptn <span class="keyword">partition</span>(city<span class="operator">=</span>c). <span class="keyword">select</span> id,name,sex, age <span class="keyword">from</span> student <span class="keyword">where</span> city<span class="operator">=</span> c;</span><br><span class="line"><span class="comment">-- 修改为：</span></span><br><span class="line"><span class="keyword">from</span> student</span><br><span class="line"><span class="keyword">insert</span> <span class="type">int</span> t_ptn <span class="keyword">partition</span>(city<span class="operator">=</span>A) <span class="keyword">select</span> id,name,sex, age <span class="keyword">where</span> city<span class="operator">=</span> A</span><br><span class="line"><span class="keyword">insert</span> <span class="type">int</span> t_ptn <span class="keyword">partition</span>(city<span class="operator">=</span>B) <span class="keyword">select</span> id,name,sex, age <span class="keyword">where</span> city<span class="operator">=</span> B</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>如果一个 HQL 底层要执行 10 个 Job，那么能优化成 8 个一般来说，肯定能有所提高，多重插入就是一个非常实用的技能。一次读取，多次插入，有些场景是从一张表读取数据后，要多次利用。</li>
</ul>
</li>
</ul>
<h2 id="3-5-in-exists-语句"><a href="#3-5-in-exists-语句" class="headerlink" title="3.5 in/exists 语句"></a>3.5 in/exists 语句</h2><ul>
<li>使用 Hive 的一个高效替代方案：left semi join</li>
<li>比如：– in / exists 实现  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.id, a.name <span class="keyword">from</span> a <span class="keyword">where</span> a.id <span class="keyword">in</span> (<span class="keyword">select</span> b.id <span class="keyword">from</span> b);</span><br><span class="line"><span class="keyword">select</span> a.id, a.name <span class="keyword">from</span> a <span class="keyword">where</span> <span class="keyword">exists</span> (<span class="keyword">select</span> id <span class="keyword">from</span> b <span class="keyword">where</span> a.id <span class="operator">=</span> b.id);</span><br></pre></td></tr></table></figure></li>
<li>可以使用 join 来改写：  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.id, a.name <span class="keyword">from</span> a <span class="keyword">join</span> b <span class="keyword">on</span> a.id <span class="operator">=</span> b.id;</span><br></pre></td></tr></table></figure></li>
<li>应该转换成left semi join 实现  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.id, a.name <span class="keyword">from</span> a <span class="keyword">left</span> semi <span class="keyword">join</span> b <span class="keyword">on</span> a.id <span class="operator">=</span> b.id;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="3-6-CBO-优化"><a href="#3-6-CBO-优化" class="headerlink" title="3.6 CBO 优化"></a>3.6 CBO 优化</h2><ul>
<li>CBO 优化可以自动优化 HQL 中多个 Join 的顺序，并选择合适的 Join 算法。代价最小的执行计划就是最好的执行计划</li>
<li>要使用基于成本的优化（也称为 CBO），请在查询开始设置以下参数：<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.cbo.enable<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.compute.query.using.stats<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.stats.fetch.column.stats<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.stats.fetch.partition.stats<span class="operator">=</span><span class="literal">true</span>;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="3-7-谓词下推"><a href="#3-7-谓词下推" class="headerlink" title="3.7 谓词下推"></a>3.7 谓词下推</h2><ul>
<li>将 SQL 语句中的 where 谓词逻辑都尽可能提前执行，减少下游处理的数据量。对应逻辑优化器是 PredicatePushDown，配置项为 hive.optimize.ppd，默认为 true。</li>
<li>案例实操：</li>
</ul>
<ol>
<li><p>打开谓词下推优化属性</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 谓词下推，默认是 true</span></span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">set</span> hive.optimize.ppd;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+</span></span><br><span class="line"><span class="operator">|</span>           <span class="keyword">set</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+</span></span><br><span class="line"><span class="operator">|</span> hive.optimize.ppd<span class="operator">=</span><span class="literal">true</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">0.01</span> seconds) </span><br></pre></td></tr></table></figure></li>
<li><p>查看先关联两张表，再用 where 条件过滤的执行计划</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> explain <span class="keyword">select</span> o.id <span class="keyword">from</span> bigtable b <span class="keyword">join</span> bigtable o <span class="keyword">on</span> o.id <span class="operator">=</span> b.id <span class="keyword">where</span> o.id <span class="operator">&lt;=</span> <span class="number">10</span>;</span><br></pre></td></tr></table></figure></li>
<li><p>查看子查询后，再关联表的执行计划</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> explain <span class="keyword">select</span> b.id <span class="keyword">from</span> bigtable b <span class="keyword">join</span> (<span class="keyword">select</span> id <span class="keyword">from</span> bigtable <span class="keyword">where</span> id <span class="operator">&lt;=</span> <span class="number">10</span>) o <span class="keyword">on</span> b.id <span class="operator">=</span> o.id;</span><br></pre></td></tr></table></figure>
<h2 id="3-8-MapJoin"><a href="#3-8-MapJoin" class="headerlink" title="3.8 MapJoin"></a>3.8 MapJoin</h2><p>MapJoin 是将 Join 双方比较小的表直接分发到各个 Map 进程的内存中，在 Map 进程中进行 Join 操 作，这样就不用进行 Reduce 步骤，从而提高了速度。如果不指定 MapJoin或者不符合 MapJoin 的条件，那么 Hive 解析器会将 Join 操作转换成 Common Join，即：在Reduce 阶段完成 Join。容易发生数据倾斜。可以用 MapJoin 把小表全部加载到内存在 Map端进行 Join，避免 Reducer 处理。</p>
</li>
<li><p>开启 MapJoin 参数设置</p>
<ol>
<li>设置自动选择 MapJoin <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 默认为 true</span></span><br><span class="line"><span class="keyword">set</span> hive.auto.convert.join<span class="operator">=</span><span class="literal">true</span>; </span><br></pre></td></tr></table></figure></li>
<li>大表小表的阈值设置（默认 25M 以下认为是小表）： <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.mapjoin.smalltable.filesize<span class="operator">=</span><span class="number">25000000</span>;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>MapJoin 工作机制</p>
<ul>
<li>MapJoin 是将 Join 双方比较小的表直接分发到各个 Map 进程的内存中，在 Map 进程中进行 Join 操作，这样就不用进行 Reduce 步骤，从而提高了速度。</li>
</ul>
</li>
<li><p>案例实操：</p>
<ol>
<li>开启 MapJoin 功能 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 默认为 true</span></span><br><span class="line"><span class="keyword">set</span> hive.auto.convert.join <span class="operator">=</span> <span class="literal">true</span>; </span><br></pre></td></tr></table></figure></li>
<li>执行小表 JOIN 大表语句<ul>
<li>注意：此时小表(左连接)作为主表，所有数据都要写出去，因此此时会走 reduce，mapjoin失效<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Explain <span class="keyword">insert</span> overwrite <span class="keyword">table</span> jointable</span><br><span class="line"><span class="keyword">select</span> b.id, b.t, b.uid, b.keyword, b.url_rank, b.click_num, b.click_url</span><br><span class="line"><span class="keyword">from</span> smalltable s</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> bigtable b</span><br><span class="line"><span class="keyword">on</span> s.id <span class="operator">=</span> b.id;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>执行大表 JOIN 小表语句 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Explain <span class="keyword">insert</span> overwrite <span class="keyword">table</span> jointable</span><br><span class="line"><span class="keyword">select</span> b.id, b.t, b.uid, b.keyword, b.url_rank, b.click_num, b.click_url</span><br><span class="line"><span class="keyword">from</span> bigtable b</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> smalltable s</span><br><span class="line"><span class="keyword">on</span> s.id <span class="operator">=</span> b.id;</span><br></pre></td></tr></table></figure>
<h2 id="3-9-大表、大表-SMB-Join"><a href="#3-9-大表、大表-SMB-Join" class="headerlink" title="3.9 大表、大表 SMB Join"></a>3.9 大表、大表 SMB Join</h2></li>
</ol>
</li>
</ol>
<ul>
<li>SMB Join ：Sort Merge Bucket Join</li>
</ul>
<h2 id="3-10-笛卡尔积"><a href="#3-10-笛卡尔积" class="headerlink" title="3.10 笛卡尔积"></a>3.10 笛卡尔积</h2><p>Join 的时候不加 on 条件，或者无效的 on 条件，因为找不到 Join key，Hive 只能使用1 个 Reducer 来完成笛卡尔积。当 Hive 设定为严格模式（hive.mapred.mode=strictnonstrict） 时，不允许在 HQL 语句中出现笛卡尔积。</p>
<h1 id="第4章-数据倾斜"><a href="#第4章-数据倾斜" class="headerlink" title="第4章 数据倾斜"></a>第4章 数据倾斜</h1><h2 id="4-1-单表数据倾斜优化"><a href="#4-1-单表数据倾斜优化" class="headerlink" title="4.1 单表数据倾斜优化"></a>4.1 单表数据倾斜优化</h2><h3 id="4-1-1-使用参数"><a href="#4-1-1-使用参数" class="headerlink" title="4.1.1 使用参数"></a>4.1.1 使用参数</h3><p>当任务中存在 GroupBy 操作同时聚合函数为 count 或者 sum 可以设置参数来处理数据<br>倾斜问题。</p>
<ul>
<li>是否在 Map 端进行聚合，默认为 True  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.map.aggr <span class="operator">=</span> <span class="literal">true</span>;</span><br></pre></td></tr></table></figure></li>
<li>在 Map 端进行聚合操作的条目数目  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.groupby.mapaggr.checkinterval <span class="operator">=</span> <span class="number">100000</span>;</span><br></pre></td></tr></table></figure></li>
<li>有数据倾斜的时候进行负载均衡（默认是 false）  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.groupby.skewindata <span class="operator">=</span> <span class="literal">true</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>当选项设定为 true，生成的查询计划会有两个 MR Job。</li>
</ul>
</li>
</ul>
<h3 id="4-1-2-增加-Reduce-数量"><a href="#4-1-2-增加-Reduce-数量" class="headerlink" title="4.1.2 增加 Reduce 数量"></a>4.1.2 增加 Reduce 数量</h3><ol>
<li>调整 reduce 个数方法一<ol>
<li>每个 Reduce 处理的数据量默认是 256MB <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer <span class="operator">=</span> <span class="number">256000000</span></span><br></pre></td></tr></table></figure></li>
<li>每个任务最大的 reduce 数，默认为 1009 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.reducers.max <span class="operator">=</span> <span class="number">1009</span></span><br></pre></td></tr></table></figure></li>
<li>计算 reducer 数的公式 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">N<span class="operator">=</span><span class="built_in">min</span>(参数 <span class="number">2</span>，总输入数据量<span class="operator">/</span>参数 <span class="number">1</span>)(参数 <span class="number">2</span> 指的是上面的 <span class="number">1009</span>，参数 <span class="number">1</span> 值得是 <span class="number">256</span>M)</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li>调整 reduce 个数方法二<ol>
<li>在 hadoop 的 mapred-default.xml 文件中修改设置每个 job 的 Reduce 个数 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapreduce.job.reduces <span class="operator">=</span> <span class="number">15</span>;</span><br></pre></td></tr></table></figure>
<h2 id="4-2-Join-数据倾斜优化"><a href="#4-2-Join-数据倾斜优化" class="headerlink" title="4.2 Join 数据倾斜优化"></a>4.2 Join 数据倾斜优化</h2><h3 id="4-2-1-使用参数"><a href="#4-2-1-使用参数" class="headerlink" title="4.2.1 使用参数"></a>4.2.1 使用参数</h3></li>
</ol>
</li>
</ol>
<ul>
<li>在编写 Join 查询语句时，如果确定是由于 join 出现的数据倾斜，那么请做如下设置：  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">join</span> 的键对应的记录条数超过这个值则会进行分拆，值根据具体数据量设置</span><br><span class="line"><span class="keyword">set</span> hive.skewjoin.key<span class="operator">=</span><span class="number">100000</span>;</span><br><span class="line"># 如果是 <span class="keyword">join</span> 过程出现倾斜应该设置为 <span class="literal">true</span></span><br><span class="line"><span class="keyword">set</span> hive.optimize.skewjoin<span class="operator">=</span><span class="literal">false</span>;</span><br></pre></td></tr></table></figure></li>
<li>如果开启了，在 Join 过程中 Hive 会将计数超过阈值 hive.skewjoin.key（默认 100000）的倾斜 key 对应的行临时写进文件中，然后再启动另一个 job 做 map join 生成结果。通过hive.skewjoin.mapjoin.map.tasks 参数还可以控制第二个 job 的 mapper 数量，默认 10000。  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.skewjoin.mapjoin.map.tasks<span class="operator">=</span><span class="number">10000</span>;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="4-2-2-MapJoin"><a href="#4-2-2-MapJoin" class="headerlink" title="4.2.2 MapJoin"></a>4.2.2 MapJoin</h2><h1 id="第5章-Hive-Job-优化"><a href="#第5章-Hive-Job-优化" class="headerlink" title="第5章 Hive Job 优化"></a>第5章 Hive Job 优化</h1><h2 id="5-1-Hive-Map-优化"><a href="#5-1-Hive-Map-优化" class="headerlink" title="5.1 Hive Map 优化"></a>5.1 Hive Map 优化</h2><h3 id="5-1-1-复杂文件增加-Map-数"><a href="#5-1-1-复杂文件增加-Map-数" class="headerlink" title="5.1.1 复杂文件增加 Map 数"></a>5.1.1 复杂文件增加 Map 数</h3><ul>
<li><p>当 input 的文件都很大，任务逻辑复杂，map 执行非常慢的时候，可以考虑增加 Map 数，来使得每个 map 处理的数据量减少，从而提高任务的执行效率。增加 map 的方法为：根据<code>computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))=blocksize=128M </code>公式，调整 maxSize 最大值。让 maxSize 最大值低于 blocksize 就可以增加 map 的个数。</p>
</li>
<li><p>案例实操：</p>
<ol>
<li>执行查询 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> emp;</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br></pre></td></tr></table></figure></li>
<li>设置最大切片值为 100 个字节 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">set</span> mapreduce.input.fileinputformat.split.maxsize<span class="operator">=</span><span class="number">100</span>;</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> emp;</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">6</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h2 id="5-1-2-小文件进行合并"><a href="#5-1-2-小文件进行合并" class="headerlink" title="5.1.2 小文件进行合并"></a>5.1.2 小文件进行合并</h2></li>
</ol>
</li>
</ul>
<ol>
<li>在 map 执行前合并小文件，减少 map 数：CombineHiveInputFormat 具有对小文件进行合并的功能（系统默认的格式）。HiveInputFormat 没有对小文件合并功能。 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.input.format<span class="operator">=</span>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span><br></pre></td></tr></table></figure></li>
<li>在 Map-Reduce 的任务结束时合并小文件的设置： <ul>
<li>在 map-only 任务结束时合并小文件，默认 true  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.merge.mapfiles <span class="operator">=</span> <span class="literal">true</span>;</span><br></pre></td></tr></table></figure></li>
<li>在 map-reduce 任务结束时合并小文件，默认 false  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.merge.mapredfiles <span class="operator">=</span> <span class="literal">true</span>;</span><br></pre></td></tr></table></figure></li>
<li>合并文件的大小，默认 256M  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.merge.size.per.task <span class="operator">=</span> <span class="number">268435456</span>;</span><br></pre></td></tr></table></figure></li>
<li>当输出文件的平均大小小于该值时，启动一个独立的 map-reduce 任务进行文件 merge  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.merge.smallfiles.avgsize <span class="operator">=</span> <span class="number">16777216</span>;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h3 id="5-1-3-Map-端聚合"><a href="#5-1-3-Map-端聚合" class="headerlink" title="5.1.3 Map 端聚合"></a>5.1.3 Map 端聚合</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 相当于 map 端执行 combiner</span></span><br><span class="line"><span class="keyword">set</span> hive.map.aggr<span class="operator">=</span><span class="literal">true</span>;</span><br></pre></td></tr></table></figure>
<h3 id="5-1-4-推测执行"><a href="#5-1-4-推测执行" class="headerlink" title="5.1.4 推测执行"></a>5.1.4 推测执行</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#默认是 <span class="literal">true</span></span><br><span class="line"><span class="keyword">set</span> mapred.map.tasks.speculative.execution <span class="operator">=</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h2 id="5-2-Hive-Reduce-优化"><a href="#5-2-Hive-Reduce-优化" class="headerlink" title="5.2 Hive Reduce 优化"></a>5.2 Hive Reduce 优化</h2><h3 id="5-2-1-合理设置-Reduce-数"><a href="#5-2-1-合理设置-Reduce-数" class="headerlink" title="5.2.1 合理设置 Reduce 数"></a>5.2.1 合理设置 Reduce 数</h3><ol>
<li>调整 reduce 个数方法一<ol>
<li>每个 Reduce 处理的数据量默认是 256MB <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer <span class="operator">=</span> <span class="number">256000000</span></span><br></pre></td></tr></table></figure></li>
<li>每个任务最大的 reduce 数，默认为 1009 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.reducers.max <span class="operator">=</span> <span class="number">1009</span></span><br></pre></td></tr></table></figure></li>
<li>计算 reducer 数的公式 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">N=min(参数 2，总输入数据量/参数 1)(参数 2 指的是上面的 1009，参数 1 值得是 256M)</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li>调整 reduce 个数方法二<ul>
<li>在 hadoop 的 mapred-default.xml 文件中修改,设置每个 job 的 Reduce 个数  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapreduce.job.reduces <span class="operator">=</span> <span class="number">15</span>;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>reduce 个数并不是越多越好<ol>
<li>过多的启动和初始化 reduce 也会消耗时间和资源；</li>
<li>另外，有多少个 reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；</li>
<li>在设置 reduce 个数的时候也需要考虑这两个原则：<ol>
<li>处理大数据量利用合适的 reduce 数；</li>
<li>使单个 reduce 任务处理数据量大小要合适；</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="5-3-2-推测执行"><a href="#5-3-2-推测执行" class="headerlink" title="5.3.2 推测执行"></a>5.3.2 推测执行</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># hadoop 里面的</span><br><span class="line">mapred.reduce.tasks.speculative.execution</span><br><span class="line"># hive 里面相同的参数，效果和hadoop 里面的一样两个随便哪个都行</span><br><span class="line">hive.mapred.reduce.tasks.speculative.execution</span><br></pre></td></tr></table></figure>

<h2 id="5-3-Hive-任务整体优化"><a href="#5-3-Hive-任务整体优化" class="headerlink" title="5.3 Hive 任务整体优化"></a>5.3 Hive 任务整体优化</h2><h3 id="5-3-1-Fetch-抓取"><a href="#5-3-1-Fetch-抓取" class="headerlink" title="5.3.1 Fetch 抓取"></a>5.3.1 Fetch 抓取</h3><ul>
<li>Fetch 抓取是指，Hive 中对某些情况的查询可以不必使用 MapReduce 计算。例如：<code>SELECT * FROM emp</code></li>
<li>在这种情况下，Hive 可以简单地读取 emp 对应的存储目录下的文件，然后输出<br>查询结果到控制台。</li>
<li>在 hive-default.xml.template 文件中 hive.fetch.task.conversion 默认是 more，老版本 hive默认是 minimal，该属性修改为 more 以后，在全局查找、字段查找、limit 查找等都不走mapreduce。  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.fetch.task.conversion<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>more<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">        Expects one of [none, minimal, more].</span><br><span class="line">        Some select queries can be converted to single FETCH task minimizing latency.</span><br><span class="line">        Currently the query should be single sourced not having any subquery and should not have any aggregations or distincts (which incurs RS), lateral views and joins.</span><br><span class="line">        0. none : disable hive.fetch.task.conversion</span><br><span class="line">        1. minimal : SELECT STAR, FILTER on partition columns, LIMIT only</span><br><span class="line">        2. more : SELECT, FILTER, LIMIT only (support TABLESAMPLE and </span><br><span class="line">        virtual columns)</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Hadoop压缩、优化、高可用"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/Hadoop%E5%8E%8B%E7%BC%A9%E3%80%81%E4%BC%98%E5%8C%96%E3%80%81%E9%AB%98%E5%8F%AF%E7%94%A8/"
    >Hadoop压缩、优化、高可用</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/Hadoop%E5%8E%8B%E7%BC%A9%E3%80%81%E4%BC%98%E5%8C%96%E3%80%81%E9%AB%98%E5%8F%AF%E7%94%A8/" class="article-date">
  <time datetime="2021-11-07T00:10:55.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Hadoop压缩、优化、高可用"><a href="#Hadoop压缩、优化、高可用" class="headerlink" title="Hadoop压缩、优化、高可用"></a>Hadoop压缩、优化、高可用</h1><h1 id="一、Hadoop数据压缩"><a href="#一、Hadoop数据压缩" class="headerlink" title="一、Hadoop数据压缩"></a>一、Hadoop数据压缩</h1><h2 id="1-1-概述"><a href="#1-1-概述" class="headerlink" title="1.1 概述"></a>1.1 概述</h2><h3 id="1-1-1-压缩概述"><a href="#1-1-1-压缩概述" class="headerlink" title="1.1.1 压缩概述"></a>1.1.1 压缩概述</h3><ul>
<li>压缩技术能够有效减少底层存储系统（HDFS）读写字节数。压缩提高了网络带宽和磁盘空间的效率。在运行MR程序时，I/O操作、网络数据传输、 Shuffle和Merge要花大量的时间，尤其是数据规模很大和工作负载密集的情况下，因此，使用数据压缩显得非常重要。</li>
<li>鉴于磁盘I/O和网络带宽是Hadoop的宝贵资源，数据压缩对于节省资源、最小化磁盘I/O和网络传输非常有帮助。可以在任意MapReduce阶段启用压缩。不过，尽管压缩与解压操作的CPU开销不高，其性能的提升和资源的节省并非没有代价。</li>
</ul>
<h2 id="1-1-2-压缩策略和原则"><a href="#1-1-2-压缩策略和原则" class="headerlink" title="1.1.2 压缩策略和原则"></a>1.1.2 压缩策略和原则</h2><ul>
<li>压缩是提高Hadoop运行效率的一种优化策略</li>
<li>通过对Mapper、Reducer运行过程的数据进行压缩，以减少磁盘IO，提高MR程序运行速度</li>
<li>注意：采用压缩技术减少了磁盘IO，但同时增加了CPU运算负担。所以，压缩特性运用得当能提高性能，但运用不当也可能降低性能</li>
<li>压缩基本原则<ul>
<li>运算密集型的job，少用压缩</li>
<li>IO密集型的job，多用压缩</li>
</ul>
</li>
</ul>
<hr>
<h2 id="1-2-MR支持的压缩编码"><a href="#1-2-MR支持的压缩编码" class="headerlink" title="1.2 MR支持的压缩编码"></a>1.2 MR支持的压缩编码</h2><ul>
<li>支持的压缩编码<table>
<thead>
<tr>
<th>压缩格式</th>
<th>hadoop自带？</th>
<th>算法</th>
<th>文件扩展名</th>
<th>是否可切分</th>
<th>换成压缩格式后，原来的程序是否需要修改</th>
</tr>
</thead>
<tbody><tr>
<td>DEFLATE</td>
<td>是，直接使用</td>
<td>DEFLATE</td>
<td>.deflate</td>
<td>否</td>
<td>和文本处理一样，不需要修改</td>
</tr>
<tr>
<td>Gzip</td>
<td>是，直接使用</td>
<td>DEFLATE</td>
<td>.gz</td>
<td>否</td>
<td>和文本处理一样，不需要修改</td>
</tr>
<tr>
<td>bzip2</td>
<td>是，直接使用</td>
<td>bzip2</td>
<td>.bz2</td>
<td>是</td>
<td>和文本处理一样，不需要修改</td>
</tr>
<tr>
<td>LZO</td>
<td>否，需要安装</td>
<td>LZO</td>
<td>.lzo</td>
<td>是</td>
<td>需要建索引，还需要指定输入格式</td>
</tr>
<tr>
<td>Snappy</td>
<td>是，直接使用</td>
<td>Snappy</td>
<td>.snappy</td>
<td>否</td>
<td>和文本处理一样，不需要修改</td>
</tr>
</tbody></table>
</li>
<li>为了支持多种压缩/解压缩算法，Hadoop引入了编码/解码器，如下表所示。<table>
<thead>
<tr>
<th>压缩格式</th>
<th>对应的编码/解码器</th>
</tr>
</thead>
<tbody><tr>
<td>DEFLATE</td>
<td>org.apache.hadoop.io.compress.DefaultCodec</td>
</tr>
<tr>
<td>gzip</td>
<td>org.apache.hadoop.io.compress.GzipCodec</td>
</tr>
<tr>
<td>bzip2</td>
<td>org.apache.hadoop.io.compress.BZip2Codec</td>
</tr>
<tr>
<td>LZO</td>
<td>com.hadoop.compression.lzo.LzopCodec</td>
</tr>
<tr>
<td>Snappy</td>
<td>org.apache.hadoop.io.compress.SnappyCodec</td>
</tr>
</tbody></table>
</li>
<li>压缩性能的比较<table>
<thead>
<tr>
<th>压缩算法</th>
<th>原始文件大小</th>
<th>压缩文件大小</th>
<th>压缩速度</th>
<th>解压速度</th>
</tr>
</thead>
<tbody><tr>
<td>gzip</td>
<td>8.3GB</td>
<td>1.8GB</td>
<td>17.5MB/s</td>
<td>58MB/s</td>
</tr>
<tr>
<td>bzip2</td>
<td>8.3GB</td>
<td>1.1GB</td>
<td>2.4MB/s</td>
<td>9.5MB/s</td>
</tr>
<tr>
<td>LZO</td>
<td>8.3GB</td>
<td>2.9GB</td>
<td>49.3MB/s</td>
<td>74.6MB/s</td>
</tr>
</tbody></table>
</li>
</ul>
<hr>
<h2 id="1-3-压缩方式选择"><a href="#1-3-压缩方式选择" class="headerlink" title="1.3 压缩方式选择"></a>1.3 压缩方式选择</h2><h3 id="1-3-1-Gzip"><a href="#1-3-1-Gzip" class="headerlink" title="1.3.1 Gzip"></a>1.3.1 Gzip</h3><ul>
<li>优点：压缩率比较高，而且压缩/解压速度也比较快；Hadoop本身支持，在应用中处理Gzip格式的文件就和直接处理文本一样；大部分Linux系统都自带Gzip命令，使用方便。</li>
<li>缺点：不支持Split。</li>
<li>应用场景：当每个文件压缩之后在130M以内的（1个块大小内），都可以考虑用Gzip压缩格式。例如说一天或者一个小时的日志压缩成一个Gzip文件。</li>
</ul>
<h3 id="1-3-2-Bzip2"><a href="#1-3-2-Bzip2" class="headerlink" title="1.3.2 Bzip2"></a>1.3.2 Bzip2</h3><ul>
<li>优点：支持Split；具有很高的压缩率，比Gzip压缩率都高；Hadoop本身自带，使用方便</li>
<li>缺点：压缩/解压速度慢</li>
<li>应用场景：适合对速度要求不高，但需要较高的压缩率的时候；或者输出之后的数据比较大，处理之后的数据需要压缩存档减少磁盘空间并且以后数据用得比较少的情况；或者对单个很大的文本文件想压缩减少存储空间，同时又需要支持Split，而且兼容之前的应用程序的情况</li>
</ul>
<h3 id="1-3-3-Lzo压缩"><a href="#1-3-3-Lzo压缩" class="headerlink" title="1.3.3 Lzo压缩"></a>1.3.3 Lzo压缩</h3><ul>
<li>优点：压缩/解压速度也比较快，合理的压缩率；支持Split，是Hadoop中最流行的压缩格式；可以在Linux系统下安装lzop命令，使用方便</li>
<li>缺点：压缩率比Gzip要低一些；Hadoop本身不支持，需要安装；在应用中对Lzo格式的文件需要做一些特殊处理（为了支持Split需要建索引，还需要指定InputFormat为Lzo格式）</li>
<li>应用场景：一个很大的文本文件，压缩之后还大于200M以上的可以考虑，而且单个文件越大，Lzo优点越越明显</li>
</ul>
<h3 id="1-3-4-Snappy压缩"><a href="#1-3-4-Snappy压缩" class="headerlink" title="1.3.4 Snappy压缩"></a>1.3.4 Snappy压缩</h3><ul>
<li>优点：高速压缩速度和合理的压缩率</li>
<li>缺点：不支持Split；压缩率比Gzip要低；Hadoop本身不支持，需要安装</li>
<li>应用场景：当MapReduce作业的Map输出的数据比较大的时候，作为Map到Reduce的中间数据的压缩格式；或者作为一个MapReduce作业的输出和另外一个MapReduce作业的输入</li>
</ul>
<hr>
<h2 id="1-4-压缩位置选择"><a href="#1-4-压缩位置选择" class="headerlink" title="1.4 压缩位置选择"></a>1.4 压缩位置选择</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16345428872480.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<hr>
<h2 id="1-5-压缩参数配置"><a href="#1-5-压缩参数配置" class="headerlink" title="1.5 压缩参数配置"></a>1.5 压缩参数配置</h2><p>要在Hadoop中启用压缩，可以配置如下参数：<br>|参数    |默认值    |阶段    |建议|<br>|——|——|——|—-|<br>|io.compression.codecs（在core-site.xml中配置）    |无，这个需要在命令行输入hadoop checknative查看    |输入压缩    |Hadoop使用文件扩展名判断是否支持某种编解码器|<br>|mapreduce.map.output.compress（在mapred-site.xml中配置）    |false    |mapper输出    |这个参数设为true启用压缩|<br>|mapreduce.map.output.compress.codec（在mapred-site.xml中配置）    |org.apache.hadoop.io.compress.DefaultCodec    |mapper输出    |企业多使用LZO或Snappy编解码器在此阶段压缩数据|<br>|mapreduce.output.fileoutputformat.compress（在mapred-site.xml中配置）    |false    |reducer输出    |这个参数设为true启用压缩|<br>|mapreduce.output.fileoutputformat.compress.codec（在mapred-site.xml中配置）    |org.apache.hadoop.io.compress.DefaultCodec    |reducer输出    |使用标准工具或者编解码器，如gzip和bzip2|<br>|mapreduce.output.fileoutputformat.compress.type（在mapred-site.xml中配置）    |RECORD    |reducer输出    |SequenceFile输出使用的压缩类型：NONE和BLOCK|</p>
<hr>
<h2 id="1-6-压缩实操案例"><a href="#1-6-压缩实操案例" class="headerlink" title="1.6 压缩实操案例"></a>1.6 压缩实操案例</h2><h3 id="1-6-1-数据流的压缩和解压缩"><a href="#1-6-1-数据流的压缩和解压缩" class="headerlink" title="1.6.1 数据流的压缩和解压缩"></a>1.6.1 数据流的压缩和解压缩</h3><ul>
<li>使用createOutputStream(OutputStreamout)方法创建一个CompressionOutputStream，将其以压缩格式写入底层的流</li>
<li>调用createInputStream(InputStreamin)函数，获得一个CompressionInputStream，从底层的流读取未压缩的数据</li>
</ul>
<h3 id="1-6-2-Map输出端压缩"><a href="#1-6-2-Map输出端压缩" class="headerlink" title="1.6.2 Map输出端压缩"></a>1.6.2 Map输出端压缩</h3><ul>
<li>即使MapReduce的输入输出文件都是未压缩的文件，仍然可以对Map任务的中间结果输出做压缩，因为它要写在硬盘并且通过网络传输到Reduce节点，对其压缩可以提高很多性能，这些工作只要设置两个属性即可。  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 开启map端输出压缩</span></span><br><span class="line">conf.setBoolean(<span class="string">&quot;mapreduce.map.output.compress&quot;</span>, <span class="keyword">true</span>);</span><br><span class="line"><span class="comment">// 设置map端输出压缩方式</span></span><br><span class="line">conf.setClass(<span class="string">&quot;mapreduce.map.output.compress.codec&quot;</span>, BZip2Codec.class,CompressionCodec.class);</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="1-6-3-Reduce输出端压缩"><a href="#1-6-3-Reduce输出端压缩" class="headerlink" title="1.6.3 Reduce输出端压缩"></a>1.6.3 Reduce输出端压缩</h3><pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置reduce端输出压缩开启</span></span><br><span class="line">FileOutputFormat.setCompressOutput(job, <span class="keyword">true</span>);</span><br><span class="line"><span class="comment">// 设置压缩的方式</span></span><br><span class="line">FileOutputFormat.setOutputCompressorClass(job, BZip2Codec.class); </span><br></pre></td></tr></table></figure>
</code></pre>
<h1 id="二、Hadoop性能优化"><a href="#二、Hadoop性能优化" class="headerlink" title="二、Hadoop性能优化"></a>二、Hadoop性能优化</h1><h2 id="2-1-MapReduce跑得慢的原因"><a href="#2-1-MapReduce跑得慢的原因" class="headerlink" title="2.1 MapReduce跑得慢的原因"></a>2.1 MapReduce跑得慢的原因</h2><ol>
<li>计算机性能<ul>
<li>CPU，内存，磁盘，网络···</li>
</ul>
</li>
<li>I/O操作优化<ol>
<li>数据倾斜</li>
<li>Map和Reduce数设置不合理</li>
<li>Map运行时间太长，导致Reduce等待过久</li>
<li>小文件过多</li>
<li>大量不可切片的超大压缩文件</li>
<li>Spill次数过多</li>
<li>Merge次数过多</li>
</ol>
</li>
</ol>
<h2 id="2-2-MapReduce优化"><a href="#2-2-MapReduce优化" class="headerlink" title="2.2 MapReduce优化"></a>2.2 MapReduce优化</h2><ul>
<li>MapReduce优化方法主要从六个方面考虑：数据输入、Map阶段、Reduce阶段、IO传输、数据倾斜问题、常用的调优参数</li>
</ul>
<h3 id="2-2-1-数据输入"><a href="#2-2-1-数据输入" class="headerlink" title="2.2.1 数据输入"></a>2.2.1 数据输入</h3><ol>
<li>合并小文件：执行MR任务前将小文件合并，大量小文件会产生大量Map任务，增大Map任务装载次数，而任务的装载比较耗时，从而导致MR运行较慢</li>
<li>采用CombineTextInputFormat来作为输入，解决输入端大量小文件场景</li>
</ol>
<h3 id="2-2-2-Map阶段"><a href="#2-2-2-Map阶段" class="headerlink" title="2.2.2 Map阶段"></a>2.2.2 Map阶段</h3><ol>
<li>减少溢写（Spill）次数：通过调整mapreduce.task.io.sort.mb及mapreduce.map.sort.spill.percent参数值，增大触发Spill的内存上限，减少Spill次数，从而减少磁盘IO</li>
<li>减少合并（Merge）次数：通过调整mapreduce.task.io.sort.factor参数，增大Merge的文件数目，减少Merge的次数，从而缩短MR处理时间</li>
<li>在Map之后，不影响业务逻辑前提下，先进行Combine处理，减少 I/O</li>
</ol>
<h3 id="2-2-3-Reduce阶段"><a href="#2-2-3-Reduce阶段" class="headerlink" title="2.2.3 Reduce阶段"></a>2.2.3 Reduce阶段</h3><ol>
<li>合理设置Map和Reduce数：两个都不能设置太少，也不能设置太多。太少，会导致Task等待，延长处理时间；太多，会导致Map、Reduce任务间竞争资源，造成处理超时等错误</li>
<li>设置Map、Reduce共存：调整mapreduce.job.reduce.slowstart.completedmaps参数，使Map运行到一定程度后，Reduce也开始运行，减少Reduce的等待时间</li>
<li>规避使用Reduce：因为Reduce在用于连接数据集的时候将会产生大量的网络消耗</li>
<li>合理设置Reduce端的Buffer：默认情况下，数据达到一个阈值的时候，Buffer中的数据就会写入磁盘，然后Reduce会从磁盘中获得所有的数据。也就是说，Buffer和Reduce是没有直接关联的，中间多次写磁盘-&gt;读磁盘的过程，既然有这个弊端，那么就可以通过参数来配置，使得Buffer中的一部分数据可以直接输送到Reduce，从而减少IO开销：<font color ='red' >mapreduce.reduce.input.buffer.percent，默认为0.0。当值大于0的时候，会保留指定比例的内存读Buffer中的数据直接拿给Reduce使用。这样一来，设置Buffer需要内存，读取数据需要内存，Reduce计算也要内存，所以要根据作业的运行情况进行调整</font></li>
</ol>
<h3 id="2-2-4-I-O传输"><a href="#2-2-4-I-O传输" class="headerlink" title="2.2.4 I/O传输"></a>2.2.4 I/O传输</h3><ol>
<li>采用数据压缩的方式，减少网络I/O传输的数据量，从而减少I/O传输时间，安装Snappy和LZO压缩编码器。</li>
<li>使用SequenceFile二进制文件</li>
</ol>
<h3 id="2-2-5-数据倾斜问题"><a href="#2-2-5-数据倾斜问题" class="headerlink" title="2.2.5 数据倾斜问题"></a>2.2.5 数据倾斜问题</h3><ol>
<li>数据倾斜现象<ul>
<li>数据频率倾斜——某一个区域的数据量要远远大于其他区域</li>
<li>数据大小倾斜——部分记录的大小远远大于平均值</li>
</ul>
</li>
<li>减少数据倾斜的方法<ul>
<li>方法1：抽样和范围分区<ol>
<li>可以通过对原始数据进行抽样得到的结果集来预设分区边界值</li>
</ol>
</li>
<li>方法2：自定义分区<ol>
<li>基于输出键的背景知识进行自定义分区。例如，如果Map输出键的单词来源于一本书。且其中某几个专业词汇较多。那么就可以自定义分区将这这些专业词汇发送给固定的一部分Reduce实例。而将其他的都发送给剩余的Reduce实例</li>
</ol>
</li>
<li>方法3：Combiner<ol>
<li>使用Combiner可以大量地减小数据倾斜。在可能的情况下，Combine的目的就是聚合并精简数据</li>
</ol>
</li>
<li>方法4：采用Map Join，尽量避免Reduce Join</li>
</ul>
</li>
</ol>
<h2 id="2-3常用的调优参数"><a href="#2-3常用的调优参数" class="headerlink" title="2.3常用的调优参数"></a>2.3常用的调优参数</h2><ol>
<li><p>资源相关参数：<br> 在MR应用程序中配置就可以生效（mapred-default.xml）</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数说明</th>
</tr>
</thead>
<tbody><tr>
<td>mapreduce.map.memory.mb</td>
<td>一个MapTask可使用的资源上限（单位:MB），默认为1024。如果MapTask实际使用的资源量超过该值，则会被强制杀死。</td>
</tr>
<tr>
<td>mapreduce.reduce.memory.mb</td>
<td>一个ReduceTask可使用的资源上限（单位:MB），默认为1024。如果ReduceTask实际使用的资源量超过该值，则会被强制杀死。</td>
</tr>
<tr>
<td>mapreduce.map.cpu.vcores</td>
<td>每个MapTask可使用的最多cpu core数目，默认值: 1</td>
</tr>
<tr>
<td>mapreduce.reduce.cpu.vcores</td>
<td>每个ReduceTask可使用的最多cpu core数目，默认值: 1</td>
</tr>
<tr>
<td>mapreduce.reduce.shuffle.parallelcopies</td>
<td>每个Reduce去Map中取数据的并行数。默认值是5</td>
</tr>
<tr>
<td>mapreduce.reduce.shuffle.merge.percent</td>
<td>Buffer中的数据达到多少比例开始写入磁盘。默认值0.66</td>
</tr>
<tr>
<td>mapreduce.reduce.shuffle.input.buffer.percent</td>
<td>Buffer大小占Reduce可用内存的比例。默认值0.7</td>
</tr>
<tr>
<td>mapreduce.reduce.input.buffer.percent</td>
<td>指定多少比例的内存用来存放Buffer中的数据，默认值是0.0</td>
</tr>
</tbody></table>
</li>
<li><p>在YARN启动之前就配置在服务器的配置文件中才能生效（yarn-default.xml）</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数说明</th>
</tr>
</thead>
<tbody><tr>
<td>yarn.scheduler.minimum-allocation-mb</td>
<td>给应用程序Container分配的最小内存，默认值：1024</td>
</tr>
<tr>
<td>yarn.scheduler.maximum-allocation-mb</td>
<td>给应用程序Container分配的最大内存，默认值：8192</td>
</tr>
<tr>
<td>yarn.scheduler.minimum-allocation-vcores</td>
<td>每个Container申请的最小CPU核数，默认值：1</td>
</tr>
<tr>
<td>yarn.scheduler.maximum-allocation-vcores</td>
<td>每个Container申请的最大CPU核数，默认值：32</td>
</tr>
<tr>
<td>yarn.nodemanager.resource.memory-mb</td>
<td>给Containers分配的最大物理内存，默认值：8192</td>
</tr>
</tbody></table>
</li>
<li><p>Shuffle性能优化的关键参数，应在YARN启动之前就配置好（mapred-default.xml）</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数说明</th>
</tr>
</thead>
<tbody><tr>
<td>mapreduce.task.io.sort.mb</td>
<td>Shuffle的环形缓冲区大小，默认100m</td>
</tr>
<tr>
<td>mapreduce.map.sort.spill.percent</td>
<td>环形缓冲区溢出的阈值，默认80%</td>
</tr>
</tbody></table>
</li>
<li><p>容错相关参数（MapReduce性能优化）</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数说明</th>
</tr>
</thead>
<tbody><tr>
<td>mapreduce.map.maxattempts</td>
<td>每个Map Task最大重试次数，一旦重试次数超过该值，则认为Map Task运行失败，默认值：4。</td>
</tr>
<tr>
<td>mapreduce.reduce.maxattempts</td>
<td>每个Reduce Task最大重试次数，一旦重试次数超过该值，则认为Map Task运行失败，默认值：4。</td>
</tr>
<tr>
<td>mapreduce.task.timeout</td>
<td>Task超时时间，经常需要设置的一个参数，该参数表达的意思为：如果一个Task在一定时间内没有任何进入，即不会读取新的数据，也没有输出数据，则认为该Task处于Block状态，可能是卡住了，也许永远会卡住，为了防止因为用户程序永远Block住不退出，则强制设置了一个该超时时间（单位毫秒），默认是600000（10分钟）。如果你的程序对每条输入数据的处理时间过长（比如会访问数据库，通过网络拉取数据等），建议将该参数调大，该参数过小常出现的错误提示是：“AttemptID:attempt_14267829456721_123456_m_000224_0 Timed out after 300 secsContainer killed by the ApplicationMaster.”。</td>
</tr>
</tbody></table>
</li>
</ol>
<h2 id="2-4-Hadoop小文件优化方法"><a href="#2-4-Hadoop小文件优化方法" class="headerlink" title="2.4 Hadoop小文件优化方法"></a>2.4 Hadoop小文件优化方法</h2><h3 id="2-4-1-Hadoop小文件弊端"><a href="#2-4-1-Hadoop小文件弊端" class="headerlink" title="2.4.1 Hadoop小文件弊端"></a>2.4.1 Hadoop小文件弊端</h3><ul>
<li>HDFS上每个文件都要在NameNode上创建对应的元数据，这个元数据的大小约为150byte，这样当小文件比较多的时候，就会产生很多的元数据文件，一方面会大量占用NameNode的内存空间，另一方面就是元数据文件过多，使得寻址索引速度变慢。</li>
<li>小文件过多，在进行MR计算时，会生成过多切片，需要启动过多的MapTask。每个MapTask处理的数据量小，导致MapTask的处理时间比启动时间还小，白白消耗资源。</li>
</ul>
<h3 id="2-4-2-Hadoop小文件解决方案"><a href="#2-4-2-Hadoop小文件解决方案" class="headerlink" title="2.4.2 Hadoop小文件解决方案"></a>2.4.2 Hadoop小文件解决方案</h3><ol>
<li>小文件优化的方向：<ul>
<li>（1）在数据采集的时候，就将小文件或小批数据合成大文件再上传HDFS。</li>
<li>（2）在业务处理之前，在HDFS上使用MapReduce程序对小文件进行合并。</li>
<li>（3）在MapReduce处理时，可采用CombineTextInputFormat提高效率。</li>
<li>（4）开启uber模式，实现jvm重用</li>
</ul>
</li>
<li>Hadoop Archive<ul>
<li>是一个高效的将小文件放入HDFS块中的文件存档工具，能够将多个小文件打包成一个HAR文件，从而达到减少NameNode的内存使用</li>
</ul>
</li>
<li>SequenceFile<ul>
<li>SequenceFile是由一系列的二进制k/v组成，如果为key为文件名，value为文件内容，可将大批小文件合并成一个大文件</li>
</ul>
</li>
<li>CombineTextInputFormat<ul>
<li>CombineTextInputFormat用于将多个小文件在切片过程中生成一个单独的切片或者少量的切片。 </li>
</ul>
</li>
<li>开启uber模式，实现jvm重用。默认情况下，每个Task任务都需要启动一个jvm来运行，如果Task任务计算的数据量很小，我们可以让同一个Job的多个Task运行在一个Jvm中，不必为每个Task都开启一个Jvm. <ul>
<li>开启uber模式，在mapred-site.xml中添加如下配置  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--  开启uber模式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- uber模式中最大的mapTask数量，可向下修改  --&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.maxmaps<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>9<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- uber模式中最大的reduce数量，可向下修改 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.maxreduces<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- uber模式中最大的输入数据量，默认使用dfs.blocksize 的值，可向下修改 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.maxbytes<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span><span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h1 id="三、Hadoop新特性"><a href="#三、Hadoop新特性" class="headerlink" title="三、Hadoop新特性"></a>三、Hadoop新特性</h1><h2 id="3-1-Hadoop2-x新特性"><a href="#3-1-Hadoop2-x新特性" class="headerlink" title="3.1 Hadoop2.x新特性"></a>3.1 Hadoop2.x新特性</h2><h3 id="3-1-1-集群间数据拷贝"><a href="#3-1-1-集群间数据拷贝" class="headerlink" title="3.1.1 集群间数据拷贝"></a>3.1.1 集群间数据拷贝</h3><ul>
<li>采用distcp命令实现两个Hadoop集群之间的递归数据复制<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ hadoop distcp hdfs://hadoop002:9820/WeCom_3.1.18.90318.dmg hdfs://hadoop002:9820/testDistct</span><br><span class="line">···</span><br><span class="line">···</span><br><span class="line">2021-10-19 17:56:03,705 INFO mapreduce.Job: Job job_1634633871057_0003 completed successfully</span><br><span class="line">2021-10-19 17:56:03,754 INFO mapreduce.Job: Counters: 36</span><br><span class="line">	File System Counters</span><br><span class="line">		FILE: Number of bytes <span class="built_in">read</span>=0</span><br><span class="line">		FILE: Number of bytes written=227128</span><br><span class="line">		FILE: Number of <span class="built_in">read</span> operations=0</span><br><span class="line">		FILE: Number of large <span class="built_in">read</span> operations=0</span><br><span class="line">		FILE: Number of write operations=0</span><br><span class="line">		HDFS: Number of bytes <span class="built_in">read</span>=325449295</span><br><span class="line">		HDFS: Number of bytes written=325448910</span><br><span class="line">		HDFS: Number of <span class="built_in">read</span> operations=19</span><br><span class="line">		HDFS: Number of large <span class="built_in">read</span> operations=0</span><br><span class="line">		HDFS: Number of write operations=5</span><br><span class="line">	Job Counters</span><br><span class="line">		Launched map tasks=1</span><br><span class="line">		Other <span class="built_in">local</span> map tasks=1</span><br><span class="line">		Total time spent by all maps <span class="keyword">in</span> occupied slots (ms)=5517</span><br><span class="line">		Total time spent by all reduces <span class="keyword">in</span> occupied slots (ms)=0</span><br><span class="line">		Total time spent by all map tasks (ms)=5517</span><br><span class="line">		Total vcore-milliseconds taken by all map tasks=5517</span><br><span class="line">		Total megabyte-milliseconds taken by all map tasks=5649408</span><br><span class="line">	Map-Reduce Framework</span><br><span class="line">		Map input records=1</span><br><span class="line">		Map output records=0</span><br><span class="line">		Input split bytes=136</span><br><span class="line">		Spilled Records=0</span><br><span class="line">		Failed Shuffles=0</span><br><span class="line">		Merged Map outputs=0</span><br><span class="line">		GC time elapsed (ms)=52</span><br><span class="line">		CPU time spent (ms)=1730</span><br><span class="line">		Physical memory (bytes) snapshot=270876672</span><br><span class="line">		Virtual memory (bytes) snapshot=2578894848</span><br><span class="line">		Total committed heap usage (bytes)=217055232</span><br><span class="line">		Peak Map Physical memory (bytes)=270876672</span><br><span class="line">		Peak Map Virtual memory (bytes)=2578894848</span><br><span class="line">	File Input Format Counters</span><br><span class="line">		Bytes Read=249</span><br><span class="line">	File Output Format Counters</span><br><span class="line">		Bytes Written=0</span><br><span class="line">	DistCp Counters</span><br><span class="line">		Bandwidth <span class="keyword">in</span> Btyes=81362227</span><br><span class="line">		Bytes Copied=325448910</span><br><span class="line">		Bytes Expected=325448910</span><br><span class="line">		Files Copied=1</span><br><span class="line">[atguigu@hadoop001 ~]$</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="3-1-2-小文件存档"><a href="#3-1-2-小文件存档" class="headerlink" title="3.1.2 小文件存档"></a>3.1.2 小文件存档</h3><ol>
<li>HDFS存储小文件弊端<ul>
<li>每个文件均按块存储，每个块的元数据存储在NameNode的内存中，因此HDFS存储小文件会非常低效。因为大量的小文件会耗尽NameNode中的大部分内存。但注意，存储小文件所需要的磁盘容量和数据块的大小无关。例如，一个1MB的文件设置为128MB的块存储，实际使用的是1MB的磁盘空间，而不是128MB</li>
</ul>
</li>
<li>解决存储小文件办法之一<ul>
<li>HDFS存档文件或HAR文件，是一个更高效的文件存档工具，它将文件存入HDFS块，在减少NameNode内存使用的同时，允许对文件进行透明的访问。具体说来，HDFS存档文件对内还是一个一个独立文件，对NameNode而言却是一个整体，减少了NameNode的内存<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16346376074095.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ul>
</li>
<li>案例实操<ul>
<li>归档文件:把/user/atguigu/input目录里面的所有文件归档成一个叫input.har的归档文件，并把归档后文件存储到/user/atguigu/output路径下。  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 hadoop-3.1.3]$ hadoop archive -archiveName input.har -p  /user/atguigu/input   /user/atguigu/output</span><br></pre></td></tr></table></figure></li>
<li>查看归档  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 hadoop-3.1.3]$ hadoop fs -ls /user/atguigu/output/input.har</span><br><span class="line">[atguigu@hadoop001 hadoop-3.1.3]$ hadoop fs -ls har:///user/atguigu/output/input.har</span><br></pre></td></tr></table></figure></li>
<li>解归档文件  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 hadoop-3.1.3]$ hadoop fs -cp har:/// user/atguigu/output/input.har/*    /user/atguigu</span><br></pre></td></tr></table></figure>
<h3 id="3-1-2-回收站"><a href="#3-1-2-回收站" class="headerlink" title="3.1.2 回收站"></a>3.1.2 回收站</h3></li>
</ul>
</li>
</ol>
<ul>
<li>开启回收站功能，可以将删除的文件在不超时的情况下，恢复原数据，起到防止误删除、备份等作用</li>
<li>开启回收站功能参数说明<ol>
<li>默认值fs.trash.interval=0，0表示禁用回收站;其他值表示设置文件的存活时间</li>
<li>默认值fs.trash.checkpoint.interval=0，检查回收站的间隔时间。如果该值为0，则该值设置和fs.trash.interval的参数值相等</li>
<li>要求fs.trash.checkpoint.interval&lt;=fs.trash.interval</li>
</ol>
</li>
<li>回收站工作机制<br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16346388522940.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>回收站使用<ol>
<li>启用回收站：修改core-site.xml，配置垃圾回收时间为1分钟。 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.checkpoint.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>查看回收站 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#回收站目录在hdfs集群中的路径：</span></span><br><span class="line">/user/atguigu/.Trash/</span><br></pre></td></tr></table></figure></li>
<li>通过程序删除的文件不会经过回收站，需要调用moveToTrash()才进入回收站 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Trash trash = <span class="function">New <span class="title">Trash</span><span class="params">(conf)</span></span>;</span><br><span class="line">trash.moveToTrash(path);</span><br></pre></td></tr></table></figure></li>
<li>通过网页上直接删除的文件也不会走回收站。</li>
<li>只有在命令行利用hadoop fs -rm命令删除的文件才会走回收站。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 hadoop-3.1.3]$ hadoop fs -rm -r /user/atguigu/input</span><br><span class="line">2020-07-14 16:13:42,643 INFO fs.TrashPolicyDefault: Moved: <span class="string">&#x27;hdfs://hadoop001:9820/user/atguigu/input&#x27;</span> to trash at: hdfs://hadoop001:9820/user/atguigu/.Trash/Current/user/atguigu/input</span><br></pre></td></tr></table></figure></li>
<li>恢复回收站数据 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 hadoop-3.1.3]$ hadoop fs -mv /user/atguigu/.Trash/Current/user/atguigu/input    /user/atguigu/input</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
<h2 id="3-2-Hadoop3-x新特性"><a href="#3-2-Hadoop3-x新特性" class="headerlink" title="3.2 Hadoop3.x新特性"></a>3.2 Hadoop3.x新特性</h2><h3 id="3-2-1-多NN的HA架构"><a href="#3-2-1-多NN的HA架构" class="headerlink" title="3.2.1 多NN的HA架构"></a>3.2.1 多NN的HA架构</h3><ul>
<li>HDFS NameNode高可用性的初始实现为单个活动NameNode和单个备用NameNode，将edits复制到三个JournalNode。该体系结构能够容忍系统中一个NN或一个JN的故障。但是，某些部署需要更高程度的容错能力。</li>
<li>Hadoop3.x允许用户运行多个备用NameNode。例如，通过配置三个NameNode和五个JournalNode，群集能够容忍两个节点而不是一个节点的故障。</li>
</ul>
<h3 id="3-2-2-纠删码"><a href="#3-2-2-纠删码" class="headerlink" title="3.2.2 纠删码"></a>3.2.2 纠删码</h3><ul>
<li>HDFS中的默认3副本方案在存储空间和其他资源（例如，网络带宽）中具有200％的开销。但是，对于I / O活动相对较低暖和冷数据集，在正常操作期间很少访问其他块副本，但仍会消耗与第一个副本相同的资源量。</li>
<li>纠删码（Erasure Coding）能够在不到50% 的数据冗余情况下提供和3副本相同的容错能力，因此，使用纠删码作为副本机制的改进是自然而然的。</li>
<li>查看集群支持的纠删码策略：hdfs ec -listPolicies</li>
</ul>
<p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16346151537039.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h1 id="四、HadoopHA高可用"><a href="#四、HadoopHA高可用" class="headerlink" title="四、HadoopHA高可用"></a>四、HadoopHA高可用</h1><h2 id="4-1-现有集群存在哪些问题？"><a href="#4-1-现有集群存在哪些问题？" class="headerlink" title="4.1 现有集群存在哪些问题？"></a>4.1 现有集群存在哪些问题？</h2><ol>
<li>HDFS集群 单个NN场景下NN如果故障了，整个HDFS集群就不可用（中心化集群） <ul>
<li>解决方案：配置多个NN !!!</li>
</ul>
</li>
<li>多个NN的场景下由哪一台对外进行服务？<ul>
<li>当HDFS实现多NN的高可用后，但是只有一台 NN 对外提供服务(Active)，其他的NN都是替补（Standby），当正在提供服务的NN宕机故障，其他的NN自动切换成Active状态</li>
</ul>
</li>
<li>HA实现后，元数据的管理策略是否发生改变？<ul>
<li>不改变，但是在HA的HDFS中合并 fsimage和edits编辑日志的合并工作交给Standby状态的NN去完成！</li>
</ul>
</li>
<li>2NN 在高可用的集群中还要不要？<ul>
<li>不要了！2NN的工作有Standby状态的NN完成！</li>
</ul>
</li>
<li>为了保证整个集群中的所有NN 能够共享元数据信息，会新增一个 JournalNode 服务，在集群中我们会启动多个JournalNode服务 形成一个集群，每个JournalNode服务对应一个NN。进行数共享！</li>
<li>JournalNode如何实现元数据的共享？<ul>
<li>在集群状态下，当一个请求对元数据进行更改的时候，此时Active状态的NN会处理请求，会往磁盘上的编辑日志edits文件追加记录，并且会通过当前机器的JournalNode服务同步edits日志文件。接下来请求也会被转发到Standby状态的NN上，Standby状态的NN接收到请求后，只去读取自己的JournalNode服务中保存的最新的编辑日志信息，加载内存中形成最新的元数据映像，保证一旦Active状态的NN宕机，Standby自己马上顶上后能够展示最新的元数据。  </li>
<li>到达checkPoint之后，Standby都会尝试进行合并Edit和Fsimage，以接收到的第一个为准</li>
</ul>
</li>
<li>当一台NN故障后，其他NN如何争抢上位？<ul>
<li>采用高可用集群中的自动故障转移机制来完成切换。</li>
</ul>
</li>
<li>自动故障转移的机制如何实现？</li>
</ol>
<h2 id="4-2-HDFS-HA工作机制"><a href="#4-2-HDFS-HA工作机制" class="headerlink" title="4.2 HDFS-HA工作机制"></a>4.2 HDFS-HA工作机制</h2><ul>
<li>通过多个NameNode消除单点故障<h3 id="4-2-1-HDFS-HA工作要点"><a href="#4-2-1-HDFS-HA工作要点" class="headerlink" title="4.2.1 HDFS-HA工作要点"></a>4.2.1 HDFS-HA工作要点</h3></li>
</ul>
<ol>
<li>元数据管理方式需要改变<ul>
<li>内存中各自保存一份元数据；</li>
<li>Edits日志只有Active状态的NameNode节点可以做写操作；</li>
<li>所有的NameNode都可以读取Edits；</li>
<li>共享的Edits放在一个共享存储中管理（qjournal和NFS两个主流实现）；</li>
</ul>
</li>
<li>需要一个状态管理功能模块<ul>
<li>实现了一个zkfailover，常驻在每一个namenode所在的节点，每一个zkfailover负责监控自己所在NameNode节点，利用zk进行状态标识，当需要进行状态切换时，由zkfailover来负责切换，切换时需要防止brain split现象的发生。</li>
</ul>
</li>
<li>必须保证两个NameNode之间能够ssh无密码登录</li>
<li>隔离（Fence），即同一时刻仅仅有一个NameNode对外提供服务</li>
</ol>
<h3 id="4-2-2-HDFS-HA自动故障转移工作机制"><a href="#4-2-2-HDFS-HA自动故障转移工作机制" class="headerlink" title="4.2.2 HDFS-HA自动故障转移工作机制"></a>4.2.2 HDFS-HA自动故障转移工作机制</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16346403266012.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ul>
<li>自动故障转移为HDFS部署增加了两个新组件：ZooKeeper和ZKFailoverController（ZKFC）进程。</li>
<li>ZooKeeper是维护少量协调数据，通知客户端这些数据的改变和监视客户端故障的高可用服务。</li>
<li>HA的自动故障转移依赖于ZooKeeper的以下功能：<ol>
<li>故障检测<ul>
<li>集群中的每个NameNode在ZooKeeper中维护了一个会话，如果机器崩溃，ZooKeeper中的会话将终止，ZooKeeper通知另一个NameNode需要触发故障转移。</li>
</ul>
</li>
<li>现役NameNode选择<ul>
<li>ZooKeeper提供了一个简单的机制用于唯一的选择一个节点为active状态。如果目前现役NameNode崩溃，另一个节点可能从ZooKeeper获得特殊的排外锁以表明它应该成为现役NameNode。</li>
</ul>
</li>
</ol>
</li>
<li>ZKFC是自动故障转移中的另一个新组件，是ZooKeeper的客户端，也监视和管理NameNode的状态。每个运行NameNode的主机也运行了一个ZKFC进程，ZKFC负责：<ol>
<li>健康监测<ul>
<li>ZKFC使用一个健康检查命令定期地ping与之在相同主机的NameNode，只要该NameNode及时地回复健康状态，ZKFC认为该节点是健康的。如果该节点崩溃，冻结或进入不健康状态，健康监测器标识该节点为非健康的。</li>
</ul>
</li>
<li>ZooKeeper会话管理<ul>
<li>当本地NameNode是健康的，ZKFC保持一个在ZooKeeper中打开的会话。如果本地NameNode处于active状态，ZKFC也保持一个特殊的znode锁，该锁使用了ZooKeeper对短暂节点的支持，如果会话终止，锁节点将自动删除。</li>
</ul>
</li>
<li>基于ZooKeeper的选择<ul>
<li>如果本地NameNode是健康的，且ZKFC发现没有其它的节点当前持有znode锁，它将为自己获取该锁。如果成功，则它已经赢得了选择，并负责运行故障转移进程以使它的本地NameNode为Active。</li>
</ul>
</li>
</ol>
</li>
</ul>
<h2 id="4-3-HDFS-HA集群配置"><a href="#4-3-HDFS-HA集群配置" class="headerlink" title="4.3 HDFS-HA集群配置"></a>4.3 HDFS-HA集群配置</h2><h3 id="4-3-1-环境准备"><a href="#4-3-1-环境准备" class="headerlink" title="4.3.1 环境准备"></a>4.3.1 环境准备</h3><ul>
<li>准备三台服务器</li>
<li>JDK,Hadoop安装包</li>
<li>干净的集群</li>
<li>环境变量</li>
</ul>
<h3 id="4-3-2-规划集群"><a href="#4-3-2-规划集群" class="headerlink" title="4.3.2 规划集群"></a>4.3.2 规划集群</h3><table>
<thead>
<tr>
<th>hadoop001</th>
<th>hadoop002</th>
<th>hadoop003</th>
</tr>
</thead>
<tbody><tr>
<td>NameNode</td>
<td>NameNode</td>
<td>NameNode</td>
</tr>
<tr>
<td>ZKFC</td>
<td>ZKFC</td>
<td>ZKFC</td>
</tr>
<tr>
<td>JournalNode</td>
<td>JournalNode</td>
<td>JournalNode</td>
</tr>
<tr>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>ZK</td>
<td>ZK</td>
<td>ZK</td>
</tr>
<tr>
<td>-</td>
<td>ResourceManager</td>
<td>-</td>
</tr>
<tr>
<td>NodeManager</td>
<td>NodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<h3 id="4-3-3-配置HA集群"><a href="#4-3-3-配置HA集群" class="headerlink" title="4.3.3 配置HA集群"></a>4.3.3 配置HA集群</h3><ol>
<li>修改配置文件 core-site.xml  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 把多个NameNode的地址组装成一个集群mycluster --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	  <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">&lt;!-- 指定hadoop数据的存储目录 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/ha/hadoop-3.1.3/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">&lt;!-- 配置HDFS网页登录使用的静态用户为atguigu --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>atguigu<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">&lt;!-- 配置该atguigu(superUser)允许通过代理访问的主机节点 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.atguigu.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 配置该atguigu(superUser)允许通过代理用户所属组 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.atguigu.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 配置该atguigu(superUser)允许通过代理的用户--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.atguigu.users<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>修改配置文件 hdfs-site.xml    <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- NameNode数据存储目录 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- DataNode数据存储目录 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- JournalNode数据存储目录 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;hadoop.tmp.dir&#125;/jn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 完全分布式HDFS集群名称 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 集群中NameNode节点都有哪些 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2,nn3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- NameNode的RPC通信地址 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop001:9820<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop002:9820<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop003:9820<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- NameNode的Web通信地址 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop001:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop002:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop003:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定NameNode元数据在JournalNode上的存放位置 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://hadoop001:8485;hadoop002:8485;hadoop003:8485/mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 访问代理类：client用于确定哪个NameNode为Active --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 使用隔离机制时需要ssh秘钥登录--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/atguigu/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	</span><br><span class="line">  <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>修改每一台机器的HADOOP_HOME 的环境变量打开 /etc/profile.d/set_evn.sh 修改如下： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HADOOP_HOME=/opt/module/ha/hadoop-3.1.3</span><br></pre></td></tr></table></figure></li>
<li>将/opt/ha/hadoop-3.1.3 分发到103 和 104 并且修改103和104的 HADOOP_HOME=/opt/module/ha/hadoop-3.1.3<ul>
<li>注意：修改完环境变量后一定要重新加载 profile 文件</li>
</ul>
</li>
<li>在102、103、104 各个JournalNode节点上，输入以下命令启动journalnode服务 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs --daemon start journalnode</span><br></pre></td></tr></table></figure></li>
<li>在 hadoop001的 nn1 上，对其进行格式化，并启动 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br><span class="line">hdfs --daemon start namenode</span><br></pre></td></tr></table></figure></li>
<li>分别在 hadoop002的nn2 和 hadoop003的nn3上，同步nn1的元数据信息 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -bootstrapStandby</span><br></pre></td></tr></table></figure></li>
<li>分别在 hadoop002上启动nn2 和 hadoop003上启动nn3 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs --daemon start namenode</span><br></pre></td></tr></table></figure></li>
<li>通过web地址访问nn1 nn2 nn3    <ul>
<li>nn1:<a target="_blank" rel="noopener" href="http://hadoop001:9870/">http://hadoop001:9870</a></li>
<li>nn2:<a target="_blank" rel="noopener" href="http://hadoop002:9870/">http://hadoop002:9870</a></li>
<li>nn3:<a target="_blank" rel="noopener" href="http://hadoop003:9870/">http://hadoop003:9870</a></li>
</ul>
</li>
<li>在每台机器上启动DN <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    hdfs --daemon start datanode</span><br><span class="line">    ```   </span><br><span class="line">9. 将其中的一个nn切换成Active状态</span><br><span class="line">    ```bash</span><br><span class="line">    hdfs haadmin -transitionToActive nn1</span><br></pre></td></tr></table></figure></li>
<li>查看是否Active<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs haadmin -getServiceState nn1</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="4-3-4-实现HA的故障自动转移"><a href="#4-3-4-实现HA的故障自动转移" class="headerlink" title="4.3.4 实现HA的故障自动转移"></a>4.3.4 实现HA的故障自动转移</h3><ol>
<li>在core-site.xml文件中增加 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定zkfc要连接的zkServer地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop001:2181,hadoop002:2181,hadoop003:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>在hdfs-site.xml中增加 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 启用nn故障自动转移 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>修改后分发配置文件<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">   xsync /opt/module/ha/hadoop-3.1.3/etc/hadoop </span><br><span class="line">   ```   </span><br><span class="line">4. 关闭HDFS集群</span><br><span class="line">   ```bash</span><br><span class="line">   stop-dfs.sh</span><br></pre></td></tr></table></figure></li>
<li>启动Zookeeper集群<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zk.sh start</span><br></pre></td></tr></table></figure></li>
<li>初始化HA在Zookeeper中状态<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure></li>
<li>启动HDFS服务<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure></li>
<li>可以去zkCli.sh客户端查看Namenode选举锁节点内容 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">get /hadoop-ha/mycluster/ActiveStandbyElectorLock</span><br></pre></td></tr></table></figure></li>
<li>测试故障自动转移<ul>
<li>将当前状态为Active的namenode 杀死</li>
<li>刷新另外两台namenode的web端，关注状态</li>
<li>最后可以到zk中验证锁内容的名称</li>
</ul>
</li>
</ol>
<h2 id="4-4-YARN-HA配置"><a href="#4-4-YARN-HA配置" class="headerlink" title="4.4 YARN-HA配置"></a>4.4 YARN-HA配置</h2><p>YARN HA 集群搭建步骤</p>
<ol>
<li>修改yarn-site.xml <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 启用resourcemanager ha --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 声明三台resourcemanager的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster-yarn1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--指定resourcemanager的逻辑列表--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2,rm3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- ========== rm1的配置 ========== --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定rm1的主机名 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop001<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定rm1的web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop001:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定rm1的 RPC 通信地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop001:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定AM向rm1申请资源的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop001:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定供NM连接的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop001:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- ========== rm2的配置 ========== --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定rm2的主机名 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop002<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop002:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop002:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop002:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop002:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- ========== rm3的配置 ========== --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定rm3的主机名 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop003<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop003:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop003:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop003:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop003:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定zookeeper集群的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop001:2181,hadoop002:2181,hadoop003:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 启用自动恢复,启用自动故障转移 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定resourcemanager的状态信息存储在zookeeper集群 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>将yarn-site.xml文件进行分发<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /opt/module/ha/hadoop-3.1.3/etc/hadoop/yarn-site.xml</span><br></pre></td></tr></table></figure></li>
<li>在任意的机器上启动yarn <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure></li>
<li>通过访问web地址验证<br> <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16346426629749.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"> </li>
<li>测试Yarn故障自动转移<ul>
<li>kill 当前active节点，会有另一个standby节点自动升级成active</li>
</ul>
</li>
</ol>
<h2 id="4-5-HDFS-Federation架构设计"><a href="#4-5-HDFS-Federation架构设计" class="headerlink" title="4.5 HDFS Federation架构设计"></a>4.5 HDFS Federation架构设计</h2><h3 id="4-5-1-NameNode架构的局限性"><a href="#4-5-1-NameNode架构的局限性" class="headerlink" title="4.5.1 NameNode架构的局限性"></a>4.5.1 NameNode架构的局限性</h3><ol>
<li>Namespace（命名空间）的限制<ul>
<li>由于NameNode在内存中存储所有的元数据（metadata），因此单个NameNode所能存储的对象（文件+块）数目受到NameNode所在JVM的heap size的限制。50G的heap能够存储20亿（200million）个对象，这20亿个对象支持4000个DataNode，12PB的存储（假设文件平均大小为40MB）。随着数据的飞速增长，存储的需求也随之增长。单个DataNode从4T增长到36T，集群的尺寸增长到8000个DataNode。存储的需求从12PB增长到大于100PB。</li>
</ul>
</li>
<li>隔离问题<ul>
<li>由于HDFS仅有一个NameNode，无法隔离各个程序，因此HDFS上的一个实验程序就很有可能影响整个HDFS上运行的程序。</li>
</ul>
</li>
<li>性能的瓶颈<ul>
<li>由于是单个NameNode的HDFS架构，因此整个HDFS文件系统的吞吐量受限于单个NameNode的吞吐量。</li>
</ul>
</li>
</ol>
<h3 id="4-5-2-HDFS-Federation架构设计"><a href="#4-5-2-HDFS-Federation架构设计" class="headerlink" title="4.5.2 HDFS Federation架构设计"></a>4.5.2 HDFS Federation架构设计</h3><p>多个NameNode集群管理不同业务线的元数据<br>| NameNode | NameNode | NameNode          |<br>| ——– | ——– | —————– |<br>| 元数据   | 元数据   | 元数据            |<br>| Log      | machine  | 电商数据/话单数据 |</p>
<p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16346432680052.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h3 id="4-5-3-HDFS-Federation应用思考"><a href="#4-5-3-HDFS-Federation应用思考" class="headerlink" title="4.5.3 HDFS Federation应用思考"></a>4.5.3 HDFS Federation应用思考</h3><p>不同应用可以使用不同NameNode进行数据管理图片业务、爬虫业务、日志审计业务。Hadoop生态系统中，不同的框架使用不同的NameNode进行管理NameSpace。（隔离性）<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16346433814694.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h3 id="4-5-4-联邦机制原理："><a href="#4-5-4-联邦机制原理：" class="headerlink" title="4.5.4 联邦机制原理："></a>4.5.4 联邦机制原理：</h3><ol>
<li>将NameNode划分成不同的命名空间并进行编号。不同的命名空间之间相互隔离互不干扰。</li>
<li>在DataNode中创建目录，此目录对应命名空间的编号。</li>
<li>由此，编号相同的数据由对应的命名空间进行管理</li>
<li>适用场景分析 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">128G(内存空间大小) * 1024(M) * 1024(KB) * 1024(bety) / 150 = xxx（元数据的数量）</span><br><span class="line">xxx * 256M（每一个文件大小） = yyy</span><br><span class="line">yyy / 1024(G) / 1024(TB) / 1024(PB) = 200 左右PB的数据</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="问答"><a href="#问答" class="headerlink" title="问答"></a>问答</h1><h3 id="一、Hadoop中的压缩作为一种常用的优化手段，经常被用在什么场景下？"><a href="#一、Hadoop中的压缩作为一种常用的优化手段，经常被用在什么场景下？" class="headerlink" title="一、Hadoop中的压缩作为一种常用的优化手段，经常被用在什么场景下？"></a>一、Hadoop中的压缩作为一种常用的优化手段，经常被用在什么场景下？</h3><ol>
<li>降低磁盘占用</li>
<li>减少网络IO</li>
</ol>
<h3 id="二、如果想要使用压缩，Hadoop如何对某一种压缩编码格式进行取舍？"><a href="#二、如果想要使用压缩，Hadoop如何对某一种压缩编码格式进行取舍？" class="headerlink" title="二、如果想要使用压缩，Hadoop如何对某一种压缩编码格式进行取舍？"></a>二、如果想要使用压缩，Hadoop如何对某一种压缩编码格式进行取舍？</h3><ol>
<li>压缩/解压的速度，资源占用</li>
<li>压缩率</li>
<li>压缩后是否支持切片</li>
</ol>
<h3 id="三、你们公司常用的压缩方式有哪些？"><a href="#三、你们公司常用的压缩方式有哪些？" class="headerlink" title="三、你们公司常用的压缩方式有哪些？"></a>三、你们公司常用的压缩方式有哪些？</h3><ol>
<li>单文件压缩后再130M以内使用gzip，如每天的日志文件，可以支持并行处理</li>
<li>单文件压缩后大于400M考虑支持切片的lzo 或者bzip</li>
</ol>
<h3 id="四、从哪些方面定位MR执行的效率（如何分析MR执行慢的原因）"><a href="#四、从哪些方面定位MR执行的效率（如何分析MR执行慢的原因）" class="headerlink" title="四、从哪些方面定位MR执行的效率（如何分析MR执行慢的原因）"></a>四、从哪些方面定位MR执行的效率（如何分析MR执行慢的原因）</h3><ol>
<li>计算机性能<ul>
<li>cpu，内存，磁盘，网络</li>
</ul>
</li>
<li>I/O操作优化<ol>
<li>数据倾斜</li>
<li>Map和Reduce数量设置不合理</li>
<li>Map运行时间过长，导致Reduce等待过久</li>
<li>小文件过多</li>
<li>大量不可切片的超大压缩文件</li>
<li>Spill次数过多</li>
<li>Merge次数过多</li>
</ol>
</li>
</ol>
<h3 id="五、如果想对MR程序进行优化，应该从哪些方面入手以及可能用到的优化手段？"><a href="#五、如果想对MR程序进行优化，应该从哪些方面入手以及可能用到的优化手段？" class="headerlink" title="五、如果想对MR程序进行优化，应该从哪些方面入手以及可能用到的优化手段？"></a>五、如果想对MR程序进行优化，应该从哪些方面入手以及可能用到的优化手段？</h3><ol>
<li>数据输入<ol>
<li>合并小文件</li>
<li>使用CombineTextInputFormat作为输入解决小文件场景</li>
</ol>
</li>
<li>Map阶段<ol>
<li>减少Spill溢写次数，调整环形缓冲区大小和触发溢写的内存上限，减少磁盘IO</li>
<li>减少Merge合并次数：调整一次merge合并的Spill溢写文件数量，减少Merge次数</li>
<li>Map之后合理使用Combine，减少网络IO</li>
</ol>
</li>
<li>Reduce阶段<ol>
<li>合理设置Map和Reduce数量</li>
<li>设置Map和Reduce并行处理，减少Reduce等待时间</li>
<li>规避使用Reduce，减少连接数据集产生的网络IO</li>
<li>合理设置Reduce端的Buffer</li>
</ol>
</li>
<li>IO传输<ol>
<li>选择合适的压缩算法，减少网络I\O传输的数据量</li>
<li>使用sequenceFile二进制文件</li>
</ol>
</li>
<li>数据倾斜<ol>
<li>对原始数据进行抽样得到结果集来预设分区边界值</li>
<li>根据业务分析自定义分区</li>
<li>使用combiner减少数据倾斜</li>
<li>尽量使用MapJoin，避免ReduceJoin</li>
</ol>
</li>
<li>参数调优<ol>
<li>MR源相关配置：MapTask和ReduceTask使用的内存，cpu</li>
<li>Yarn资源配置：Container使用的内存，cpu</li>
<li>Shuffer配置：环形缓冲区的大小，触发溢写的内存比例</li>
<li>容错配置：任务重试次数，超时时间</li>
</ol>
</li>
</ol>
<h3 id="六、在Hadoop针对小文件的处理方案有哪些？"><a href="#六、在Hadoop针对小文件的处理方案有哪些？" class="headerlink" title="六、在Hadoop针对小文件的处理方案有哪些？"></a>六、在Hadoop针对小文件的处理方案有哪些？</h3><ol>
<li>数据采集的时候，将小文件或小批数据合并成大文件在上传HDFS，从源头上避免小文件产生</li>
<li>业务处理之前，使用MapReduce程序对HDFS上的小文件进行合并</li>
<li>使用CombineTextInputFormat处理小文件的输入</li>
<li>开启uber模式，实现jvm重用</li>
</ol>
<h3 id="七、如何解决MR中Reduce的数据倾斜问题？"><a href="#七、如何解决MR中Reduce的数据倾斜问题？" class="headerlink" title="七、如何解决MR中Reduce的数据倾斜问题？"></a>七、如何解决MR中Reduce的数据倾斜问题？</h3><ol>
<li>对原始数据进行抽样得到结果集来预设分区边界值</li>
<li>根据业务分析自定义分区</li>
<li>使用combiner减少数据倾斜</li>
<li>尽量使用MapJoin，避免ReduceJoin</li>
</ol>
<h3 id="八、大概简述一下-Hadoop每一代版本的新特性？"><a href="#八、大概简述一下-Hadoop每一代版本的新特性？" class="headerlink" title="八、大概简述一下 Hadoop每一代版本的新特性？"></a>八、大概简述一下 Hadoop每一代版本的新特性？</h3><ol>
<li>Hadoop 2.x<ul>
<li>distcp命令实现两个Hadoop集群之间的递归数据复制</li>
<li>小文件存档</li>
<li>回收站</li>
</ul>
</li>
<li>Hadoop 3.x<ul>
<li>多NN的HA架构：提高集群的可用性</li>
<li>纠删码：降低磁盘占用</li>
</ul>
</li>
</ol>
<h3 id="九、什么是Hadoop的HA"><a href="#九、什么是Hadoop的HA" class="headerlink" title="九、什么是Hadoop的HA?"></a>九、什么是Hadoop的HA?</h3><ol>
<li>集群可实现7*24小时不中断服务</li>
<li>不存在单点故障</li>
<li>可以实现故障自动转移</li>
</ol>
<h3 id="十、描述一下HDFS-HA的工作机制？"><a href="#十、描述一下HDFS-HA的工作机制？" class="headerlink" title="十、描述一下HDFS-HA的工作机制？"></a>十、描述一下HDFS-HA的工作机制？</h3><ol>
<li>多NN消除单点故障</li>
<li>由Active状态的NN负责写操作，JournalNode负责同步Edits，Standby状态的NN读取自己的Edit，加载到内存形成完整元数据</li>
<li>Standby状态的NN负责合并Edit和FsImage</li>
<li>依赖Zookeeper实现故障自动转移</li>
</ol>
<h3 id="十一、如何实现HA的集群搭建-用话术描述即可！！！"><a href="#十一、如何实现HA的集群搭建-用话术描述即可！！！" class="headerlink" title="十一、如何实现HA的集群搭建?(用话术描述即可！！！)"></a>十一、如何实现HA的集群搭建?(用话术描述即可！！！)</h3><ol>
<li>配置集群名称</li>
<li>配置集群节点</li>
<li>配置JournalNode</li>
<li>配置zookeeper连接地址</li>
</ol>
<h3 id="十二、HDFS如何实现自动故障转移？"><a href="#十二、HDFS如何实现自动故障转移？" class="headerlink" title="十二、HDFS如何实现自动故障转移？"></a>十二、HDFS如何实现自动故障转移？</h3><ol>
<li>HDFS故障自动转移依赖zookeeper和zkfc进程</li>
<li>zookeeper实现功能<ol>
<li>故障检测：集群中的每个NameNode在ZooKeeper中维护了一个会话，如果机器崩溃，ZooKeeper中的会话将终止，ZooKeeper通知另一个NameNode触发故障转移</li>
<li>现役NameNode选择：ZooKeeper提供了一个简单的机制用于唯一的选择一个节点为active状态。如果目前现役NameNode崩溃，另一个节点可能从ZooKeeper获得特殊的排外锁以表明它应该成为现役NameNode</li>
</ol>
</li>
<li>zkfc进程是ZooKeeper的客户端，也监视和管理NameNode的状态。每个运行NameNode的主机也运行了一个ZKFC进程，ZKFC负责：<ol>
<li>健康监测<ul>
<li>ZKFC使用一个健康检查命令定期地ping与之在相同主机的NameNode，只要该NameNode及时地回复健康状态，ZKFC认为该节点是健康的。如果该节点崩溃，冻结或进入不健康状态，健康监测器标识该节点为非健康的。</li>
</ul>
</li>
<li>ZooKeeper会话管理<ul>
<li>当本地NameNode是健康的，ZKFC保持一个在ZooKeeper中打开的会话。如果本地NameNode处于active状态，ZKFC也保持一个特殊的znode锁，该锁使用了ZooKeeper对短暂节点的支持，如果会话终止，锁节点将自动删除。</li>
</ul>
</li>
<li>基于ZooKeeper的选择<ul>
<li>如果本地NameNode是健康的，且ZKFC发现没有其它的节点当前持有znode锁，它将为自己获取该锁。如果成功，则它已经赢得了选择，并负责运行故障转移进程以使它的本地NameNode为Active。</li>
</ul>
</li>
</ol>
</li>
</ol>
<h3 id="十三、什么是脑裂问题？HDFS-HA中如何解决的脑裂问题？"><a href="#十三、什么是脑裂问题？HDFS-HA中如何解决的脑裂问题？" class="headerlink" title="十三、什么是脑裂问题？HDFS-HA中如何解决的脑裂问题？"></a>十三、什么是脑裂问题？HDFS-HA中如何解决的脑裂问题？</h3><ol>
<li>active节点的zkfc进程检测到namenode异常，会通知另一台NameNode的zkfc</li>
<li>接收通知的zkf会通过ssh在异常namenode上执行kill命令，确保异常NameNode死透</li>
<li>避免了出现两个active节点，解决了脑裂问题</li>
</ol>
<h3 id="十四、YARN-HA-实现高可用的思路"><a href="#十四、YARN-HA-实现高可用的思路" class="headerlink" title="十四、YARN-HA 实现高可用的思路"></a>十四、YARN-HA 实现高可用的思路</h3><ol>
<li>ResourceManager启动时候会向ZK的/rmstore目录写lock文件，写成功就为active，否则standby.</li>
<li>ResourceManager节点zkfc会一直监控这个lock文件是否存在，假如不存在，就为active，否则为standby.</li>
<li>zookeeper存储RMStateStore。选举active RM。</li>
<li>RMStateStore: 存储在zk的/rmstore目录下。</li>
<li>activeRM会向这个目录写APP信息</li>
<li>当activeRM挂了，另外一个standby RM通过ZKFC选举成功为active，会从/rmstore读取相应的作业信息。重新构建作业的内存信息，启动内部的服务，开始接收NM的心跳，构建集群的资源信息，并且接收客户端的作业提交请求。</li>
</ol>
<h3 id="十五、简单说一下-联邦架构-HDFS-Federation-架构设计思想。-了解"><a href="#十五、简单说一下-联邦架构-HDFS-Federation-架构设计思想。-了解" class="headerlink" title="十五、简单说一下 联邦架构(HDFS Federation) 架构设计思想。(了解)"></a>十五、简单说一下 联邦架构(HDFS Federation) 架构设计思想。(了解)</h3><ol>
<li>解决Namespace（命名空间）的限制</li>
<li>解决隔离问题</li>
<li>解决性能的瓶颈</li>
<li>将NameNode划分成不同的命名空间并进行编号。不同的命名空间之间相互隔离互不干扰。</li>
<li>在DataNode中创建目录，此目录对应命名空间的编号。</li>
<li>由此，编号相同的数据由对应的命名空间进行管理</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Zookeeper"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/Zookeeper/"
    >Zookeeper</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/Zookeeper/" class="article-date">
  <time datetime="2021-11-07T00:08:46.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Zookeeper/">Zookeeper</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h1><h1 id="一、Zookeeper入门"><a href="#一、Zookeeper入门" class="headerlink" title="一、Zookeeper入门"></a>一、Zookeeper入门</h1><h2 id="1-1-概述"><a href="#1-1-概述" class="headerlink" title="1.1 概述"></a>1.1 概述</h2><ul>
<li>Zookeeper是一个开源的分布式的，为分布式应用提供协调服务的Apache项目。</li>
<li>Zookeeper从设计模式角度来理解，是一个基于<font color ='red' >观察者模式</font>设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生了变化，Zookeeper就负责通知已经在Zookeeper上注册的那些观察者做出相应的反应.</li>
<li>Zookeeper = 文件系统 + 通知机制</li>
</ul>
<hr>
<h2 id="1-2-特点"><a href="#1-2-特点" class="headerlink" title="1.2 特点"></a>1.2 特点</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16345175804501.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ul>
<li>Zookeeper：一个领导者（Leader），多个跟随者（Follower）组成的集群。</li>
<li>集群中只要有半数以上节点存活，Zookeeper集群就能正常服务</li>
<li>全局数据一致：每个Server保存一份相同的数据副本，Client无论连接到哪个Server，数据都是一致的</li>
<li>更新请求顺序进行，来自同一个Client的更新请求按其发送顺序依次执行</li>
<li>数据更新原子性，一次数据更新要么全部成功（超集群半数节点），要么所有节点全部失败</li>
<li>实时性，在一定时间范围内，Client能读到最新数据</li>
</ul>
<hr>
<h2 id="1-3-数据结构"><a href="#1-3-数据结构" class="headerlink" title="1.3 数据结构"></a>1.3 数据结构</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16345177645379.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ul>
<li>ZooKeeper数据模型的结构与Unix文件系统很类似，整体上可以看作是一棵树，每个节点称做一个ZNode。每一个ZNode默认能够存储1MB的数据，每个ZNode都可以通过其路径唯一标识。</li>
</ul>
<hr>
<h2 id="1-4-应用场景"><a href="#1-4-应用场景" class="headerlink" title="1.4 应用场景"></a>1.4 应用场景</h2><ul>
<li><p>提供的服务包括：统一命名服务、统一配置管理、统一集群管理、服务器节点动态上下线、软负载均衡等。</p>
</li>
<li><p>统一命名服务：在分布式环境下，经常需要对应用/服务进行统一命名，便于识别。<br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16345532077391.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
</li>
<li><p>统一配置管理<br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16345533954441.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>分布式环境下，配置文件同步非常常见，配置管理可交由ZooKeeper实现</li>
<li>一般要求一个集群中，所有节点的配置信息是一致的，比如 Kafka 集群</li>
<li>对配置文件修改后，希望能够快速同步到各个节点上</li>
<li>将配置信息写入ZooKeeper上的一个Znode</li>
<li>各个客户端服务器监听这个Znode</li>
<li>Znode中的数据被修改，ZooKeeper将通知各个客户端服务器</li>
</ol>
</li>
<li><p>统一集群管理<br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16345535437380.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>分布式环境中，实时掌握每个节点的状态是必要的。 <ol>
<li>可根据节点实时状态做出一些调整。 </li>
</ol>
</li>
<li>ZooKeeper可以实现实时监控节点状态变化<ol>
<li>可将节点信息写入ZooKeeper上的一个ZNode</li>
<li>监听这个ZNode可获取它的实时状态变化。</li>
</ol>
</li>
</ol>
</li>
<li><p>服务器动态上下线<br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16345535923783.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
</li>
<li><p>软负载均衡：在Zookeeper中记录每台服务器的访问数，让访问数最少的服务器去处理最新的客户端请求<br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16345536248922.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
</li>
</ul>
<hr>
<h1 id="二、Zookeeper-安装"><a href="#二、Zookeeper-安装" class="headerlink" title="二、Zookeeper 安装"></a>二、Zookeeper 安装</h1><h2 id="2-1-安装ZK"><a href="#2-1-安装ZK" class="headerlink" title="2.1 安装ZK:"></a>2.1 安装ZK:</h2><ol>
<li>把软件包上传的Linux的 /opt/software 下</li>
<li>加压ZK到 /opt/module 下</li>
<li>将加压后的目录名称修改一下（选做）</li>
<li>将zk的安装目录下 conf/zoo_sample.cfg 文件改名为 zoo.cfg</li>
<li>在ZK的安装目录下创建一个新的目录，作为zk的数据持久化目录</li>
<li>修改zoo.cfg配置文件<code>dataDir=/opt/module/zookeeper-3.5.7/zkData</code></li>
<li>配置ZK的环境变量 （选做）</li>
</ol>
<h2 id="2-2-单点模式的简单操作"><a href="#2-2-单点模式的简单操作" class="headerlink" title="2.2 单点模式的简单操作"></a>2.2 单点模式的简单操作</h2><ol>
<li>启停zk服务端 和 zk客户端<ul>
<li>启停 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">    [atguigu@hadoop001 zookeeper-3.5.7]$ bin/zkServer.sh start</span><br><span class="line">    ZooKeeper JMX enabled by default</span><br><span class="line">    Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">    Starting zookeeper ... STARTED</span><br><span class="line">    [atguigu@hadoop001 zookeeper-3.5.7]$ jps</span><br><span class="line">    1456 NameNode</span><br><span class="line">    8225 QuorumPeerMain</span><br><span class="line">    1619 DataNode</span><br><span class="line">    2076 JobHistoryServer</span><br><span class="line">    1901 NodeManager</span><br><span class="line">    8269 Jps</span><br><span class="line">    [atguigu@hadoop001 zookeeper-3.5.7]$ bin/zkServer.sh stop</span><br><span class="line">    ZooKeeper JMX enabled by default</span><br><span class="line">    Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">    Stopping zookeeper ... STOPPED</span><br><span class="line">    [atguigu@hadoop001 zookeeper-3.5.7]$ jps</span><br><span class="line">    1456 NameNode</span><br><span class="line">    1619 DataNode</span><br><span class="line">    2076 JobHistoryServer</span><br><span class="line">    1901 NodeManager</span><br><span class="line">    8302 Jps</span><br><span class="line">    [atguigu@hadoop001 zookeeper-3.5.7]$</span><br><span class="line">    ```   </span><br><span class="line">- 客户端连接</span><br><span class="line">    ```bash</span><br><span class="line">    [atguigu@hadoop001 zookeeper-3.5.7]$ bin/zkCli.sh -server hadoop001:2181</span><br><span class="line">    Connecting to hadoop001:2181</span><br><span class="line">    ········</span><br><span class="line"></span><br><span class="line">    2021-10-18 16:36:10,536 [myid:hadoop001:2181] - INFO  [main-SendThread(hadoop001:2181):ClientCnxn<span class="variable">$SendThread</span>@1394] - Session establishment complete on server hadoop001/192.168.2.6:2181, sessionid = 0x10000a6d44b0000, negotiated timeout = 30000</span><br><span class="line">    </span><br><span class="line">    WATCHER::</span><br><span class="line">    </span><br><span class="line">    WatchedEvent state:SyncConnected <span class="built_in">type</span>:None path:null</span><br><span class="line">    [zk: hadoop001:2181(CONNECTED) 0]</span><br></pre></td></tr></table></figure>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ jps</span><br><span class="line">1456 NameNode</span><br><span class="line">1619 DataNode</span><br><span class="line">8483 ZooKeeperMain</span><br><span class="line">8532 Jps</span><br><span class="line">8378 QuorumPeerMain</span><br><span class="line">2076 JobHistoryServer</span><br><span class="line">1901 NodeManager</span><br><span class="line">[atguigu@hadoop001 ~]$</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>查看一下zk的服务端和客户端对应的进程 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ jps</span><br><span class="line">1456 NameNode</span><br><span class="line">1619 DataNode</span><br><span class="line">8483 ZooKeeperMain      <span class="comment">#客户端</span></span><br><span class="line">8532 Jps</span><br><span class="line">8378 QuorumPeerMain     <span class="comment">#服务端</span></span><br><span class="line">2076 JobHistoryServer</span><br><span class="line">1901 NodeManager</span><br><span class="line">[atguigu@hadoop001 ~]$</span><br></pre></td></tr></table></figure></li>
<li>退出客户端 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop001:2181(CONNECTED) 0] quit</span><br><span class="line"></span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:Closed <span class="built_in">type</span>:None path:null</span><br><span class="line">2021-10-18 16:41:05,769 [myid:] - INFO  [main:ZooKeeper@1422] - Session: 0x10000a6d44b0001 closed</span><br><span class="line">2021-10-18 16:41:05,769 [myid:] - INFO  [main-EventThread:ClientCnxn<span class="variable">$EventThread</span>@524] - EventThread shut down <span class="keyword">for</span> session: 0x10000a6d44b0001</span><br><span class="line">[atguigu@hadoop001 zookeeper-3.5.7]$ jps</span><br><span class="line">1456 NameNode</span><br><span class="line">1619 DataNode</span><br><span class="line">8552 Jps</span><br><span class="line">8378 QuorumPeerMain</span><br><span class="line">2076 JobHistoryServer</span><br><span class="line">1901 NodeManager</span><br><span class="line">[atguigu@hadoop001 zookeeper-3.5.7]$</span><br></pre></td></tr></table></figure></li>
<li>当客户端启动连接后不能单独关闭，当服务端关闭后，客户端也就消失了。</li>
</ol>
<h2 id="2-2-配置参数解读"><a href="#2-2-配置参数解读" class="headerlink" title="2.2 配置参数解读"></a>2.2 配置参数解读</h2><p>Zookeeper中的配置文件zoo.cfg中参数含义解读如下：</p>
<ol>
<li>tickTime =2000：通信心跳数，Zookeeper服务器与客户端心跳时间，单位毫秒<ul>
<li>Zookeeper使用的基本时间，服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个tickTime时间就会发送一个心跳，时间单位为毫秒。</li>
<li>它用于心跳检测机制，并且设置最小的session超时时间为两倍心跳时间。(session的最小超时时间是2*tickTime)</li>
</ul>
</li>
<li>initLimit =10：LF初始通信时限<ul>
<li>集群中的Follower跟随者服务器与Leader领导者服务器之间初始连接时能容忍的最多心跳数（tickTime的数量），用它来限定集群中的Zookeeper服务器连接到Leader的时限。</li>
</ul>
</li>
<li>syncLimit =5：LF同步通信时限<ul>
<li>集群中Leader与Follower之间的最大响应时间单位，假如响应超过syncLimit * tickTime，Leader认为Follwer死掉，从服务器列表中删除Follwer。</li>
</ul>
</li>
<li>dataDir：数据文件目录+数据持久化路径<ul>
<li>用于保存Zookeeper中的数据。</li>
</ul>
</li>
<li>clientPort=2181：客户端连接端口<ul>
<li>监听客户端连接的端口。</li>
</ul>
</li>
</ol>
<h1 id="三、Zookeeper-实战"><a href="#三、Zookeeper-实战" class="headerlink" title="三、Zookeeper 实战"></a>三、Zookeeper 实战</h1><h2 id="3-1-搭建ZK的集群"><a href="#3-1-搭建ZK的集群" class="headerlink" title="3.1 搭建ZK的集群"></a>3.1 搭建ZK的集群</h2><ol>
<li>集群规划：在hadoop102、hadoop103和hadoop104三个节点上部署Zookeeper </li>
<li>每个节点执行单节点部署的步骤</li>
<li>修改zoo.cfg 配置文件 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 数据存储路径</span><br><span class="line">dataDir=/opt/module/zookeeper-3.5.7/zkData</span><br><span class="line"></span><br><span class="line">#集群节点配置</span><br><span class="line">server.2=hadoop102:2888:3888</span><br><span class="line">server.3=hadoop103:2888:3888</span><br><span class="line">server.4=hadoop104:2888:3888</span><br></pre></td></tr></table></figure></li>
<li>zkData目录下创建myid的文件对应上述配置编号</li>
<li>配置参数解读<ul>
<li>server.A=B:C:D</li>
<li>A是一个数字，表示这个是第几号服务器，对应zkData/myid中的编号；Zookeeper启动时读取此文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server</li>
<li>B是Zookeeper节点的地址（域名/IP）</li>
<li>C是这个服务器Follower与集群中的Leader服务器交换信息的端口</li>
<li>D是集群中的Leader服务器挂掉之后，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口</li>
</ul>
</li>
<li>编写启动/停止Zookeeper集群脚本 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#检验参数</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -lt 1 ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&#x27;参数不能为空！！！&#x27;</span></span><br><span class="line">    <span class="built_in">exit</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#循环遍历每一台机器，分别启动或者停止ZK服务</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> hadoop001 hadoop002 hadoop003 hadoop004 hadoop005; <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line">    <span class="string">&quot;start&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;*****************<span class="variable">$1</span> <span class="variable">$host</span> zookeeper****************&quot;</span></span><br><span class="line">        ssh <span class="variable">$host</span> /opt/module/zookeeper-3.5.7/bin/zkServer.sh <span class="variable">$1</span></span><br><span class="line">        ;;</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;stop&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;*****************<span class="variable">$1</span> <span class="variable">$host</span> zookeeper****************&quot;</span></span><br><span class="line">        ssh <span class="variable">$host</span> /opt/module/zookeeper-3.5.7/bin/zkServer.sh <span class="variable">$1</span></span><br><span class="line">        ;;</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;status&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;*****************<span class="variable">$1</span> <span class="variable">$host</span> zookeeper****************&quot;</span></span><br><span class="line">        ssh <span class="variable">$host</span> /opt/module/zookeeper-3.5.7/bin/zkServer.sh <span class="variable">$1</span></span><br><span class="line">        ;;</span><br><span class="line"></span><br><span class="line">    *)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&#x27;参数有误！！！&#x27;</span></span><br><span class="line">        <span class="built_in">exit</span></span><br><span class="line">        ;;</span><br><span class="line">    <span class="keyword">esac</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></li>
<li>执行脚本 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 bin]$ zookeeper_cluster.sh start</span><br><span class="line">*****************start hadoop001 zookeeper****************</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br><span class="line">*****************start hadoop002 zookeeper****************</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br><span class="line">*****************start hadoop003 zookeeper****************</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br><span class="line">[atguigu@hadoop001 bin]$ zookeeper_cluster.sh status</span><br><span class="line">*****************status hadoop001 zookeeper****************</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost.</span><br><span class="line">Mode: follower</span><br><span class="line">*****************status hadoop002 zookeeper****************</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost.</span><br><span class="line">Mode: follower</span><br><span class="line">*****************status hadoop003 zookeeper****************</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost.</span><br><span class="line">Mode: leader</span><br><span class="line">[atguigu@hadoop001 bin]$ zookeeper_cluster.sh stop</span><br><span class="line">*****************stop hadoop001 zookeeper****************</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Stopping zookeeper ... STOPPED</span><br><span class="line">*****************stop hadoop002 zookeeper****************</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Stopping zookeeper ... STOPPED</span><br><span class="line">*****************stop hadoop003 zookeeper****************</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Stopping zookeeper ... STOPPED</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="3-2-客户端命令行操作"><a href="#3-2-客户端命令行操作" class="headerlink" title="3.2 客户端命令行操作"></a>3.2 客户端命令行操作</h2><h2 id="3-2-1-基本命令"><a href="#3-2-1-基本命令" class="headerlink" title="3.2.1 基本命令"></a>3.2.1 基本命令</h2><table>
<thead>
<tr>
<th>命令基本语法</th>
<th>功能描述</th>
</tr>
</thead>
<tbody><tr>
<td>help</td>
<td>显示所有操作命令</td>
</tr>
<tr>
<td>ls path</td>
<td>使用 ls 命令来查看当前znode的子节点 <br> -w  监听子节点变化 <br>-s   附加次级信息</td>
</tr>
<tr>
<td>create</td>
<td>普通创建 <br>-s  含有序列 <br>-e  临时（重启或者超时消失）</td>
</tr>
<tr>
<td>get path</td>
<td>获得节点的值<br>-w  监听节点内容变化<br>-s   附加次级信息</td>
</tr>
<tr>
<td>set</td>
<td>设置节点的具体值</td>
</tr>
<tr>
<td>stat</td>
<td>查看节点状态</td>
</tr>
<tr>
<td>delete</td>
<td>删除节点</td>
</tr>
<tr>
<td>deleteall</td>
<td>递归删除节点</td>
</tr>
</tbody></table>
<h2 id="3-2-2-具体操作"><a href="#3-2-2-具体操作" class="headerlink" title="3.2.2 具体操作"></a>3.2.2 具体操作</h2><ol>
<li><p>启动客户端</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 zookeeper-3.5.7]$ bin/zkCli.sh -server hadoop001:2181</span><br><span class="line">Connecting to hadoop001:2181</span><br><span class="line">·······</span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected <span class="built_in">type</span>:None path:null</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 0]</span><br></pre></td></tr></table></figure></li>
<li><p>显示所有操作命令</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop001:2181(CONNECTED) 0] <span class="built_in">help</span></span><br><span class="line">ZooKeeper -server host:port cmd args</span><br><span class="line">	addauth scheme auth</span><br><span class="line">	close</span><br><span class="line">	config [-c] [-w] [-s]</span><br><span class="line">	connect host:port</span><br><span class="line">	create [-s] [-e] [-c] [-t ttl] path [data] [acl]</span><br><span class="line">	delete [-v version] path</span><br><span class="line">	deleteall path</span><br><span class="line">	delquota [-n|-b] path</span><br><span class="line">	get [-s] [-w] path</span><br><span class="line">	getAcl [-s] path</span><br><span class="line">	<span class="built_in">history</span></span><br><span class="line">	listquota path</span><br><span class="line">	ls [-s] [-w] [-R] path</span><br><span class="line">	ls2 path [watch]</span><br><span class="line">	printwatches on|off</span><br><span class="line">	quit</span><br><span class="line">	reconfig [-s] [-v version] [[-file path] | [-members serverID=host:port1:port2;port3[,...]*]] | [-add serverId=host:port1:port2;port3[,...]]* [-remove serverId[,...]*]</span><br><span class="line">	redo cmdno</span><br><span class="line">	removewatches path [-c|-d|-a] [-l]</span><br><span class="line">	rmr path</span><br><span class="line">	<span class="built_in">set</span> [-s] [-v version] path data</span><br><span class="line">	setAcl [-s] [-v version] [-R] path acl</span><br><span class="line">	setquota -n|-b val path</span><br><span class="line">	<span class="built_in">stat</span> [-w] path</span><br><span class="line">	sync path</span><br></pre></td></tr></table></figure></li>
<li><p>查看当前znode中所包含的内容</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop001:2181(CONNECTED) 2] ls /</span><br><span class="line">[zookeeper]</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 3]</span><br></pre></td></tr></table></figure></li>
<li><p>查看当前节点详细数据</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop001:2181(CONNECTED) 3] ls -s /</span><br><span class="line">[zookeeper]cZxid = 0x0</span><br><span class="line">ctime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">mZxid = 0x0</span><br><span class="line">mtime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">pZxid = 0x100000011</span><br><span class="line">cversion = 1</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 0</span><br><span class="line">numChildren = 1</span><br><span class="line"></span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 4]</span><br></pre></td></tr></table></figure></li>
<li><p>分别创建2个普通节点</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop001:2181(CONNECTED) 4] create /sanguo <span class="string">&quot;diaochan&quot;</span></span><br><span class="line">Created /sanguo</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 6] create /sanguo/shuguo <span class="string">&quot;liubei&quot;</span></span><br><span class="line">Created /sanguo/shuguo</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 8] ls  /</span><br><span class="line">[sanguo, zookeeper]</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 9] ls  /sanguo</span><br><span class="line">[shuguo]</span><br></pre></td></tr></table></figure></li>
<li><p>获得节点的值</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop001:2181(CONNECTED) 10] get /sanguo</span><br><span class="line">diaochan</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 11] get -s /sanguo</span><br><span class="line">diaochan</span><br><span class="line">cZxid = 0x300000004</span><br><span class="line">ctime = Mon Oct 18 17:31:28 CST 2021</span><br><span class="line">mZxid = 0x300000004</span><br><span class="line">mtime = Mon Oct 18 17:31:28 CST 2021</span><br><span class="line">pZxid = 0x300000006</span><br><span class="line">cversion = 1</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 8</span><br><span class="line">numChildren = 1</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 12] get -s /sanguo/shuguo</span><br><span class="line">liubei</span><br><span class="line">cZxid = 0x300000006</span><br><span class="line">ctime = Mon Oct 18 17:32:12 CST 2021</span><br><span class="line">mZxid = 0x300000006</span><br><span class="line">mtime = Mon Oct 18 17:32:12 CST 2021</span><br><span class="line">pZxid = 0x300000006</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 6</span><br><span class="line">numChildren = 0</span><br></pre></td></tr></table></figure></li>
<li><p>创建临时节点</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建临时节点</span></span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 13] create -e /sanguo/wuguo <span class="string">&quot;zhouyu&quot;</span></span><br><span class="line">Created /sanguo/wuguo</span><br><span class="line"><span class="comment"># 查看节点存在</span></span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 15] ls /sanguo</span><br><span class="line">[shuguo, wuguo]</span><br><span class="line"><span class="comment"># 退出客户端</span></span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 16] quit</span><br><span class="line"></span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:Closed <span class="built_in">type</span>:None path:null</span><br><span class="line">2021-10-18 17:35:37,751 [myid:] - INFO  [main:ZooKeeper@1422] - Session: 0x10000c30dbf0001 closed</span><br><span class="line">2021-10-18 17:35:37,752 [myid:] - INFO  [main-EventThread:ClientCnxn<span class="variable">$EventThread</span>@524] - EventThread shut down <span class="keyword">for</span> session: 0x10000c30dbf0001</span><br><span class="line"><span class="comment"># 重新连接客户端</span></span><br><span class="line">[atguigu@hadoop001 zookeeper-3.5.7]$ bin/zkCli.sh -server hadoop001:2181</span><br><span class="line">Connecting to hadoop001:2181</span><br><span class="line">···</span><br><span class="line">···</span><br><span class="line">WatchedEvent state:SyncConnected <span class="built_in">type</span>:None path:null</span><br><span class="line"><span class="comment"># 再次查看节点 发现临时节点被删除</span></span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 0] ls /sanguo</span><br><span class="line">[shuguo]</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 1]</span><br></pre></td></tr></table></figure></li>
<li><p>创建带序号的节点</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop001:2181(CONNECTED) 6] ls /sanguo/weiguo</span><br><span class="line">[]</span><br><span class="line"><span class="comment"># 创建普通节点xiaobing</span></span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 7] create /sanguo/weiguo/xiaobing</span><br><span class="line">Created /sanguo/weiguo/xiaobing</span><br><span class="line"><span class="comment"># 再次创建普通节点xiaobing--Node already exists</span></span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 8] create /sanguo/weiguo/xiaobing</span><br><span class="line">Node already exists: /sanguo/weiguo/xiaobing</span><br><span class="line"><span class="comment"># 创建普通节点xiaobing1</span></span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 9] create /sanguo/weiguo/xiaobing1</span><br><span class="line">Created /sanguo/weiguo/xiaobing1</span><br><span class="line"><span class="comment"># 创建带序号的节点xiaobing</span></span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 10] create -s /sanguo/weiguo/xiaobing</span><br><span class="line">Created /sanguo/weiguo/xiaobing0000000002</span><br><span class="line"><span class="comment"># 创建带序号的节点xiaobing</span></span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 11] create -s /sanguo/weiguo/xiaobing</span><br><span class="line">Created /sanguo/weiguo/xiaobing0000000003</span><br><span class="line"><span class="comment"># 创建带序号的节点xiaobing</span></span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 12] create -s /sanguo/weiguo/xiaobing</span><br><span class="line">Created /sanguo/weiguo/xiaobing0000000004</span><br><span class="line"><span class="comment"># 查看节点，如果节点下原来没有子节点，序号从0开始依次递增。如果原节点下已有2个节点，则再排序时从2开始，以此类推</span></span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 13] ls /sanguo/weiguo</span><br><span class="line">[xiaobing, xiaobing0000000002, xiaobing0000000003, xiaobing0000000004, xiaobing1]</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 14]</span><br></pre></td></tr></table></figure></li>
<li><p>修改节点数据值</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop001:2181(CONNECTED) 0] get /sanguo/weiguo</span><br><span class="line">caocao</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 1] <span class="built_in">set</span> /sanguo/weiguo <span class="string">&#x27;caopi&#x27;</span></span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 2] get /sanguo/weiguo</span><br><span class="line">caopi</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 3]</span><br></pre></td></tr></table></figure></li>
<li><p>节点的值变化监听</p>
<ol>
<li>在hadoop002主机上注册监听/sanguo节点数据变化 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop002:2181(CONNECTED) 0] get -w /sanguo</span><br><span class="line">null</span><br><span class="line">[zk: hadoop002:2181(CONNECTED) 1]</span><br></pre></td></tr></table></figure></li>
<li>在hadoop001主机上修改/sanguo节点的数据 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop001:2181(CONNECTED) 5] <span class="built_in">set</span> /sanguo <span class="string">&quot;xishi&quot;</span></span><br></pre></td></tr></table></figure></li>
<li>观察hadoop002主机收到数据变化的监听 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected <span class="built_in">type</span>:NodeDataChanged path:/sanguo</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>节点的子节点变化监听路径变化.</p>
<ol>
<li>在hadoop002主机上注册监听/sanguo节点的子节点变化 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop002:2181(CONNECTED) 0] ls -w /sanguo</span><br><span class="line">[shuguo, weiguo, wuguo]</span><br></pre></td></tr></table></figure></li>
<li>在hadoop001主机/sanguo节点上创建子节点 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop001:2181(CONNECTED) 4] create /sanguo/jin</span><br><span class="line">Created /sanguo/jin</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 5]</span><br></pre></td></tr></table></figure></li>
<li>观察hadoop002主机收到子节点变化的监听 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop002:2181(CONNECTED) 1]</span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected <span class="built_in">type</span>:NodeChildrenChanged path:/sanguo</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>删除节点</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop001:2181(CONNECTED) 7] ls /sanguo</span><br><span class="line">[jin, shuguo, weiguo, wuguo]</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 8] delete /sanguo/jin</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 9] ls /sanguo</span><br><span class="line">[shuguo, weiguo, wuguo]</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 10]</span><br></pre></td></tr></table></figure></li>
<li><p>递归删除节点</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop001:2181(CONNECTED) 12] ls /sanguo/weiguo</span><br><span class="line">[xiaobing, xiaobing0000000002, xiaobing0000000003, xiaobing0000000004, xiaobing1]</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 13] deleteall /sanguo/weiguo</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 14] ls /sanguo/weiguo</span><br><span class="line">Node does not exist: /sanguo/weiguo</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 15]</span><br></pre></td></tr></table></figure></li>
<li><p>查看节点状态</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop001:2181(CONNECTED) 15] <span class="built_in">stat</span> /sanguo</span><br><span class="line">cZxid = 0x300000016</span><br><span class="line">ctime = Mon Oct 18 17:41:54 CST 2021</span><br><span class="line">mZxid = 0x300000028</span><br><span class="line">mtime = Mon Oct 18 17:58:53 CST 2021</span><br><span class="line">pZxid = 0x300000030</span><br><span class="line">cversion = 6</span><br><span class="line">dataVersion = 1</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 5</span><br><span class="line">numChildren = 2</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 16]</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="四、Zookeeper-原理"><a href="#四、Zookeeper-原理" class="headerlink" title="四、Zookeeper 原理"></a>四、Zookeeper 原理</h1><h2 id="4-1-节点类型"><a href="#4-1-节点类型" class="headerlink" title="4.1 节点类型"></a>4.1 节点类型</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16345542078737.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ul>
<li>持久（Persistent）：客户端和服务器端断开连接后，创建的节点不删除</li>
<li>短暂（Ephemeral）：客户端和服务器端断开连接后，创建的节点自己删除</li>
<li>在分布式系统中，顺序号可以被用于为所有的事件进行全局排序，这样客户端可以通过顺序号推断事件的顺序</li>
<li>创建znode时设置顺序标识，znode名称后会附加一个值，顺序号是一个单调递增的计数器，由父节点维护</li>
</ul>
<h2 id="4-2-Stat结构体"><a href="#4-2-Stat结构体" class="headerlink" title="4.2 Stat结构体"></a>4.2 Stat结构体</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[zk: hadoop001:2181(CONNECTED) 15] <span class="built_in">stat</span> /sanguo</span><br><span class="line"><span class="comment"># czxid-创建节点的事务zxid</span></span><br><span class="line"><span class="comment">#   每次修改ZooKeeper状态都会收到一个zxid形式的时间戳，也就是ZooKeeper事务ID。</span></span><br><span class="line"><span class="comment">#   事务ID是ZooKeeper中所有修改总的次序。每个修改都有唯一的zxid，如果zxid1小于zxid2，那么zxid1在zxid2之前发生。</span></span><br><span class="line">cZxid = 0x300000016</span><br><span class="line"><span class="comment"># ctime - znode被创建的毫秒数(从1970年开始)</span></span><br><span class="line">ctime = Mon Oct 18 17:41:54 CST 2021</span><br><span class="line"><span class="comment"># mzxid - znode最后更新的事务zxid</span></span><br><span class="line">mZxid = 0x300000028</span><br><span class="line"><span class="comment"># mtime - znode最后修改的毫秒数(从1970年开始)</span></span><br><span class="line">mtime = Mon Oct 18 17:58:53 CST 2021</span><br><span class="line"><span class="comment"># pZxid - znode最后更新的子节点zxid</span></span><br><span class="line">pZxid = 0x300000030</span><br><span class="line"><span class="comment"># cversion - znode子节点变化号，znode子节点修改次数</span></span><br><span class="line">cversion = 6</span><br><span class="line"><span class="comment"># dataversion - znode数据变化号</span></span><br><span class="line">dataVersion = 1</span><br><span class="line"><span class="comment"># aclVersion - znode访问控制列表的变化号</span></span><br><span class="line">aclVersion = 0</span><br><span class="line"><span class="comment"># ephemeralOwner- 如果是临时节点，这个是znode拥有者的session id。如果不是临时节点则是0。</span></span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line"><span class="comment"># dataLength - znode的数据长度</span></span><br><span class="line">dataLength = 5</span><br><span class="line"><span class="comment"># numChildren - znode子节点数量</span></span><br><span class="line">numChildren = 2</span><br><span class="line">[zk: hadoop001:2181(CONNECTED) 16]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="4-3-监听器原理"><a href="#4-3-监听器原理" class="headerlink" title="4.3 监听器原理"></a>4.3 监听器原理</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16345549940089.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h3 id="4-3-1-监听原理详解"><a href="#4-3-1-监听原理详解" class="headerlink" title="4.3.1 监听原理详解"></a>4.3.1 监听原理详解</h3><ol>
<li>首先要有一个main()线程</li>
<li>在main线程中创建Zookeeper客户端，这时就会创建两个线程，一个负责网络连接通信（connet），一个负责监听（listener）。 </li>
<li>通过connect线程将注册的监听事件发送给Zookeeper。 </li>
<li>在Zookeeper的注册监听器列表中将注册的监听事件添加到列表中。 </li>
<li>Zookeeper监听到有数据或路径变化，就会将这个消息发送给listener线程。 </li>
<li>listener线程内部调用了process()方法。 <h3 id="4-3-2-常见的监听"><a href="#4-3-2-常见的监听" class="headerlink" title="4.3.2 常见的监听"></a>4.3.2 常见的监听</h3></li>
<li>监听节点数据的变化<ul>
<li><code>get path [watch]</code></li>
</ul>
</li>
<li>监听子节点增减的变化<ul>
<li><code>ls path [watch]</code></li>
</ul>
</li>
</ol>
<h2 id="4-4-选举机制"><a href="#4-4-选举机制" class="headerlink" title="4.4 选举机制"></a>4.4 选举机制</h2><ol>
<li>半数机制：集群中半数以上机器存活，集群可用。所以<font color ='red' >Zookeeper适合安装奇数台服务器</font>。</li>
<li>Zookeeper虽然在配置文件中并没有指定Master和Slave。但是，Zookeeper工作时，是有一个节点为Leader，其他则为Follower，Leader是通过内部的选举机制临时产生的。</li>
<li>以一个简单的例子来说明整个选举的过程。<br> <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16345388234410.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"><ul>
<li>假设有五台服务器组成的Zookeeper集群，它们的id从1-5，同时它们都是最新启动的，也就是没有历史数据，在存放数据量这一点上，都是一样的。假设这些服务器依序启动，来看看会发生什么。</li>
<li>Zookeeper的选举机制<ol>
<li>服务器1启动，发起一次选举。服务器1投自己一票。此时服务器1票数一票，不够半数以上（3票），选举无法完成，服务器1状态保持为LOCKING；</li>
<li>服务器2启动，再发起一次选举。服务器1和2分别投自己一票并交换选票信息：此时服务器1发现服务器2的ID比自己目前投票推举的（服务器1）大，更改选票为推举服务器2。此时服务器1票数0票，服务器2票数2票，没有半数以上结果，选举无法完成，服务器1，2状态保持LOCKING</li>
<li>服务器3启动，发起一次选举。此时服务器1和2都会更改选票为服务器3。此次投票结果：服务器1为0票，服务器2为0票，服务器3为3票。此时服务器3的票数已经超过半数，服务器3当选Leader。服务器1，2更改状态为FOLLOWING，服务器3更改状态为LEADING；</li>
<li>服务器4启动，发起一次选举。此时服务器1，2，3已经不是LOOKING状态，不会更改选票信息。交换选票信息结果：服务器3为3票，服务器4为1票。此时服务器4服从多数，更改选票信息为服务器3，并更改状态为FOLLOWING；</li>
<li>服务器5启动，同4一样当小弟。</li>
</ol>
</li>
<li>举例1<ul>
<li>场景：以5台机器为例，集群的机器顺时启动，当前集群中没有任何数据。<ol>
<li>server1 启动，首先server1给自己投一票，然后看当前票数是否超过半数，结果没有超过，这时候leader就没选出来，当前选举状态是Locking状态。</li>
<li>server2 启动，首先server2先给自己投一票，因为当前集群已经有两台机器已启动，所以server1</li>
<li>server2会交换选票，交换后发现各自有一票，接下来比较 myid 发现server2的myid值 &gt; server1的myid值此时server2胜出，最后server2有两票。最后再看当前票数是否半，发现未过半，集群的选举状态集训保持locking状态。</li>
<li>server3启动， 首先自己投自己一票，server1和server2也会投自己一票，然后交换选票发现都一样，接着比较myid 最后server3胜出，此时server3就有3票，同时server3的票数超过半数。所以server3成为leader。</li>
<li>server4启动，发现当前集群已经有leader 它自己自动成为follower</li>
<li>server5启动，发现当前集群已经有leader 它自己自动成为follower</li>
</ol>
</li>
</ul>
</li>
<li>举例说明2<ul>
<li>场景：以5台机器为例，当前集群正在使用（有数据/没数据），leader突然宕机的情况。</li>
<li>当集群中的leader挂掉，集群会重新选出一个leader，此时首先会比较每一台机器的mzxid,mzxid最大的被选为leader。极端情况，mzxid都相等的情况，那么就会直接比较myid。</li>
</ul>
</li>
<li>举例说明3<ul>
<li>场景：集群中有数据，重启的时候Leader该如何选？</li>
<li>和场景一选举机制是一样！</li>
</ul>
</li>
</ul>
</li>
<li>一般情况下ZK集群更推荐使用奇数台机器原因？<ul>
<li>在ZK集群中 奇数台 和 偶数台（接近的台数） 机器的容错能力是一样的，所以在考虑资源节省的情况我们推荐使用奇数台方案</li>
</ul>
</li>
</ol>
<h2 id="4-5-写数据流程"><a href="#4-5-写数据流程" class="headerlink" title="4.5 写数据流程"></a>4.5 写数据流程</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16345398429599.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>客户端会向ZK集群中的一台机器server1发送写数据的请求。</li>
<li>server1接收到请求后，马上会通知leader 有写数据的请求来了</li>
<li>leader拿到请求后，进行广播，让集群每一台机器都准备要写数据</li>
<li>集群中的所有机机器接收到leader广播后都回应一下leader</li>
<li>leader接收机器数过半的机器回应后，再次进行广播 开始写数据，<br>其他机器接收到广播后也开始写数据</li>
<li>数据成功写入后，回应leader，最后由leader来做整个事务提交</li>
<li>当数据成功写入后，由最初和客户端发生连接的 server1 回应客户端数据写入成功。</li>
</ol>
<h1 id="五、Zookeeper-面试真题"><a href="#五、Zookeeper-面试真题" class="headerlink" title="五、Zookeeper 面试真题"></a>五、Zookeeper 面试真题</h1><h2 id="5-1-请简述ZooKeeper的选举机制"><a href="#5-1-请简述ZooKeeper的选举机制" class="headerlink" title="5.1 请简述ZooKeeper的选举机制"></a>5.1 请简述ZooKeeper的选举机制</h2><h2 id="5-2-ZooKeeper的监听原理是什么？"><a href="#5-2-ZooKeeper的监听原理是什么？" class="headerlink" title="5.2 ZooKeeper的监听原理是什么？"></a>5.2 ZooKeeper的监听原理是什么？</h2><h2 id="5-3-ZooKeeper的部署方式有哪几种？集群中的角色有哪些？集群最少需要几台机器？"><a href="#5-3-ZooKeeper的部署方式有哪几种？集群中的角色有哪些？集群最少需要几台机器？" class="headerlink" title="5.3 ZooKeeper的部署方式有哪几种？集群中的角色有哪些？集群最少需要几台机器？"></a>5.3 ZooKeeper的部署方式有哪几种？集群中的角色有哪些？集群最少需要几台机器？</h2><ol>
<li>部署方式单机模式、集群模式</li>
<li>角色：Leader和Follower</li>
<li>集群最少需要机器数：3</li>
</ol>
<h2 id="5-4-ZooKeeper的常用命令Keeper的常用命令"><a href="#5-4-ZooKeeper的常用命令Keeper的常用命令" class="headerlink" title="5.4 ZooKeeper的常用命令Keeper的常用命令"></a>5.4 ZooKeeper的常用命令Keeper的常用命令</h2> 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Zookeeper/" rel="tag">Zookeeper</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
  </article>
  

  
  <nav class="page-nav">
    
    <a class="extend prev" rel="prev" href="/">上一页</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/">下一页</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2019-2022
        <i class="ri-heart-fill heart_icon"></i> Anzhen
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src=''></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="anzhen.tech"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/HDFS">HDFS</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Yarn">Yarn</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/MR">MR</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Hive">Hive</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86">数据采集</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/HBase">HBase</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Kafka">Kafka</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Spark">Spark</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Flink">Flink</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/MySQL">MySQL</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Java">Java</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/interview">面试宝典</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2019/11/07/about-me">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.png">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.png">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->
 <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true,
  };
</script>

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    <div id="music">
    
    
    
    <iframe frameborder="no" border="1" marginwidth="0" marginheight="0" width="200" height="52"
        src="//music.163.com/outchain/player?type=2&id=318916815&auto=1&height=32"></iframe>
</div>

<style>
    #music {
        position: fixed;
        right: 15px;
        bottom: 0;
        z-index: 998;
    }
</style>
    
    

  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>